# ğŸ§­ Cuaderno de BitÃ¡cora del Proyecto Cognitiva-AI

Este cuaderno recopila **todo el recorrido del proyecto Cognitiva-AI**, desde los primeros experimentos con datos clÃ­nicos hasta los pipelines mÃ¡s recientes con arquitecturas alternativas y ensembles de backbones.  
Se ha mantenido un registro exhaustivo de cada fase, anotando decisiones tÃ©cnicas, dificultades encontradas, soluciones aplicadas y reflexiones tras cada bloque de resultados.  
El objetivo es que actÃºe como un **diario tÃ©cnico detallado**, Ãºtil tanto para revisiones futuras como para terceros interesados en reproducir o extender el trabajo.

---

## ğŸ“… 01/07/2025 â€“ Inicio del proyecto

- **Fase inicial**: planteamiento general del proyecto.  
- Se define que Cognitiva-AI explorarÃ¡ **clasificaciÃ³n de enfermedad de Alzheimer** usando datos clÃ­nicos (OASIS-2) y resonancias magnÃ©ticas.  
- Se establecen los objetivos:  
  1. Validar la viabilidad con modelos clÃ­nicos tabulares (XGBoost).  
  2. Extender a MRI con backbones CNN/transformers.  
  3. Explorar calibraciÃ³n, ensembles y, finalmente, multimodalidad.

---

## ğŸ“… 03/07/2025 â€“ Pipeline 1 (ClÃ­nico OASIS-2)

- **Notebook:** `p1_clinico_oasis2.ipynb`.  
- **Datos:** cohortes clÃ­nicas de OASIS-2.  
- **Modelo:** XGBoost.  
- **Resultados preliminares:**  
  - AUC â‰ˆ 0.897.  
  - Buenas mÃ©tricas en validaciÃ³n, confirmando que los datos clÃ­nicos son predictivos.  

**ReflexiÃ³n:** excelente punto de partida, sirve de baseline. Se decide extender a fusiÃ³n y multimodalidad mÃ¡s adelante.

---

## ğŸ“… 06/07/2025 â€“ Pipeline 2 (ClÃ­nico FusiÃ³n)

- **Notebook:** `p2_clinico_fusion.ipynb`.  
- **Estrategia:** se fusionan variables clÃ­nicas tabulares adicionales.  
- **Modelo:** XGBoost mejorado.  
- **Resultados:**  
  - AUC â‰ˆ 0.991.  
  - Recall casi perfecto (~1.0).  

**ReflexiÃ³n:** mÃ©tricas altÃ­simas, posible riesgo de overfitting, pero muestra el potencial de fusiÃ³n de datos tabulares.  
Se decide dar el salto a MRI.

---

## ğŸ“… 10/07/2025 â€“ Pipeline 3 (MRI OASIS-2 con ResNet50)

- **Notebook:** `p3_mri_oasis2_resnet50.ipynb`.  
- **Datos:** imÃ¡genes MRI de OASIS-2.  
- **Backbone:** ResNet50 preentrenada en ImageNet.  
- **Resultados:**  
  - AUC (test) â‰ˆ 0.938.  

**ReflexiÃ³n:** confirmaciÃ³n de que los modelos CNN estÃ¡ndar son viables en MRI.  
Este pipeline sirve de puente hacia la fase Colab (con datos mÃ¡s grandes y pipelines posteriores).

---

## ğŸ“… 15/07/2025 â€“ Pipeline 5 (MRI Colab con ResNet18 + CalibraciÃ³n)

- **Notebook:** `p5_mri_colab_resnet18_calib.ipynb`.  
- **MotivaciÃ³n:** probar pipeline en Colab con mayor escala y calibraciÃ³n.  
- **Resultados:**  
  - AUC â‰ˆ 0.724.  
  - PR-AUC â‰ˆ 0.606.  
  - Accuracy â‰ˆ 0.60.  
  - Recall 0.80 | Precision 0.52.  

**ReflexiÃ³n:** mÃ©tricas mÃ¡s bajas que en OASIS-2, debido a mayor complejidad. Se confirma la necesidad de arquitecturas mÃ¡s potentes (EfficientNet).

---

## ğŸ“… 20/07/2025 â€“ Pipeline 6 (EfficientNet-B3 embeddings)

- **Notebook:** `p6_mri_colab_effb3_embed.ipynb`.  
- **Enfoque:** usar EffNet-B3 como extractor de embeddings, clasificando con capa adicional.  
- **Resultados:**  
  - AUC â‰ˆ 0.704.  
  - PR-AUC â‰ˆ 0.623.  
  - Accuracy â‰ˆ 0.70.  
  - Recall 0.90 | Precision 0.60.  

**ReflexiÃ³n:** mejora en recall, aunque el modelo aÃºn no se estabiliza.  
Se plantea probar fine-tuning completo.

---

## ğŸ“… 23/07/2025 â€“ Pipeline 7 (EfficientNet-B3 fine-tune)

- **Notebook:** `p7_mri_colab_effb3_finetune.ipynb`.  
- **MotivaciÃ³n:** pasar de embeddings fijos a fine-tuning completo.  
- **Resultados:**  
  - AUC â‰ˆ 0.876.  
  - PR-AUC â‰ˆ 0.762.  
  - Accuracy â‰ˆ 0.745.  
  - Recall 1.0 | Precision 0.625.  

**ReflexiÃ³n:** salto cualitativo, confirma que EffNet-B3 es un backbone sÃ³lido para MRI.  
Se establece como baseline.

---

## ğŸ“… 30/07/2025 â€“ Pipeline 9 (EfficientNet-B3 stable)

- **Notebook:** `p9_mri_colab_effb3_stable.ipynb`.  
- **MotivaciÃ³n:** buscar estabilidad entre runs, reduciendo variabilidad.  
- **Resultados:**  
  - AUC â‰ˆ 0.740.  
  - PR-AUC â‰ˆ 0.630.  
  - Accuracy â‰ˆ 0.72.  
  - Recall 0.65 | Precision 0.62.  

**ReflexiÃ³n:** mejora en estabilidad, pero con ligera pÃ©rdida de recall.  
Sirve como base para el pipeline 10.

---

## ğŸ“… 05/08/2025 â€“ Pipeline 10 (EfficientNet-B3 stable + calibraciÃ³n)

- **Notebook:** `p10_mri_colab_effb3_stable_plus.ipynb`.  
- **Objetivo:** aÃ±adir calibraciÃ³n (temperature scaling, isotonic).  
- **Resultados:**  
  - AUC (test) â‰ˆ 0.546â€“0.583.  
  - PR-AUC â‰ˆ 0.50â€“0.53.  
  - Accuracy â‰ˆ 0.51â€“0.55.  
  - Recall 1.0 | Precision â‰ˆ 0.47â€“0.49.  

**ReflexiÃ³n:** caÃ­da de mÃ©tricas tras calibraciÃ³n, pero resultados mÃ¡s interpretables.  
Se descubre la importancia de ensembles para recuperar rendimiento.

---

## ğŸ“… 10/08/2025 â€“ Pipeline 10-ext (TRIMMED y ensembles)

- **Notebook:** `p10ext_mri_colab_effb3_ext.ipynb`.  
- **Estrategia:** variantes TRIMMED y ensembles de MEAN/TRIMMED/TOP7.  
- **Resultados:**  
  - TRIMMED: AUC â‰ˆ 0.744, PR-AUC â‰ˆ 0.746.  
  - Ensemble: AUC â‰ˆ 0.754, PR-AUC â‰ˆ 0.737.  

**ReflexiÃ³n:** ensembles simples logran mejoras claras.  
Refuerza la idea de avanzar hacia ensembles mÃ¡s sofisticados.

---

## ğŸ“… 15/08/2025 â€“ Pipeline 11 (Backbones alternativos)

- **Notebook:** `cognitiva_ai_backbones.ipynb`.  
- **MotivaciÃ³n:** verificar si otros backbones pueden superar a EffNet-B3.  
- **Backbones probados:**  
  - ResNet-50.  
  - DenseNet-121.  
  - ConvNeXt-Tiny.  
  - Swin-Tiny.  

### Resultados preliminares:
- **ResNet-50:** AUC â‰ˆ 0.740, PR-AUC â‰ˆ 0.730.  
- **DenseNet-121:** AUC â‰ˆ 0.343, PR-AUC â‰ˆ 0.407.  
- **ConvNeXt-Tiny:** AUC â‰ˆ 0.509, PR-AUC â‰ˆ 0.479.  
- **Swin-Tiny:** AUC â‰ˆ 0.641, PR-AUC â‰ˆ 0.597.  

**ReflexiÃ³n:** ningÃºn backbone supera claramente a EffNet-B3. Swin-Tiny destaca levemente, DenseNet decepciona.  
La evidencia refuerza el interÃ©s en **ensembles de backbones**.

---

## ğŸ“… 20/08/2025 â€“ Ensembles de Backbones

- **Objetivo:** combinar predicciones slice-level y patient-level de varios backbones (Swin, ConvNeXt, DenseNet).  
- **MÃ©todos:**  
  - Promedios simples.  
  - Random weights (Dirichlet).  
  - Stacking (logistic regression, isotonic calibration).  

### Resultados:
- **Dirichlet (3 backbones, means):**  
  - VAL: AUC â‰ˆ 0.71, PRAUC â‰ˆ 0.63.  
  - TEST: AUC â‰ˆ 0.52, PRAUC â‰ˆ 0.52.  

- **Dirichlet EXT (12 features):**  
  - VAL: AUC â‰ˆ 0.71, PRAUC â‰ˆ 0.68.  
  - TEST: AUC â‰ˆ 0.36, PRAUC â‰ˆ 0.40.  

- **Stack_LR (all_features):**  
  - VAL: AUC â‰ˆ 0.81, PRAUC â‰ˆ 0.70.  
  - TEST: AUC â‰ˆ 0.29, PRAUC â‰ˆ 0.39.  

- **Swin-Tiny isotonic:**  
  - VAL: AUC â‰ˆ 0.71, PRAUC â‰ˆ 0.55.  
  - TEST: AUC â‰ˆ 0.56, PRAUC â‰ˆ 0.45.  

**ReflexiÃ³n:** aunque los ensembles no logran mejorar consistentemente el test, sÃ­ confirman la complementariedad entre modelos.  
El reto serÃ¡ combinar estabilidad de EffNet-B3 con la diversidad de backbones.

---

## ğŸ” DesafÃ­os principales encontrados

1. **Inestabilidad en Colab:** sesiones largas provocaban errores o pÃ©rdida de conexiÃ³n. Reinicios forzados solucionaron varios problemas.  
2. **GestiÃ³n de Google Drive:** errores frecuentes de montaje/desmontaje y rutas inconsistentes, resueltos con reinicios y verificaciones explÃ­citas.  
3. **Variabilidad de resultados:** seeds distintas producÃ­an mÃ©tricas diferentes; se resolviÃ³ con ensembles y calibraciÃ³n.  
4. **Dificultad en calibraciÃ³n:** temperature scaling mejoraba interpretabilidad pero bajaba AUC. Hubo que combinar con ensembles.  
5. **Backbones alternativos:** algunos decepcionaron (DenseNet) o no superaron a EffNet, confirmando que no hay â€œganador absolutoâ€.  
6. **Complejidad de ensembles:** mÃ©todos como Dirichlet o Stacking mostraron sobreajuste en validaciÃ³n y peores mÃ©tricas en test.  
7. **LimitaciÃ³n de datos:** tamaÃ±o reducido del dataset afectÃ³ a generalizaciÃ³n, especialmente en arquitecturas grandes como Swin.  
8. **GestiÃ³n de logs y CSV:** mÃºltiples formatos distintos (`y_score`, `sigmoid(logit)`, etc.), lo que exigiÃ³ unificaciÃ³n manual en varios experimentos.

---

## ğŸ“Œ Estado actual y prÃ³ximos pasos

- Pipelines clÃ­nicos y MRI probados, con EffNet-B3 como backbone base mÃ¡s sÃ³lido.  
- Backbones alternativos probados y documentados.  
- Ensembles explorados con distintos enfoques, aunque sin mejora clara en test.  

**PrÃ³ximos pasos:**  
1. Probar ensembles hÃ­bridos (EffNet-B3 + Swin/ConvNeXt).  
2. Introducir datos multimodales (clÃ­nicos + MRI) en un solo modelo.  
3. Optimizar regularizaciÃ³n y calibraciÃ³n avanzada.  
4. Ampliar el dataset (otras cohortes) para mejorar generalizaciÃ³n.

---

# âœ… ConclusiÃ³n

Este cuaderno refleja el progreso continuo del proyecto Cognitiva-AI.  
Se han probado **11 pipelines principales**, numerosos experimentos de calibraciÃ³n y ensembles, asÃ­ como mÃºltiples backbones alternativos.  
Cada fase ha aportado aprendizajes valiosos, aunque los mejores resultados aÃºn provienen de **EfficientNet-B3 finetune (Pipeline 7)** y **EfficientNet-B3 ensembles calibrados (Pipeline 10-ext)**.  
El camino hacia multimodalidad queda abierto, apoyado en todo este historial experimental.

---
