# ğŸ§  Proyecto de DetecciÃ³n Temprana de Alzheimer (COGNITIVA-AI)

Este proyecto explora la detecciÃ³n temprana de Alzheimer combinando **datos clÃ­nicos tabulares** y **resonancias magnÃ©ticas (MRI)** del conjunto **OASIS-2**.  
Construimos dos pipelines complementarios:

1) **COGNITIVA-AI-CLINIC** â†’ *aprendizaje clÃ¡sico (ML) con datos clÃ­nicos.*  
2) **COGNITIVA-AI-IMAGES** â†’ *Deep Learning con imÃ¡genes (fine-tuning de ResNet50).*

El objetivo es ofrecer una lÃ­nea base sÃ³lida, documentar decisiones y resultados, y dejar una hoja de ruta clara para mejoras.

---

## ğŸ“¦ Datos y alcance

- **Fuente principal:** `oasis_longitudinal_demographics.xlsx` (demografÃ­a + medidas clÃ­nicas/estructurales) y MRI en carpetas `OAS2_XXX_MRy/RAW` (+ `OLD` en algunos sujetos).  
- **Problema:** clasificaciÃ³n **binaria** a nivel de paciente:  
  - `0 = Nondemented`  
  - `1 = Demented` o `Converted` (paciente que progresa a demencia).  
- **Razonamiento de la binarizaciÃ³n:** el dataset es pequeÃ±o; un esquema binario simplifica y mejora estabilidad en mÃ©tricas, especialmente con validaciÃ³n honesta por paciente.

> ğŸ”’ **Evitar fugas de informaciÃ³n** (data leakage):  
> - Con datos clÃ­nicos: elegimos **una visita por sujeto** (baseline) para no mezclar repeticiones del mismo paciente entre train y test.  
> - Con imÃ¡genes: el **split es por paciente/scan_id**; todas las slices de un scan quedan en el mismo subset.

---

# 1ï¸âƒ£ COGNITIVA-AI-CLINIC (Datos clÃ­nicos)

### ğŸ“‚ Variables (principales)
- DemogrÃ¡ficas: `Age`, `Sex (M/F)`, `Education (EDUC)`, `SES`.  
- ClÃ­nicas/neuropsicolÃ³gicas: `MMSE`, `CDR`.  
- Estructurales globales: `eTIV`, `nWBV`, `ASF`.  
- Target: `Group` â†’ mapeado a `target âˆˆ {0,1}` (Nondemented vs Demented/Converted).

### ğŸ§¹ Preprocesamiento
- **Renombrado a `snake_case`** para legibilidad (`Subject ID â†’ subject_id`, etc.).  
- **SelecciÃ³n de una visita por sujeto**: baseline (mÃ­nimo `mr_delay`) para tener un Ãºnico registro representativo por paciente.  
- ConversiÃ³n de tipos numÃ©ricos y **imputaciÃ³n** (mediana) para columnas con NaN (`ses`, `mmse`, `cdr`, â€¦).  
- CodificaciÃ³n:
  - `sex`: `M â†’ 0`, `F â†’ 1`.  
  - `hand`: one-hot (categorÃ­a desconocida a `Unknown`).  

### âš™ï¸ Modelado
- **Modelos base:** Logistic Regression, Random Forest, XGBoost.  
- **ValidaciÃ³n:** `StratifiedKFold` y mÃ©trica **ROC-AUC**.  
- **OptimizaciÃ³n:**  
  - *GridSearchCV* para Random Forest.  
  - **Algoritmo GenÃ©tico (DEAP)** para RF/XGB: bÃºsqueda evolutiva de hiperparÃ¡metros (mÃ¡s eficiente en espacios grandes/no convexos).

> â„¹ï¸ **Por quÃ© ROC-AUC**: mide la capacidad de discriminaciÃ³n a todos los umbrales, robusta ante desbalance moderado y facilita comparaciÃ³n entre modelos.

### ğŸ“Š Resultados (clÃ­nico)

- **Cross-val (grid/genÃ©tico):**  
  - RF (grid) â†’ mejor ROC-AUC CV â‰ˆ **0.9224**  
  - RF (GA) â†’ mejor ROC-AUC CV â‰ˆ **0.9215**  
  - XGB (GA) â†’ mejor ROC-AUC CV â‰ˆ **0.9215**

- **Test hold-out (final):**
  | Modelo              | ROC-AUC (Test) |
  |---------------------|----------------|
  | Random Forest (opt) | 0.884          |
  | **XGBoost (opt)**   | **0.897**      |

## ğŸ“Š Resultados (MRI â€“ nivel paciente)

> **Split estratificado por paciente 60/20/20** (train/val/test)

| ConfiguraciÃ³n | Preprocesamiento | Train Acc | Val Acc | Test Acc | ROC-AUC | Comentarios |
|---|---|---:|---:|---:|---:|---|
| **5 slices** | **Sin CLAHE** | â†‘ (â‰ˆ0.94) | â‰ˆ0.73 | **0.89** | **0.938** | LÃ­nea base fuerte; generaliza bien en test. |
| 5 slices | CLAHE | â‰ˆ0.95 | â‰ˆ0.72 | 0.69 | 0.777 | Mejora visual, pero menor discriminaciÃ³n; probable realce de ruido. |
| 5 slices | CLAHE + z-score | â‰ˆ0.96 | â‰ˆ0.75 | 0.72 | 0.820 | Recupera estabilidad; mejor balance entre clases, sigue < baseline. |
| **20 slices** | CLAHE + z-score | **0.98** | â‰ˆ0.71 | **0.80** | **0.858** | MÃ¡s cobertura anatÃ³mica; mejora global respecto a CLAHE, aunque con algo de sobreajuste. |

**ConclusiÃ³n MRI:**  
- El **baseline sin CLAHE con 5 slices** fue el mÃ¡s alto en **ROC-AUC (0.94)** en nuestro test.  
- **Aumentar a 20 slices** mejora la robustez general y el *recall* de la clase positiva, pero aÃºn no supera al baseline en ROC-AUC.  
- **CLAHE** debe usarse con cautela (o de forma selectiva) y acompaÃ±ado de normalizaciÃ³n adecuada.

---

## ğŸ§  Decisiones de diseÃ±o (y por quÃ©)

- **Binarizar `Group`** (`Nondemented` vs `Demented/Converted`): simplifica el problema y mejora estabilidad en CV y test.  
- **Una visita por sujeto (clÃ­nico)**: evita duplicar pacientes y **fuga de informaciÃ³n**.  
- **Split por paciente (imÃ¡genes)**: todas las slices de un `scan_id` deben ir al mismo subset â†’ evaluaciÃ³n realista.  
- **EvaluaciÃ³n por paciente** (MRI): lo clÃ­nicamente relevante es la clasificaciÃ³n del **paciente**, no de cada corte aislado.  
- **Early stopping**: protege frente a sobreajuste visible (train â‰« val).  
- **MÃ©trica ROC-AUC**: adecuada con clases desbalanceadas/moderadas y para comparar modelos a distintos umbrales.

---

## ğŸ§ª Notas de implementaciÃ³n (fragmentos clave)

**Mapeo de etiquetas por `scan_id`:**
```python
labels = pd.read_excel("oasis_longitudinal_demographics.xlsx").rename(columns={
    "MRI ID": "scan_id", "Group": "group"
})
labels["label"] = labels["group"].map({"Nondemented": 0, "Demented": 1, "Converted": 1})
labels = labels.dropna(subset=["label"]).astype({"label": int})
label_map = labels.set_index("scan_id")["label"].to_dict()
```

**ExtracciÃ³n de `scan_id` desde ruta y guardado de slices (ejemplo):**
```python
from pathlib import Path
import nibabel as nib, numpy as np, cv2, os

def save_slices_from_nifti(img_path, scan_id, out_dir, max_slices=5, use_clahe=False):
    vol = nib.load(img_path).get_fdata()
    vol = (vol - vol.min()) / (vol.max() - vol.min() + 1e-8) * 255
    vol = vol.astype(np.uint8)

    zmid = vol.shape[2] // 2
    idxs = range(zmid - max_slices//2, zmid - max_slices//2 + max_slices)

    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) if use_clahe else None

    paths = []
    for i, z in enumerate(idxs):
        if 0 <= z < vol.shape[2]:
            sl = vol[:,:,z]
            if clahe is not None:
                sl = clahe.apply(sl)
            out = os.path.join(out_dir, f"{scan_id}_slice{i}.png")
            cv2.imwrite(out, sl)
            paths.append(out)
    return paths
```

**Dataset PyTorch (con `return_path` para agregaciÃ³n paciente):**
```python
class MRIDataset(Dataset):
    def __init__(self, img_dir, label_map, scan_ids, transform=None, return_path=False):
        self.transform = transform
        self.return_path = return_path
        self.label_map = label_map
        self.scan_ids = set(scan_ids)
        all_png = glob.glob(os.path.join(img_dir, "*.png"))
        self.img_paths = [p for p in all_png if self._scan_id(p) in self.scan_ids]

    def _scan_id(self, p):
        return os.path.basename(p).split("_slice")[0]

    def __getitem__(self, i):
        p = self.img_paths[i]
        sid = self._scan_id(p)
        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # ResNet espera 3 canales
        if self.transform: img = self.transform(img)
        y = self.label_map[sid]
        return (img, y, p) if self.return_path else (img, y)

    def __len__(self): return len(self.img_paths)
```

**AgregaciÃ³n por paciente (nivel test):**
```python
from collections import defaultdict
patient_probs, patient_labels = defaultdict(list), {}

with torch.no_grad():
    for x, y, paths in test_loader:
        prob = torch.softmax(model(x.to(device)), dim=1)[:,1].cpu().numpy()
        for pp, yy, path in zip(prob, y.numpy(), paths):
            sid = os.path.basename(path).split("_slice")[0]
            patient_probs[sid].append(pp)
            patient_labels[sid] = int(yy)

final_probs = {sid: np.mean(v) for sid, v in patient_probs.items()}
final_preds = {sid: int(p > 0.5) for sid, p in final_probs.items()}
```

---

## ğŸ§­ Limitaciones conocidas

- **TamaÃ±o muestral** limitado â†’ sensibilidad a splits y a *overfitting*.  
- **Slices 2D** no capturan plena continuidad 3D.  
- **CLAHE** puede perjudicar patrones de intensidad sutiles (dependiente de parÃ¡metros y de sujeto).  
- Diferencia CV vs Test en clÃ­nico sugiere **optimismo** por bÃºsqueda de hiperparÃ¡metros (normal/esperable).

---

## ğŸš€ PrÃ³ximos pasos propuestos

1) **RegularizaciÃ³n explÃ­cita en imÃ¡genes:**  
   - Congelar capas iniciales en warm-up, **Dropout** en la cabeza, **Weight Decay**, **Label Smoothing**.  
   - **Class weights** en la loss si hay desbalance real.

2) **MÃ¡s slices / selecciÃ³n inteligente:**  
   - 32â€“64 slices equiespaciadas; o seleccionar automÃ¡ticamente cortes â€œmÃ¡s informativosâ€ (ej., centrados en hipocampo).

3) **NormalizaciÃ³n adaptada a MRI:**  
   - Z-score **por volumen** (no por slice) o *histogram matching* intra-sujeto.

4) **Arquitecturas modernas / 3D:**  
   - EfficientNet, DenseNet, ConvNeXt; versiones 3D si el cÃ³mputo lo permite.

5) **Multimodalidad:**  
   - Fusionar **clÃ­nico + imÃ¡genes** (early/late fusion); Ãºtil cuando los patrones de ambos dominios son complementarios.

---

## ğŸ§ª Resumen comparativo final

| Modalidad       | Modelo                          | ROC-AUC (Test) | Notas |
|-----------------|----------------------------------|----------------|-------|
| **ClÃ­nico**     | **XGBoost (opt)**               | **0.897**      | Mejor en tabular; pipeline robusto y explicable. |
| **ImÃ¡genes**    | **ResNet50 â€“ 5 slices (sin CLAHE)** | **0.938**   | Mejor AUC en test con split por paciente. |
| ImÃ¡genes        | ResNet50 â€“ 5 slices (CLAHE)     | 0.777          | Legibilidad â†‘, discriminaciÃ³n â†“. |
| ImÃ¡genes        | ResNet50 â€“ 5 slices (CLAHE+Z)   | 0.820          | Estabilidad â†‘, aÃºn < baseline. |
| ImÃ¡genes        | ResNet50 â€“ **20 slices (CLAHE+Z)** | 0.858       | Robustez â†‘, mejor recall; algo de sobreajuste. |

---

## ğŸ§¾ Reproducibilidad (guÃ­a breve)

1. **ClÃ­nico**  
   - Cargar Excel â†’ renombrar columnas â†’ 1 visita por sujeto â†’ imputaciÃ³n â†’ encoding.  
   - `train_test_split` estratificado â†’ *GridSearchCV* / GA â†’ reportar CV y Test.

2. **ImÃ¡genes**  
   - Convertir `.hdr/.img` a PNG (5 o 20 slices) con `label_map` por `scan_id`.  
   - Split estratificado **por paciente** (60/20/20).  
   - Entrenar ResNet50 (fine-tuning) con *early stopping*.  
   - Evaluar **por paciente** agregando probabilidades de sus slices.

---

**AutorÃ­a:** Fran RamÃ­rez  
**AÃ±o:** 2025.
