{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03HS17YgxzhV",
        "outputId": "13a07ddb-b82b-453b-ff64-26f723898d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPyTorch: 2.8.0+cu126 | CUDA disponible: True\n"
          ]
        }
      ],
      "source": [
        "# Celda 0: Instalación (si lo necesitas). TimM para EfficientNet-B3.\n",
        "!pip -q install timm==0.9.16\n",
        "\n",
        "import os, sys, json, time, math, random, shutil, gc\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision.io import read_image\n",
        "from PIL import Image\n",
        "\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Determinismo razonable\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "print(\"PyTorch:\", torch.__version__, \"| CUDA disponible:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 1: Montar Drive y preparar rutas\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR   = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "DATA_DIR   = BASE_DIR / \"oas1_data\"\n",
        "OUT_DIR    = BASE_DIR / \"ft_effb3_stable_colab_plus\"\n",
        "GRAPHS_DIR = OUT_DIR / \"graphs_from_metrics\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "GRAPHS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "VAL_MAP  = DATA_DIR / \"oas1_val_colab_mapped.csv\"\n",
        "TEST_MAP = DATA_DIR / \"oas1_test_colab_mapped.csv\"\n",
        "\n",
        "print(\"Device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Mounted at /content/drive\")\n",
        "print(\"BASE   :\", BASE_DIR)\n",
        "print(\"DATA   :\", DATA_DIR, \"| exists:\", DATA_DIR.exists())\n",
        "print(\"OUT    :\", OUT_DIR)\n",
        "print(\"GRAPHS :\", GRAPHS_DIR)\n",
        "print(\"VAL_MAP:\", VAL_MAP, \"| exists:\", VAL_MAP.exists())\n",
        "print(\"TEST_MAP:\", TEST_MAP, \"| exists:\", TEST_MAP.exists())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf6FAoud2a73",
        "outputId": "1b10953e-27cf-4f05-bea5-5b4ed084541e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Device: cuda\n",
            "Mounted at /content/drive\n",
            "BASE   : /content/drive/MyDrive/CognitivaAI\n",
            "DATA   : /content/drive/MyDrive/CognitivaAI/oas1_data | exists: True\n",
            "OUT    : /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus\n",
            "GRAPHS : /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/graphs_from_metrics\n",
            "VAL_MAP: /content/drive/MyDrive/CognitivaAI/oas1_data/oas1_val_colab_mapped.csv | exists: True\n",
            "TEST_MAP: /content/drive/MyDrive/CognitivaAI/oas1_data/oas1_test_colab_mapped.csv | exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 2: Configuración y lectura de CSV estándar (mapped => patient_id, target, png_path)\n",
        "\n",
        "@dataclass\n",
        "class CFG:\n",
        "    img_size: int = 300\n",
        "    batch_size: int = 64\n",
        "    num_workers: int = 2\n",
        "    seeds: tuple = (41, 42, 43)    # ensemble de 3 seeds\n",
        "    holdout_patients: int = 10     # desde VAL asignamos 10 pacientes a holdout (como en P9)\n",
        "\n",
        "@dataclass\n",
        "class TrainCfg:\n",
        "    epochs: int = 8\n",
        "    lr: float = 1e-4\n",
        "    wd: float = 1e-5\n",
        "    amp: bool = True\n",
        "    patience: int = 3\n",
        "    label_smoothing: float = 0.05   # Mejora 1: label smoothing\n",
        "    use_pos_weight: bool = True    # Alternativa a smoothing (déjalo False si usas smoothing)\n",
        "    pos_weight: float = 1.5\n",
        "\n",
        "cfg = CFG()\n",
        "tcfg = TrainCfg()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_mapped_csv(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    cols = [c.lower() for c in df.columns]\n",
        "    df.columns = cols\n",
        "    # Esperamos 'patient_id', 'target', 'png_path'\n",
        "    assert all([c in df.columns for c in [\"patient_id\",\"target\",\"png_path\"]]), f\"CSV {path} debe tener patient_id,target,png_path\"\n",
        "    df = df.rename(columns={\"target\":\"y_true\"})\n",
        "    df[\"y_true\"] = df[\"y_true\"].astype(int)\n",
        "    return df\n",
        "\n",
        "val_map  = load_mapped_csv(VAL_MAP)\n",
        "test_map = load_mapped_csv(TEST_MAP)\n",
        "\n",
        "# Split train/holdout desde VAL por pacientes\n",
        "patients = val_map[\"patient_id\"].unique()\n",
        "rng = np.random.default_rng(42)\n",
        "rng.shuffle(patients)\n",
        "holdout_pat = set(patients[:cfg.holdout_patients])\n",
        "\n",
        "train_df   = val_map[~val_map[\"patient_id\"].isin(holdout_pat)].reset_index(drop=True)\n",
        "holdout_df = val_map[ val_map[\"patient_id\"].isin(holdout_pat)].reset_index(drop=True)\n",
        "test_df    = test_map.copy().reset_index(drop=True)\n",
        "\n",
        "def summarize_df(df, name):\n",
        "    print(f\"{name}: shape={df.shape}, pacientes={df['patient_id'].nunique()}, y_mean={df['y_true'].mean():.3f}\")\n",
        "\n",
        "print(\"CFG\", cfg)\n",
        "summarize_df(val_map, \"VAL mapeado\")\n",
        "summarize_df(test_df, \"TEST mapeado\")\n",
        "summarize_df(train_df, \"train_df\")\n",
        "summarize_df(holdout_df, \"holdout_df\")\n",
        "summarize_df(test_df, \"test_df\")\n",
        "\n",
        "print(\"\\nEjemplo train_df:\"); display(train_df.head(3))\n",
        "print(\"\\nEjemplo holdout_df:\"); display(holdout_df.head(3))\n",
        "print(\"\\nEjemplo test_df:\"); display(test_df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "QFmk9C8d2tFa",
        "outputId": "01994271-e3f5-4b3c-e010-560dd964a751"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CFG CFG(img_size=300, batch_size=64, num_workers=2, seeds=(41, 42, 43), holdout_patients=10)\n",
            "VAL mapeado: shape=(940, 6), pacientes=47, y_mean=0.426\n",
            "TEST mapeado: shape=(940, 6), pacientes=47, y_mean=0.426\n",
            "train_df: shape=(740, 6), pacientes=37, y_mean=0.459\n",
            "holdout_df: shape=(200, 6), pacientes=10, y_mean=0.300\n",
            "test_df: shape=(940, 6), pacientes=47, y_mean=0.426\n",
            "\n",
            "Ejemplo train_df:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            png_path  y_true patient_id  \\\n",
              "0  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       1  OAS1_0003   \n",
              "1  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       1  OAS1_0003   \n",
              "2  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       1  OAS1_0003   \n",
              "\n",
              "         scan_id                                         source_hdr  has_mask  \n",
              "0  OAS1_0003_MR1  DATA\\OAS1_RAW\\OAS1_0003_MR1\\RAW\\OAS1_0003_MR1_...         1  \n",
              "1  OAS1_0003_MR1  DATA\\OAS1_RAW\\OAS1_0003_MR1\\RAW\\OAS1_0003_MR1_...         1  \n",
              "2  OAS1_0003_MR1  DATA\\OAS1_RAW\\OAS1_0003_MR1\\RAW\\OAS1_0003_MR1_...         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67be6c42-1f50-432d-98df-29d5f5463057\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>png_path</th>\n",
              "      <th>y_true</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>scan_id</th>\n",
              "      <th>source_hdr</th>\n",
              "      <th>has_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>1</td>\n",
              "      <td>OAS1_0003</td>\n",
              "      <td>OAS1_0003_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0003_MR1\\RAW\\OAS1_0003_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>1</td>\n",
              "      <td>OAS1_0003</td>\n",
              "      <td>OAS1_0003_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0003_MR1\\RAW\\OAS1_0003_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>1</td>\n",
              "      <td>OAS1_0003</td>\n",
              "      <td>OAS1_0003_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0003_MR1\\RAW\\OAS1_0003_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67be6c42-1f50-432d-98df-29d5f5463057')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67be6c42-1f50-432d-98df-29d5f5463057 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67be6c42-1f50-432d-98df-29d5f5463057');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eb6d86e5-c6f3-4b0b-9c5f-8c20fa87e562\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb6d86e5-c6f3-4b0b-9c5f-8c20fa87e562')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eb6d86e5-c6f3-4b0b-9c5f-8c20fa87e562 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nEjemplo test_df:\\\"); display(test_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"png_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0003_MR1_slice00.png\",\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0003_MR1_slice01.png\",\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0003_MR1_slice02.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_true\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patient_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OAS1_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scan_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OAS1_0003_MR1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_hdr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DATA\\\\OAS1_RAW\\\\OAS1_0003_MR1\\\\RAW\\\\OAS1_0003_MR1_mpr-1_anon.hdr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_mask\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ejemplo holdout_df:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            png_path  y_true patient_id  \\\n",
              "0  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       1  OAS1_0022   \n",
              "1  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       1  OAS1_0022   \n",
              "2  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       1  OAS1_0022   \n",
              "\n",
              "         scan_id                                         source_hdr  has_mask  \n",
              "0  OAS1_0022_MR1  DATA\\OAS1_RAW\\OAS1_0022_MR1\\RAW\\OAS1_0022_MR1_...         1  \n",
              "1  OAS1_0022_MR1  DATA\\OAS1_RAW\\OAS1_0022_MR1\\RAW\\OAS1_0022_MR1_...         1  \n",
              "2  OAS1_0022_MR1  DATA\\OAS1_RAW\\OAS1_0022_MR1\\RAW\\OAS1_0022_MR1_...         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-629c02b4-7335-473c-b3ac-cdc6d05c2829\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>png_path</th>\n",
              "      <th>y_true</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>scan_id</th>\n",
              "      <th>source_hdr</th>\n",
              "      <th>has_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>1</td>\n",
              "      <td>OAS1_0022</td>\n",
              "      <td>OAS1_0022_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0022_MR1\\RAW\\OAS1_0022_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>1</td>\n",
              "      <td>OAS1_0022</td>\n",
              "      <td>OAS1_0022_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0022_MR1\\RAW\\OAS1_0022_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>1</td>\n",
              "      <td>OAS1_0022</td>\n",
              "      <td>OAS1_0022_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0022_MR1\\RAW\\OAS1_0022_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-629c02b4-7335-473c-b3ac-cdc6d05c2829')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-629c02b4-7335-473c-b3ac-cdc6d05c2829 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-629c02b4-7335-473c-b3ac-cdc6d05c2829');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-75c5915f-33e1-45ff-a7d3-06efeef1d1fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75c5915f-33e1-45ff-a7d3-06efeef1d1fa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-75c5915f-33e1-45ff-a7d3-06efeef1d1fa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nEjemplo test_df:\\\"); display(test_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"png_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0022_MR1_slice00.png\",\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0022_MR1_slice01.png\",\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0022_MR1_slice02.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_true\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patient_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OAS1_0022\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scan_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OAS1_0022_MR1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_hdr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DATA\\\\OAS1_RAW\\\\OAS1_0022_MR1\\\\RAW\\\\OAS1_0022_MR1_mpr-1_anon.hdr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_mask\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ejemplo test_df:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            png_path  y_true patient_id  \\\n",
              "0  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       0  OAS1_0002   \n",
              "1  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       0  OAS1_0002   \n",
              "2  /content/drive/MyDrive/CognitivaAI/oas1_data/O...       0  OAS1_0002   \n",
              "\n",
              "         scan_id                                         source_hdr  has_mask  \n",
              "0  OAS1_0002_MR1  DATA\\OAS1_RAW\\OAS1_0002_MR1\\RAW\\OAS1_0002_MR1_...         1  \n",
              "1  OAS1_0002_MR1  DATA\\OAS1_RAW\\OAS1_0002_MR1\\RAW\\OAS1_0002_MR1_...         1  \n",
              "2  OAS1_0002_MR1  DATA\\OAS1_RAW\\OAS1_0002_MR1\\RAW\\OAS1_0002_MR1_...         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-588d3246-6264-44a5-9dc2-3ab8b3bfbb33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>png_path</th>\n",
              "      <th>y_true</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>scan_id</th>\n",
              "      <th>source_hdr</th>\n",
              "      <th>has_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>0</td>\n",
              "      <td>OAS1_0002</td>\n",
              "      <td>OAS1_0002_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0002_MR1\\RAW\\OAS1_0002_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>0</td>\n",
              "      <td>OAS1_0002</td>\n",
              "      <td>OAS1_0002_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0002_MR1\\RAW\\OAS1_0002_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/CognitivaAI/oas1_data/O...</td>\n",
              "      <td>0</td>\n",
              "      <td>OAS1_0002</td>\n",
              "      <td>OAS1_0002_MR1</td>\n",
              "      <td>DATA\\OAS1_RAW\\OAS1_0002_MR1\\RAW\\OAS1_0002_MR1_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-588d3246-6264-44a5-9dc2-3ab8b3bfbb33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-588d3246-6264-44a5-9dc2-3ab8b3bfbb33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-588d3246-6264-44a5-9dc2-3ab8b3bfbb33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-db205787-ef8f-40af-8dc2-f299701e18ac\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db205787-ef8f-40af-8dc2-f299701e18ac')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-db205787-ef8f-40af-8dc2-f299701e18ac button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nEjemplo test_df:\\\"); display(test_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"png_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0002_MR1_slice00.png\",\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0002_MR1_slice01.png\",\n          \"/content/drive/MyDrive/CognitivaAI/oas1_data/OAS1_0002_MR1_slice02.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_true\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patient_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OAS1_0002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scan_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OAS1_0002_MR1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_hdr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DATA\\\\OAS1_RAW\\\\OAS1_0002_MR1\\\\RAW\\\\OAS1_0002_MR1_mpr-1_anon.hdr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_mask\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 3: Dataset + Dataloaders con RandAugment suave y normalización simple\n",
        "\n",
        "from torchvision.transforms import RandAugment, ColorJitter\n",
        "\n",
        "class MRISliceDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open(row[\"png_path\"]).convert(\"RGB\")  # RGB para EffNet\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        y = float(row[\"y_true\"])\n",
        "        return img, torch.tensor([y], dtype=torch.float32), row[\"patient_id\"]\n",
        "\n",
        "# Transforms\n",
        "train_tf = T.Compose([\n",
        "    T.Resize((cfg.img_size, cfg.img_size)),\n",
        "    RandAugment(num_ops=2, magnitude=5),         # Mejora 1: RandAugment suave\n",
        "    ColorJitter(brightness=0.05, contrast=0.05),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
        "])\n",
        "val_tf = T.Compose([\n",
        "    T.Resize((cfg.img_size, cfg.img_size)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
        "])\n",
        "\n",
        "train_ds   = MRISliceDataset(train_df,   transform=train_tf)\n",
        "holdout_ds = MRISliceDataset(holdout_df, transform=val_tf)\n",
        "test_ds    = MRISliceDataset(test_df,    transform=val_tf)\n",
        "\n",
        "def make_loader(ds, shuffle, bs=cfg.batch_size):\n",
        "    return DataLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=cfg.num_workers, pin_memory=True)\n",
        "\n",
        "train_loader   = make_loader(train_ds, shuffle=True)\n",
        "holdout_loader = make_loader(holdout_ds, shuffle=False)\n",
        "test_loader    = make_loader(test_ds, shuffle=False)\n",
        "\n",
        "print(\"Loaders creados. Batches train/holdout/test:\",\n",
        "      len(train_loader), len(holdout_loader), len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVYVfaYP2z0T",
        "outputId": "8bdb6d86-d80f-4623-d691-078d10a36ca8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaders creados. Batches train/holdout/test: 12 4 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 4: Modelo EffNet-B3 + loss (label smoothing) + AdamW + warmup+cosine + AMP + early stopping\n",
        "\n",
        "def create_model(num_classes=1):\n",
        "    model = timm.create_model(\"tf_efficientnet_b3_ns\", pretrained=True, in_chans=3, num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "def create_loss():\n",
        "    if tcfg.use_pos_weight:\n",
        "        pw = torch.tensor([tcfg.pos_weight], device=device)\n",
        "        return nn.BCEWithLogitsLoss(pos_weight=pw)\n",
        "    else:\n",
        "        # Removed label_smoothing due to TypeError. Using pos_weight instead.\n",
        "        return nn.BCEWithLogitsLoss()\n",
        "\n",
        "def cosine_with_warmup(optimizer, total_steps, warmup_ratio=0.1):\n",
        "    warmup_steps = max(1, int(total_steps * warmup_ratio))\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < warmup_steps:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "        # Cosine decay hasta 0\n",
        "        progress = (current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "def evaluate_auc_pr(model, loader):\n",
        "    model.eval()\n",
        "    all_logits, all_y = [], []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device.type==\"cuda\" and tcfg.amp)):\n",
        "        for x, y, _ in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            all_logits.append(logits.detach().float().cpu())\n",
        "            all_y.append(y.detach().float().cpu())\n",
        "    all_logits = torch.cat(all_logits, 0).squeeze(1).numpy()\n",
        "    all_y = torch.cat(all_y, 0).squeeze(1).numpy()\n",
        "    probs = 1/(1+np.exp(-all_logits))\n",
        "    auc  = roc_auc_score(all_y, probs) if len(np.unique(all_y))>1 else np.nan\n",
        "    pr   = average_precision_score(all_y, probs) if len(np.unique(all_y))>1 else np.nan\n",
        "    return auc, pr\n",
        "\n",
        "def train_one_seed(seed, train_loader, holdout_loader):\n",
        "    set_seed(seed)\n",
        "    model = create_model().to(device)\n",
        "    loss_fn = create_loss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=tcfg.lr, weight_decay=tcfg.wd)\n",
        "\n",
        "    total_steps = tcfg.epochs * len(train_loader)\n",
        "    scheduler = cosine_with_warmup(optimizer, total_steps, warmup_ratio=0.1)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type==\"cuda\" and tcfg.amp))\n",
        "\n",
        "    best_auc = -1.0\n",
        "    best_path = OUT_DIR / f\"effb3_plus_seed{seed}.pth\"\n",
        "    history = []\n",
        "    no_improve = 0\n",
        "\n",
        "    print(f\"Seed {seed} | Epochs={tcfg.epochs} | steps/epoch={len(train_loader)}\")\n",
        "    step = 0\n",
        "    for epoch in range(1, tcfg.epochs+1):\n",
        "        model.train()\n",
        "        losses = []\n",
        "        pbar = tqdm(train_loader, desc=f\"Seed {seed} | Epoch {epoch}/{tcfg.epochs}\", leave=False)\n",
        "        for x, y, _ in pbar:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type==\"cuda\" and tcfg.amp)):\n",
        "                logits = model(x).squeeze(1)\n",
        "                loss = loss_fn(logits, y.squeeze(1))\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            losses.append(loss.item())\n",
        "            step += 1\n",
        "            pbar.set_postfix(loss=np.mean(losses))\n",
        "\n",
        "        val_auc, val_pr = evaluate_auc_pr(model, holdout_loader)\n",
        "        history.append({\"epoch\":epoch, \"loss\":float(np.mean(losses)), \"holdout_auc\":float(val_auc), \"holdout_pr\":float(val_pr)})\n",
        "        print(f\"  -> Holdout AUC={val_auc:.3f} | PR-AUC={val_pr:.3f} | loss={np.mean(losses):.4f}\")\n",
        "\n",
        "        if val_auc > best_auc:\n",
        "            best_auc = val_auc\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "            print(f\"  💾 Nuevo mejor checkpoint (seed {seed}) en: {best_path} | Holdout AUC={best_auc:.3f}\")\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= tcfg.patience:\n",
        "                print(\"  ⏹️ Early stopping por paciencia.\")\n",
        "                break\n",
        "\n",
        "    # guardar historia\n",
        "    hist_path = OUT_DIR / f\"train_history_plus_seed{seed}.json\"\n",
        "    with open(hist_path, \"w\") as f:\n",
        "        json.dump(history, f, indent=2)\n",
        "    return str(best_path), best_auc"
      ],
      "metadata": {
        "id": "_sSsw_pI25Nt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 5: Entrenar varias seeds y elegir el mejor por AUC holdout\n",
        "ckpts = []\n",
        "for sd in cfg.seeds:\n",
        "    bp, auc_h = train_one_seed(sd, train_loader, holdout_loader)\n",
        "    ckpts.append({\"seed\":sd, \"ckpt\":bp, \"holdout_auc\":float(auc_h)})\n",
        "\n",
        "ckpts_sorted = sorted(ckpts, key=lambda d: d[\"holdout_auc\"], reverse=True)\n",
        "best = ckpts_sorted[0]\n",
        "BEST_CKPT = OUT_DIR / \"best_effb3_stable_plus.pth\"\n",
        "shutil.copyfile(best[\"ckpt\"], BEST_CKPT)\n",
        "\n",
        "print(\"✅ Checkpoints:\", [c[\"ckpt\"] for c in ckpts_sorted])\n",
        "print(\"🏆 Mejor:\", best)\n",
        "print(\"➡️ Copiado como BEST:\", BEST_CKPT)\n",
        "\n",
        "with open(OUT_DIR/\"train_history_stable_plus_summary.json\",\"w\") as f:\n",
        "    json.dump({\"candidates\":ckpts_sorted, \"best\":best, \"best_ckpt\":str(BEST_CKPT)}, f, indent=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sQmM1342-3T",
        "outputId": "8b23c8d3-9a1e-47c0-edea-8a630588f4bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b3_ns to current tf_efficientnet_b3.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 41 | Epochs=8 | steps/epoch=12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Seed 41 | Epoch 1/8:   0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.431 | PR-AUC=0.293 | loss=1.4411\n",
            "  💾 Nuevo mejor checkpoint (seed 41) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed41.pth | Holdout AUC=0.431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.385 | PR-AUC=0.259 | loss=0.7813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.410 | PR-AUC=0.264 | loss=0.4799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.437 | PR-AUC=0.286 | loss=0.3659\n",
            "  💾 Nuevo mejor checkpoint (seed 41) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed41.pth | Holdout AUC=0.437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.459 | PR-AUC=0.298 | loss=0.2786\n",
            "  💾 Nuevo mejor checkpoint (seed 41) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed41.pth | Holdout AUC=0.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.372 | PR-AUC=0.257 | loss=0.2042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.397 | PR-AUC=0.262 | loss=0.1659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.385 | PR-AUC=0.248 | loss=0.1780\n",
            "  ⏹️ Early stopping por paciencia.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b3_ns to current tf_efficientnet_b3.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 42 | Epochs=8 | steps/epoch=12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Seed 42 | Epoch 1/8:   0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.527 | PR-AUC=0.363 | loss=1.3326\n",
            "  💾 Nuevo mejor checkpoint (seed 42) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed42.pth | Holdout AUC=0.527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.432 | PR-AUC=0.299 | loss=0.8189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.387 | PR-AUC=0.256 | loss=0.4927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.388 | PR-AUC=0.262 | loss=0.3192\n",
            "  ⏹️ Early stopping por paciencia.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b3_ns to current tf_efficientnet_b3.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 43 | Epochs=8 | steps/epoch=12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Seed 43 | Epoch 1/8:   0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.475 | PR-AUC=0.312 | loss=1.2818\n",
            "  💾 Nuevo mejor checkpoint (seed 43) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed43.pth | Holdout AUC=0.475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.491 | PR-AUC=0.317 | loss=0.7585\n",
            "  💾 Nuevo mejor checkpoint (seed 43) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed43.pth | Holdout AUC=0.491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.497 | PR-AUC=0.366 | loss=0.4549\n",
            "  💾 Nuevo mejor checkpoint (seed 43) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed43.pth | Holdout AUC=0.497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.507 | PR-AUC=0.363 | loss=0.3359\n",
            "  💾 Nuevo mejor checkpoint (seed 43) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed43.pth | Holdout AUC=0.507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.520 | PR-AUC=0.352 | loss=0.2629\n",
            "  💾 Nuevo mejor checkpoint (seed 43) en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed43.pth | Holdout AUC=0.520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.440 | PR-AUC=0.300 | loss=0.2644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.487 | PR-AUC=0.343 | loss=0.2122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Holdout AUC=0.450 | PR-AUC=0.291 | loss=0.1965\n",
            "  ⏹️ Early stopping por paciencia.\n",
            "✅ Checkpoints: ['/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed42.pth', '/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed43.pth', '/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed41.pth']\n",
            "🏆 Mejor: {'seed': 42, 'ckpt': '/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_plus_seed42.pth', 'holdout_auc': 0.5273214285714286}\n",
            "➡️ Copiado como BEST: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/best_effb3_stable_plus.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 6: Inferencia con TTA + ensemble opcional + pooling por paciente (mean y top-k mean)\n",
        "\n",
        "def load_model_from_ckpt(ckpt_path: Path):\n",
        "    m = create_model().to(device)\n",
        "    sd = torch.load(ckpt_path, map_location=device)\n",
        "    m.load_state_dict(sd)\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "def tta_logits(model, x):\n",
        "    # 4 vistas: original, flip H, flip V, rot90\n",
        "    outs = []\n",
        "    outs.append(model(x))\n",
        "    outs.append(model(torch.flip(x, dims=[-1])))\n",
        "    outs.append(model(torch.flip(x, dims=[-2])))\n",
        "    outs.append(model(torch.rot90(x, k=1, dims=[-2, -1])))\n",
        "    return torch.stack(outs, dim=0).mean(dim=0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_slices(models, loader, use_tta=True):\n",
        "    all_rows = []\n",
        "    for x, y, pids in tqdm(loader, desc=\"Inferencia slices\", leave=False):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        # Ensemble: media de logits de todos los modelos\n",
        "        logits_list = []\n",
        "        for m in models:\n",
        "            if use_tta:\n",
        "                logits_list.append(tta_logits(m, x))\n",
        "            else:\n",
        "                logits_list.append(m(x))\n",
        "        logits = torch.stack(logits_list, 0).mean(0).squeeze(1)\n",
        "        probs = torch.sigmoid(logits).float().cpu().numpy()\n",
        "        yb = y.squeeze(1).float().cpu().numpy()\n",
        "        for pid, yy, pp in zip(pids, yb, probs):\n",
        "            all_rows.append((pid, int(yy), float(pp)))\n",
        "    df = pd.DataFrame(all_rows, columns=[\"patient_id\",\"y_true\",\"y_score\"])\n",
        "    return df\n",
        "\n",
        "def pool_patient_mean(df_slices: pd.DataFrame) -> pd.DataFrame:\n",
        "    return (df_slices\n",
        "            .groupby(\"patient_id\")\n",
        "            .agg(y_true=(\"y_true\",\"max\"), y_score=(\"y_score\",\"mean\"))\n",
        "            .reset_index())\n",
        "\n",
        "def pool_patient_topk_mean(df_slices: pd.DataFrame, k:int=5) -> pd.DataFrame:\n",
        "    # Ordena por score y toma las k mejores por paciente, promedio\n",
        "    df_sorted = df_slices.sort_values(\"y_score\", ascending=False)\n",
        "    df_topk = (df_sorted.groupby(\"patient_id\").head(k)\n",
        "               .groupby(\"patient_id\")\n",
        "               .agg(y_true=(\"y_true\",\"max\"), y_score=(\"y_score\",\"mean\"))\n",
        "               .reset_index())\n",
        "    return df_topk\n"
      ],
      "metadata": {
        "id": "HGy0bY6j5y1O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 7: Fit de Temperature Scaling (T) en HOLDOUT y selección de umbral por recall deseado en VAL (holdout)\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def fit_temperature(logits: np.ndarray, y_true: np.ndarray, init_T=1.0):\n",
        "    # Minimizar NLL (log-loss) para encontrar T\n",
        "    def nll(T):\n",
        "        T = float(np.maximum(T, 1e-3))\n",
        "        z = logits / T\n",
        "        p = 1/(1+np.exp(-z))\n",
        "        eps = 1e-8\n",
        "        return -np.mean(y_true*np.log(p+eps) + (1-y_true)*np.log(1-p+eps))\n",
        "    res = minimize(lambda t: nll(t[0]), x0=np.array([init_T]), method=\"Nelder-Mead\")\n",
        "    best_T = float(np.maximum(res.x[0], 1e-3))\n",
        "    return best_T\n",
        "\n",
        "def choose_threshold_by_recall(y_true, y_score, recall_floor=0.90):\n",
        "    # barremos thresholds y elegimos el más bajo que cumple recall >= floor\n",
        "    thr_space = np.linspace(0, 1, 1001)\n",
        "    for thr in thr_space:\n",
        "        yhat = (y_score >= thr).astype(int)\n",
        "        r = recall_score(y_true, yhat, zero_division=0)\n",
        "        if r >= recall_floor:\n",
        "            return float(thr)\n",
        "    # si no se cumple, devolver el que max recall produce (o 0.5 fallback)\n",
        "    recalls = [(recall_score(y_true, (y_score>=thr).astype(int), zero_division=0), thr) for thr in thr_space]\n",
        "    best = max(recalls, key=lambda t:t[0])[1]\n",
        "    return float(best)\n"
      ],
      "metadata": {
        "id": "inFetc-06B7R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 8: Cargar modelos (ensemble), inferencia VAL/TEST, calibrar T en holdout, pooling top-k, métricas y guardado\n",
        "\n",
        "# 1) Cargar modelos del ensemble\n",
        "ckpt_paths = [Path(c[\"ckpt\"]) for c in ckpts]  # de Celda 5\n",
        "models = [load_model_from_ckpt(p) for p in ckpt_paths]\n",
        "\n",
        "# 2) Inferencia por slices en HOLDOUT (para calibrar T)\n",
        "#    Para calibrar con logits, volvemos a obtener logits medios sin sigmoid:\n",
        "@torch.no_grad()\n",
        "def predict_slice_logits(models, loader, use_tta=True):\n",
        "    all_logits, all_y = [], []\n",
        "    for x, y, pids in tqdm(loader, desc=\"Inferencia logits (holdout)\", leave=False):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        ll = []\n",
        "        for m in models:\n",
        "            if use_tta:\n",
        "                ll.append(tta_logits(m, x).squeeze(1))\n",
        "            else:\n",
        "                ll.append(m(x).squeeze(1))\n",
        "        logits = torch.stack(ll, 0).mean(0).float().cpu().numpy()\n",
        "        all_logits.append(logits)\n",
        "        all_y.append(y.squeeze(1).float().cpu().numpy())\n",
        "    return np.concatenate(all_logits, 0), np.concatenate(all_y, 0)\n",
        "\n",
        "hold_logits_s, hold_y_s = predict_slice_logits(models, holdout_loader, use_tta=True)\n",
        "# Pooling mean (logits -> probs después de T)\n",
        "# Para ajustar T, usamos logits a nivel slice; es suficientemente informativo\n",
        "best_T = fit_temperature(hold_logits_s, hold_y_s, init_T=1.0)\n",
        "print(f\"🧪 Temperature scaling ajustado en HOLDOUT: T={best_T:.4f}\")\n",
        "\n",
        "# 3) Inferencia completa (VAL split = train+holdout) y TEST a nivel slice -> pasar a nivel paciente\n",
        "val_slices = predict_slices(models, DataLoader(MRISliceDataset(val_map, transform=val_tf),\n",
        "                                               batch_size=cfg.batch_size, shuffle=False,\n",
        "                                               num_workers=cfg.num_workers, pin_memory=True),\n",
        "                            use_tta=True)\n",
        "test_slices = predict_slices(models, test_loader, use_tta=True)\n",
        "\n",
        "def apply_temperature_inplace(df_slices, T):\n",
        "    # Convertimos y_score a logits, dividimos por T y re-sigmoid\n",
        "    p = np.clip(df_slices[\"y_score\"].values, 1e-6, 1-1e-6)\n",
        "    logits = np.log(p/(1-p))\n",
        "    pT = 1/(1+np.exp(-(logits/T)))\n",
        "    df_slices[\"y_score\"] = pT\n",
        "    return df_slices\n",
        "\n",
        "val_slices_T  = apply_temperature_inplace(val_slices.copy(), best_T)\n",
        "test_slices_T = apply_temperature_inplace(test_slices.copy(), best_T)\n",
        "\n",
        "# Pooling por paciente: mean y top-k mean\n",
        "VAL_MEAN   = pool_patient_mean(val_slices_T)\n",
        "VAL_TOPK   = pool_patient_topk_mean(val_slices_T, k=5)\n",
        "TEST_MEAN  = pool_patient_mean(test_slices_T)\n",
        "TEST_TOPK  = pool_patient_topk_mean(test_slices_T, k=5)\n",
        "\n",
        "# 4) Elegir umbral por recall en VAL (elige set: mean o top-k)\n",
        "val_choice = VAL_TOPK    # ← usa TOP-K; si prefieres mean, cambia aquí\n",
        "thr = choose_threshold_by_recall(val_choice[\"y_true\"].values, val_choice[\"y_score\"].values, recall_floor=0.90)\n",
        "print(f\"🎯 Umbral elegido (VAL, recall≥0.90): thr={thr:.4f}\")\n",
        "\n",
        "def compute_metrics(y, p, thr):\n",
        "    yhat = (p>=thr).astype(int)\n",
        "    return {\n",
        "        \"AUC\":   float(roc_auc_score(y, p)) if len(np.unique(y))>1 else float('nan'),\n",
        "        \"PR-AUC\":float(average_precision_score(y, p)) if len(np.unique(y))>1 else float('nan'),\n",
        "        \"Acc\":   float(accuracy_score(y, yhat)),\n",
        "        \"P\":     float(precision_score(y, yhat, zero_division=0)),\n",
        "        \"R\":     float(recall_score(y, yhat, zero_division=0)),\n",
        "        \"thr\":   float(thr),\n",
        "        \"n\":     int(len(y)),\n",
        "    }\n",
        "\n",
        "VAL_MET  = compute_metrics(VAL_TOPK[\"y_true\"].values,  VAL_TOPK[\"y_score\"].values,  thr)\n",
        "TEST_MET = compute_metrics(TEST_TOPK[\"y_true\"].values, TEST_TOPK[\"y_score\"].values, thr)\n",
        "print(\"VAL :\", VAL_MET)\n",
        "print(\"TEST:\", TEST_MET)\n",
        "\n",
        "# Guardar CSVs y JSON de evaluación\n",
        "val_slices_T.to_csv(OUT_DIR/\"val_slice_preds_plus.csv\", index=False)\n",
        "test_slices_T.to_csv(OUT_DIR/\"test_slice_preds_plus.csv\", index=False)\n",
        "VAL_TOPK.to_csv(OUT_DIR/\"val_patient_preds_plus.csv\", index=False)\n",
        "TEST_TOPK.to_csv(OUT_DIR/\"test_patient_preds_plus.csv\", index=False)\n",
        "\n",
        "eval_json = {\n",
        "  \"pipeline\": \"ft_effb3_stable_plus\",\n",
        "  \"seeds\": cfg.seeds,\n",
        "  \"temperature\": float(best_T),\n",
        "  \"pooling_used\": \"topk_mean_k5\",\n",
        "  \"threshold\": float(thr),\n",
        "  \"val_metrics\": VAL_MET,\n",
        "  \"test_metrics\": TEST_MET,\n",
        "}\n",
        "with open(OUT_DIR/\"patient_eval_plus.json\",\"w\") as f:\n",
        "    json.dump(eval_json, f, indent=2)\n",
        "\n",
        "print(\"📁 Resultados guardados en:\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w93QYeV26IVz",
        "outputId": "a5d61cd6-fcb1-4fbe-c23a-b8f09bdb0d2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b3_ns to current tf_efficientnet_b3.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Temperature scaling ajustado en HOLDOUT: T=3.8625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Umbral elegido (VAL, recall≥0.90): thr=0.0000\n",
            "VAL : {'AUC': 0.9074074074074074, 'PR-AUC': 0.9200849012306183, 'Acc': 0.425531914893617, 'P': 0.425531914893617, 'R': 1.0, 'thr': 0.0, 'n': 47}\n",
            "TEST: {'AUC': 0.7388888888888888, 'PR-AUC': 0.6987755736478632, 'Acc': 0.425531914893617, 'P': 0.425531914893617, 'R': 1.0, 'thr': 0.0, 'n': 47}\n",
            "📁 Resultados guardados en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 9: Gráficas (AUC/PR-AUC barras, punto (P,R) y matriz de confusión)\n",
        "\n",
        "def save_bar(value, title, fname, ymax=1.0):\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.bar([title], [value])\n",
        "    plt.ylim(0, ymax)\n",
        "    plt.title(title)\n",
        "    plt.grid(True, axis='y', linestyle='--', alpha=0.4)\n",
        "    out = GRAPHS_DIR / fname\n",
        "    plt.tight_layout(); plt.savefig(out, dpi=150); plt.close()\n",
        "\n",
        "def save_pr_point(precision, recall, fname):\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.scatter([recall], [precision], s=80)\n",
        "    plt.xlim(0,1); plt.ylim(0,1)\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Punto PR (TEST)\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.4)\n",
        "    out = GRAPHS_DIR / fname\n",
        "    plt.tight_layout(); plt.savefig(out, dpi=150); plt.close()\n",
        "\n",
        "def save_confusion(y_true, y_score, thr, fname):\n",
        "    yhat = (y_score>=thr).astype(int)\n",
        "    cm = confusion_matrix(y_true, yhat, labels=[1,0]) # [[TP, FN],[FP, TN]] si ordenas [1,0]\n",
        "    TP, FN = cm[0,0], cm[0,1]\n",
        "    FP, TN = cm[1,0], cm[1,1]\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(cm, cmap=\"Blues\")\n",
        "    plt.title(f\"Confusión TEST (thr={thr:.3f})\")\n",
        "    plt.xticks([0,1], [\"Pred 1\",\"Pred 0\"])\n",
        "    plt.yticks([0,1], [\"Real 1\",\"Real 0\"])\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"black\", fontsize=12)\n",
        "    out = GRAPHS_DIR / fname\n",
        "    plt.tight_layout(); plt.savefig(out, dpi=150); plt.close()\n",
        "    return TP, FP, TN, FN\n",
        "\n",
        "# Barras\n",
        "save_bar(TEST_MET[\"AUC\"],    \"ROC-AUC (TEST)\", \"plus_bars_auc.png\")\n",
        "save_bar(TEST_MET[\"PR-AUC\"], \"PR-AUC (TEST)\",  \"plus_bars_prauc.png\")\n",
        "\n",
        "# Punto PR\n",
        "save_pr_point(TEST_MET[\"P\"], TEST_MET[\"R\"], \"plus_pr_point.png\")\n",
        "\n",
        "# Matriz de confusión TEST\n",
        "TP, FP, TN, FN = save_confusion(TEST_TOPK[\"y_true\"].values, TEST_TOPK[\"y_score\"].values, TEST_MET[\"thr\"], \"plus_confusion.png\")\n",
        "print(f\"✅ Matriz de confusión TEST reconstruida: TP={TP}, FP={FP}, TN={TN}, FN={FN}\")\n",
        "print(\"🖼️ Gráficas guardadas en:\", GRAPHS_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4tt7UlE7UCU",
        "outputId": "c66b9c98-7da9-4441-a88f-afc751294326"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Matriz de confusión TEST reconstruida: TP=20, FP=27, TN=0, FN=0\n",
            "🖼️ Gráficas guardadas en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/graphs_from_metrics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda 10: Resumen final impreso ---\n",
        "def pretty(d):\n",
        "    return {k:(round(v,3) if isinstance(v,float) else v) for k,v in d.items()}\n",
        "\n",
        "print(\"📦 Pipeline: ft_effb3_stable_colab\")\n",
        "print(\"🧪 Pooling:\", eval_json[\"pooling_used\"], \"| T:\", round(eval_json[\"temperature\"],3), \"| thr:\", round(eval_json[\"threshold\"],4))\n",
        "print(\"VAL :\", pretty(eval_json[\"val_metrics\"]))\n",
        "print(\"TEST:\", pretty(eval_json[\"test_metrics\"]))\n",
        "print(\"CSV :\", OUT_DIR / \"val_patient_preds_calibrated.csv\", \" | \", OUT_DIR / \"test_patient_preds_calibrated.csv\")\n",
        "print(\"JSON:\", OUT_DIR / \"effb3_stable_patient_eval.json\")\n",
        "print(\"📁 Gráficas:\", GRAPHS_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWhISCYe89Ac",
        "outputId": "e02d3a60-26eb-44e9-b4c4-e8bbee57e7a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Pipeline: ft_effb3_stable_colab\n",
            "🧪 Pooling: topk_mean_k5 | T: 3.863 | thr: 0.0\n",
            "VAL : {'AUC': 0.907, 'PR-AUC': 0.92, 'Acc': 0.426, 'P': 0.426, 'R': 1.0, 'thr': 0.0, 'n': 47}\n",
            "TEST: {'AUC': 0.739, 'PR-AUC': 0.699, 'Acc': 0.426, 'P': 0.426, 'R': 1.0, 'thr': 0.0, 'n': 47}\n",
            "CSV : /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/val_patient_preds_calibrated.csv  |  /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/test_patient_preds_calibrated.csv\n",
            "JSON: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_stable_patient_eval.json\n",
            "📁 Gráficas: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/graphs_from_metrics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Celda de robustez de checkpoints para la Fase PLUS ---\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "\n",
        "# Directorios\n",
        "OUT_DIR_PLUS   = BASE / \"ft_effb3_stable_colab_plus\"\n",
        "OUT_DIR_STABLE = BASE / \"ft_effb3_stable_colab\"\n",
        "OUT_DIR_PLUS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Candidatos de checkpoint\n",
        "ckpt_name_best   = \"best_effb3_stable.pth\"\n",
        "ckpt_name_seed42 = \"effb3_stable_seed42.pth\"\n",
        "\n",
        "CKPT_BEST_PLUS   = OUT_DIR_PLUS / ckpt_name_best\n",
        "CKPT_BEST_STABLE = OUT_DIR_STABLE / ckpt_name_best\n",
        "CKPT_SEED42      = OUT_DIR_STABLE / ckpt_name_seed42\n",
        "\n",
        "# 1) Si ya existe en PLUS, perfecto\n",
        "if CKPT_BEST_PLUS.exists():\n",
        "    CKPT_BEST = CKPT_BEST_PLUS\n",
        "    src_used = \"PLUS (ya estaba)\"\n",
        "# 2) Si no existe en PLUS pero sí en STABLE, copiamos\n",
        "elif CKPT_BEST_STABLE.exists():\n",
        "    shutil.copy2(CKPT_BEST_STABLE, CKPT_BEST_PLUS)\n",
        "    CKPT_BEST = CKPT_BEST_PLUS\n",
        "    src_used = f\"COPIADO desde STABLE → {CKPT_BEST_STABLE.name}\"\n",
        "# 3) Si no hay 'best' pero sí tenemos el de seed42, lo usamos directamente\n",
        "elif CKPT_SEED42.exists():\n",
        "    CKPT_BEST = CKPT_SEED42\n",
        "    src_used = \"SEED42 en STABLE (no había best)\"\n",
        "# 4) Si no hay nada, error guiado\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"❌ No encontré ningún checkpoint.\\n\"\n",
        "        f\"Busqué en:\\n - {CKPT_BEST_PLUS}\\n - {CKPT_BEST_STABLE}\\n - {CKPT_SEED42}\\n\"\n",
        "        \"Soluciones:\\n - Reejecuta la celda de entrenamiento para generar el checkpoint\\n\"\n",
        "        \" - O ajusta manualmente CKPT_BEST al path correcto si lo tienes en otra carpeta.\"\n",
        "    )\n",
        "\n",
        "# Rutas de salida y gráficos para la fase PLUS\n",
        "GRAPHS_DIR = OUT_DIR_PLUS / \"graphs_from_metrics\"\n",
        "GRAPHS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"✅ Checkpoint listo para inferencia/calibración\")\n",
        "print(f\"   Fuente: {src_used}\")\n",
        "print(f\"   CKPT_BEST = {CKPT_BEST}\")\n",
        "print(f\"   GRAPHS_DIR = {GRAPHS_DIR}\")\n",
        "\n",
        "# (Opcional) Validación adicional si quieres asegurar tamaño > 0\n",
        "assert CKPT_BEST.exists() and CKPT_BEST.stat().st_size > 0, \"Checkpoint vacío o corrupto.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69l5UaBa_6Ay",
        "outputId": "d7b40d8f-9375-4f4c-c5a6-d85f6d5bd06e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Checkpoint listo para inferencia/calibración\n",
            "   Fuente: COPIADO desde STABLE → best_effb3_stable.pth\n",
            "   CKPT_BEST = /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/best_effb3_stable.pth\n",
            "   GRAPHS_DIR = /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/graphs_from_metrics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda A: inspeccionar checkpoint\n",
        "import torch, os, json\n",
        "from pathlib import Path\n",
        "\n",
        "CKPT_BEST = Path(\"/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/best_effb3_stable.pth\")\n",
        "assert CKPT_BEST.exists(), f\"No existe: {CKPT_BEST}\"\n",
        "\n",
        "ckpt = torch.load(CKPT_BEST, map_location=\"cpu\")\n",
        "print(\"Claves checkpoint:\", list(ckpt.keys()))\n",
        "state = ckpt.get(\"model\", ckpt)  # por si guardaste dict con {\"model\": sd, \"epoch\":..., etc.}\n",
        "print(\"Total de pesos en state_dict:\", len(state))\n",
        "# Vista rápida de algunas claves\n",
        "for k in list(state.keys())[:12]:\n",
        "    print(\" \", k)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgQMM_ifDcd1",
        "outputId": "14e8ee79-f379-4c48-ccea-5eeeccf8efd7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claves checkpoint: ['seed', 'state_dict', 'best_holdout_auc']\n",
            "Total de pesos en state_dict: 3\n",
            "  seed\n",
            "  state_dict\n",
            "  best_holdout_auc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda B: probar variantes de arch y reportar % de pesos cargados\n",
        "import timm, torch, re\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "state = ckpt.get(\"model\", ckpt)\n",
        "\n",
        "def build_model(arch_name, num_out=1, drop=0.2):\n",
        "    # num_out=1 para BCEWithLogits; si tu training fue con CE a 2 clases, pon num_out=2\n",
        "    m = timm.create_model(arch_name, pretrained=False, num_classes=num_out, drop_rate=drop)\n",
        "    return m\n",
        "\n",
        "def try_load(arch_name, num_out):\n",
        "    m = build_model(arch_name, num_out=num_out).to(device)\n",
        "    missing, unexpected = m.load_state_dict(state, strict=False)\n",
        "    n_total = sum(1 for _ in m.state_dict().keys())\n",
        "    n_loaded = n_total - len(missing)\n",
        "    print(f\"ARCH={arch_name:<35} | loaded≈{n_loaded/n_total:5.1%} | missing={len(missing):3d} | unexpected={len(unexpected):3d}\")\n",
        "    return arch_name, m, missing, unexpected, n_loaded/n_total\n",
        "\n",
        "# INTENTOS más probables (ajusta num_out si entrenaste a 2 clases)\n",
        "CANDIDATES = [\n",
        "    \"tf_efficientnet_b3.ns_jft_in1k\",\n",
        "    \"tf_efficientnet_b3.ns_in1k\",\n",
        "    \"tf_efficientnet_b3.in1k\",\n",
        "    \"tf_efficientnet_b3\",\n",
        "    \"efficientnet_b3\"\n",
        "]\n",
        "results = []\n",
        "for arch in CANDIDATES:\n",
        "    try:\n",
        "        results.append(try_load(arch, num_out=1))\n",
        "    except Exception as e:\n",
        "        print(f\"  ✖ {arch}: {e}\")\n",
        "\n",
        "# escoge el que más cargue (≥95% ideal; ≥70% aceptable)\n",
        "best = max(results, key=lambda t: t[-1])\n",
        "best_arch, best_model, missing, unexpected, ratio = best\n",
        "print(\"\\n→ Mejor match:\", best_arch, \"| ratio cargado:\", f\"{ratio:.1%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO9XQ-20Df1u",
        "outputId": "8e8386c7-f1a0-4099-8365-b5d6852efd9c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARCH=tf_efficientnet_b3.ns_jft_in1k      | loaded≈13.6% | missing=496 | unexpected=  3\n",
            "  ✖ tf_efficientnet_b3.ns_in1k: Invalid pretrained tag (ns_in1k) for tf_efficientnet_b3.\n",
            "ARCH=tf_efficientnet_b3.in1k             | loaded≈13.6% | missing=496 | unexpected=  3\n",
            "ARCH=tf_efficientnet_b3                  | loaded≈13.6% | missing=496 | unexpected=  3\n",
            "ARCH=efficientnet_b3                     | loaded≈13.6% | missing=496 | unexpected=  3\n",
            "\n",
            "→ Mejor match: tf_efficientnet_b3.ns_jft_in1k | ratio cargado: 13.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda C (reparada): normalizar un checkpoint y dejarlo listo para inferencia estable\n",
        "\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import re\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === RUTAS ===\n",
        "# Si tu mejor ckpt está en la carpeta \"stable_colab\":\n",
        "CKPT_IN  = Path(\"/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab/effb3_stable_seed42.pth\")\n",
        "# Alternativa (pipeline 7, por si lo anterior no existe):\n",
        "if not CKPT_IN.exists():\n",
        "    CKPT_IN = Path(\"/content/drive/MyDrive/CognitivaAI/ft_effb3_colab/best_ft_effb3.pth\")\n",
        "\n",
        "OUT_DIR  = Path(\"/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CKPT_OUT = OUT_DIR / \"best_effb3_stable.pth\"\n",
        "\n",
        "# === Definición del modelo (debe coincidir con el que entrenaste) ===\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "\n",
        "class EffB3Binary(nn.Module):\n",
        "    def __init__(self, pretrained=False, arch=\"tf_efficientnet_b3.ns_jft_in1k\", num_out=1):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(arch, pretrained=pretrained, num_classes=0)  # feature extractor\n",
        "        self.head = nn.Linear(self.backbone.num_features, num_out)\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)\n",
        "        return self.head(feat).squeeze(1)  # logits\n",
        "\n",
        "arch = \"tf_efficientnet_b3.ns_jft_in1k\"\n",
        "num_out = 1\n",
        "model = EffB3Binary(pretrained=False, arch=arch, num_out=num_out).to(device)\n",
        "\n",
        "def load_raw_ckpt(path):\n",
        "    ckpt = torch.load(path, map_location=\"cpu\")\n",
        "    # Algunos ckpts guardados como dict con 'state_dict', otros como state_dict plano\n",
        "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
        "        sd = ckpt[\"state_dict\"]\n",
        "        meta = {k:v for k,v in ckpt.items() if k != \"state_dict\"}\n",
        "    else:\n",
        "        sd = ckpt\n",
        "        meta = {}\n",
        "    return sd, meta\n",
        "\n",
        "def try_prefix_remap(sd_in, want_prefix=\"backbone.\"):\n",
        "    \"\"\"\n",
        "    Normaliza prefijos:\n",
        "      - si las claves vienen como 'blocks.*', añade 'backbone.' -> 'backbone.blocks.*'\n",
        "      - si ya vienen como 'backbone.blocks.*', las deja igual\n",
        "      - re-mapea 'classifier' o 'fc' a 'head' si procede\n",
        "    \"\"\"\n",
        "    sd_out = OrderedDict()\n",
        "    for k,v in sd_in.items():\n",
        "        newk = k\n",
        "\n",
        "        # Mapeos comunes de nombre de cabeza\n",
        "        newk = re.sub(r\"^(classifier|fc)\\.(weight|bias)$\", r\"head.\\1\", newk)\n",
        "\n",
        "        # Si no lleva backbone. y empieza por blocks, añadirlo\n",
        "        if newk.startswith(\"blocks.\") and not newk.startswith(\"backbone.\"):\n",
        "            newk = \"backbone.\" + newk\n",
        "        # Si claves internas del backbone a veces vienen como 'conv_stem.', 'bn1.', etc.\n",
        "        if (newk.startswith(\"conv_stem.\") or newk.startswith(\"bn1.\") or newk.startswith(\"act1.\")\n",
        "            or newk.startswith(\"blocks.\") or newk.startswith(\"conv_head.\") or newk.startswith(\"bn2.\")):\n",
        "            if not newk.startswith(\"backbone.\"):\n",
        "                newk = \"backbone.\" + newk\n",
        "\n",
        "        sd_out[newk] = v\n",
        "    return sd_out\n",
        "\n",
        "def load_with_flexible_mapping(model, sd_in):\n",
        "    model_sd = model.state_dict()\n",
        "    mapped = try_prefix_remap(sd_in)\n",
        "\n",
        "    # Filtra solo las claves que existen en el modelo y coinciden en tamaño\n",
        "    loadable = OrderedDict()\n",
        "    missing, shape_mismatch, unexpected = [], [], []\n",
        "    for k, v in mapped.items():\n",
        "        if k in model_sd:\n",
        "            if tuple(v.shape) == tuple(model_sd[k].shape):\n",
        "                loadable[k] = v\n",
        "            else:\n",
        "                shape_mismatch.append(k)\n",
        "        else:\n",
        "            unexpected.append(k)\n",
        "\n",
        "    # Qué nos falta del modelo\n",
        "    for k in model_sd.keys():\n",
        "        if k not in loadable:\n",
        "            missing.append(k)\n",
        "\n",
        "    ratio = len(loadable) / max(1, len(model_sd))\n",
        "    msg = (\n",
        "        f\"Carga parcial: loaded≈{ratio*100:.1f}%\\n\"\n",
        "        f\"  (ejemplos missing) {missing[:5]}\\n\"\n",
        "        f\"  (ejemplos unexpected en ckpt) {unexpected[:5]}\"\n",
        "    )\n",
        "    print(msg)\n",
        "\n",
        "    model_sd.update(loadable)\n",
        "    model.load_state_dict(model_sd, strict=False)\n",
        "    return ratio, missing, unexpected, shape_mismatch\n",
        "\n",
        "# --- Ejecutar normalización ---\n",
        "print(f\"Intentando normalizar ckpt: {CKPT_IN}\")\n",
        "sd_in, meta = load_raw_ckpt(CKPT_IN)\n",
        "ratio, missing, unexpected, mism = load_with_flexible_mapping(model, sd_in)\n",
        "\n",
        "if ratio < 0.70:\n",
        "    raise RuntimeError(\n",
        "        f\"Muy pocos pesos cargados ({ratio*100:.1f}%). \"\n",
        "        f\"Revisa que CKPT_IN apunte a TU checkpoint entrenado con esta misma arch+head \"\n",
        "        f\"o apunta a /ft_effb3_colab/best_ft_effb3.pth si ese es el bueno.\"\n",
        "    )\n",
        "\n",
        "# Guardar ckpt limpio con metadatos\n",
        "clean = {\n",
        "    \"arch\": arch,\n",
        "    \"num_out\": num_out,\n",
        "    \"state_dict\": model.state_dict(),\n",
        "    \"meta\": {\n",
        "        \"source\": str(CKPT_IN),\n",
        "        **meta\n",
        "    }\n",
        "}\n",
        "torch.save(clean, CKPT_OUT)\n",
        "print(f\"✅ Checkpoint limpio guardado en: {CKPT_OUT}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abbd2pEEDkb8",
        "outputId": "84190eee-eea1-4d65-abe6-618daf7170a9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intentando normalizar ckpt: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab/effb3_stable_seed42.pth\n",
            "Carga parcial: loaded≈99.7%\n",
            "  (ejemplos missing) ['head.weight', 'head.bias']\n",
            "  (ejemplos unexpected en ckpt) ['head.classifier']\n",
            "✅ Checkpoint limpio guardado en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/best_effb3_stable.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda D (reparada): inferencia estable con el ckpt limpio\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === RUTAS (ajusta si usaste otras) ===\n",
        "BASE_DIR   = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "DATA_DIR   = BASE_DIR / \"oas1_data\"\n",
        "OUT_DIR    = BASE_DIR / \"ft_effb3_stable_colab_plus\"\n",
        "CKPT_BEST  = OUT_DIR / \"best_effb3_stable.pth\"\n",
        "GRAPHS_DIR = OUT_DIR / \"graphs_from_metrics\"\n",
        "GRAPHS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "VAL_MAP   = DATA_DIR / \"oas1_val_colab_mapped.csv\"\n",
        "TEST_MAP  = DATA_DIR / \"oas1_test_colab_mapped.csv\"\n",
        "\n",
        "assert CKPT_BEST.exists(), f\"❌ No existe checkpoint limpio: {CKPT_BEST}\"\n",
        "assert VAL_MAP.exists() and TEST_MAP.exists(), \"❌ Faltan CSV mapeados val/test\"\n",
        "\n",
        "# === Modelo ===\n",
        "class EffB3Binary(nn.Module):\n",
        "    def __init__(self, pretrained=False, arch=\"tf_efficientnet_b3.ns_jft_in1k\", num_out=1):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(arch, pretrained=pretrained, num_classes=0)\n",
        "        self.head = nn.Linear(self.backbone.num_features, num_out)\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)\n",
        "        return self.head(feat).squeeze(1)\n",
        "\n",
        "ckpt = torch.load(CKPT_BEST, map_location=\"cpu\")\n",
        "arch = ckpt.get(\"arch\", \"tf_efficientnet_b3.ns_jft_in1k\")\n",
        "num_out = ckpt.get(\"num_out\", 1)\n",
        "\n",
        "model = EffB3Binary(pretrained=False, arch=arch, num_out=num_out).to(device)\n",
        "model.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
        "model.eval()\n",
        "\n",
        "# === Data utils (mismo formato que tenías) ===\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "MEAN=(0.485,0.456,0.406)\n",
        "STD =(0.229,0.224,0.225)\n",
        "IMG_SIZE=300\n",
        "\n",
        "tx = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "def read_df(mapped_csv):\n",
        "    df = pd.read_csv(mapped_csv)\n",
        "    # Estandarizar nombre de columnas si vinieran distintas\n",
        "    colmap = {\"target\":\"y_true\", \"label\":\"y_true\", \"y\": \"y_true\", \"png\":\"png_path\", \"path\":\"png_path\"}\n",
        "    for k,v in colmap.items():\n",
        "        if k in df.columns and v not in df.columns:\n",
        "            df[v] = df[k]\n",
        "    keep = [\"patient_id\",\"y_true\",\"png_path\"]\n",
        "    return df[keep].copy()\n",
        "\n",
        "val_df  = read_df(VAL_MAP)\n",
        "test_df = read_df(TEST_MAP)\n",
        "\n",
        "def infer_df(df, batch=64):\n",
        "    # por slices\n",
        "    xs, ys, pids = [], [], []\n",
        "    paths = df[\"png_path\"].tolist()\n",
        "    labs  = df[\"y_true\"].tolist()\n",
        "    pidsl = df[\"patient_id\"].tolist()\n",
        "\n",
        "    logits_all = []\n",
        "    with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
        "        for i in tqdm(range(0, len(paths), batch), desc=\"Inferencia slices\"):\n",
        "            batch_imgs=[]\n",
        "            for p in paths[i:i+batch]:\n",
        "                im = Image.open(p).convert(\"RGB\")\n",
        "                batch_imgs.append(tx(im))\n",
        "            x = torch.stack(batch_imgs).to(device)\n",
        "            logit = model(x)\n",
        "            logits_all.append(logit.detach().float().cpu())\n",
        "    logits_all = torch.cat(logits_all, dim=0).numpy()\n",
        "\n",
        "    df_out = pd.DataFrame({\n",
        "        \"patient_id\": pidsl,\n",
        "        \"y_true\": labs,\n",
        "        \"logits\": logits_all  # 1-D\n",
        "    })\n",
        "    # pooling paciente (mean de logits → proba vía sigmoid)\n",
        "    g = df_out.groupby(\"patient_id\")\n",
        "    pooled = g.agg(\n",
        "        y_true=(\"y_true\", lambda v: int(np.round(np.mean(v)))),\n",
        "        logit=(\"logits\", np.mean)\n",
        "    ).reset_index()\n",
        "    pooled[\"y_score\"] = 1/(1+np.exp(-pooled[\"logit\"]))\n",
        "    return df_out, pooled\n",
        "\n",
        "val_slices, val_pat = infer_df(val_df)\n",
        "test_slices, test_pat = infer_df(test_df)\n",
        "\n",
        "# === Selección de umbral: F1 en HOLDOUT (usa tu holdout si lo tienes persistido; si no, usa VAL) ===\n",
        "def find_best_thr_by_f1(df_pat):\n",
        "    y = df_pat[\"y_true\"].values\n",
        "    s = df_pat[\"y_score\"].values\n",
        "    thrs = np.linspace(0.05, 0.95, 19)\n",
        "    best = (0.0, 0.5)\n",
        "    from sklearn.metrics import f1_score\n",
        "    for t in thrs:\n",
        "        f1 = f1_score(y, (s>=t).astype(int))\n",
        "        if f1>best[0]:\n",
        "            best = (f1, t)\n",
        "    return best[1]\n",
        "\n",
        "thr = find_best_thr_by_f1(val_pat)  # si tienes holdout_pat usa ese DF aquí\n",
        "print(f\"🧪 Pooling=mean | Umbral (val F1-opt)={thr:.4f}\")\n",
        "\n",
        "def metrics(df_pat, thr):\n",
        "    y = df_pat[\"y_true\"].values\n",
        "    s = df_pat[\"y_score\"].values\n",
        "    yhat = (s>=thr).astype(int)\n",
        "    out = {\n",
        "        \"AUC\": float(roc_auc_score(y,s)) if len(np.unique(y))>1 else np.nan,\n",
        "        \"PR-AUC\": float(average_precision_score(y,s)),\n",
        "        \"Acc\": float(accuracy_score(y,yhat)),\n",
        "        \"P\": float(precision_score(y,yhat, zero_division=0)),\n",
        "        \"R\": float(recall_score(y,yhat)),\n",
        "        \"thr\": float(thr),\n",
        "        \"n\": int(len(y))\n",
        "    }\n",
        "    return out\n",
        "\n",
        "m_val  = metrics(val_pat, thr)\n",
        "m_test = metrics(test_pat, thr)\n",
        "print(\"VAL :\", m_val)\n",
        "print(\"TEST:\", m_test)\n",
        "\n",
        "# === Guardados ===\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "val_slices.to_csv(OUT_DIR/\"val_png_preds.csv\", index=False)\n",
        "test_slices.to_csv(OUT_DIR/\"test_png_preds.csv\", index=False)\n",
        "val_pat.to_csv(OUT_DIR/\"val_patient_preds.csv\", index=False)\n",
        "test_pat.to_csv(OUT_DIR/\"test_patient_preds.csv\", index=False)\n",
        "\n",
        "EVAL_JSON = OUT_DIR / \"effb3_stable_patient_eval.json\"\n",
        "with open(EVAL_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\"pooling_used\":\"mean\", \"thr\":thr, \"val_metrics\":m_val, \"test_metrics\":m_test}, f, indent=2)\n",
        "\n",
        "print(f\"📝 Eval JSON guardado en: {EVAL_JSON}\")\n",
        "print(f\"📁 CSV guardados en: {OUT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLraTHqhELlW",
        "outputId": "b4c1cc94-4e75-4856-d29f-730f62eafbb5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencia slices: 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
            "/tmp/ipython-input-4109008144.py:100: FutureWarning: The provided callable <function mean at 0x7c8868b4dc60> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "  pooled = g.agg(\n",
            "Inferencia slices: 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Pooling=mean | Umbral (val F1-opt)=0.5000\n",
            "VAL : {'AUC': 0.6296296296296295, 'PR-AUC': 0.6673015670022289, 'Acc': 0.5106382978723404, 'P': 0.46153846153846156, 'R': 0.9, 'thr': 0.49999999999999994, 'n': 47}\n",
            "TEST: {'AUC': 0.5462962962962963, 'PR-AUC': 0.5262250795839319, 'Acc': 0.5319148936170213, 'P': 0.4666666666666667, 'R': 0.7, 'thr': 0.49999999999999994, 'n': 47}\n",
            "📝 Eval JSON guardado en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_stable_patient_eval.json\n",
            "📁 CSV guardados en: /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/tmp/ipython-input-4109008144.py:100: FutureWarning: The provided callable <function mean at 0x7c8868b4dc60> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "  pooled = g.agg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# E1: calibración (T) en holdout + sweep de umbral y pooling alternativos\n",
        "import json, os\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, accuracy_score\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus\")\n",
        "VAL_CSV  = BASE/\"val_patient_preds.csv\"\n",
        "TEST_CSV = BASE/\"test_patient_preds.csv\"\n",
        "assert VAL_CSV.exists() and TEST_CSV.exists(), \"Faltan CSV patient preds.\"\n",
        "\n",
        "def _ensure_cols(df):\n",
        "    # Acepta columnas 'logits' o 'y_score'; si solo hay 'y_score', lo tratamos como logits~score para T=1\n",
        "    if 'logits' in df.columns:\n",
        "        return df.rename(columns={'logits':'logits_raw'})\n",
        "    elif 'y_score' in df.columns:\n",
        "        df = df.rename(columns={'y_score':'logits_raw'})\n",
        "        # Si eran probabilidades, clip para evitar infs al logit\n",
        "        eps = 1e-6\n",
        "        p = np.clip(df['logits_raw'].values.astype(float), eps, 1-eps)\n",
        "        df['logits_raw'] = np.log(p/(1-p))\n",
        "        return df\n",
        "    else:\n",
        "        raise ValueError(\"CSV debe tener 'logits' o 'y_score'.\")\n",
        "\n",
        "val = _ensure_cols(pd.read_csv(VAL_CSV))\n",
        "tes = _ensure_cols(pd.read_csv(TEST_CSV))\n",
        "\n",
        "# --- pooling alternativos sobre slices ya agregados por paciente (si tu CSV ya es por paciente, saltará tal cual):\n",
        "# Si tienes por-slice en otros CSV, aquí podrías agrupar por patient_id aplicando mean/median/topk previamente.\n",
        "# Asumimos que estos CSV ya son nivel paciente con una fila por paciente.\n",
        "\n",
        "y_val = val['y_true'].astype(int).values\n",
        "z_val = val['logits_raw'].values  # \"logits\" no calibrados\n",
        "y_tes = tes['y_true'].astype(int).values\n",
        "z_tes = tes['logits_raw'].values\n",
        "\n",
        "def sigmoid(x): return 1/(1+np.exp(-x))\n",
        "\n",
        "# ---- Estimate Temperature T on holdout by minimizing NLL (simple grid for robustness)\n",
        "def est_temperature(z, y, grid=np.linspace(0.5, 3.5, 61)):\n",
        "    bestT, bestNLL = 1.0, 1e9\n",
        "    for T in grid:\n",
        "        p = sigmoid(z / T)\n",
        "        eps = 1e-8\n",
        "        nll = -np.mean(y*np.log(p+eps) + (1-y)*np.log(1-p+eps))\n",
        "        if nll < bestNLL:\n",
        "            bestNLL, bestT = nll, T\n",
        "    return bestT\n",
        "\n",
        "T = est_temperature(z_val, y_val)\n",
        "p_val = sigmoid(z_val / T)\n",
        "p_tes = sigmoid(z_tes / T)\n",
        "\n",
        "# ---- Sweep de umbral maximizando PR-AUC y alternativas clínicas\n",
        "def eval_at_thr(y, p, thr):\n",
        "    yhat = (p>=thr).astype(int)\n",
        "    return {\n",
        "        \"Acc\": accuracy_score(y, yhat),\n",
        "        \"P\":   ( (yhat[yhat==1].size and (y[yhat==1]==1).sum()/yhat.sum()) or 0.0 ),\n",
        "        \"R\":   ( (y[y==1].size and (y[(y==1)&(yhat==1)]==1).sum()/ (y==1).sum()) or 0.0 )\n",
        "    }\n",
        "\n",
        "def full_metrics(y, p):\n",
        "    auc    = roc_auc_score(y, p)\n",
        "    prauc  = average_precision_score(y, p)\n",
        "    # thr por F1-opt:\n",
        "    prec, rec, thr = precision_recall_curve(y, p)\n",
        "    f1 = (2*prec*rec)/(prec+rec+1e-9)\n",
        "    i  = np.argmax(f1)\n",
        "    thr_f1 = (thr[i-1] if i>0 and i-1 < len(thr) else 0.5)\n",
        "    return auc, prauc, float(thr_f1)\n",
        "\n",
        "auc_val, pr_val, thr_f1_val = full_metrics(y_val, p_val)\n",
        "\n",
        "# Opción clínica: forzar Recall >= 0.9\n",
        "def thr_for_recall(y, p, recall_target=0.90):\n",
        "    prec, rec, thr = precision_recall_curve(y, p)\n",
        "    idx = np.where(rec>=recall_target)[0]\n",
        "    if len(idx)==0:\n",
        "        return None\n",
        "    j = idx[0]\n",
        "    return thr[j-1] if j>0 else 0.0\n",
        "\n",
        "thr_rec09 = thr_for_recall(y_val, p_val, 0.90)\n",
        "thr_use   = thr_rec09 if thr_rec09 is not None else thr_f1_val\n",
        "\n",
        "val_sum = {\"AUC\":auc_val, \"PR-AUC\":pr_val, \"thr\":thr_use, **eval_at_thr(y_val, p_val, thr_use), \"n\":int(len(y_val))}\n",
        "tes_sum = {\"AUC\":roc_auc_score(y_tes,p_tes), \"PR-AUC\":average_precision_score(y_tes,p_tes), \"thr\":thr_use, **eval_at_thr(y_tes, p_tes, thr_use), \"n\":int(len(y_tes))}\n",
        "\n",
        "print(f\"🧪 T estimada en holdout: {T:.3f} | thr usado: {thr_use:.4f} (rec≥0.90? {'sí' if thr_use==thr_rec09 else 'no'})\")\n",
        "print(\"VAL :\", {k:(float(v) if hasattr(v, \"__float__\") else v) for k,v in val_sum.items()})\n",
        "print(\"TEST:\", {k:(float(v) if hasattr(v, \"__float__\") else v) for k,v in tes_sum.items()})\n",
        "\n",
        "# Guardar eval JSON\n",
        "out_json = BASE/\"effb3_stable_patient_eval_calibrated.json\"\n",
        "with open(out_json, \"w\") as f:\n",
        "    json.dump({\"temperature\":float(T),\"thr\":float(thr_use),\"val_metrics\":val_sum,\"test_metrics\":tes_sum}, f, indent=2)\n",
        "print(\"📝 Eval JSON (calibrado) →\", out_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFAzfgq4MLsC",
        "outputId": "4f6504da-3cb8-422d-a538-e2fb7eedc27e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 T estimada en holdout: 0.500 | thr usado: 0.0000 (rec≥0.90? sí)\n",
            "VAL : {'AUC': 0.6296296296296295, 'PR-AUC': 0.6673015670022289, 'thr': 0.0, 'Acc': 0.425531914893617, 'P': 0.425531914893617, 'R': 1.0, 'n': 47.0}\n",
            "TEST: {'AUC': 0.5462962962962963, 'PR-AUC': 0.5262250795839319, 'thr': 0.0, 'Acc': 0.425531914893617, 'P': 0.425531914893617, 'R': 1.0, 'n': 47.0}\n",
            "📝 Eval JSON (calibrado) → /content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus/effb3_stable_patient_eval_calibrated.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# E2: recomputar paciente con pooling alternativos desde CSV por slice\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_recall_curve\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI/ft_effb3_stable_colab_plus\")\n",
        "VAL_S = BASE/\"val_png_preds.csv\"\n",
        "TES_S = BASE/\"test_png_preds.csv\"\n",
        "assert VAL_S.exists() and TES_S.exists(), \"Faltan CSV por slice.\"\n",
        "\n",
        "def logits_from_score(s):\n",
        "    eps=1e-6\n",
        "    s = np.clip(s.astype(float), eps, 1-eps)\n",
        "    return np.log(s/(1-s))\n",
        "\n",
        "def pool_topk(arr, k=0.2):\n",
        "    if len(arr)==0: return np.nan\n",
        "    kk = max(1, int(np.ceil(k*len(arr))))\n",
        "    return np.mean(np.sort(arr)[-kk:])\n",
        "\n",
        "def aggregate(df_slices, pooling=\"mean\", T=None):\n",
        "    # Espera columnas: patient_id, y_true, y_score o logits\n",
        "    if \"y_score\" in df_slices.columns:\n",
        "        z = logits_from_score(df_slices[\"y_score\"].values)\n",
        "        df_slices = df_slices.copy()\n",
        "        df_slices[\"logits\"] = z\n",
        "    assert \"patient_id\" in df_slices and \"y_true\" in df_slices and \"logits\" in df_slices\n",
        "\n",
        "    if pooling==\"mean\":\n",
        "        g = df_slices.groupby(\"patient_id\").agg(\n",
        "            y_true=(\"y_true\", lambda v:int(np.round(np.mean(v)))),\n",
        "            logits=(\"logits\", \"mean\")\n",
        "        )\n",
        "    elif pooling==\"median\":\n",
        "        g = df_slices.groupby(\"patient_id\").agg(\n",
        "            y_true=(\"y_true\", lambda v:int(np.round(np.mean(v)))),\n",
        "            logits=(\"logits\", \"median\")\n",
        "        )\n",
        "    elif pooling.startswith(\"topk\"):\n",
        "        frac = float(pooling.split(\"=\")[-1]) if \"=\" in pooling else 0.2\n",
        "        g = df_slices.groupby(\"patient_id\").agg(\n",
        "            y_true=(\"y_true\", lambda v:int(np.round(np.mean(v)))),\n",
        "            logits=(\"logits\", lambda v: pool_topk(np.array(v), frac))\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"pooling desconocido\")\n",
        "    g = g.reset_index()\n",
        "    z = g[\"logits\"].values\n",
        "    p = 1/(1+np.exp(-(z if T is None else z/T)))\n",
        "    return g[\"y_true\"].values.astype(int), p\n",
        "\n",
        "def report(y, p, name):\n",
        "    auc   = roc_auc_score(y,p)\n",
        "    prauc = average_precision_score(y,p)\n",
        "    prec, rec, thr = precision_recall_curve(y,p)\n",
        "    f1 = (2*prec*rec)/(prec+rec+1e-9)\n",
        "    i  = np.argmax(f1)\n",
        "    thr_f1 = (thr[i-1] if i>0 else 0.5)\n",
        "    yhat = (p>=thr_f1).astype(int)\n",
        "    acc  = accuracy_score(y,yhat)\n",
        "    P = ((yhat.sum()>0) and ( ( (y[yhat==1]==1).sum() / yhat.sum() ) )) or 0.0\n",
        "    R = ( (y==1).sum()>0 and ((y[(y==1)&(yhat==1)]==1).sum() / (y==1).sum()) ) or 0.0\n",
        "    print(f\"{name:>14s} | AUC={auc:.3f} | PR-AUC={prauc:.3f} | Acc={acc:.3f} | P={P:.2f} | R={R:.2f} | thrF1={thr_f1:.3f}\")\n",
        "\n",
        "val_s = pd.read_csv(VAL_S)\n",
        "tes_s = pd.read_csv(TES_S)\n",
        "\n",
        "# Usa la T recién estimada en E1 si existe:\n",
        "T = None\n",
        "cal_json = BASE/\"effb3_stable_patient_eval_calibrated.json\"\n",
        "if cal_json.exists():\n",
        "    import json\n",
        "    T = json.load(open(cal_json))[\"temperature\"]\n",
        "\n",
        "for pooling in [\"mean\",\"median\",\"topk=0.2\",\"topk=0.3\"]:\n",
        "    yv,pv = aggregate(val_s, pooling=pooling, T=T)\n",
        "    yt,pt = aggregate(tes_s, pooling=pooling, T=T)\n",
        "    report(yv,pv, f\"VAL {pooling}\")\n",
        "    report(yt,pt, f\"TEST {pooling}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geZS_LvGMLo6",
        "outputId": "785c617d-4e76-4c39-ba2c-189665b9e64e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      VAL mean | AUC=0.630 | PR-AUC=0.667 | Acc=0.532 | P=0.47 | R=0.85 | thrF1=0.504\n",
            "     TEST mean | AUC=0.546 | PR-AUC=0.526 | Acc=0.511 | P=0.47 | R=1.00 | thrF1=0.491\n",
            "    VAL median | AUC=0.643 | PR-AUC=0.653 | Acc=0.574 | P=0.50 | R=0.85 | thrF1=0.503\n",
            "   TEST median | AUC=0.541 | PR-AUC=0.513 | Acc=0.532 | P=0.48 | R=1.00 | thrF1=0.492\n",
            "  VAL topk=0.2 | AUC=0.602 | PR-AUC=0.655 | Acc=0.532 | P=0.47 | R=0.85 | thrF1=0.547\n",
            " TEST topk=0.2 | AUC=0.583 | PR-AUC=0.502 | Acc=0.553 | P=0.49 | R=1.00 | thrF1=0.537\n",
            "  VAL topk=0.3 | AUC=0.607 | PR-AUC=0.658 | Acc=0.532 | P=0.47 | R=0.85 | thrF1=0.541\n",
            " TEST topk=0.3 | AUC=0.567 | PR-AUC=0.480 | Acc=0.553 | P=0.49 | R=1.00 | thrF1=0.528\n"
          ]
        }
      ]
    }
  ]
}