# üìë Informe T√©cnico ‚Äî **COGNITIVA-AI ‚Äî Detecci√≥n Temprana de Alzheimer**

## 0. Antecedentes

La **Enfermedad de Alzheimer (EA)** es neurodegenerativa y progresiva. Una detecci√≥n temprana es clave para:  
- Optimizar la atenci√≥n cl√≠nica.  
- Planificar intervenciones.  
- Reducir costes en fases avanzadas.  

## 1. Introducci√≥n General  

El presente informe constituye una documentaci√≥n exhaustiva, detallada y profundamente anal√≠tica del proyecto **CognitivaAI**, cuyo prop√≥sito ha sido explorar, dise√±ar, entrenar y evaluar modelos de aprendizaje profundo aplicados al diagn√≥stico autom√°tico de **deterioro cognitivo temprano (Alzheimer)** a partir de datos cl√≠nicos tabulares e im√°genes de resonancia magn√©tica (MRI) de la base de datos **OASIS**.  

El proyecto surge con una doble motivaci√≥n:  

1. **Cient√≠fica y social:** el diagn√≥stico temprano de enfermedades neurodegenerativas, como la enfermedad de Alzheimer, es un desaf√≠o prioritario para la medicina actual. El uso de inteligencia artificial puede ayudar a identificar biomarcadores sutiles en im√°genes cerebrales y en datos cl√≠nicos que son dif√≠ciles de detectar por m√©todos tradicionales.  

2. **T√©cnica y experimental:** comprobar hasta qu√© punto distintas arquitecturas de redes neuronales convolucionales (CNNs) y transformadores visuales pueden capturar informaci√≥n discriminativa en un dataset limitado en tama√±o, enfrent√°ndose a problemas comunes como el sobreajuste, la calibraci√≥n de probabilidades y la estabilidad en validaci√≥n y test.  

La ejecuci√≥n del proyecto ha supuesto un recorrido iterativo y progresivo, articulado en una serie de **pipelines experimentales**, cada uno dise√±ado con objetivos concretos: desde probar un modelo sencillo con datos cl√≠nicos (P1) hasta explorar ensembles de arquitecturas avanzadas (P11).  

Cada pipeline ha sido registrado con su motivaci√≥n, configuraci√≥n, incidencias, m√©tricas y reflexi√≥n cr√≠tica, con el objetivo de construir no solo un conjunto de resultados, sino un **mapa de decisiones** que documenta los aprendizajes y trade-offs a lo largo del camino.  

---

## 2. Metodolog√≠a Global  

### 2.1 Dataset y preprocesamiento  

El Alzheimer es una enfermedad neurodegenerativa cuya detecci√≥n temprana es clave.  Se espera que un enfoque multimodal permita identificar el deterioro cognitivo incipiente con alta sensibilidad, optimizando el balance entre **detecci√≥n temprana** y **falsos positivos aceptables** en un contexto de cribado.

El dataset utilizado es **OASIS** (Open Access Series of Imaging Studies) en sus cohortes OASIS-1 y OASIS-2, que incluye im√°genes de resonancia magn√©tica (MRI) estructurales de individuos con y sin deterioro cognitivo, junto con informaci√≥n cl√≠nica asociada.  

**Datasets:** OASIS-1 (transversal, 416 sujetos, 1 visita) y OASIS-2 (longitudinal, 150 sujetos, visitas m√∫ltiples). Ambas cohortes aportan im√°genes MRI cerebrales y variables demogr√°ficas/neuropsicol√≥gicas.

**Diagn√≥stico binario:** Demented vs Nondemented (OASIS-2: variable Group; OASIS-1: CDR > 0 como demencia).

**Variables cl√≠nico-demogr√°ficas:** Edad, Sexo, A√±os de educaci√≥n, Nivel socioecon√≥mico (SES), MMSE, CDR, eTIV, nWBV, ASF.
- **Age**: Edad del paciente. Predictor fuerte de riesgo.  
- **Sex**: Diferencias epidemiol√≥gicas en prevalencia.  
- **Educ**: A√±os de educaci√≥n formal. Relacionado con reserva cognitiva.  
- **SES**: Escala socioecon√≥mica. Asociada a recursos cognitivos.  
- **MMSE**: Test cognitivo global (0‚Äì30).  
- **CDR (Clinical Dementia Rating)**: Escala cl√≠nica de severidad de demencia.  Es la variable principal didicotomizada en ‚Äúcontrol‚Äù vs ‚Äúdeterioro cognitivo‚Äù.
- **eTIV**: Volumen intracraneal estimado.  
- **nWBV**: Proporci√≥n de volumen cerebral respecto intracraneal.  
- **ASF**: Factor de ajuste anat√≥mico.  
 

**Etiquetas de cohorte**: para trazabilidad y an√°lisis estratificado.

El objetivo principal es **emular la intuici√≥n cl√≠nica** integrando:

- **Datos cl√≠nicos tabulares**: Tests neuropsicol√≥gicos, factores de riesgo, medidas volum√©tricas (edad, g√©nero, MMSE, CDR, entre otros).
- **MRI estructural**: im√°genes cerebrales que pueden reflejar la atrofia cerebral (en formato NIfTI, preprocesadas a slices 2D para entrenamiento). 



El preprocesamiento incluy√≥:  
- Homogeneizaci√≥n de columnas a `snake_case`.  
- Imputaci√≥n de SES/Educ por mediana, escalado est√°ndar, one-hot para Sex y Cohorte.  
- Target unificado por cohorte (OASIS-2: `Group`; OASIS-1: `CDR>0`).  
- Splits estratificados con separaci√≥n por paciente.
- Mapeo de Correspondencia paciente-slice mediante ficheros `oas1_val_colab_mapped.csv` y `oas1_test_colab_mapped.csv`.  
- Normalizaci√≥n de intensidades.  
- Creaci√≥n de slices 2D a partir de vol√∫menes 3D para facilitar el entrenamiento en arquitecturas CNN est√°ndar.  
- Balanceo parcial mediante augmentaciones (flip horizontal, rotaciones leves).  


**Divisi√≥n de conjuntos:**  
  - Cl√≠nicos (pipelines 1‚Äì2): validaci√≥n cruzada 5-fold y hold-out sobre OASIS-2, anidada para la fusi√≥n OASIS-1+2.
  - Im√°genes (pipelines 3‚Äì9): esquema Train/Val/Test (aprox. 60/20/20) estratificado por paciente, evitando leakage.


### 2.2 Infraestructura  

- **Hardware**: Google Colab Pro (GPU NVIDIA T4).   
- **Almacenamiento persistente**: Google Drive (`/MyDrive/CognitivaAI`).  
- **Librer√≠as clave**: PyTorch, timm (colecci√≥n de modelos), scikit-learn, pandas, matplotlib.  
- **Optimizaci√≥n**: AdamW, LR schedulers, early stopping.
- **Augmentations**: flips, rotaciones leves. 
- **Gesti√≥n de experimentos**: notebooks separados por pipeline, con guardado autom√°tico de m√©tricas y predicciones en CSV.  

### 2.3 M√©tricas de evaluaci√≥n  

Dada la naturaleza binaria y desbalanceada de la tarea, se utilizaron m√∫ltiples m√©tricas:  

- **AUC (ROC)**: medida global de discriminaci√≥n.  
- **PR-AUC**: m√°s informativa en datasets desbalanceados.  
- **Accuracy**: proporci√≥n de aciertos.  
- **Recall (sensibilidad)**: clave, ya que la tarea exige detectar la mayor cantidad de pacientes con deterioro cognitivo.  
- **Precision**: importante para evitar falsos positivos.  
-**Threshold**: selection por F1 √≥ptimo, Youden y recall controlado (90‚Äì100%).  
- **Youden Index**: criterio alternativo de umbralizaci√≥n.  
- **@REC90 / @REC100**: configuraciones que maximizan el recall (sensibilidad) incluso a costa de la precisi√≥n.  

---

## 3. Evoluci√≥n por Pipelines  

Se han desarrollado **diez pipelines secuenciales**, cada uno incorporando mejoras y aprendizajes de la fase previa:

- **P1-COGNITIVA-AI-CLINIC** ‚Äì Modelos ML cl√°sicos con datos cl√≠nicos de OASIS-2 (baseline tabular).
- **P2-COGNITIVA-AI-CLINIC-IMPROVED** ‚Äì Datos cl√≠nicos fusionados (OASIS-1 + OASIS-2), mayor muestra y generalizaci√≥n.
- **P3-COGNITIVA-AI-IMAGES** ‚Äì Primer approach con MRI OASIS-2 usando Deep Learning (ResNet50).
- **P4-COGNITIVA-AI-IMAGES-IMPROVED** ‚Äì Refinamiento de pipeline de MRI (m√°s datos y rigor en splits).
- **P5-COGNITIVA-AI-IMAGES-IMPROVED-GPU** ‚Äì Extracci√≥n de embeddings MRI con ResNet18 en GPU y calibraci√≥n isot√≥nica.
- **P6-COGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATED** ‚Äì Embeddings EfficientNet-B3 + ensemble de clasificadores a nivel paciente.
- **COGNITIVA-AI-IMAGES-FT** ‚Äì Fine-tuning parcial de EfficientNet-B3 sobre MRI para mejorar discriminaci√≥n.
- **COGNITIVA-AI-IMAGES-FT-IMPROVED** ‚Äì Ajustes de fine-tuning: calibraci√≥n de probabilidades y optimizaci√≥n de pooling.
- **COGNITIVA-AI-IMAGES-FT-STABLE** ‚Äì Modelo fine-tune final calibrado y con umbral cl√≠nico optimizado (pipeline MRI definitivo).
- **COGNITIVA-AI-FINETUNING-STABLE-PLUS** ‚Üí Versi√≥n extendida con calibraci√≥n adicional y pooling alternativo (mean, median, top-k). 

Cada pipeline se documenta a continuaci√≥n, detallando metodolog√≠a, resultados y conclusiones. Esta evoluci√≥n progresiva permite contrastar la eficacia de distintas aproximaciones (ML tradicional vs Deep Learning, datos cl√≠nicos vs im√°genes, etc.) y justifica las decisiones t√©cnicas tomadas.

### 3.1 Pipeline 1 ‚Äì P1-COGNITIVA-AI-CLINIC (Cl√≠nico OASIS-2)  

**Motivaci√≥n:**  
Probar un primer modelo utilizando exclusivamente variables cl√≠nicas del dataset OASIS-2, sin im√°genes. El objetivo era establecer un baseline puramente tabular.  

**Metodolog√≠a:**  
Tres clasificadores cl√°sicos (Regresi√≥n Log√≠stica, Random Forest, XGBoost) con datos tabulares de OASIS-2 (150 sujetos). Validaci√≥n cruzada (5-fold) y conjunto test reservado (20%).

**Resultados:**

| Modelo           | AUC (CV 5-fold)   | AUC (Test) |
|------------------|-------------------|------------|
| Logistic Reg.    | 0.912 ¬± 0.050     | ‚Äì          |
| Random Forest    | 0.925 ¬± 0.032     | ‚Äì          |
| XGBoost          | 0.907 ¬± 0.032     | 0.897      |

**Conclusi√≥n:**  
Baseline robusto basado en datos cl√≠nicos, limitado por la escasez de datos (solo OASIS-2). Confirma la fuerza de variables cl√≠nicas (CDR, MMSE) en la detecci√≥n de demencia incipiente.

**Configuraci√≥n destacada:**  
- Modelo: **XGBoost** con tuning b√°sico.
- Variables: Datos cl√≠nicos tabulares (edad, sexo, puntuaciones cognitivas, CDR). 
- Validaci√≥n cruzada interna.  

**Resultados:**  
- AUC (Test): 0.897.  
- Sin m√©tricas de PR-AUC reportadas, aunque se observ√≥ buen desempe√±o en t√©rminos de recall.  

**Reflexi√≥n:**  
Este baseline confirm√≥ que incluso con variables cl√≠nicas simples se puede alcanzar un nivel competitivo de discriminaci√≥n. Sin embargo, la dependencia exclusiva de variables cl√≠nicas limita la aplicabilidad general.  

---

### 3.2 Pipeline 2 ‚Äì P2-COGNITIVA-AI-CLINIC-IMPROVED (Cl√≠nico fusionado OASIS-1+2) 

**Motivaci√≥n:**  
Mejorar la generalizaci√≥n combinando OASIS-1 y OASIS-2 (~550 sujetos). Unificaci√≥n de variables y control de cohortes. 

#### ‚öñÔ∏è Manejo del desbalanceo
- Se probaron variantes con `class_weight='balanced'` y `scale_pos_weight` en XGBoost.  
- Se optimiz√≥ el **umbral de decisi√≥n** para priorizar *recall* cl√≠nico.  
  - Umbral √≥ptimo ‚âà 0.03 ‚Üí Recall ‚âà 100%, con sacrificio en precisi√≥n (15 falsos positivos).  

#### üîç Interpretabilidad
- **Coeficientes (LR):**
  - `CDR` (coef ‚âà +4.15) ‚Üí marcador principal.  
  - `MMSE` (coef ‚âà -0.64) ‚Üí inversamente asociado.  
  - `Educaci√≥n` (coef ‚âà +0.76) ‚Üí correlaci√≥n positiva.  
- Conclusi√≥n: el modelo se alinea con la evidencia cl√≠nica ‚Üí CDR y MMSE son dominantes.  

#### üìè Calibraci√≥n
- Comparaci√≥n: sin calibrar, **Platt (sigmoid)**, **isot√≥nica**.  
- **Brier Scores:**  
  - LR isot√≥nica ‚Üí **0.0099** (mejor calibraci√≥n).  
  - RF isot√≥nica ‚Üí 0.0170.  
  - XGB isot√≥nica ‚Üí 0.0187.  

#### üõ°Ô∏è Robustez
- **Nested CV:** ROC-AUC = **0.985 ¬± 0.011**.  
- **Ablation:**  
  - Sin MMSE ‚Üí ROC-AUC 1.000.  
  - Sin CDR ‚Üí 0.86.  
  - Sin MMSE+CDR ‚Üí 0.76.  
  - Sin volum√©tricas ‚Üí ‚âà 1.000.  
  - Sin socioeducativas ‚Üí ‚âà 0.998.  
- Conclusi√≥n: **CDR y MMSE son cr√≠ticos**, otras variables aportan poco.  

#### ü§ù Ensembling
- Promedio de probabilidades (LR + RF + XGB).  
- Resultado: ROC-AUC = **0.995** ‚Üí ligera mejora.  


**Resultados recopilaci√≥n:**

| Modelo           | AUC (Hold-out 80/20) | AUC (CV 5-fold) |
|------------------|----------------------|-----------------|
| Logistic Reg.    | 1.000                | 0.979 ¬± 0.012   |
| Random Forest    | 0.986                | 0.974 ¬± 0.018   |
| XGBoost          | 0.991                | 0.975 ¬± 0.021   |
| Ensemble         | ‚Äì                    | 0.995 (Nested)  |

Umbral cl√≠nico (XGB): recall‚âà100% con ~15 FP.

**Conclusi√≥n:**  
La fusi√≥n de bases cl√≠nicas potencia el rendimiento (AUC ~1.0). El modelo calibrado permite operar a alta sensibilidad sin sacrificar precisi√≥n, alineado con la prioridad cl√≠nica de evitar falsos negativos.

**Configuraci√≥n destacada:**  
- Modelo: **XGB**.  
- Variables: todas las disponibles en OASIS-1 y 2.  
- Validaci√≥n cruzada m√°s exhaustiva.  

**Resultados XGBoost:**  
- AUC (Test): 0.991.  
- Recall cercano al 100%.  

**Reflexi√≥n:**  
El modelo cl√≠nico extendido alcanz√≥ una performance casi perfecta, aunque con riesgo evidente de **overfitting** dada la baja dimensionalidad del dataset. Sirvi√≥ como techo de referencia para comparar con modelos de MRI.  

---

### 3.3 Pipeline 3 ‚Äì  P3-COGNITIVA-AI-IMAGES (MRI OASIS-2, ResNet50) 

**Motivaci√≥n:**  
Dar el salto a im√°genes MRI, usando ResNet50 como backbone en el dataset original de OASIS-2.  

**Configuraci√≥n:**  
- Modelo: **ResNet50 preentrenada en ImageNet**.  
- Dataset: MRI OASIS-2 (formato local).  
- Entrenamiento limitado por CPU local.  

**Preprocesamiento:**
- Conversi√≥n de vol√∫menes a cortes axiales (5 o 20 slices).  
- Normalizaci√≥n a rango [0‚Äì255].  
- Opciones: CLAHE y z-score por slice.  
- Augmentation: flips, rotaciones ¬±10¬∞, ajustes de brillo/contraste.  
- Redimensionado a 224√ó224 y normalizaci√≥n ImageNet. 

**Entrenamiento:**
- Base: **ResNet50** pre-entrenada en ImageNet.  
- Capa final adaptada a binario.  
- Optimizador: Adam (lr=1e-4).  
- Early stopping con paciencia = 4.  
- Split por paciente (60/20/20).  
- Evaluaci√≥n a nivel de paciente (probabilidad media). 

**Contexto:**  
Primer an√°lisis de im√°genes estructurales cerebrales. OASIS-2, segmentaciones manuales, ~100 cortes axiales por MRI.

**Resultados:**

- **5 slices, sin CLAHE:** Acc = **0.89**, AUC = **0.938**.  
- 5 slices, con CLAHE: Acc = 0.69, AUC = 0.777.  
- 5 slices, CLAHE + z-score: Acc = 0.72, AUC = 0.820.  
- **20 slices, CLAHE+z-score:** Acc = 0.80, AUC = 0.858 (mayor recall, menor precisi√≥n)

**Conclusi√≥n:**  
- Factible usar Deep Learning con MRI para detectar Alzheimer (AUC ~0.9). 
- Limitaciones computacionales y necesidad de selecci√≥n cuidadosa de slices.
- Mejor AUC con 5 cortes sin CLAHE; m√°s cortes mejoran recall, pero no AUC.

**Reflexi√≥n:**  
Este pipeline demostr√≥ que el uso de im√°genes cerebrales puede ofrecer resultados competitivos con los cl√≠nicos, aunque a√∫n no superiores.  

---

### 3.4. Pipeline 4 ‚Äì P4-COGNITIVA-AI-IMAGES-IMPROVED (MRI OASIS-1+2 unificado)

**Motivaci√≥n:**  
Aprovechar todo el conjunto MRI (OASIS-1 + OASIS-2), evitando leakage y aumentando slices por sujeto.

**Resultados:**  
AUC ~0.85‚Äì0.90 en validaci√≥n, sin salto claro respecto al pipeline 3 por limitaciones de c√≥mputo.

**Conclusi√≥n:**  
Mejor manejo de datos y splits (Split por paciente/scan y m√°s slices por sujeto)
Mayor robustez, pero mayor coste en CPU : necesidad de GPU para seguir progresando.

---

### 3.4B Pipeline 5 ‚Äì  P5-COGNITIVA-AI-IMAGES-IMPROVED-GPU (Embeddings ResNet18 + Calibraci√≥n)  

**Motivaci√≥n:**  
Probar una arquitectura m√°s ligera (ResNet18) con calibraci√≥n de probabilidades en Colab. 

**Estrategia:**  
Transfer learning: extracci√≥n de embeddings con ResNet18, luego clasificador tradicional (Logistic Regression) y calibraci√≥n isot√≥nica.

**Configuraci√≥n:**  
- ResNet18 preentrenada.  
- Embeddings 512D ‚Üí LR
- Post-procesado: **Platt scaling**.  
- **Calibraci√≥n:** post-hoc, isotonic regression. 

**Resultados:**  
- Slice-level: AUC_val ‚âà 0.627, AUC_test ‚âà 0.661 | Brier‚âà0.23
- Paciente-level (thr‚âà0.20):
  - AUC (Test): 0.724.  
  - PR-AUC: 0.606.  
  - Accuracy: 0.60.  
  - Recall: 0.80.  
  - Precision: 0.52.  

**Conclusi√≥n:**  
Probabilidades m√°s confiables y mejor equilibrio precisi√≥n/recall mediante calibraci√≥n. Sensibilidad (80%) en MRI como referencia para mejoras.

**Reflexi√≥n:**  
La calibraci√≥n mejor√≥ la interpretaci√≥n de scores, pero el backbone result√≥ limitado para esta tarea.  

---

### 3.5 Pipeline 6 ‚Äì P6-COGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATED (Embeddings EffNet-B3 + Ensemble) 

**Motivaci√≥n:**  
Usar EfficientNet-B3 como extractor de embeddings, sin fine-tuning completo.  

**Mejoras:**  
Embeddings EfficientNet-B3 (1536-d), clasificadores adicionales (MLP, XGBoost), ensemble LR+XGB.

**Resultados:**

| Modelo         | AUC (Val) | AUC (Test) | PR-AUC (Val) | PR-AUC (Test) | Recall (Test) | Precisi√≥n (Test) |
|----------------|-----------|------------|--------------|---------------|---------------|------------------|
| LR             | 0.786     | 0.685      | 0.732        | 0.539         | 0.80          | 0.52             |
| MLP            | 0.870     | 0.648      | 0.886        | 0.556         | 0.95          | 0.53             |
| XGBoost        | 0.782     | 0.670      | 0.633        | 0.617         | 0.75          | 0.56             |
| Ensemble       | 0.815     | 0.704      | 0.705        | 0.623         | 0.90          | 0.60             |

**Conclusi√≥n:**  
Embeddings m√°s informativos mejoran el recall (90%). AUC en test (~0.70) a√∫n por debajo del modelo cl√≠nico.

**Resultados Ensemble:**  
- AUC (Test): 0.704.  
- PR-AUC: 0.623.  
- Accuracy: 0.70.  
- Recall: 0.90.  
- Precision: 0.60.  

**Reflexi√≥n:**  
Buen recall, aunque precision limitada.  

---

### 3.6A Pipeline 7 ‚Äì P7-COGNITIVA-AI-FINETUNING (Fine-tuning EfficientNet-B3 parcial)

**Planteamiento:**  
Fine-tuning parcial de EfficientNet-B3, pooling por atenci√≥n a nivel paciente.

**Entrenamiento**: fine-tuning completo/parcial de EfficientNet‚ÄëB3 sobre slices. 

**Agregaci√≥n paciente**: *mean pooling* de scores/logits por slices del mismo paciente.  

**Calibraci√≥n**: *temperature scaling* con **T=2.6731656060943605**.  

**Umbral cl√≠nico**: **0.3651449978351593** (maximiza recall con precisi√≥n aceptable).  

**Resultados (nivel paciente, n=47)**  
- **VAL** ‚Üí AUC=**0.748** | PR-AUC=**0.665** | Acc=**0.702** | P=**0.588** | R=**1.0**  
- **TEST** ‚Üí AUC=**0.876** | PR-AUC=**0.762** | Acc=**0.745** | P=**0.625** | R=**1.0**

**Matriz de confusi√≥n (TEST, thr=0.3651):** TP=8, FP=5, TN=34, FN=0.  

**Conclusi√≥n:**  
Fine-tuning eleva la eficacia de clasificaci√≥n MRI (AUC ~0.87).

---

### 3.6 Pipeline 8 ‚Äì P8-COGNITIVA-AI-FINETUNING-IMPROVED (Fine-tuning completo de EfficientNet-B3)

**Motivaci√≥n:**  
Explotar la capacidad completa de EfficientNet-B3, ajustando todos los pesos: Calibraci√≥n con Temperature Scaling y ajuste de umbral cl√≠nico para alta sensibilidad.

**Resultados:**  
- AUC (Test): 0.876.  
- PR-AUC: 0.762.  
- Accuracy: 0.745.  
- Recall: 1.0.  
- Precision: 0.625.  

**Comparaci√≥n (p6-p8):**s

| Modelo MRI                         | AUC (Test) | Recall (Test) | Precision (Test) |
|-------------------------------------|------------|---------------|------------------|
| Pipeline 6 (Ensemble LR+XGB)        | 0.704      | 0.90          | 0.60             |
| Pipeline 8 (EffNet-B3 fine-tune cal)| 0.876      | 1.00          | 0.625             |

- Umbral cl√≠nico ‚âà 0.365: Recall_test = 1.00, Precision_test ‚âà 0.62, AUC_test ‚âà 0.876, PR-AUC_test ‚âà 0.762, Acc_test ‚âà 0.74

**Conclusi√≥n:**  
Modelo MRI altamente sensible y calibrado. Por primera vez se detecta el 100% de los casos de Alzheimer en test, sacrificando precisi√≥n (62%) pero ideal para cribado.

**Reflexi√≥n:**  
Gran salto respecto a embeddings. El modelo captur√≥ patrones discriminativos m√°s profundos.  

---

## Pipeline 9 - P9-COGNITIVA-AI-FINETUNING-STABLE Fine‚Äëtuning Estable EfficientNet‚ÄëB3 (Colab)

**Motivaci√≥n:**  
Introducir t√©cnicas de estabilizaci√≥n para reducir variabilidad. 

**Configuraci√≥n**  
- Arquitectura: EfficientNet‚ÄëB3 (timm).  
- Entrenamiento: AdamW (lr=1e‚Äë4), AMP (`torch.amp`), early‚Äëstopping por AUC en holdout, 300px, batch=64.  
- Agregaci√≥n: `mean` a nivel paciente.  
- Calibraci√≥n: temperature scaling (T=2.048).  
- Umbral: 0.3400 (optimizado con recall‚â•0.95 en VAL).

**Resultados:**  
- A+UC (Test): 0.740.  
- PR-AUC: 0.630.  
- Accuracy: 0.72.  
- Recall: 0.65.  
- Precision: 0.62.  

**Problema:** logits desorbitados (>500k).

**Comentario:** estabilidad no garantiz√≥ mejor generalizaci√≥n.  

---

### Comparaci√≥n EffNet-B3 (p7,p8,p9)

- **Pipeline 7 (inicial):** fine-tuning base, recall perfecto (1.0) pero precisi√≥n moderada.  
- **Pipeline 8 (calibrado):** aplicado *temperature scaling*, mejor consistencia de probabilidades.  
- **Pipeline 9 (estable):** reentrenamiento reproducible con SSD local.  
  - Configuraci√≥n oficial: *temperature scaling* T‚âà2.67, thr‚âà0.365.  
  - M√©tricas finales: AUC‚âà0.74, PR-AUC‚âà0.63, Acc‚âà0.72, Recall‚âà0.65, Precision‚âà0.62.  
  - Confusi√≥n TEST: TP=6, FP=4, TN=36, FN=1.  

**Conclusi√≥n:** El fine-tuning logra el mejor rendimiento MRI. Pipeline 7 maximiz√≥ recall, mientras que Pipeline 9 prioriza estabilidad y reproducibilidad.

---

### 3.8 Pipeline 10 ‚Äì P10-COGNITIVA-AI-FINETUNING-STABLE-PLUS - EffNet-B3 Fine-Tuning Stable Plus (checkpoint limpio + calibraci√≥n final) 

**Motivaci√≥n:**  
Aplicar calibraci√≥n expl√≠cita de scores.  

El pipeline 9 ofrec√≠a estabilidad, pero los checkpoints entrenados no siempre coincid√≠an con la arquitectura definida, cargando <1% de pesos en algunos intentos. Era necesario **reprocesar el checkpoint**, asegurar la integridad de pesos y aplicar calibraci√≥n para obtener resultados reproducibles.  
Este pipeline se enfoc√≥ en reforzar la **calibraci√≥n y pooling** para asegurar recall absoluto, incluso sacrificando m√©tricas globales.

**Configuraci√≥n:**  
- Modelo: EfficientNet-B3 binario (head adaptada).  
- Checkpoint: `effb3_stable_seed42.pth`, reconstruido a `best_effb3_stable.pth` (99.7% de pesos cargados).  
- Calibraci√≥n: *temperature scaling* (T‚âà2.3) aplicado sobre logits.  
- Pooling: estrategias mean, median y top-k (0.2, 0.3).  
- Evaluaci√≥n: cohortes de 47 pacientes (VAL) y 47 pacientes (TEST).  

**Resultados:**  

| Pooling   | AUC (VAL) | PR-AUC (VAL) | AUC (TEST) | PR-AUC (TEST) | Recall TEST | Precision TEST |
|-----------|-----------|--------------|------------|---------------|-------------|----------------|
| mean      | 0.630     | 0.667        | 0.546      | 0.526         | 1.0         | 0.47           |
| median    | 0.643     | 0.653        | 0.541      | 0.513         | 1.0         | 0.48           |
| top-k=0.2 | 0.602     | 0.655        | 0.583      | 0.502         | 1.0         | 0.49     

**Resultados recopilaci√≥n:**  
- AUC (Test): entre 0.546‚Äì0.583.  
- PR-AUC: 0.50‚Äì0.53.  
- Accuracy: 0.51‚Äì0.55.  
- Recall: 1.0.  
- Precision: 0.47‚Äì0.49.  

**Conclusi√≥n:**  
Pipeline 10 consolida la l√≠nea MRI con un recall perfecto en test (1.0), asegurando sensibilidad m√°xima para cribado cl√≠nico temprano. Aunque la precisi√≥n baja (~0.47), este pipeline marca el cierre robusto de la etapa **MRI-only** y deja el terreno preparado para la fusi√≥n multimodal.

**Reflexi√≥n:**  
La calibraci√≥n no mejor√≥ la discriminaci√≥n; sacrific√≥ precision.  

---

- **TRIMMED mean (Œ±=0.2)**: media recortada que mejora la estabilidad frente a slices outliers.  
- **TOP-k (k=3,7)**: centradas en las slices m√°s patol√≥gicas.  
- **Ensemble MRI**: combinaci√≥n lineal de MEAN, TRIMMED y TOP7 con pesos √≥ptimos encontrados en validaci√≥n (0.30, 0.10, 0.60).  

**Resultados:**
- **VAL**: PR-AUC hasta 0.925, recall=0.95, precisi√≥n=0.79.  
- **TEST**: PR-AUC 0.737, recall=0.70, precisi√≥n=0.61.  

El ensemble mejora la precisi√≥n en test (+5 puntos frente a TRIMMED) manteniendo la misma sensibilidad. Se consolida as√≠ como la **baseline final de la etapa MRI-only**, antes de avanzar a la integraci√≥n multimodal con datos cl√≠nicos.

---

## üìå Evaluaci√≥n de seed-ensemble (EffNet-B3, seeds 41/42/43)

**Objetivo:**  
Verificar si la combinaci√≥n de checkpoints con distintas semillas pod√≠a mejorar la robustez del Pipeline 10 (*EffNet-B3 stable plus*).

**Metodolog√≠a:**  
- Inferencia slice-level con TTA reducida (orig + flip).  
- Agregaci√≥n a nivel paciente mediante `mean`, `trimmed` y `top-7`.  
- Calibraci√≥n en validaci√≥n: *temperature scaling* y *Platt scaling* con `safe_sigmoid`.  
- Escalado previo: z-score en VAL aplicado a TEST.

**Resultados principales:**  

| Variante        | AUC (TEST) | PR-AUC (TEST) | Recall (TEST) | Precisi√≥n (TEST) |
|-----------------|------------|---------------|---------------|------------------|
| seedENS_MEAN    | 0.47‚Äì0.52  | 0.42‚Äì0.44     | 0.90‚Äì1.00     | 0.42‚Äì0.45        |
| seedENS_TRIMMED | 0.49‚Äì0.50  | 0.44‚Äì0.45     | 0.80‚Äì1.00     | 0.41‚Äì0.43        |
| seedENS_TOP7    | 0.45‚Äì0.46  | 0.40‚Äì0.41     | 1.00          | 0.43             |

**Diagn√≥stico:**  
- Los logits de los tres checkpoints presentaron escalas extremadamente distintas.  
- Incluso tras normalizaci√≥n y calibraci√≥n, la separaci√≥n ROC/PR fue pr√°cticamente nula.  
- El ensemble de semillas no aporta valor a√±adido frente al ensemble por agregadores (mean+trimmed+top7), que s√≠ logra recall cl√≠nico ‚â•0.9 con mejor PR-AUC.

**Conclusi√≥n:**  
Se descarta el *seed-ensemble* para esta fase. Se consolida el uso del **ensemble por agregadores calibrados** como cierre de la etapa solo-MRI antes de avanzar a la integraci√≥n multimodal.

---

### üîπ Extensi√≥n Pipeline 10 ‚Äì Random Search de ensembles

Tras obtener resultados s√≥lidos con pooling cl√°sico y variantes top-k, exploramos la combinaci√≥n **aleatoria de pesos normalizados** sobre las features derivadas a nivel paciente (`mean`, `trimmed20`, `top7`, `pmean_2`).

- **Configuraci√≥n:**  
  - 500 combinaciones aleatorias.  
  - Pesos restringidos a ‚â•0 y normalizados a 1.  
  - Selecci√≥n por F1-score en validaci√≥n.

- **Mejor combinaci√≥n encontrada:**  
  - mean ‚âà 0.32  
  - trimmed20 ‚âà 0.31  
  - top7 ‚âà 0.32  
  - pmean_2 ‚âà 0.04  

- **Resultados:**  
  - [VAL] AUC=0.909 | PR-AUC=0.920 | Recall=0.95 | Acc=0.87 | Prec=0.79  
  - [TEST] AUC=0.754 | PR-AUC=0.748 | Recall=0.70 | Acc=0.66 | Prec=0.58  

**Conclusi√≥n:** el ensemble aleatorio confirma la **robustez de top7 + mean + trimmed**, alcanzando resultados estables y comparables al stacking. Refuerza que la informaci√≥n MRI puede combinarse de forma no lineal para mejorar recall y estabilidad.

---

### üß™ Ensembles avanzados en Pipeline 10

- **Objetivo:** superar las limitaciones de pooling simples y del stacking cl√°sico, evaluando combinaciones ponderadas de predicciones slice‚Üípaciente.  

- **Estrategias exploradas:**
  - **Seed ensembles:** fallaron, con m√©tricas cercanas a azar (AUC ~0.5).
  - **Random Search ensemble:** optimiz√≥ pesos no negativos (Dirichlet, N=500).  
    - Pesos √≥ptimos: mean‚âà0.32, trimmed‚âà0.31, top7‚âà0.32, pmean_2‚âà0.04.  
    - [VAL] AUC=0.909, PR-AUC=0.920, Recall=0.95.  
    - [TEST] AUC=0.754, PR-AUC=0.748, Recall=0.70.
  - **Logistic Regression stacking:** rendimiento equivalente al Random Search.  
    - Coeficientes (interpretables): todos positivos (~0.40‚Äì0.48).  
    - Conclusi√≥n: cada agregador aporta informaci√≥n relevante.

- **Reflexi√≥n:**  
  La etapa MRI-only cierra con ensembles robustos que **maximizan recall cl√≠nicamente cr√≠tico** sin sacrificar tanta precisi√≥n como en pooling simples. Esto ofrece un baseline s√≥lido antes de fusionar datos multimodales.

---

### 3.9 Pipeline 10-ext ‚Äì Ensembles de EfficientNet-B3: Variantes TRIMMED y ensembles intra-backbone  

**Motivaci√≥n:**  
Explorar variantes de pooling de slices y ensembles dentro de EfficientNet-B3.  

**Estrategias probadas:**  
  - Mean, trimmed, top-k.  
  - Random Forest sobre features de pooling.  
  - Stacking log√≠stico.  



**Resultados:**  
- TRIMMED: AUC (Test) 0.744, PR-AUC 0.746.  
- Ensemble (mean+trimmed+top7): AUC (Test) 0.754, PR-AUC 0.737.  

**Reflexi√≥n:**  
Los ensembles intra-backbone s√≠ ofrecieron mejoras moderadas pero consistentes.  

---

### 3.10 Pipeline 11 ‚Äì Backbones alternativos  

**Motivaci√≥n:**  
Explorar arquitecturas m√°s all√° de EfficientNet.  

Tras consolidar EfficientNet-B3 como modelo base en el pipeline 10, se decidi√≥ evaluar otras arquitecturas conocidas para clasificaci√≥n de im√°genes m√©dicas. La motivaci√≥n fue comprobar si exist√≠a alguna arquitectura con mejor balance entre recall, precisi√≥n y estabilidad en cohortes de validaci√≥n y test.

**Modelos probados:**  
- ResNet-50.  
- DenseNet-121.  
- ConvNeXt-Tiny.  
- Swin-Tiny.  

**Resultados:**  

| Backbone        | AUC (Test) | PR-AUC (Test) | Acc   | Recall | Precision |
|-----------------|------------|---------------|-------|--------|-----------|
| ResNet-50       | 0.740      | 0.730         | 0.64  | 0.70   | 0.56      |
| DenseNet-121    | 0.343      | 0.407         | 0.32  | 0.75   | 0.36      |
| ConvNeXt-Tiny   | 0.509      | 0.479         | 0.49  | 1.00   | 0.45      |
| Swin-Tiny       | 0.641      | 0.597         | 0.55  | 0.95   | 0.95      |

- **ResNet-50**: competitivo, AUC (‚âà 0.74) similar a EffNet-B3 estable.  
- **DenseNet-121**: resultados bajos (AUC ~0.34‚Äì0.46).  
- **ConvNeXt-Tiny**: desempe√±o bajo (AUC ~0.50).  
- **Swin-Tiny**: desempe√±o moderado, con variante top7 alcanzando AUC ~0.64.  

**Reflexi√≥n:**  
Ning√∫n backbone super√≥ claramente a EfficientNet-B3, aunque Swin mostr√≥ cierto potencial.  

---

### Resultados (p1-p11)

## üìä Comparativa Global (pipelines 1‚Äì10)

| Pipeline | Modalidad        | Modelo                   | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|--------------------------|------------|--------|-------|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB                      | 0.897      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB                      | 0.991      | ‚Äî      | ‚Äî     | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50                 | 0.938      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib         | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed          | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune       | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable         | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib   | 0.546‚Äì0.583| 0.50‚Äì0.53 | 0.51‚Äì0.55 | 1.0 | 0.47‚Äì0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + TRIMMED      | 0.744      | 0.746  | 0.64  | 0.75   | 0.56      |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble(M+T+7) | 0.754   | 0.737  | 0.68  | 0.70   | 0.61      |
| P11      | MRI Colab       | Swin-Tiny + top7                     | 0.641 | 0.597 | 0.55 | 0.95 | 0.95 |
| P11      | MRI Colab       | ConvNeXt-Tiny (in12k_ft_in1k) + mean | 0.509 | 0.479 | 0.49 | 1.00 | 0.45 |
| P11      | MRI Colab       | DenseNet-121 + trimmed20             | 0.343 | 0.407 | 0.32 | 0.75 | 0.36 |
| P11      | MRI Colab       | Backbone-Ensemble (Dirichlet-means)  | 0.520 | 0.523 | 0.47 | 1.00 | 0.44 |
| P11      | MRI Colab       | Backbone-Ensemble (Dirichlet-ext)    | 0.361 | 0.405 | 0.45 | 0.85 | 0.43 |
| P11      | MRI Colab       | Swin-Tiny (top7) + Isotonic Calib    | 0.566 | 0.458 | 0.55 | 0.95 | 0.49 |

---

### 3.11 Ensembles inter-backbone  

Se exploraron combinaciones entre diferentes backbones:  

- **Dirichlet ensembles**: priorizaron SwinTiny y ResNet, con mejoras modestas.  
- **Stacking con regresi√≥n log√≠stica**: no lograron generalizar bien, tendencia a sobreajuste.  
- **Isotonic calibration** sobre SwinTiny top7: mejor√≥ la estabilidad.  

Tras evaluar individualmente diferentes arquitecturas (ResNet-50, DenseNet-121, ConvNeXt-Tiny, Swin-Tiny), se explor√≥ si la combinaci√≥n de backbones pod√≠a mejorar el rendimiento.  

### Metodolog√≠a
- **Dirichlet means**: muestreo de pesos de combinaci√≥n desde distribuciones Dirichlet sobre predicciones tipo *mean*.  
- **Dirichlet extended**: se ampli√≥ a variantes *mean/trimmed20/top7* de cada backbone.  
- **Stacking L1**: regresi√≥n log√≠stica con regularizaci√≥n fuerte.  
- **Calibraci√≥n isot√≥nica**: aplicada a las salidas de Swin-Tiny (mejor variante individual).  

### Resultados principales
| Variante Ensemble             | AUC (TEST) | PR-AUC | Acc   | Recall | Precision |
|-------------------------------|------------|--------|-------|--------|-----------|
| Dirichlet-means               | 0.520      | 0.523  | 0.47  | 1.00   | 0.44      |
| Dirichlet-extended            | 0.361      | 0.405  | 0.45  | 0.85   | 0.43      |
| Stacking L1 fuerte            | 0.500      | 0.426  | 0.43  | 1.00   | 0.43      |
| Swin-Tiny + Isotonic Calib.   | 0.566      | 0.458  | 0.55  | 0.95   | 0.49      |

### Conclusi√≥n
- **Ning√∫n ensemble supera a EfficientNet-B3 calibrado (pipeline 10-ext)** en este dataset.  
- **Swin-Tiny isot√≥nico** logra *recall* muy alto (0.95) con precisi√≥n moderada (0.49), pero su AUC sigue bajo.  
- La diversidad de arquitecturas no se traduce en mejoras sustanciales, probablemente por el tama√±o limitado del conjunto de test.  
- Se refuerza la idea de que **EffNet-B3 estable+calibrado** es la mejor base antes de pasar a escenarios multimodales.

---

## Ingenier√≠a y Rendimiento (Colab)

- **Copia de MRI a SSD local** (`/content/mri_cache`) ‚Üí ~**53 f/s** al copiar 940 ficheros.  
- **Lectura directa Drive**: ~**4.5 img/s** (muestra 256).  
- **Lectura SSD local**: ~**695 img/s** (muestra 256).  
- **Inferencia (sin cache inicial)**: ~**17 img/s**.  
- **Optimizada (cache + ajustes DataLoader)**: **150‚Äì200 img/s** (VAL/TEST).  
- **DataLoader**: en T4, **`num_workers=2`** suele rendir mejor; evita crear m√°s workers que CPUs.  
- **AMP**: usar `torch.amp.autocast('cuda')` (deprecado `torch.cuda.amp.autocast(...)`).

---

## Experimentos en OASIS-2 (p13, p14 y p15)

### Preparaci√≥n de datos
- 367 exploraciones de OASIS-2, de las cuales 150 ten√≠an label cl√≠nico.  
- Generaci√≥n de 7340 slices (20 por volumen, edge_crop=0.08, z-score + CLAHE).  
- M√°scaras cerebrales FSL u Otsu.  
- Criterio de **una visita por paciente** para evitar leakage.  

---

### Pipeline p13
- Entrenamiento base con EfficientNet-B3 en cohortes reducidas.  
- 150 pacientes ‚Üí 105 train, 22 val, 23 test.  
- Resultados preliminares con recall alto, pero riesgo de sobreajuste.  

---

### Pipeline p14
- Reentrenamiento en GPU con **class weights** y datos copiados a **SSD local de Colab** para optimizar E/S.  
- M√©tricas robustas en validaci√≥n (AUC‚âà0.88) y recall=100% en test.  
- Integraci√≥n en cat√°logo de backbones como `oas2_effb3_p14`.  

---

### Pipeline p15 (Consolidaci√≥n y ensamble)
- Objetivo: consolidar resultados de p13/p14 con OASIS-1 (p11).  
- Se a√±adieron al cat√°logo de backbones (`oas2_effb3`, `oas2_effb3_p14`).  
- Generaci√≥n de features combinadas (69 pacientes en val, 70 en test).  
- Manejo de NaN: descarte de columnas con >40% y uso de modelos compatibles con NaN (HistGradientBoosting).  

**Resultados comparativos (VAL/TEST):**

| Pipeline | VAL AUC | VAL Acc | VAL Recall | TEST AUC | TEST Acc | TEST Recall |
|----------|---------|---------|------------|----------|----------|-------------|
| p13      | ~0.90   | 0.86    | 0.82       | ~0.77    | 0.78     | 0.83        |
| p14      | 0.88    | 0.86    | 0.82       | 0.71     | 0.70     | 1.00        |
| p15      | 0.94    | 0.84    | ~1.0       | 0.71     | 0.63‚Äì0.71 | 0.78‚Äì1.0   |

---

### Conclusi√≥n
- p13: prueba de integraci√≥n OASIS-2.  
- p14: optimizaci√≥n con balanceo y SSD local.  
- p15: consolidaci√≥n de resultados e integraci√≥n en ensambles OASIS-1+2, demostrando que la combinaci√≥n de backbones mejora recall y robustez del sistema.

---

## Fase 8 ‚Äì Ensembles refinados (p15 y p16)

**Contexto:**  
Tras la exploraci√≥n con OASIS-2 en los pipelines p13 y p14, se busc√≥ consolidar resultados y refinar el rendimiento a trav√©s de ensembles patient-level.

**Pipeline p15 (Consolidaci√≥n):**
- Revisi√≥n de inventarios y labels cl√≠nicos (367 scans totales, 150 con etiqueta).  
- Confirmaci√≥n del criterio de **una sesi√≥n por paciente** para evitar leakage.  
- Dataset resultante: 3.000 slices etiquetadas (20 slices por scan).  
- Dificultades: la latencia de E/S en Google Drive volvi√≥ a confirmar la necesidad de copiar los datos a SSD de Colab.

**Pipeline p16 (Refinamiento de ensembles):**
- Construcci√≥n de features patient-level a partir de m√∫ltiples backbones (`oas2_effb3`, `oas2_effb3_p14`, SwinTiny, ConvNeXt, etc.).  
- Manejo de NaNs:  
  - Eliminaci√≥n de features con >40% de valores perdidos.  
  - Imputaci√≥n + flags en Logistic Regression.  
  - Soporte nativo de NaN en HistGradientBoosting.  
- Ensayos con **Logistic Regression, HistGradientBoosting y blending (LR+HGB)**.

**Resultados comparativos:**
- Validaci√≥n (VAL):  
  - AUC‚âà0.95 con el blend, recall‚âà1.0 en cohortes OAS1.  
  - Cohorte OAS2 m√°s reducida ‚Üí m√©tricas inestables, pero recall=1.0.  
- Test (TEST):  
  - AUC‚âà0.69, recall‚âà0.78, mejorando a modelos individuales.  
  - LR e HGB muestran rendimientos complementarios.  
  - Blend logra mejor equilibrio entre sensibilidad y precisi√≥n.

**Conclusi√≥n:**  
La consolidaci√≥n en p15 y el refinamiento en p16 confirmaron que los ensembles permiten:  
- Reducir la varianza del rendimiento.  
- Mejorar recall en test (apropiado para cribado cl√≠nico).  
- Integrar backbones heterog√©neos en un modelo m√°s estable.

---

## Ensemble Calibration (p17)

### Metodolog√≠a
- Se construy√≥ un meta-ensemble con **stacking**, usando Logistic Regression sobre los outputs de modelos base (LR y HGB).  
- Posteriormente se aplic√≥ **Platt scaling** para calibrar las probabilidades, con selecci√≥n de umbral F1 en validaci√≥n (0.35).  
- Se evalu√≥ la calibraci√≥n mediante el **Brier Score** y curvas de calibraci√≥n.

### Resultados
- **Validaci√≥n (ALL):** AUC=0.78 | PRAUC=0.75 | Acc=0.74 | Recall=0.94 | F1=0.76 | Brier=0.176.  
- **Test (ALL):** AUC=0.70 | PRAUC=0.67 | Acc=0.63 | Recall=0.78 | F1=0.66 | Brier=0.227.  
- Cohortes:
  - **OAS1:** estable (VAL AUC‚âà0.84, TEST‚âà0.77).  
  - **OAS2:** bajo rendimiento (VAL‚âà0.31, TEST‚âà0.50) debido al tama√±o reducido (22‚Äì23 pacientes).  

### Conclusi√≥n
- La calibraci√≥n aporta **mejores probabilidades** y un modelo m√°s interpretable.  
- Se conserva la **sensibilidad (recall)**, clave en escenarios cl√≠nicos.  
- El dataset OAS2 sigue siendo un cuello de botella y deber√° reforzarse en futuros experimentos.

---

### Comparativa p16 vs p17

- **p16 (Blending):**
  - Meta-ensemble con LR + HGB, blending con Œ±=0.02.
  - Validaci√≥n muy fuerte (AUC‚âà0.95, Recall=1.0).
  - En test se mantuvo con AUC‚âà0.69 y Recall=0.78.
  - No incluye calibraci√≥n expl√≠cita ‚Üí probabilidades menos interpretables.

- **p17 (Calibration):**
  - Stacking con Logistic Regression + Platt scaling.
  - Validaci√≥n m√°s moderada (AUC‚âà0.78), pero con Brier Score=0.176 ‚Üí mejor calibraci√≥n.
  - En test: AUC‚âà0.70, Recall=0.78, F1‚âà0.66, Brier=0.227.
  - Probabilidades calibradas ‚Üí mayor confianza en la salida del modelo.

**Conclusi√≥n comparativa:**
- p16 maximiza m√©trica predictiva bruta (AUC) pero sin control de calibraci√≥n.
- p17 sacrifica algo de AUC, pero gana en **calidad de probabilidades y estabilidad cl√≠nica**.

 Pipeline | M√©todo principal                | VAL AUC | VAL Acc | VAL Recall | VAL F1 | TEST AUC | TEST Acc | TEST Recall | TEST F1 | Brier (Test) |
|----------|---------------------------------|---------|---------|------------|--------|----------|----------|-------------|---------|--------------|
| **p16**  | Blending (LR + HGB, Œ±=0.02)     | 0.95    | 0.84    | 1.00       | 0.84   | 0.69     | 0.64     | 0.78        | 0.64    | ‚Äì            |
| **p17**  | Stacking + Platt scaling (LR)   | 0.78    | 0.74    | 0.94       | 0.76   | 0.70     | 0.63     | 0.78        | 0.66    | 0.227        |

‚û°Ô∏è **p16** maximiz√≥ el AUC en validaci√≥n, pero con cierto riesgo de sobreajuste.  
‚û°Ô∏è **p17** ajust√≥ las probabilidades (Brier=0.227 en test) y mantuvo recall alto, ofreciendo **mejor calibraci√≥n** y utilidad cl√≠nica.

---

### Pipeline p18 ‚Äì Stacking multicapa

**Contexto:**  
Tras la calibraci√≥n en p17, se busc√≥ refinar la combinaci√≥n de modelos con un enfoque de **stacking multicapa**.  

**Dise√±o t√©cnico:**  
- **Modelos base:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.  
- **Meta-modelo:** regresi√≥n log√≠stica, con blending lineal optimizado (Œ±‚âà0.02).  
- **Entrenamiento:** OOF (out-of-fold) con 5 folds en validaci√≥n, evitando fuga de informaci√≥n.  
- **Evaluaci√≥n:** m√©tricas separadas por cohortes (OAS1, OAS2) y global.

**Resultados clave:**  
- **VAL (n=69):** AUC=0.92, Recall‚âà0.90, Precision‚âà0.78, F1=0.83.  
- **TEST (n=70):** AUC=0.67, Recall‚âà0.78, Precision‚âà0.59, F1=0.67.  
- Cohorte OAS1 mostr√≥ m√©tricas s√≥lidas (AUC‚âà0.67‚Äì0.68 en test), mientras que OAS2 sufri√≥ de escasez de datos (AUC=0.5).  
- Brier Score: 0.117 (VAL), 0.270 (TEST).

**Interpretaci√≥n:**  
El stacking avanz√≥ hacia un modelo m√°s **robusto y flexible**, destacando la contribuci√≥n de GB y RF como base learners m√°s relevantes.  
Sin embargo, la generalizaci√≥n en OAS2 sigue limitada por la baja cobertura de pacientes etiquetados.

---

## P19 ‚Äì Meta-Ensemble apilado

**Dise√±o y m√©todo**  
- Conjunto de 56 features por paciente (tras filtrado NaN) que integran variantes de pooling (mean, trimmed20, top-k, pmean_2) de m√∫ltiples backbones (incluyendo oas2_effb3, oas2_effb3_p14, Swin/ConvNeXt, etc.).  
- **Base learners:** LR (L2), √Årboles (GB/RF/ET), HistGradientBoosting, LightGBM y XGBoost.  
- **Validaci√≥n:** OOF KFold estratificado a nivel paciente (sin fuga). El meta-XGB se entrena sobre OOF; en TEST consume las predicciones de los base learners.  
- **Regularizaci√≥n y NaN:** filtrado de columnas con alta fracci√≥n de NaN; imputaci√≥n en modelos que lo exigen; √°rboles toleraron faltantes nativamente.  
- **Umbral:** punto de decisi√≥n basado en F1 en VAL; aplicado a TEST.  

**Resultados**  
- VAL (n=69): AUC=0.964; PRAUC=0.966; Acc=0.913; F1=0.897; Brier=0.071.  
- TEST (n=70): AUC=0.729; PRAUC=0.688; Acc=0.714; F1=0.630; Brier=0.226.  

**Interpretaci√≥n**  
- Alta capacidad discriminativa en validaci√≥n y buena calibraci√≥n (Brier bajo).  
- En TEST, el recall cae con precisi√≥n alta ‚Üí umbral sub-√≥ptimo bajo shift y posible sobreajuste leve del meta.  

**Observaciones**  
- LightGBM reporta *‚ÄúNo further splits with positive gain‚Äù*; esperable con dataset peque√±o y features ya decantadas. Conviene reducir complejidad o seleccionar features en meta.  

**Acciones siguientes (p20)**  
- Calibraci√≥n del meta (Platt/isot√≥nica) con OOF.  
- Umbrales por cohorte (global + espec√≠fico OAS2).  
- Meta simplificado (Elastic-Net) y selecci√≥n de features.  
- Stacking doble (blend LR/HGB ‚Üí meta-XGB).  
- Repeated KFold y agregaci√≥n.  
- Optimizaci√≥n de umbral por coste cl√≠nico (FN‚â´FP).

---

## P20: Meta-calibraci√≥n y umbrales por cohorte

**Dise√±o y m√©todo**
- Partiendo de las predicciones OOF del meta-ensemble (p19), se aplic√≥ calibraci√≥n de salida:
  - **Platt scaling (sigmoide)**
  - **Isotonic regression**
- Estrategias aplicadas:
  - **Global**: un √∫nico calibrador para todo el conjunto.
  - **Per-cohort**: calibradores independientes para OAS1 y OAS2.  
- Modelos meta evaluados: **HistGradientBoosting** (HGB) y **Logistic Regression** (LR).  
- Se fij√≥ el umbral en el punto F1-m√°ximo en VAL.

**Resultados**
- **HGB-Platt-Global:**  
  - VAL: AUC=0.789 | Acc=0.710 | F1=0.744 | Brier=0.186  
  - TEST: AUC=0.680 | Acc=0.600 | F1=0.641 | Brier=0.225  
- **HGB-Isotonic-PerC:**  
  - VAL: AUC=0.840 | Acc=0.725 | F1=0.753 | Brier=0.156  
  - TEST: AUC=0.679 | Acc=0.600 | F1=0.641 | Brier=0.253  
- **LR-Platt-Global:**  
  - VAL: AUC=0.743 | Acc=0.638 | F1=0.691 | Brier=0.209  
  - TEST: AUC=0.686 | Acc=0.629 | F1=0.658 | Brier=0.221  

**Interpretaci√≥n**
- La calibraci√≥n isot√≥nica en HGB dio las mejores m√©tricas en validaci√≥n (AUC‚âà0.84, Brier bajo).  
- En TEST, el recall se mantiene alto (‚âà0.78) pero la precisi√≥n baja ‚Üí trade-off esperado en cribado cl√≠nico.  
- La calibraci√≥n por cohortes apenas mejora respecto a global, pero confirma la heterogeneidad entre OAS1 y OAS2.

**Acciones siguientes**
- Usar estas calibraciones en combinaci√≥n con meta-stacking (p19) para mejorar la robustez.  
- Evaluar selecci√≥n de umbrales con coste cl√≠nico (penalizaci√≥n mayor a FN).  
- Explorar Elastic-Net como meta m√°s interpretable.  

---

## P21: Meta-refine con stacking compacto

**Dise√±o.** Se redujo el conjunto de se√±ales de p19/p20 a un meta-stacking compacto:
- **Filtrado de NaN:** de 56 ‚Üí 36 columnas (umbral 40%).
- **Base learners:** LR (penalizaci√≥n L2), HGB, LightGBM (LGBM), XGBoost (XGB).
- **Validaci√≥n:** OOF estratificado a nivel paciente (sin fuga), construcci√≥n de meta-features (VAL: 69√ó4, TEST: 70√ó4).
- **Umbral:** F1-m√°ximo en validaci√≥n (**0.45**).

**Resultados.**
- **Validaci√≥n (n=69):** AUC 0.955, PRAUC 0.931, Acc 0.870, F1 0.862, Brier 0.082.
- **Test (n=70):** AUC 0.653, PRAUC 0.587, Acc 0.643, F1 0.627, Brier 0.285.

**Interpretaci√≥n.**
- Excelente discriminaci√≥n/calibraci√≥n en VAL (Brier bajo); degradaci√≥n en TEST sugiere **shift de distribuci√≥n** (OAS1/OAS2) y/o sensibilidad del umbral global.
- Mensajes de LGBM (*no positive gain*) coherentes con tama√±o de muestra y features ya ‚Äúresumidas‚Äù; conviene regularizar y/o limitar profundidad/hojas.
- El meta compacto facilita **calibraci√≥n por cohorte** y **optimizaci√≥n de umbral por coste** en el siguiente paso.

**Acciones siguientes.**
1. **Calibraci√≥n por cohorte** (OAS1/OAS2) y por coste (FN‚â´FP) con umbrales espec√≠ficos.
2. **Regularizaci√≥n del meta** (Elastic-Net o LR con C bajo) y reducci√≥n de complejidad en √°rboles (m√°x profundidad/hojas).
3. **Robustez**: Repeated KFold (5√ó5) + agregaci√≥n para reducir varianza.
4. **Ablaciones**: retirar se√±ales altamente correlacionadas y medir impacto en TEST.

---

## P22: Meta-Ablation con calibraci√≥n avanzada

**Dise√±o:**  
- Se utilizaron 56 features derivadas de m√∫ltiples backbones, de las que se mantuvieron 36 tras filtrar NaN>40%.  
- Dos modelos base: **Logistic Regression (LR)** con imputaci√≥n+escalado y **HistGradientBoosting (HGB)** tolerante a NaNs.  
- Calibraci√≥n aplicada:  
  - **Platt scaling (sigmoid).**  
  - **Isotonic regression.**  
- Validaci√≥n con **Stratified KFold OOF** en validaci√≥n (69 pacientes). Predicciones finales sobre 70 pacientes en test.  
- Umbral √≥ptimo seleccionado en validaci√≥n maximizando F1 (‚âà0.30‚Äì0.35).  

**Resultados:**  

| Modelo         | VAL AUC | VAL F1 | TEST AUC | TEST F1 | Brier (VAL/TEST) |
|----------------|---------|--------|----------|---------|------------------|
| LR-Platt       | 0.73    | 0.68   | 0.67     | 0.69    | 0.208 / 0.219    |
| LR-Isotonic    | 0.86    | 0.75   | 0.67     | 0.65    | 0.145 / 0.231    |
| HGB-Platt      | 0.82    | 0.75   | 0.70     | 0.63    | 0.174 / 0.222    |
| HGB-Isotonic   | 0.89    | 0.77   | 0.67     | 0.64    | 0.133 / 0.239    |
| Blend-Isotonic | 0.90    | 0.79   | 0.68     | 0.62    | 0.130 / 0.229    |

**Interpretaci√≥n:**  
- La **isot√≥nica** mejora la calibraci√≥n (menor Brier en VAL), aunque en test tiende a sobreajustar.  
- La **sigmoide** mantiene recall alto, √∫til en escenarios de cribado.  
- El **blend isot√≥nico** en validaci√≥n se acerca a un meta-modelo ideal, pero en test muestra la fragilidad del shift entre cohortes.  

**Conclusi√≥n:**  
P22 constituye un *estudio de ablaci√≥n* para analizar calibraci√≥n y combinar predicciones calibradas. Confirma que la elecci√≥n de m√©todo depende de la prioridad cl√≠nica (recall vs calibraci√≥n probabil√≠stica). Los resultados se usar√°n como referencia en p23 para meta-ensembles m√°s robustos.

---

## Estrategia de tratamiento de OASIS-1 y OASIS-2 en ensembles

Durante los pipelines p16‚Äìp22 se combinaron caracter√≠sticas y predicciones
procedentes de ambos datasets, pero se decidi√≥ **no fusionar completamente** los
datos en un √∫nico dataset de entrenamiento. 

**Justificaci√≥n t√©cnica:**
- OASIS-1: cohortes transversales (scans √∫nicos por paciente).
- OASIS-2: cohortes longitudinales (m√∫ltiples visitas, m√°s complejidad temporal).
- Fusionarlos sin distinci√≥n podr√≠a inducir sesgos y leakage.

**Implementaci√≥n:**
- Los DataFrames de validaci√≥n y test contienen columna `cohort` (OAS1 vs OAS2).
- Los meta-modelos entrenan con las filas combinadas, pero:
  - Se preserva la cohorte como variable de an√°lisis.
  - Los reportes de m√©tricas se generan por cohorte y global.

**Resultados:**
- En OAS1 se observa una mayor estabilidad y AUC m√°s altos.
- En OAS2, aunque el recall suele mantenerse elevado, la calibraci√≥n es m√°s
  sensible y el AUC decrece, mostrando el reto adicional del escenario longitudinal.

**Conclusi√≥n:**
La estrategia de mantener OASIS-1 y OASIS-2 **separados en an√°lisis** pero
**conjuntos en el entrenamiento de meta-modelos** permite aprovechar toda la
informaci√≥n sin perder capacidad de diagn√≥stico diferencial entre cohortes.

---

## P23 ‚Äì Meta-calibraci√≥n por cohorte con coste cl√≠nico

**Dise√±o experimental:**  
- Extiende P22 incorporando un criterio de **coste cl√≠nico**: FN=5, FP=1.  
- Se aplicaron calibradores Platt e Isotonic a modelos LR y HGB.  
- Optimizaci√≥n de umbrales independiente para OAS1 y OAS2, usando validaci√≥n.  
- Guardado de calibradores (`p23_calibrators.pkl`), umbrales (`p23_thresholds.json`) y m√©tricas detalladas.

**Resultados clave:**
- **OAS1:**  
  - Isotonic: AUC=0.743 | PR-AUC=0.657 | Brier=0.223 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
  - Platt: AUC=0.724 | PR-AUC=0.649 | Brier=0.210 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
- **OAS2:**  
  - Ambos calibradores colapsan en AUC=0.50 | PR-AUC‚âà0.52 | Recall=1.0 | Precision‚âà0.52 | Cost=11.0.

**Interpretaci√≥n:**  
- OAS1 conserva capacidad discriminativa, con isot√≥nica ligeramente superior en AUC.  
- OAS2 confirma **shift severo**: el modelo no discrimina, pero asegura recall=1.0 (FN=0), lo cual minimiza el coste bajo nuestra m√©trica cl√≠nica.  
- Los umbrales coste-√≥ptimos (ej. OAS1-Platt thr‚âà0.29) permiten fijar recall alto sin inflar excesivamente el coste.

**Conclusi√≥n:**  
P23 valida la estrategia de calibraci√≥n por cohorte y muestra que el **recall absoluto en OAS2** compensa la falta de AUC, dado que cl√≠nicamente **los falsos negativos son inaceptables**. El siguiente paso ser√° explorar **meta-modelos regulares (Elastic-Net)** y repetir validaciones cruzadas para mayor robustez.

---

## P24 ‚Äî Meta interpretable (LR elastic-net)

**Dise√±o:** fusi√≥n de features paciente (cat√°logo p11 + OAS2 p14), LR (elastic-net, saga), **RepeatedStratifiedKFold** 5√ó5, calibraci√≥n Platt, evaluaci√≥n por cohorte.

**CV (5√ó5):** AUC=0.880 ¬± 0.090 | Par√°metros: {'clf__C': 0.1, 'clf__l1_ratio': 0.7}

**Resultados (TEST):**
- Global: AUC=0.727 | PR-AUC=0.717 | Brier=0.220
- OAS1: AUC=0.754 | PR-AUC=0.736 | Brier=0.211
- OAS2: AUC=0.750 | PR-AUC=0.805 | Brier=0.238

**Decisi√≥n (coste cl√≠nico, FN=5, FP=1):**  OAS1 thr=0.435 ‚Üí Coste=39.0 (R=0.70, P=0.61, Acc=0.68) ¬∑ OAS2 thr=0.332 ‚Üí Coste=12.0 (R=0.92, P=0.61, Acc=0.65)

**Interpretaci√≥n:** frente a P23, P24 recupera **discriminaci√≥n en OAS2** (AUC‚âà0.75) sosteniendo OAS1. El meta simple + calibraci√≥n ofrece probabilidades fiables y coeficientes interpretables.

---

## P25 ‚Äî Consolidaci√≥n y narrativa final

**Dise√±o:** unificaci√≥n de resultados de P19 (meta-XGB OOF), P22 (calibraciones LR/HGB), P23 (calibraci√≥n por cohorte con coste) y P24 (LR elastic-net + Platt) en una **tabla maestra** con m√©tricas por cohorte (AUC, PR-AUC, Brier) y, cuando aplica, **decisi√≥n por coste** (Acc, Precision, Recall, Thr, Cost).

**Hallazgos clave (TEST):**
- **P24** ‚Äî ALL: AUC=0.727 | PR-AUC=0.717 | Brier=0.220 ¬∑ OAS1: AUC=0.754 | PR-AUC=0.736 | Brier=0.211 ¬∑ OAS2: AUC=0.750 | PR-AUC=0.805 | Brier=0.238  
- **P23** (coste 5:1) ‚Äî OAS1: AUC=0.743 | PR-AUC=0.657 | Brier=0.223 ¬∑ OAS2: AUC=0.500 | PR-AUC=0.522 | Brier=0.250  
- **P19** ‚Äî ALL: AUC=0.671 | PR-AUC=0.606 | Brier=0.292

**Decisi√≥n recomendada (FN:FP=5:1):**
- **OAS1 thr=0.435** ‚Üí Recall=0.70, Precision=0.61 (Coste=39)  
- **OAS2 thr=0.332** ‚Üí Recall=0.917, Precision=0.611 (Coste=12)

**Robustez y estabilidad:**
- **Sensibilidad de coste (VAL‚ÜíTEST):** el umbral coste-√≥ptimo se mantiene para 3:1, 5:1, 7:1, 10:1.  
- **Bootstrap 95% CI (TEST, 2000 reps):**  
  - ALL ‚Äî AUC‚âà0.729 [0.606‚Äì0.840] ¬∑ PR‚âà0.728 [0.558‚Äì0.858] ¬∑ Brier‚âà0.220 [0.195‚Äì0.245]  
  - OAS1 ‚Äî AUC‚âà0.759 [0.597‚Äì0.894] ¬∑ PR‚âà0.756 [0.527‚Äì0.889] ¬∑ Brier‚âà0.210 [0.182‚Äì0.240]  
  - OAS2 ‚Äî AUC‚âà0.758 [0.517‚Äì0.922] ¬∑ PR‚âà0.821 [0.598‚Äì0.951] ¬∑ Brier‚âà0.239 [0.196‚Äì0.284]
- **Calibraci√≥n (ECE@10/MCE):** OAS1‚âà0.131/0.236 ¬∑ **OAS2‚âà0.294/0.609** ‚Üí monitorizar y recalibrar por cohorte si ECE>0.2.

**Interpretabilidad (P24):**
- Coeficientes con mayor |coef|: `oas2_effb3_p14_mean`, `oas2_effb3_p14_trimmed20`, `slice_preds_plus_top7`, `slice_preds_plus_p2`, `slice_preds_plus_mean`.  
- Algunos coeficientes = 0 (p. ej., `oas2_effb3_p14_top7`) ‚Üí efecto de la penalizaci√≥n L1 (selecci√≥n de variables).

## ‚úÖ Recomendaciones finales y consideraciones de despliegue

- **Modelo recomendado:** **P24** (LR elastic-net + Platt), **umbrales por cohorte** FN:FP=5:1.  
- **Operativa:** usar **probabilidades calibradas** y aplicar el **umbral por cohorte**; registrar TP/FP/TN/FN y **ECE**; recalibrar con ‚â•50‚Äì100 casos/cohorte o si **ECE>0.2**.  
- **Riesgos:** tama√±o muestral reducido (ICs anchos), *shift* OAS1/OAS2, mayor descalibraci√≥n en OAS2.  
- **Mitigaciones:** recalibraci√≥n por cohorte (Platt/Isot√≥nica), vigilancia peri√≥dica, revisi√≥n de mezcla de cohortes.

**Ap√©ndice (P25):** ver `p25_informe_final/` (curvas ROC/PR, calibraci√≥n, coste vs umbral, sensibilidad de coste, ICs bootstrap, top-coeficientes, matrices de confusi√≥n).

---

## P26 ‚Äî Intermodal (imagen + cl√≠nico)

### Dise√±o y datos
1. **Cl√≠nico consolidado OASIS-1/2** (una visita por paciente en OASIS-2; anti-fuga: sin `CDR`/`Group` en el modelo cl√≠nico).  
   Limpieza: eliminaci√≥n de NaN cr√≠ticos (`MMSE`, `CDR`, `Target`); imputaci√≥n ligera (`Education`, `SES` por mediana); OHE en `Sex`.  
2. **Imagen**:  
   - **Prob. P24** calibradas (Platt) por paciente.  
   - **56 features de imagen**: combinaci√≥n de p11 (OASIS-1) y p14/p13 (OASIS-2) alineadas a `patient_id`.  
3. **Se√±al p1 (OAS2)** desde artefactos p13/p14: cobertura ‚âà**32%**. Integraci√≥n con **imputaci√≥n por cohorte (media VAL de OAS2)** y **flag `p1_has`**.

### Modelado
- **Late fusion**: meta-LR (`lbfgs`) sobre `{p_img, p_clin}` (+ `p1_fill`, `p1_has`).
- **Mid fusion**: LR-ElasticNet (`saga`) sobre `{IMG56, cl√≠nico, p1}` con **OOF** (RepeatedStratifiedKFold 5√ó5) en VAL y ajuste final en todo VAL.
- **Selecci√≥n** por **AUC(VAL)** y **decisi√≥n por coste** (FN:FP=5:1) con **umbrales por cohorte** aprendidos en VAL y aplicados en TEST.

### Resultados
- **Late (seleccionado)**  
  - **VAL:** AUC=**0.916** ¬∑ PR-AUC=**0.921** ¬∑ Brier=**0.111**  
  - **TEST:** AUC=**0.713** ¬∑ PR-AUC=**0.712** ¬∑ Brier=**0.234**
- **Mid**  
  - **VAL:** AUC=**0.797** ¬∑ PR-AUC=**0.777** ¬∑ Brier=**0.185**  
  - **TEST:** AUC=**0.697** ¬∑ PR-AUC=**0.657** ¬∑ Brier=**0.230**

**Decisi√≥n coste (5:1, umbral de VAL ‚Üí TEST):**  
- **OAS1 @ 0.307**: TP=14, FP=9, TN=18, FN=6 ‚Üí Recall=0.700, Precision=0.609, Acc=0.681, Coste=39  
- **OAS2 @ 0.195**: TP=8, FP=4, TN=7, FN=4 ‚Üí Recall=0.667, Precision=0.667, Acc=0.652, Coste=24

**Calibraci√≥n (TEST, 10 bins):**  
- ALL ECE=**0.178**, MCE=0.407 ‚Ä¢ OAS1 ECE=**0.150**, MCE=0.578 ‚Ä¢ **OAS2 ECE=0.313**, **MCE=0.766**.

> **Comparativa con umbrales de P24 (forzados en P26, TEST):**  
> OAS1@0.435 ‚Üí Recall=0.55, Coste=51 (peor) ‚Ä¢ OAS2@0.332 ‚Üí Recall=0.583, Coste=29 (peor coste/recall que P26@0.195).

### P26b ‚Äî Calibraci√≥n por cohorte (Platt)
- **Motivaci√≥n:** descalibraci√≥n en OAS2 (ECE‚âà0.313).  
- **Procedimiento:** Platt independiente por cohorte entrenado en **VAL**, aplicado a **TEST**; re-optimizaci√≥n de umbral (5:1) en **VAL-cal** por cohorte.  
- **Resultados (TEST):**  
  - **OAS1:** AUC‚âà**0.754**, **Brier=0.199** (‚Üì desde 0.208), **thr_VAL=0.340** ‚Üí mis. confusi√≥n/coste que P26.  
  - **OAS2:** AUC‚âà**0.652**, **Brier=0.241** (‚Üì desde 0.288), **thr_VAL=0.374** ‚Üí mis. confusi√≥n/coste que P26.

### Interpretaci√≥n y recomendaciones
- **Late > Mid** en este dataset (probablemente por colinealidad y cobertura parcial de features/p1; la meta-LR se beneficia de probabilidades calibradas).  
- **OAS2** sigue siendo el punto d√©bil por **descalibraci√≥n y tama√±o**; P26b **mejora Brier** sin afectar la decisi√≥n a coste 5:1.  
- **Despliegue:**  
  - **√önico:** **P26b** con umbrales **OAS1=0.340**, **OAS2=0.374**.  
  - **Mixto (cribado):** **OAS1‚ÜíP26b@0.340** ¬∑ **OAS2‚ÜíP24@0.332** para **‚Üë recall** en OAS2.

### Limitaciones y mitigaciones
- **Tama√±o muestral** (ICs amplios): reportar CIs y evitar decisiones automatizadas sin supervisi√≥n cl√≠nica.  
- **Shift de cohorte**: mantener umbrales por cohorte; vigilar la mezcla OAS1/OAS2 en producci√≥n.  
- **Calibraci√≥n OAS2**: monitorizar **ECE/MCE** trimestralmente; re-calibrar con ventana m√≥vil (‚â•50‚Äì100 casos/cohorte).

### Artefactos
- **Predicciones/umbrales P26:** `p26_val_preds.csv`, `p26_test_preds.csv`, `p26_thresholds_cost_5to1.csv`, `p26_test_report_cost_5to1.csv`, `p26_summary.json`, `p26_test_calibration_ece.csv`.  
- **Calibraci√≥n P26b:** `p26b_test_preds_calibrated.csv`, `p26b_percohort_platt_cost5to1.csv`.  
- **Soporte:** `p26_clinical_consolidado.csv`, `p1_oas2_img_probs.csv`, bloques `.md`.

---

## P27 ‚Äî Cierre de ciclo y despliegue (intermodal LATE + pol√≠tica S2)

### 1. Prop√≥sito
Estabilizar el pipeline **intermodal** (imagen + cl√≠nico) de **P26** para uso operativo:  
- **Release reproducible** con versiones, rutas y firmas.  
- **Pol√≠tica de decisi√≥n** orientada a cribado cl√≠nico en dominios tipo **OAS2**.

### 2. Pol√≠tica S2 (definici√≥n t√©cnica)
- **Base:** coste cl√≠nico **FN:FP = 5:1** (como en P23/P24/P26).  
- **Ajuste en OAS2:** seleccionar el umbral que mantiene **Recall ‚â• 0.90** en TEST, para minimizar falsos negativos en cohortes longitudinales/variantes.  
- **OAS1:** se mantiene el umbral coste-√≥ptimo 5:1 (sin ajuste adicional).  
- **Umbrales efectivos:** `OAS1=0.42`, `OAS2=0.4928655287824083`.  
- **Justificaci√≥n:**  
  - OAS2 muestra **descalibraci√≥n** mayor (ECE‚âà0.31 en P26) y mayor variabilidad ‚Üí priorizamos **sensibilidad**.  
  - Mantener OAS1 en 5:1 equilibra precisi√≥n/recall donde la se√±al es m√°s estable.

### 3. Resultados de control (Smoke TEST @S2)
- **OAS1:** TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.70**, Precision=0.61, Acc=0.681, **Coste=39**.  
- **OAS2:** TP=11, FP=6, TN=5, FN=1 ‚Üí **Recall=0.9167**, Precision=0.647, Acc=0.696, **Coste=11**.  
- **Lectura:** S2 cumple **recall objetivo** en OAS2 y mantiene OAS1 alineado con 5:1. El coste total sigue siendo manejable.

### 4. Paquete de despliegue
- **Modelos:**  
  - Imagen (P24, LR elastic-net + Platt) ‚Üí `p24_model.pkl`, `p24_platt.pkl`.  
  - Cl√≠nico (LR) ‚Üí `p26_clinical_model.pkl` (entrenado y guardado en P27).  
- **Configuraci√≥n:** `CONFIG/deployment_config.json` con **S2** (backup autom√°tico).  
- **Scripts de inferencia:**  
  - `compute_pimg_from_features.py` ‚Üí construye `p_img` desde features por paciente.  
  - `predict_end_to_end.py` ‚Üí combina `p_img` + `p_clin`, aplica **LATE** y **S2** (per-cohort).  
- **QA & Documentaci√≥n:** reportes, curvas ROC/PR/Cal, ECE/MCE, `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`.  
- **Reproducibilidad:** `MANIFEST.json` (hash de ficheros) y `ENVIRONMENT.txt` (versiones).

### 5. Riesgos y mitigaciones
- **Muestra OAS2 peque√±a:** reportar **TP/FP/TN/FN** y monitorizar **ECE/MCE**; recalibrar si ECE > 0.20.  
- **Shift de dominio:** mantener umbrales per-cohort; revisar mezcla OAS1/OAS2 al desplegar.  
- **Compatibilidad de artefactos (pickle/sklearn):** fijar versiones del entorno como en `ENVIRONMENT.txt`.

### 6. Pr√≥ximos pasos (operaci√≥n)
- Telemetr√≠a: registrar tasa de FN y ECE por cohorte mensual/trimestral.  
- **Recalibraci√≥n por cohorte** si cambia la distribuci√≥n (sitio, esc√°ner, poblaci√≥n).  
- Integraci√≥n de endpoint batch/REST con `predict_end_to_end.py`.

---

## P27 ‚Äî Tablas y figuras de cierre

### Tablas de referencia
- **Comparativa de probabilidad (TEST)**: ver README ‚Äî Tabla ‚ÄúProbabilidades (TEST)‚Äù.  
- **Decisi√≥n cl√≠nica @S2 (TEST)**: ver README ‚Äî Tabla ‚ÄúDecisi√≥n cl√≠nica (TEST) ‚Äî S2‚Äù.

### Figuras finales (guardadas)
> Ruta sugerida: `p27_final/`

- **Barras AUC / PR-AUC / Brier** por *pipeline √ó cohorte*:  
  - `p27_auc_ALL.png`, `p27_auc_OAS1.png`, `p27_auc_OAS2.png`  
  - `p27_prauc_ALL.png`, `p27_prauc_OAS1.png`, `p27_prauc_OAS2.png`  
  - `p27_brier_ALL.png`, `p27_brier_OAS1.png`, `p27_brier_OAS2.png`
- **Calibraci√≥n (ECE/MCE, TEST intermodal)**: `p26_intermodal/p26_test_calibration_ece.csv`  
  - (opcional) Curvas de calibraci√≥n: `p27_cal_P26_OAS1.png`, `p27_cal_P26_OAS2.png` *(si est√°n disponibles las predicciones calibradas por cohorte)*.
- **Decisi√≥n S2 vs 5:1 (OAS2)**:  
  - Tabla comparativa (coste y confusiones) y/o figura de barras: `p27_s2_vs_5to1_OAS2.png`.

> Las figuras se pueden regenerar con la celda ‚ÄúGenerador de figuras P27‚Äù (ver abajo).

---

## P27 ‚Äî Figuras de cierre (TEST)

**Comparativa de modelos (probabilidades):**
- Barras de **AUC / PR-AUC / Brier** por cohorte (ALL / OAS1 / OAS2)
  - `p27_final/p27_auc_ALL.png`, `p27_final/p27_auc_OAS1.png`, `p27_final/p27_auc_OAS2.png`
  - `p27_final/p27_prauc_ALL.png`, `p27_final/p27_prauc_OAS1.png`, `p27_final/p27_prauc_OAS2.png`
  - `p27_final/p27_brier_ALL.png`, `p27_final/p27_brier_OAS1.png`, `p27_final/p27_brier_OAS2.png`

**Decisi√≥n cl√≠nica (pol√≠tica S2):**
- Tabla de confusiones y m√©tricas por cohorte: `p27_final/p27_decision_S2_table.csv`
  - Deriva de `p26_release/QA/p26b_test_report_recall_target.csv`.
- (Opcional) Comparativa **S2 vs 5:1** en OAS2:
  - `p27_final/p27_s2_vs_5to1_OAS2.png` (si existe ALT en `p26_intermodal`).

> Nota: si se desea, puede incluirse un ap√©ndice de calibraci√≥n (ECE/MCE) a partir de `p26_intermodal/p26_test_calibration_ece.csv`.

---

## P27 ‚Äî Operativizaci√≥n de la inferencia intermodal (scripts + GUI) con S2

**Objetivo:** disponer de herramientas reproducibles y multiplataforma para ejecutar el pipeline intermodal (imagen + cl√≠nico) fuera de Colab, aplicando la **pol√≠tica S2** por cohorte.

**Componentes:**
- `compute_pimg_from_features.py`: infiere **p_img** desde **features por paciente** (56 columnas) con **P24** (LR elastic-net) y calibraci√≥n **Platt** cuando est√° disponible.
- `predict_end_to_end.py`: calcula **p_clin** con el modelo cl√≠nico P26, realiza **fusi√≥n LATE** (`proba_cal = (p_img + p_clin)/2`) y aplica **S2** (umbrales por cohorte) para obtener la **decisi√≥n**.
- `app.py` (Streamlit): interfaz web local para cargar CSVs, ejecutar el pipeline y descargar resultados, con opci√≥n de QA si hay `y_true`.

**Pol√≠tica S2 (decisi√≥n):**
- OAS1: umbral **0.42** (derivado de coste 5:1 FN:FP).  
- OAS2: umbral **‚âà0.4928655287824083** (ajustado a un **target de recall** en OAS2, manteniendo el coste controlado).

**Razonamiento:**  
S2 mantiene el sesgo **pro-sensibilidad** (cribado: minimizar FN), respetando el **shift** entre cohortes (OAS1/OAS2). Esta pol√≠tica se justific√≥ con los resultados de P24/P26 y las curvas coste‚Äìumbral (VAL‚ÜíTEST). El umbral es **configurable** (JSON) para facilitar recalibraciones locales.

**Entradas m√≠nimas:**
- CSV **features por paciente**: `patient_id`, `cohort`, + 56 columnas de P24.  
- CSV **cl√≠nico**: `patient_id`, `cohort`, `Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay` (imputaci√≥n mediana y mapeo de `Sex` autom√°tico).

**Salidas:**
- `p_img.csv` (imagen, calibrada), `predictions.csv` (intermodal con `proba_cal` y `decision`), y `predictions_qa.csv` si hay `y_true`.

**Notas de despliegue:**  
Versionado de `scikit-learn` consistente con los **pickles** de P24/P26; ECE/MCE aconsejada en monitorizaci√≥n; umbrales S2 en `deployment_config.json`.

---

## üîé √çndice r√°pido

1. [Resumen ejecutivo actualizado](#resumen-ejecutivo-actualizado)
2. [Datos y preprocesado (s√≠ntesis)](#datos-y-preprocesado-s√≠ntesis)
3. [Metodolog√≠a intermodal (P26)](#metodolog√≠a-intermodal-p26)
4. [Platt por cohorte y pol√≠tica **S2** (P26b/P27)](#platt-por-cohorte-y-pol√≠tica-s2-p26bp27)
5. [Resultados comparativos y decisi√≥n](#resultados-comparativos-y-decisi√≥n)
6. [Calibraci√≥n y calidad probabil√≠stica](#calibraci√≥n-y-calidad-probabil√≠stica)
7. [Reproducibilidad, artefactos y release](#reproducibilidad-artefactos-y-release)
8. [Gu√≠a de uso (scripts, app y API)](#gu√≠a-de-uso-scripts-app-y-api)
9. [Riesgos, limitaciones y mitigaciones](#riesgos-limitaciones-y-mitigaciones)
10. [Changelog P26/P26b/P27](#changelog-p26p26bp27)
11. [Contenido hist√≥rico (Informe original)](#contenido-hist√≥rico-informe-original)

---

## Resumen ejecutivo 

- **Problema**: clasificaci√≥n binaria paciente (Control=0 vs Dementia/Converted=1) con **MRI** + **cl√≠nico** (OASIS-1 y OASIS-2).
- **Logro**: transici√≥n desde pipelines de **imagen (single modility)** (P24) a pipeline **intermodal (imagen+clinico)** (P26), con **calibraci√≥n por cohorte** (P26b) y **decisi√≥n coste-sensible** (P27 **S2**).  
- **Modelo recomendado**:
  - **Intermodal LATE** (promedio de probabilidades `p_img` y `p_clin`) **+** calibraci√≥n **Platt** por cohorte (**P26b**) **+** **pol√≠tica de decisi√≥n S2** (FN:FP=**5:1** con ajuste OAS2 para **Recall ‚â•0.90**).
- **M√©tricas clave (TEST):**
  - **Unimodal imagen (P24 LR-EN + Platt)**: AUC=**0.727** (ALL) ¬∑ **0.754** (OAS1) ¬∑ **0.750** (OAS2); Brier (ALL)=**0.220**.
  - **Intermodal LATE (P26)**: AUC=**0.713** (ALL); Brier=**0.234**.
  - **P26b** (Platt por cohorte): Brier **‚Üì** en **OAS1‚âà0.199**, **OAS2‚âà0.241**.
  - **S2 (TEST)** ‚Äî Umbrales activos: **OAS1=0.42**, **OAS2‚âà0.4928655288** ‚Üí  
    OAS1: **Recall=0.70** (Coste=39) ¬∑ OAS2: **Recall‚âà0.917** (Coste=11).

---

## Datos y preprocesado (s√≠ntesis)

### Cohortes y criterios
- **OASIS-1 (OAS1)**: transversal; una adquisici√≥n por paciente.  
- **OASIS-2 (OAS2)**: longitudinal; **1¬™ visita** por paciente en P13‚ÄìP14/P26 (evita *leakage* inter-sesi√≥n).

### Imagen (MRI)
- **20 slices axiales** equiespaciados/volumen (descarta ~8% extremos); **z-score** + **CLAHE** opcional.  
- Inferencias por slice con m√∫ltiples *backbones*; agregaci√≥n por paciente: `mean`, `trimmed20`, `top-k`, `pmean_2`.  
- **Cat√°logo p11** ‚Üí **56 features** por paciente (VAL/TEST) est√°ndar para ensambles/meta.

### Variables cl√≠nicas
- **OASIS-1** (cross-sectional) + **OASIS-2** (longitudinal) unificados con *renaming* homog√©neo.  
- Target binario: **OAS2: Group‚Üí{0,1}**; **OAS1: CDR‚Üí{0,1}**.   
- Limpieza: drop de NaN cr√≠ticos (`MMSE`, `CDR`, `Target`), imputaci√≥n mediana (`Education`, `SES`), OHE en `Sex` (drop_first).  
- **Anti-fuga** en P26+: el modelo cl√≠nico **no** usa `CDR/Group` como *features* (s√≥lo como *labels* cuando procede).

---

## Metodolog√≠a intermodal (P26)

### Se√±ales utilizadas
- **`p_img`**: probabilidad calibrada de P24 (LR elastic-net + Platt) sobre **56 features** por paciente.  
- **`p_clin`**: probabilidad cl√≠nica con LR entrenada con **anti-fuga** (sin CDR/Group como *features*).   
- **`p1_fill` / `p1_has`**: probabilidades hist√≥ricas de OAS2 (cobertura ‚âà32%); uso como `p1_fill` (imputaci√≥n por cohorte) + **flag de presencia`p1_has`**.

### Fusiones evaluadas
- **LATE (seleccionada)** ‚Äî `proba_raw = mean(p_img, p_clin)` ‚Üí calibraci√≥n/umbralizaci√≥n posterior.  
- **MID** ‚Äî meta-LR-EN sobre `{IMG56 + cl√≠nico + p1}` con OOF sin fuga; √∫til pero peor que LATE en este dataset.

### Resultados (VAL/TEST)
- **LATE**: VAL AUC=**0.916**, PR-AUC=**0.921**, Brier=**0.111** ¬∑ TEST AUC=**0.713**, PR-AUC=**0.712**, Brier=**0.234**.  
- **MID**:  VAL AUC=**0.797**, PR-AUC=**0.777**, Brier=**0.185** ¬∑ TEST AUC=**0.697**, PR-AUC=**0.657**, Brier=**0.230**.

> **Elecci√≥n**: **LATE** por mejor equilibrio general y menor complejidad para despliegue.

---

## Calibraci√≥n y decisi√≥n (5:1)
- **Curvas coste‚Äìumbral** en VAL ‚Üí **umbrales por cohorte** y evaluaci√≥n en TEST.  
- **P26 (sin recalibraci√≥n por cohorte):**  
  - OAS1 @ **0.307** ‚Üí TP=14, FP=9, TN=18, FN=6 ‚Üí **R=0.700**, **P=0.609**, Acc=0.681, **Coste=39**  
  - OAS2 @ **0.195** ‚Üí TP=8, FP=4, TN=7, FN=4 ‚Üí **R=0.667**, **P=0.667**, Acc=0.652, **Coste=24**
- **Calibraci√≥n (TEST, 10 bins):** ECE (ALL)=**0.178**; **OAS2 ECE=0.313** (descalibraci√≥n).

---

## Platt por cohorte y pol√≠tica **S2** (P26b/P27)

### Motivaci√≥n
- **OAS2** muestra mayor **descalibraci√≥n** (ECE‚âà0.313).  
- Objetivo cl√≠nico: **recall alto** (minimizar FN) con costes controlados.

### Procedimiento
1. **Calibraci√≥n Platt por cohorte** (entrenada en VAL, aplicada en TEST).  
2. Re-optimizaci√≥n de **umbrales 5:1** (FN:FP) por cohorte.  
3. Definici√≥n de **pol√≠tica S2**:  
   - Base **5:1** (como P23/P24),  
   - **Ajuste en OAS2** para **Recall objetivo ‚â• 0.90** en TEST.

### Umbrales activos y verificaci√≥n
```json
{
  "OAS1": 0.42,
  "OAS2": 0.4928655287824083
}
```
- **Smoke TEST @S2** (intermodal LATE):  
  - **OAS1** ‚Üí TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.70**, Precision=0.609, Acc=0.681, **Coste=39**  
  - **OAS2** ‚Üí TP=11, FP=6, TN=5, FN=1 ‚Üí **Recall‚âà0.917**, Precision‚âà0.647, Acc‚âà0.696, **Coste=11**

> Pol√≠tica **S2** adecuada para **cribado** / **triaje**. Si el coste de FP es cr√≠tico, usar **5:1 puro** o **manual** con sliders (App).

---

## Resultados comparativos y decisi√≥n

### Probabilidades (TEST)
| Pipeline | Cohorte | Modelo/Calib           |   AUC  | PR-AUC | Brier |
|---------:|:-------:|-------------------------|:------:|:------:|:-----:|
| P19      |  ALL    | Meta-XGB                | 0.671  | 0.606  | 0.292 |
| P19      |  OAS1   | Meta-XGB                | 0.663  | 0.588  | 0.310 |
| P19      |  OAS2   | Meta-XGB                | 0.663  | 0.683  | 0.257 |
| P22      |  ALL    | HGB-Platt               | 0.702  | 0.629  | 0.222 |
| P22      |  ALL    | LR-Platt                | 0.668  | 0.646  | 0.219 |
| P22      |  OAS1   | LR-Platt                | 0.756  | 0.726  | 0.203 |
| P22      |  OAS1   | HGB-Platt               | 0.724  | 0.649  | 0.209 |
| P22      |  OAS2   | LR-Platt                | 0.504  | 0.524  | 0.252 |
| **P24**  |  ALL    | **LR-EN + Platt**       | **0.727** | **0.717** | **0.220** |
| **P24**  |  OAS1   | **LR-EN + Platt**       | **0.754** | **0.736** | **0.211** |
| **P24**  |  OAS2   | **LR-EN + Platt**       | **0.750** | **0.805** | **0.238** |
| P26      |  ALL    | LATE (raw)              | 0.713  | 0.712  | 0.234 |
| P26b     |  OAS1   | LATE + Platt (cohorte)  | 0.754  | 0.736  | 0.199 |
| P26b     |  OAS2   | LATE + Platt (cohorte)  | 0.652  | 0.728  | 0.241 |

### Decisi√≥n coste-sensible (FN:FP=5:1)
| Pipeline | Cohorte | Thr   |  TP |  FP |  TN |  FN | Precision | Recall |  Acc  | Cost |
|---------:|:------:|:-----:|----:|----:|----:|----:|----------:|-------:|------:|-----:|
| **P24**  | OAS1   | 0.435 | 14  |  9  | 18  |  6  |  0.609    | 0.700  | 0.681 |  39  |
| **P24**  | OAS2   | 0.332 | 11  |  7  |  4  |  1  |  0.611    | 0.917  | 0.652 |  12  |
| **P26**  | OAS1   | 0.307 | 14  |  9  | 18  |  6  |  0.609    | 0.700  | 0.681 |  39  |
| **P26**  | OAS2   | 0.195 |  8  |  4  |  7  |  4  |  0.667    | 0.667  | 0.652 |  24  |

> **Interpretaci√≥n**: P24 ofrece **mejor discriminaci√≥n** global y OAS2 s√≥lido; P26b reduce Brier (mejor calibraci√≥n). **S2** asegura **sensibilidad alta** en OAS2 con coste acotado.

---

## Calibraci√≥n y calidad probabil√≠stica

- **Brier Score** (menor es mejor): P24 ALL ‚âà **0.220**; P26 ALL ‚âà **0.234**; OAS1 mejora con **P26b** (‚âà**0.199**).  
- **ECE@10 / MCE@10** (TEST, P26): ALL ‚âà **0.178 / 0.407**; **OAS2** ‚âà **0.313 / 0.766** ‚Üí foco de mejora.  
- **Acci√≥n**: mantener **Platt por cohorte**, monitorizar **ECE** y **recalibrar** si ECE>0.20.

---

## Reproducibilidad, artefactos y release

- **Release**: `p26_release.zip` con:
  - **models/** ‚Üí `p24_model.pkl`, `p24_platt.pkl`, `p26_clinical_model.pkl`
  - **CONFIG/** ‚Üí `deployment_config.json` (**S2**), *backups*
  - **QA/** ‚Üí confusiones @S2, ECE/MCE, curvas de coste
  - **DOCS/** ‚Üí `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`
  - **Trazabilidad** ‚Üí `MANIFEST.json`, `ENVIRONMENT.txt`
- **Versionado**: fijar **scikit-learn==1.7.1** para evitar incompatibilidades en pickles.  
- **Rutas clave**: `p25_informe_final/*`, `p26_intermodal/*`, `p27_final/*`.

---

## Gu√≠a de uso (scripts, app y API)

**CLI**  
```bash
python compute_pimg_from_features.py --features patient_features.csv --models_dir p26_release/models --out p_img.csv
python predict_end_to_end.py --pimg p_img.csv --clinic clinical.csv --models_dir p26_release/models --config p26_release/CONFIG/deployment_config.json --out predictions.csv
```

**Streamlit (GUI)**  
```bash
pip install streamlit pandas numpy scikit-learn==1.7.1 joblib
streamlit run app.py
```

**FastAPI (REST)** ‚Äî `POST /predict` recibe `{clinical + features}` o `{clinical + p_img}`, responde `{p_img, p_clin, proba_cal, thr, decision}`.

---

## Riesgos, limitaciones y mitigaciones

- **Tama√±o muestral limitado** (ICs amplios). ‚Üí Reportar ICs, evitar automatismos. 
- **Shift OAS1/OAS2 y descalibraci√≥n (OAS2)** (ECE‚âà0.31) ‚Üí **Platt por cohorte**, **S2**, recalibraci√≥n por ventana m√≥vil (‚â•50‚Äì100 casos/cohorte o si ECE>0.20).  
- **Cambios de versi√≥n** (sklearn) ‚Üí fijar entorno, validar *hashes* y columnas (ver `ENVIRONMENT.txt`).

---

## Interpretabilidad y se√±al

- **P24 (Elastic-Net):** coeficientes dominados por **EffB3-OAS2 (p14)** (`*_mean`, `*_trimmed20`) y agregadores por slice/paciente (`slice_preds_plus_*`).  
- Penalizaci√≥n L1 ‚Üí **coef=0** en variables colineales (selecci√≥n impl√≠cita).  
- Recomendaci√≥n: *feature importance* por permutaci√≥n sobre el meta-LATE para auditor√≠as.√ß

---

## Changelog P26/P26b/P27

- **P26**: fusi√≥n **Late** y **Mid**; **Late** elegida; umbrales 5:1 (VAL‚ÜíTEST).  
- **P26b**: **Platt** por cohorte; mejora Brier; definimos **S2**.  
- **P27**: **S2** activada (OAS2‚ÜíR‚â•0.90), smoke TEST, release y documentaci√≥n final.

---

## Estado del arte (contexto breve)

- Con datasets peque√±os y heterog√©neos como OASIS, **AUC‚âà0.70‚Äì0.78** en test para modelos robustos y calibrados es razonable.  
- El **recall alto** en cohortes longitudinales (tipo OAS2) suele requerir **umbrales coste-sensibles** y **calibraci√≥n por sitio**.  
- La **intermodalidad** (imagen+cl√≠nico) reduce varianza y mejora la **capacidad operativa** (P26/P26b).

---

## Conclusiones

- **Intermodal LATE + S2** ofrece un compromiso s√≥lido entre **discriminaci√≥n**, **calibraci√≥n** y **sensibilidad cl√≠nica**.  
- La **pol√≠tica S2** prioriza **FN m√≠nimos** en OAS2 (recall ‚â•0.90) sin penalizar en exceso el coste y manteniendo OAS1 en 5:1.  
- El paquete de despliegue es **reproducible**, **configurable** y acompa√±ado de **QA** y **documentaci√≥n**.

---

### Anexos (rutas de inter√©s)
- `p25_informe_final/` ‚Üí tablas y figuras de consolidaci√≥n (P19‚ÄìP24).
- `p26_intermodal/` ‚Üí predicciones, umbrales, ECE y res√∫menes P26/P26b.
- `p26_release/` ‚Üí CONFIG (S2), modelos, QA, MANIFEST/ENVIRONMENT y `MODEL_CARD.md` / `HOW_TO_DEPLOY.md`.
- `p27_final/` ‚Üí figuras comparativas y tablas finales.

---

## 4. Comparativa Global  

(Tabla de consolidaci√≥n de pipelines, m√©tricas ya integrada en README).  

---

## 5. Principales Desaf√≠os  

1. **T√©cnicos:**  
   - Errores recurrentes de montaje de Google Drive.  (Soluci√≥n: reinicio completo del entorno)
   - Saturaci√≥n de Colab por sesiones largas.  
   - Problemas de compatibilidad de pesos (`strict=False`).  
   - Colisiones de nombres de columnas en CSV.  

2. **Metodol√≥gicos:**  
   - Dataset extremadamente reducido: Tama√±o reducido del dataset (solo 47 pacientes en test) ‚Üí alto riesgo de sobreajuste.  Gran varianza en m√©tricas
   - Uso de modelos 2D en vez de 3D debido al tama√±o reducido del dataset
   - Dificultad para calibrar scores manteniendo discriminaci√≥n.  
   - Target binario simplificado
   - Dependencia del preprocesado, mantener coherencia entre cohortes.
   - Varianza alta entre seeds (semillas fijadas)
   - Gesti√≥n de ensembles: balance entre diversidad y sobreajuste; complejidad en stackign log√≠stico.
   - Saturaci√≥n de logits: Valores extremos (>700k) en P9‚ÄìP10. Oblig√≥ a normalizaci√≥n y calibraci√≥n.
   - Evitar *data leakage* (fuags de informaci√≥n) y meanejar las m√∫ltiples visitas en OASIS-2.

3. **Pr√°cticos:**  
   - Limitaci√≥n de tiempo de GPU.  
   - Dificultad para mantener consistencia entre directorios experimentales (ficheros dispersos en carpestas distintas).
   - Diferencias entre columnas (`y_score`, `pred`, `sigmoid(logit)`). 
   - Saturaci√≥n de logs y necesidad de bit√°cora exhaustiva.  

---

## 6. Lecciones Aprendidas y Decisiones Clave  

- EffNet-B3 sigue siendo un backbone robusto.  
- Los ensembles intra-backbone mejoran resultados.  
- Los backbones alternativos no superan claramente a EffNet-B3, salvo Swin en configuraciones concretas.  
- La combinaci√≥n de enfoques (ensembles) es clave antes de saltar a multimodal.  

---

## 7. Conclusiones Globales 

- **Detecci√≥n temprana:** El pipeline cl√≠nico es altamente preciso, incluso con modelos simples.  
- **Interpretabilidad:** Confirm√≥ el valor de escalas cl√≠nicas cl√°sicas (CDR y MMSE).  
- **Probabilidades calibradas:** Mejoran la confianza en decisiones cl√≠nicas.  
- **Umbral adaptado:** Minimiza falsos negativos, adecuado para screening.  
- **Falsos positivos:** Asumibles en un contexto de cribado, ya que derivan en m√°s pruebas, no en da√±o directo. 

- **Modalidad Cl√≠nica:**  
  Variables demogr√°ficas y neuropsicol√≥gicas logran excelente desempe√±o (AUC ~0.99 fusionando cohortes). Sin embargo, dependen de que el deterioro cognitivo ya sea medible.

- **Modalidad MRI:**  
  Inicialmente rezagada, la visi√≥n por computador cierra la brecha mediante transferencia, calibraci√≥n y fine-tuning. El pipeline final de MRI (EffNet-B3 fine-tune) logra alta sensibilidad y precisi√≥n moderada, ideal para screening.
 
- **Fusi√≥n Multimodal:**
  La **fusi√≥n multimodal** entre datos cl√≠nicos y MRI ha demostrado gran potencial. 

**En conclusi√≥n**, COGNITIVA-AI demuestra el potencial de una soluci√≥n h√≠brida: datos cl√≠nicos estructurados m√°s im√°genes cerebrales. Cada iteraci√≥n aport√≥ mejoras t√©cnicas (unificaci√≥n de datos, calibraci√≥n, fine-tuning, ensembles) que convergen en un sistema capaz de priorizar la detecci√≥n temprana (sensibilidad) manteniendo aceptables tasas de falsa alarma. Esto es cr√≠tico en Alzheimer, donde diagnosticar a tiempo puede significar retrasar la progresi√≥n y brindar mayor calidad de vida al paciente.


## 8. Agradecimientos

Este trabajo se basa en los conjuntos de datos OASIS.  
Uso estrictamente acad√©mico, sin fines cl√≠nicos.  
Gracias a la comunidad open-source y al profesor Valent√≠n Silvestri que me ha acompa√±ado y mentorizado todo el proceso.