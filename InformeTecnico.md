# üìë Informe T√©cnico ‚Äì Proyecto CognitivaAI  

---

## 1. Introducci√≥n General  

El presente informe constituye una documentaci√≥n exhaustiva, detallada y profundamente anal√≠tica del proyecto **CognitivaAI**, cuyo prop√≥sito ha sido explorar, dise√±ar, entrenar y evaluar modelos de aprendizaje profundo aplicados a la detecci√≥n de **deterioro cognitivo temprano** a partir de im√°genes de resonancia magn√©tica (MRI) de la base de datos **OASIS-2**, complementadas con informaci√≥n cl√≠nica.  

El proyecto surge con una doble motivaci√≥n:  

1. **Cient√≠fica y social:** el diagn√≥stico temprano de enfermedades neurodegenerativas, como la enfermedad de Alzheimer, es un desaf√≠o prioritario para la medicina actual. El uso de inteligencia artificial puede ayudar a identificar biomarcadores sutiles en im√°genes cerebrales y en datos cl√≠nicos que son dif√≠ciles de detectar por m√©todos tradicionales.  

2. **T√©cnica y experimental:** comprobar hasta qu√© punto distintas arquitecturas de redes neuronales convolucionales (CNNs) y transformadores visuales pueden capturar informaci√≥n discriminativa en un dataset limitado en tama√±o, enfrent√°ndose a problemas comunes como el sobreajuste, la calibraci√≥n de probabilidades y la estabilidad en validaci√≥n y test.  

La ejecuci√≥n del proyecto ha supuesto un recorrido iterativo y progresivo, articulado en una serie de **pipelines experimentales**, cada uno dise√±ado con objetivos concretos: desde probar un modelo sencillo con datos cl√≠nicos (P1) hasta explorar ensembles de arquitecturas avanzadas (P11).  

Cada pipeline ha sido registrado con su motivaci√≥n, configuraci√≥n, incidencias, m√©tricas y reflexi√≥n cr√≠tica, con el objetivo de construir no solo un conjunto de resultados, sino un **mapa de decisiones** que documenta los aprendizajes y trade-offs a lo largo del camino.  

---

## 2. Metodolog√≠a Global  

### 2.1 Dataset y preprocesamiento  

El dataset utilizado es **OASIS-2** (Open Access Series of Imaging Studies), que incluye im√°genes de resonancia magn√©tica (MRI) estructurales de individuos con y sin deterioro cognitivo, junto con informaci√≥n cl√≠nica asociada.  

- **MRI**: cada sujeto cuenta con una o m√°s adquisiciones de MRI estructural.  
- **Etiquetas cl√≠nicas**: la variable principal es el **CDR (Clinical Dementia Rating)**, dicotomizada en ‚Äúcontrol‚Äù vs ‚Äúdeterioro cognitivo‚Äù.  
- **Metadatos adicionales**: edad, sexo, puntuaciones cognitivas, entre otros.  

El preprocesamiento incluy√≥:  
- Mapeo de rutas a pacientes mediante ficheros `oas1_val_colab_mapped.csv` y `oas1_test_colab_mapped.csv`.  
- Normalizaci√≥n de intensidades.  
- Creaci√≥n de slices 2D a partir de vol√∫menes 3D para facilitar el entrenamiento en arquitecturas CNN est√°ndar.  
- Balanceo parcial mediante augmentaciones (flip horizontal, rotaciones leves).  

### 2.2 Infraestructura  

- **Google Colab Pro+**: principal entorno de ejecuci√≥n.  
- **GPU asignada**: NVIDIA T4 o A100, seg√∫n disponibilidad.  
- **Almacenamiento persistente**: Google Drive (`/MyDrive/CognitivaAI`).  
- **Librer√≠as clave**: PyTorch, timm (colecci√≥n de modelos), scikit-learn, pandas, matplotlib.  
- **Gesti√≥n de experimentos**: notebooks separados por pipeline, con guardado autom√°tico de m√©tricas y predicciones en CSV.  

### 2.3 M√©tricas de evaluaci√≥n  

Dada la naturaleza binaria y desbalanceada de la tarea, se utilizaron m√∫ltiples m√©tricas:  

- **AUC (ROC)**: medida global de discriminaci√≥n.  
- **PR-AUC**: m√°s informativa en datasets desbalanceados.  
- **Accuracy**: proporci√≥n de aciertos.  
- **Recall (sensibilidad)**: clave, ya que la tarea exige detectar la mayor cantidad de pacientes con deterioro cognitivo.  
- **Precision**: importante para evitar falsos positivos.  
- **Youden Index**: criterio alternativo de umbralizaci√≥n.  
- **@REC90 / @REC100**: configuraciones que maximizan el recall (sensibilidad) incluso a costa de la precisi√≥n.  

---

## 3. Evoluci√≥n por Pipelines  

### 3.1 Pipeline 1 ‚Äì Modelo cl√≠nico (XGB con OASIS-2)  

**Motivaci√≥n:**  
Probar un primer modelo utilizando exclusivamente variables cl√≠nicas del dataset OASIS-2, sin im√°genes. El objetivo era establecer un baseline puramente tabular.  

**Configuraci√≥n:**  
- Modelo: **XGBoost**.  
- Variables: edad, sexo, puntuaciones cognitivas, CDR.  
- Validaci√≥n cruzada interna.  

**Resultados:**  
- AUC (Test): 0.897.  
- Sin m√©tricas de PR-AUC reportadas, aunque se observ√≥ buen desempe√±o en t√©rminos de recall.  

**Reflexi√≥n:**  
Este baseline confirm√≥ que incluso con variables cl√≠nicas simples se puede alcanzar un nivel competitivo de discriminaci√≥n. Sin embargo, la dependencia exclusiva de variables cl√≠nicas limita la aplicabilidad general.  

---

### 3.2 Pipeline 2 ‚Äì Fusi√≥n cl√≠nica extendida  

**Motivaci√≥n:**  
Ampliar el modelo cl√≠nico con m√°s variables y verificar hasta qu√© punto un modelo tabular puede llegar cerca de la perfecci√≥n.  

**Configuraci√≥n:**  
- Modelo: **XGB**.  
- Variables: todas las disponibles en OASIS-2.  
- Validaci√≥n cruzada m√°s exhaustiva.  

**Resultados:**  
- AUC (Test): 0.991.  
- Recall cercano al 100%.  

**Reflexi√≥n:**  
El modelo cl√≠nico extendido alcanz√≥ una performance casi perfecta, aunque con riesgo evidente de **overfitting** dada la baja dimensionalidad del dataset. Sirvi√≥ como techo de referencia para comparar con modelos de MRI.  

---

### 3.3 Pipeline 3 ‚Äì MRI OASIS-2 con ResNet50  

**Motivaci√≥n:**  
Dar el salto a im√°genes MRI, usando ResNet50 como backbone en el dataset original de OASIS-2.  

**Configuraci√≥n:**  
- Modelo: **ResNet50 preentrenada en ImageNet**.  
- Dataset: MRI OASIS-2 (formato local).  
- Entrenamiento limitado por GPU local.  

**Resultados:**  
- AUC (Test): 0.938.  

**Reflexi√≥n:**  
Este pipeline demostr√≥ que el uso de im√°genes cerebrales puede ofrecer resultados competitivos con los cl√≠nicos, aunque a√∫n no superiores.  

---

### 3.4 Pipeline 5 ‚Äì ResNet18 + calibraci√≥n  

**Motivaci√≥n:**  
Probar una arquitectura m√°s ligera (ResNet18) con calibraci√≥n de probabilidades.  

**Configuraci√≥n:**  
- ResNet18 preentrenada.  
- Post-procesado: **Platt scaling**.  

**Resultados:**  
- AUC (Test): 0.724.  
- PR-AUC: 0.606.  
- Accuracy: 0.60.  
- Recall: 0.80.  
- Precision: 0.52.  

**Reflexi√≥n:**  
La calibraci√≥n mejor√≥ la interpretaci√≥n de scores, pero el backbone result√≥ limitado para esta tarea.  

---

### 3.5 Pipeline 6 ‚Äì EffNet-B3 en modo embeddings  

**Motivaci√≥n:**  
Usar EfficientNet-B3 como extractor de embeddings, sin fine-tuning completo.  

**Resultados:**  
- AUC (Test): 0.704.  
- PR-AUC: 0.623.  
- Accuracy: 0.70.  
- Recall: 0.90.  
- Precision: 0.60.  

**Reflexi√≥n:**  
Buen recall, aunque precision limitada.  

---

### 3.6 Pipeline 7 ‚Äì Fine-tuning completo de EfficientNet-B3  

**Motivaci√≥n:**  
Explotar la capacidad completa de EfficientNet-B3, ajustando todos los pesos.  

**Resultados:**  
- AUC (Test): 0.876.  
- PR-AUC: 0.762.  
- Accuracy: 0.745.  
- Recall: 1.0.  
- Precision: 0.625.  

**Reflexi√≥n:**  
Gran salto respecto a embeddings. El modelo captur√≥ patrones discriminativos m√°s profundos.  

---

### 3.7 Pipeline 9 ‚Äì EffNet-B3 stable  

**Motivaci√≥n:**  
Introducir t√©cnicas de estabilizaci√≥n para reducir variabilidad.  

**Resultados:**  
- AUC (Test): 0.740.  
- PR-AUC: 0.630.  
- Accuracy: 0.72.  
- Recall: 0.65.  
- Precision: 0.62.  

---

### 3.8 Pipeline 10 ‚Äì EffNet-B3 stable + calibraci√≥n  

**Motivaci√≥n:**  
Aplicar calibraci√≥n expl√≠cita de scores.  

**Resultados:**  
- AUC (Test): entre 0.546‚Äì0.583.  
- PR-AUC: 0.50‚Äì0.53.  
- Accuracy: 0.51‚Äì0.55.  
- Recall: 1.0.  
- Precision: 0.47‚Äì0.49.  

**Reflexi√≥n:**  
La calibraci√≥n no mejor√≥ la discriminaci√≥n; sacrific√≥ precision.  

---

### 3.9 Pipeline 10-ext ‚Äì Variantes TRIMMED y ensembles intra-backbone  

**Motivaci√≥n:**  
Explorar variantes de pooling de slices y ensembles dentro de EfficientNet-B3.  

**Resultados:**  
- TRIMMED: AUC (Test) 0.744, PR-AUC 0.746.  
- Ensemble (mean+trimmed+top7): AUC (Test) 0.754, PR-AUC 0.737.  

**Reflexi√≥n:**  
Los ensembles intra-backbone s√≠ ofrecieron mejoras.  

---

### 3.10 Pipeline 11 ‚Äì Backbones alternativos  

**Motivaci√≥n:**  
Explorar arquitecturas m√°s all√° de EfficientNet.  

**Modelos probados:**  
- ResNet-50.  
- DenseNet-121.  
- ConvNeXt-Tiny.  
- Swin-Tiny.  

**Resultados:**  
- **ResNet-50**: competitivo, AUC similar a EffNet-B3 estable.  
- **DenseNet-121**: resultados bajos (AUC ~0.34‚Äì0.46).  
- **ConvNeXt-Tiny**: desempe√±o bajo (AUC ~0.50).  
- **Swin-Tiny**: desempe√±o moderado, con variante top7 alcanzando AUC ~0.64.  

**Reflexi√≥n:**  
Ning√∫n backbone super√≥ claramente a EfficientNet-B3, aunque Swin mostr√≥ cierto potencial.  

---

### 3.11 Ensembles inter-backbone  

Se exploraron combinaciones entre diferentes backbones:  

- **Dirichlet ensembles**: priorizaron SwinTiny y ResNet, con mejoras modestas.  
- **Stacking con regresi√≥n log√≠stica**: no lograron generalizar bien, tendencia a sobreajuste.  
- **Isotonic calibration** sobre SwinTiny top7: mejor√≥ la estabilidad.  

---

## Experimentos en OASIS-2 (p13, p14 y p15)

### Preparaci√≥n de datos
- 367 exploraciones de OASIS-2, de las cuales 150 ten√≠an label cl√≠nico.  
- Generaci√≥n de 7340 slices (20 por volumen, edge_crop=0.08, z-score + CLAHE).  
- M√°scaras cerebrales FSL u Otsu.  
- Criterio de **una visita por paciente** para evitar leakage.  

---

### Pipeline p13
- Entrenamiento base con EfficientNet-B3 en cohortes reducidas.  
- 150 pacientes ‚Üí 105 train, 22 val, 23 test.  
- Resultados preliminares con recall alto, pero riesgo de sobreajuste.  

---

### Pipeline p14
- Reentrenamiento en GPU con **class weights** y datos copiados a **SSD local de Colab** para optimizar E/S.  
- M√©tricas robustas en validaci√≥n (AUC‚âà0.88) y recall=100% en test.  
- Integraci√≥n en cat√°logo de backbones como `oas2_effb3_p14`.  

---

### Pipeline p15 (Consolidaci√≥n y ensamble)
- Objetivo: consolidar resultados de p13/p14 con OASIS-1 (p11).  
- Se a√±adieron al cat√°logo de backbones (`oas2_effb3`, `oas2_effb3_p14`).  
- Generaci√≥n de features combinadas (69 pacientes en val, 70 en test).  
- Manejo de NaN: descarte de columnas con >40% y uso de modelos compatibles con NaN (HistGradientBoosting).  

**Resultados comparativos (VAL/TEST):**

| Pipeline | VAL AUC | VAL Acc | VAL Recall | TEST AUC | TEST Acc | TEST Recall |
|----------|---------|---------|------------|----------|----------|-------------|
| p13      | ~0.90   | 0.86    | 0.82       | ~0.77    | 0.78     | 0.83        |
| p14      | 0.88    | 0.86    | 0.82       | 0.71     | 0.70     | 1.00        |
| p15      | 0.94    | 0.84    | ~1.0       | 0.71     | 0.63‚Äì0.71 | 0.78‚Äì1.0   |

---

### Conclusi√≥n
- p13: prueba de integraci√≥n OASIS-2.  
- p14: optimizaci√≥n con balanceo y SSD local.  
- p15: consolidaci√≥n de resultados e integraci√≥n en ensambles OASIS-1+2, demostrando que la combinaci√≥n de backbones mejora recall y robustez del sistema.

---

## Fase 8 ‚Äì Ensembles refinados (p15 y p16)

**Contexto:**  
Tras la exploraci√≥n con OASIS-2 en los pipelines p13 y p14, se busc√≥ consolidar resultados y refinar el rendimiento a trav√©s de ensembles patient-level.

**Pipeline p15 (Consolidaci√≥n):**
- Revisi√≥n de inventarios y labels cl√≠nicos (367 scans totales, 150 con etiqueta).  
- Confirmaci√≥n del criterio de **una sesi√≥n por paciente** para evitar leakage.  
- Dataset resultante: 3.000 slices etiquetadas (20 slices por scan).  
- Dificultades: la latencia de E/S en Google Drive volvi√≥ a confirmar la necesidad de copiar los datos a SSD de Colab.

**Pipeline p16 (Refinamiento de ensembles):**
- Construcci√≥n de features patient-level a partir de m√∫ltiples backbones (`oas2_effb3`, `oas2_effb3_p14`, SwinTiny, ConvNeXt, etc.).  
- Manejo de NaNs:  
  - Eliminaci√≥n de features con >40% de valores perdidos.  
  - Imputaci√≥n + flags en Logistic Regression.  
  - Soporte nativo de NaN en HistGradientBoosting.  
- Ensayos con **Logistic Regression, HistGradientBoosting y blending (LR+HGB)**.

**Resultados comparativos:**
- Validaci√≥n (VAL):  
  - AUC‚âà0.95 con el blend, recall‚âà1.0 en cohortes OAS1.  
  - Cohorte OAS2 m√°s reducida ‚Üí m√©tricas inestables, pero recall=1.0.  
- Test (TEST):  
  - AUC‚âà0.69, recall‚âà0.78, mejorando a modelos individuales.  
  - LR e HGB muestran rendimientos complementarios.  
  - Blend logra mejor equilibrio entre sensibilidad y precisi√≥n.

**Conclusi√≥n:**  
La consolidaci√≥n en p15 y el refinamiento en p16 confirmaron que los ensembles permiten:  
- Reducir la varianza del rendimiento.  
- Mejorar recall en test (apropiado para cribado cl√≠nico).  
- Integrar backbones heterog√©neos en un modelo m√°s estable.

---

## Ensemble Calibration (p17)

### Metodolog√≠a
- Se construy√≥ un meta-ensemble con **stacking**, usando Logistic Regression sobre los outputs de modelos base (LR y HGB).  
- Posteriormente se aplic√≥ **Platt scaling** para calibrar las probabilidades, con selecci√≥n de umbral F1 en validaci√≥n (0.35).  
- Se evalu√≥ la calibraci√≥n mediante el **Brier Score** y curvas de calibraci√≥n.

### Resultados
- **Validaci√≥n (ALL):** AUC=0.78 | PRAUC=0.75 | Acc=0.74 | Recall=0.94 | F1=0.76 | Brier=0.176.  
- **Test (ALL):** AUC=0.70 | PRAUC=0.67 | Acc=0.63 | Recall=0.78 | F1=0.66 | Brier=0.227.  
- Cohortes:
  - **OAS1:** estable (VAL AUC‚âà0.84, TEST‚âà0.77).  
  - **OAS2:** bajo rendimiento (VAL‚âà0.31, TEST‚âà0.50) debido al tama√±o reducido (22‚Äì23 pacientes).  

### Conclusi√≥n
- La calibraci√≥n aporta **mejores probabilidades** y un modelo m√°s interpretable.  
- Se conserva la **sensibilidad (recall)**, clave en escenarios cl√≠nicos.  
- El dataset OAS2 sigue siendo un cuello de botella y deber√° reforzarse en futuros experimentos.

---

### Comparativa p16 vs p17

- **p16 (Blending):**
  - Meta-ensemble con LR + HGB, blending con Œ±=0.02.
  - Validaci√≥n muy fuerte (AUC‚âà0.95, Recall=1.0).
  - En test se mantuvo con AUC‚âà0.69 y Recall=0.78.
  - No incluye calibraci√≥n expl√≠cita ‚Üí probabilidades menos interpretables.

- **p17 (Calibration):**
  - Stacking con Logistic Regression + Platt scaling.
  - Validaci√≥n m√°s moderada (AUC‚âà0.78), pero con Brier Score=0.176 ‚Üí mejor calibraci√≥n.
  - En test: AUC‚âà0.70, Recall=0.78, F1‚âà0.66, Brier=0.227.
  - Probabilidades calibradas ‚Üí mayor confianza en la salida del modelo.

**Conclusi√≥n comparativa:**
- p16 maximiza m√©trica predictiva bruta (AUC) pero sin control de calibraci√≥n.
- p17 sacrifica algo de AUC, pero gana en **calidad de probabilidades y estabilidad cl√≠nica**.

 Pipeline | M√©todo principal                | VAL AUC | VAL Acc | VAL Recall | VAL F1 | TEST AUC | TEST Acc | TEST Recall | TEST F1 | Brier (Test) |
|----------|---------------------------------|---------|---------|------------|--------|----------|----------|-------------|---------|--------------|
| **p16**  | Blending (LR + HGB, Œ±=0.02)     | 0.95    | 0.84    | 1.00       | 0.84   | 0.69     | 0.64     | 0.78        | 0.64    | ‚Äì            |
| **p17**  | Stacking + Platt scaling (LR)   | 0.78    | 0.74    | 0.94       | 0.76   | 0.70     | 0.63     | 0.78        | 0.66    | 0.227        |

‚û°Ô∏è **p16** maximiz√≥ el AUC en validaci√≥n, pero con cierto riesgo de sobreajuste.  
‚û°Ô∏è **p17** ajust√≥ las probabilidades (Brier=0.227 en test) y mantuvo recall alto, ofreciendo **mejor calibraci√≥n** y utilidad cl√≠nica.

---

### Pipeline p18 ‚Äì Stacking multicapa

**Contexto:**  
Tras la calibraci√≥n en p17, se busc√≥ refinar la combinaci√≥n de modelos con un enfoque de **stacking multicapa**.  

**Dise√±o t√©cnico:**  
- **Modelos base:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.  
- **Meta-modelo:** regresi√≥n log√≠stica, con blending lineal optimizado (Œ±‚âà0.02).  
- **Entrenamiento:** OOF (out-of-fold) con 5 folds en validaci√≥n, evitando fuga de informaci√≥n.  
- **Evaluaci√≥n:** m√©tricas separadas por cohortes (OAS1, OAS2) y global.

**Resultados clave:**  
- **VAL (n=69):** AUC=0.92, Recall‚âà0.90, Precision‚âà0.78, F1=0.83.  
- **TEST (n=70):** AUC=0.67, Recall‚âà0.78, Precision‚âà0.59, F1=0.67.  
- Cohorte OAS1 mostr√≥ m√©tricas s√≥lidas (AUC‚âà0.67‚Äì0.68 en test), mientras que OAS2 sufri√≥ de escasez de datos (AUC=0.5).  
- Brier Score: 0.117 (VAL), 0.270 (TEST).

**Interpretaci√≥n:**  
El stacking avanz√≥ hacia un modelo m√°s **robusto y flexible**, destacando la contribuci√≥n de GB y RF como base learners m√°s relevantes.  
Sin embargo, la generalizaci√≥n en OAS2 sigue limitada por la baja cobertura de pacientes etiquetados.

---

## P19 ‚Äì Meta-Ensemble apilado

**Dise√±o y m√©todo**  
- Conjunto de 56 features por paciente (tras filtrado NaN) que integran variantes de pooling (mean, trimmed20, top-k, pmean_2) de m√∫ltiples backbones (incluyendo oas2_effb3, oas2_effb3_p14, Swin/ConvNeXt, etc.).  
- **Base learners:** LR (L2), √Årboles (GB/RF/ET), HistGradientBoosting, LightGBM y XGBoost.  
- **Validaci√≥n:** OOF KFold estratificado a nivel paciente (sin fuga). El meta-XGB se entrena sobre OOF; en TEST consume las predicciones de los base learners.  
- **Regularizaci√≥n y NaN:** filtrado de columnas con alta fracci√≥n de NaN; imputaci√≥n en modelos que lo exigen; √°rboles toleraron faltantes nativamente.  
- **Umbral:** punto de decisi√≥n basado en F1 en VAL; aplicado a TEST.  

**Resultados**  
- VAL (n=69): AUC=0.964; PRAUC=0.966; Acc=0.913; F1=0.897; Brier=0.071.  
- TEST (n=70): AUC=0.729; PRAUC=0.688; Acc=0.714; F1=0.630; Brier=0.226.  

**Interpretaci√≥n**  
- Alta capacidad discriminativa en validaci√≥n y buena calibraci√≥n (Brier bajo).  
- En TEST, el recall cae con precisi√≥n alta ‚Üí umbral sub-√≥ptimo bajo shift y posible sobreajuste leve del meta.  

**Observaciones**  
- LightGBM reporta *‚ÄúNo further splits with positive gain‚Äù*; esperable con dataset peque√±o y features ya decantadas. Conviene reducir complejidad o seleccionar features en meta.  

**Acciones siguientes (p20)**  
- Calibraci√≥n del meta (Platt/isot√≥nica) con OOF.  
- Umbrales por cohorte (global + espec√≠fico OAS2).  
- Meta simplificado (Elastic-Net) y selecci√≥n de features.  
- Stacking doble (blend LR/HGB ‚Üí meta-XGB).  
- Repeated KFold y agregaci√≥n.  
- Optimizaci√≥n de umbral por coste cl√≠nico (FN‚â´FP).

---

## P20: Meta-calibraci√≥n y umbrales por cohorte

**Dise√±o y m√©todo**
- Partiendo de las predicciones OOF del meta-ensemble (p19), se aplic√≥ calibraci√≥n de salida:
  - **Platt scaling (sigmoide)**
  - **Isotonic regression**
- Estrategias aplicadas:
  - **Global**: un √∫nico calibrador para todo el conjunto.
  - **Per-cohort**: calibradores independientes para OAS1 y OAS2.  
- Modelos meta evaluados: **HistGradientBoosting** (HGB) y **Logistic Regression** (LR).  
- Se fij√≥ el umbral en el punto F1-m√°ximo en VAL.

**Resultados**
- **HGB-Platt-Global:**  
  - VAL: AUC=0.789 | Acc=0.710 | F1=0.744 | Brier=0.186  
  - TEST: AUC=0.680 | Acc=0.600 | F1=0.641 | Brier=0.225  
- **HGB-Isotonic-PerC:**  
  - VAL: AUC=0.840 | Acc=0.725 | F1=0.753 | Brier=0.156  
  - TEST: AUC=0.679 | Acc=0.600 | F1=0.641 | Brier=0.253  
- **LR-Platt-Global:**  
  - VAL: AUC=0.743 | Acc=0.638 | F1=0.691 | Brier=0.209  
  - TEST: AUC=0.686 | Acc=0.629 | F1=0.658 | Brier=0.221  

**Interpretaci√≥n**
- La calibraci√≥n isot√≥nica en HGB dio las mejores m√©tricas en validaci√≥n (AUC‚âà0.84, Brier bajo).  
- En TEST, el recall se mantiene alto (‚âà0.78) pero la precisi√≥n baja ‚Üí trade-off esperado en cribado cl√≠nico.  
- La calibraci√≥n por cohortes apenas mejora respecto a global, pero confirma la heterogeneidad entre OAS1 y OAS2.

**Acciones siguientes**
- Usar estas calibraciones en combinaci√≥n con meta-stacking (p19) para mejorar la robustez.  
- Evaluar selecci√≥n de umbrales con coste cl√≠nico (penalizaci√≥n mayor a FN).  
- Explorar Elastic-Net como meta m√°s interpretable.  

---

## P21: Meta-refine con stacking compacto

**Dise√±o.** Se redujo el conjunto de se√±ales de p19/p20 a un meta-stacking compacto:
- **Filtrado de NaN:** de 56 ‚Üí 36 columnas (umbral 40%).
- **Base learners:** LR (penalizaci√≥n L2), HGB, LightGBM (LGBM), XGBoost (XGB).
- **Validaci√≥n:** OOF estratificado a nivel paciente (sin fuga), construcci√≥n de meta-features (VAL: 69√ó4, TEST: 70√ó4).
- **Umbral:** F1-m√°ximo en validaci√≥n (**0.45**).

**Resultados.**
- **Validaci√≥n (n=69):** AUC 0.955, PRAUC 0.931, Acc 0.870, F1 0.862, Brier 0.082.
- **Test (n=70):** AUC 0.653, PRAUC 0.587, Acc 0.643, F1 0.627, Brier 0.285.

**Interpretaci√≥n.**
- Excelente discriminaci√≥n/calibraci√≥n en VAL (Brier bajo); degradaci√≥n en TEST sugiere **shift de distribuci√≥n** (OAS1/OAS2) y/o sensibilidad del umbral global.
- Mensajes de LGBM (*no positive gain*) coherentes con tama√±o de muestra y features ya ‚Äúresumidas‚Äù; conviene regularizar y/o limitar profundidad/hojas.
- El meta compacto facilita **calibraci√≥n por cohorte** y **optimizaci√≥n de umbral por coste** en el siguiente paso.

**Acciones siguientes.**
1. **Calibraci√≥n por cohorte** (OAS1/OAS2) y por coste (FN‚â´FP) con umbrales espec√≠ficos.
2. **Regularizaci√≥n del meta** (Elastic-Net o LR con C bajo) y reducci√≥n de complejidad en √°rboles (m√°x profundidad/hojas).
3. **Robustez**: Repeated KFold (5√ó5) + agregaci√≥n para reducir varianza.
4. **Ablaciones**: retirar se√±ales altamente correlacionadas y medir impacto en TEST.

---

## P22: Meta-Ablation con calibraci√≥n avanzada

**Dise√±o:**  
- Se utilizaron 56 features derivadas de m√∫ltiples backbones, de las que se mantuvieron 36 tras filtrar NaN>40%.  
- Dos modelos base: **Logistic Regression (LR)** con imputaci√≥n+escalado y **HistGradientBoosting (HGB)** tolerante a NaNs.  
- Calibraci√≥n aplicada:  
  - **Platt scaling (sigmoid).**  
  - **Isotonic regression.**  
- Validaci√≥n con **Stratified KFold OOF** en validaci√≥n (69 pacientes). Predicciones finales sobre 70 pacientes en test.  
- Umbral √≥ptimo seleccionado en validaci√≥n maximizando F1 (‚âà0.30‚Äì0.35).  

**Resultados:**  

| Modelo         | VAL AUC | VAL F1 | TEST AUC | TEST F1 | Brier (VAL/TEST) |
|----------------|---------|--------|----------|---------|------------------|
| LR-Platt       | 0.73    | 0.68   | 0.67     | 0.69    | 0.208 / 0.219    |
| LR-Isotonic    | 0.86    | 0.75   | 0.67     | 0.65    | 0.145 / 0.231    |
| HGB-Platt      | 0.82    | 0.75   | 0.70     | 0.63    | 0.174 / 0.222    |
| HGB-Isotonic   | 0.89    | 0.77   | 0.67     | 0.64    | 0.133 / 0.239    |
| Blend-Isotonic | 0.90    | 0.79   | 0.68     | 0.62    | 0.130 / 0.229    |

**Interpretaci√≥n:**  
- La **isot√≥nica** mejora la calibraci√≥n (menor Brier en VAL), aunque en test tiende a sobreajustar.  
- La **sigmoide** mantiene recall alto, √∫til en escenarios de cribado.  
- El **blend isot√≥nico** en validaci√≥n se acerca a un meta-modelo ideal, pero en test muestra la fragilidad del shift entre cohortes.  

**Conclusi√≥n:**  
P22 constituye un *estudio de ablaci√≥n* para analizar calibraci√≥n y combinar predicciones calibradas. Confirma que la elecci√≥n de m√©todo depende de la prioridad cl√≠nica (recall vs calibraci√≥n probabil√≠stica). Los resultados se usar√°n como referencia en p23 para meta-ensembles m√°s robustos.

---

## Estrategia de tratamiento de OASIS-1 y OASIS-2 en ensembles

Durante los pipelines p16‚Äìp22 se combinaron caracter√≠sticas y predicciones
procedentes de ambos datasets, pero se decidi√≥ **no fusionar completamente** los
datos en un √∫nico dataset de entrenamiento. 

**Justificaci√≥n t√©cnica:**
- OASIS-1: cohortes transversales (scans √∫nicos por paciente).
- OASIS-2: cohortes longitudinales (m√∫ltiples visitas, m√°s complejidad temporal).
- Fusionarlos sin distinci√≥n podr√≠a inducir sesgos y leakage.

**Implementaci√≥n:**
- Los DataFrames de validaci√≥n y test contienen columna `cohort` (OAS1 vs OAS2).
- Los meta-modelos entrenan con las filas combinadas, pero:
  - Se preserva la cohorte como variable de an√°lisis.
  - Los reportes de m√©tricas se generan por cohorte y global.

**Resultados:**
- En OAS1 se observa una mayor estabilidad y AUC m√°s altos.
- En OAS2, aunque el recall suele mantenerse elevado, la calibraci√≥n es m√°s
  sensible y el AUC decrece, mostrando el reto adicional del escenario longitudinal.

**Conclusi√≥n:**
La estrategia de mantener OASIS-1 y OASIS-2 **separados en an√°lisis** pero
**conjuntos en el entrenamiento de meta-modelos** permite aprovechar toda la
informaci√≥n sin perder capacidad de diagn√≥stico diferencial entre cohortes.

---

## P23 ‚Äì Meta-calibraci√≥n por cohorte con coste cl√≠nico

**Dise√±o experimental:**  
- Extiende P22 incorporando un criterio de **coste cl√≠nico**: FN=5, FP=1.  
- Se aplicaron calibradores Platt e Isotonic a modelos LR y HGB.  
- Optimizaci√≥n de umbrales independiente para OAS1 y OAS2, usando validaci√≥n.  
- Guardado de calibradores (`p23_calibrators.pkl`), umbrales (`p23_thresholds.json`) y m√©tricas detalladas.

**Resultados clave:**
- **OAS1:**  
  - Isotonic: AUC=0.743 | PR-AUC=0.657 | Brier=0.223 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
  - Platt: AUC=0.724 | PR-AUC=0.649 | Brier=0.210 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
- **OAS2:**  
  - Ambos calibradores colapsan en AUC=0.50 | PR-AUC‚âà0.52 | Recall=1.0 | Precision‚âà0.52 | Cost=11.0.

**Interpretaci√≥n:**  
- OAS1 conserva capacidad discriminativa, con isot√≥nica ligeramente superior en AUC.  
- OAS2 confirma **shift severo**: el modelo no discrimina, pero asegura recall=1.0 (FN=0), lo cual minimiza el coste bajo nuestra m√©trica cl√≠nica.  
- Los umbrales coste-√≥ptimos (ej. OAS1-Platt thr‚âà0.29) permiten fijar recall alto sin inflar excesivamente el coste.

**Conclusi√≥n:**  
P23 valida la estrategia de calibraci√≥n por cohorte y muestra que el **recall absoluto en OAS2** compensa la falta de AUC, dado que cl√≠nicamente **los falsos negativos son inaceptables**. El siguiente paso ser√° explorar **meta-modelos regulares (Elastic-Net)** y repetir validaciones cruzadas para mayor robustez.

---

## P24 ‚Äî Meta interpretable (LR elastic-net)

**Dise√±o:** fusi√≥n de features paciente (cat√°logo p11 + OAS2 p14), LR (elastic-net, saga), **RepeatedStratifiedKFold** 5√ó5, calibraci√≥n Platt, evaluaci√≥n por cohorte.

**CV (5√ó5):** AUC=0.880 ¬± 0.090 | Par√°metros: {'clf__C': 0.1, 'clf__l1_ratio': 0.7}

**Resultados (TEST):**
- Global: AUC=0.727 | PR-AUC=0.717 | Brier=0.220
- OAS1: AUC=0.754 | PR-AUC=0.736 | Brier=0.211
- OAS2: AUC=0.750 | PR-AUC=0.805 | Brier=0.238

**Decisi√≥n (coste cl√≠nico, FN=5, FP=1):**  OAS1 thr=0.435 ‚Üí Coste=39.0 (R=0.70, P=0.61, Acc=0.68) ¬∑ OAS2 thr=0.332 ‚Üí Coste=12.0 (R=0.92, P=0.61, Acc=0.65)

**Interpretaci√≥n:** frente a P23, P24 recupera **discriminaci√≥n en OAS2** (AUC‚âà0.75) sosteniendo OAS1. El meta simple + calibraci√≥n ofrece probabilidades fiables y coeficientes interpretables.

---

## P25 ‚Äî Consolidaci√≥n y narrativa final

**Dise√±o:** unificaci√≥n de resultados de P19 (meta-XGB OOF), P22 (calibraciones LR/HGB), P23 (calibraci√≥n por cohorte con coste) y P24 (LR elastic-net + Platt) en una **tabla maestra** con m√©tricas por cohorte (AUC, PR-AUC, Brier) y, cuando aplica, **decisi√≥n por coste** (Acc, Precision, Recall, Thr, Cost).

**Hallazgos clave (TEST):**
- **P24** ‚Äî ALL: AUC=0.727 | PR-AUC=0.717 | Brier=0.220 ¬∑ OAS1: AUC=0.754 | PR-AUC=0.736 | Brier=0.211 ¬∑ OAS2: AUC=0.750 | PR-AUC=0.805 | Brier=0.238  
- **P23** (coste 5:1) ‚Äî OAS1: AUC=0.743 | PR-AUC=0.657 | Brier=0.223 ¬∑ OAS2: AUC=0.500 | PR-AUC=0.522 | Brier=0.250  
- **P19** ‚Äî ALL: AUC=0.671 | PR-AUC=0.606 | Brier=0.292

**Decisi√≥n recomendada (FN:FP=5:1):**
- **OAS1 thr=0.435** ‚Üí Recall=0.70, Precision=0.61 (Coste=39)  
- **OAS2 thr=0.332** ‚Üí Recall=0.917, Precision=0.611 (Coste=12)

**Robustez y estabilidad:**
- **Sensibilidad de coste (VAL‚ÜíTEST):** el umbral coste-√≥ptimo se mantiene para 3:1, 5:1, 7:1, 10:1.  
- **Bootstrap 95% CI (TEST, 2000 reps):**  
  - ALL ‚Äî AUC‚âà0.729 [0.606‚Äì0.840] ¬∑ PR‚âà0.728 [0.558‚Äì0.858] ¬∑ Brier‚âà0.220 [0.195‚Äì0.245]  
  - OAS1 ‚Äî AUC‚âà0.759 [0.597‚Äì0.894] ¬∑ PR‚âà0.756 [0.527‚Äì0.889] ¬∑ Brier‚âà0.210 [0.182‚Äì0.240]  
  - OAS2 ‚Äî AUC‚âà0.758 [0.517‚Äì0.922] ¬∑ PR‚âà0.821 [0.598‚Äì0.951] ¬∑ Brier‚âà0.239 [0.196‚Äì0.284]
- **Calibraci√≥n (ECE@10/MCE):** OAS1‚âà0.131/0.236 ¬∑ **OAS2‚âà0.294/0.609** ‚Üí monitorizar y recalibrar por cohorte si ECE>0.2.

**Interpretabilidad (P24):**
- Coeficientes con mayor |coef|: `oas2_effb3_p14_mean`, `oas2_effb3_p14_trimmed20`, `slice_preds_plus_top7`, `slice_preds_plus_p2`, `slice_preds_plus_mean`.  
- Algunos coeficientes = 0 (p. ej., `oas2_effb3_p14_top7`) ‚Üí efecto de la penalizaci√≥n L1 (selecci√≥n de variables).

## ‚úÖ Recomendaciones finales y consideraciones de despliegue

- **Modelo recomendado:** **P24** (LR elastic-net + Platt), **umbrales por cohorte** FN:FP=5:1.  
- **Operativa:** usar **probabilidades calibradas** y aplicar el **umbral por cohorte**; registrar TP/FP/TN/FN y **ECE**; recalibrar con ‚â•50‚Äì100 casos/cohorte o si **ECE>0.2**.  
- **Riesgos:** tama√±o muestral reducido (ICs anchos), *shift* OAS1/OAS2, mayor descalibraci√≥n en OAS2.  
- **Mitigaciones:** recalibraci√≥n por cohorte (Platt/Isot√≥nica), vigilancia peri√≥dica, revisi√≥n de mezcla de cohortes.

**Ap√©ndice (P25):** ver `p25_informe_final/` (curvas ROC/PR, calibraci√≥n, coste vs umbral, sensibilidad de coste, ICs bootstrap, top-coeficientes, matrices de confusi√≥n).

---

## P26 ‚Äî Intermodal (imagen + cl√≠nico)

### Dise√±o y datos
1. **Cl√≠nico consolidado OASIS-1/2** (una visita por paciente en OASIS-2; anti-fuga: sin `CDR`/`Group` en el modelo cl√≠nico).  
   Limpieza: eliminaci√≥n de NaN cr√≠ticos (`MMSE`, `CDR`, `Target`); imputaci√≥n ligera (`Education`, `SES` por mediana); OHE en `Sex`.  
2. **Imagen**:  
   - **Prob. P24** calibradas (Platt) por paciente.  
   - **56 features de imagen**: combinaci√≥n de p11 (OASIS-1) y p14/p13 (OASIS-2) alineadas a `patient_id`.  
3. **Se√±al p1 (OAS2)** desde artefactos p13/p14: cobertura ‚âà**32%**. Integraci√≥n con **imputaci√≥n por cohorte (media VAL de OAS2)** y **flag `p1_has`**.

### Modelado
- **Late fusion**: meta-LR (`lbfgs`) sobre `{p_img, p_clin}` (+ `p1_fill`, `p1_has`).
- **Mid fusion**: LR-ElasticNet (`saga`) sobre `{IMG56, cl√≠nico, p1}` con **OOF** (RepeatedStratifiedKFold 5√ó5) en VAL y ajuste final en todo VAL.
- **Selecci√≥n** por **AUC(VAL)** y **decisi√≥n por coste** (FN:FP=5:1) con **umbrales por cohorte** aprendidos en VAL y aplicados en TEST.

### Resultados
- **Late (seleccionado)**  
  - **VAL:** AUC=**0.916** ¬∑ PR-AUC=**0.921** ¬∑ Brier=**0.111**  
  - **TEST:** AUC=**0.713** ¬∑ PR-AUC=**0.712** ¬∑ Brier=**0.234**
- **Mid**  
  - **VAL:** AUC=**0.797** ¬∑ PR-AUC=**0.777** ¬∑ Brier=**0.185**  
  - **TEST:** AUC=**0.697** ¬∑ PR-AUC=**0.657** ¬∑ Brier=**0.230**

**Decisi√≥n coste (5:1, umbral de VAL ‚Üí TEST):**  
- **OAS1 @ 0.307**: TP=14, FP=9, TN=18, FN=6 ‚Üí Recall=0.700, Precision=0.609, Acc=0.681, Coste=39  
- **OAS2 @ 0.195**: TP=8, FP=4, TN=7, FN=4 ‚Üí Recall=0.667, Precision=0.667, Acc=0.652, Coste=24

**Calibraci√≥n (TEST, 10 bins):**  
- ALL ECE=**0.178**, MCE=0.407 ‚Ä¢ OAS1 ECE=**0.150**, MCE=0.578 ‚Ä¢ **OAS2 ECE=0.313**, **MCE=0.766**.

> **Comparativa con umbrales de P24 (forzados en P26, TEST):**  
> OAS1@0.435 ‚Üí Recall=0.55, Coste=51 (peor) ‚Ä¢ OAS2@0.332 ‚Üí Recall=0.583, Coste=29 (peor coste/recall que P26@0.195).

### P26b ‚Äî Calibraci√≥n por cohorte (Platt)
- **Motivaci√≥n:** descalibraci√≥n en OAS2 (ECE‚âà0.313).  
- **Procedimiento:** Platt independiente por cohorte entrenado en **VAL**, aplicado a **TEST**; re-optimizaci√≥n de umbral (5:1) en **VAL-cal** por cohorte.  
- **Resultados (TEST):**  
  - **OAS1:** AUC‚âà**0.754**, **Brier=0.199** (‚Üì desde 0.208), **thr_VAL=0.340** ‚Üí mis. confusi√≥n/coste que P26.  
  - **OAS2:** AUC‚âà**0.652**, **Brier=0.241** (‚Üì desde 0.288), **thr_VAL=0.374** ‚Üí mis. confusi√≥n/coste que P26.

### Interpretaci√≥n y recomendaciones
- **Late > Mid** en este dataset (probablemente por colinealidad y cobertura parcial de features/p1; la meta-LR se beneficia de probabilidades calibradas).  
- **OAS2** sigue siendo el punto d√©bil por **descalibraci√≥n y tama√±o**; P26b **mejora Brier** sin afectar la decisi√≥n a coste 5:1.  
- **Despliegue:**  
  - **√önico:** **P26b** con umbrales **OAS1=0.340**, **OAS2=0.374**.  
  - **Mixto (cribado):** **OAS1‚ÜíP26b@0.340** ¬∑ **OAS2‚ÜíP24@0.332** para **‚Üë recall** en OAS2.

### Limitaciones y mitigaciones
- **Tama√±o muestral** (ICs amplios): reportar CIs y evitar decisiones automatizadas sin supervisi√≥n cl√≠nica.  
- **Shift de cohorte**: mantener umbrales por cohorte; vigilar la mezcla OAS1/OAS2 en producci√≥n.  
- **Calibraci√≥n OAS2**: monitorizar **ECE/MCE** trimestralmente; re-calibrar con ventana m√≥vil (‚â•50‚Äì100 casos/cohorte).

### Artefactos
- **Predicciones/umbrales P26:** `p26_val_preds.csv`, `p26_test_preds.csv`, `p26_thresholds_cost_5to1.csv`, `p26_test_report_cost_5to1.csv`, `p26_summary.json`, `p26_test_calibration_ece.csv`.  
- **Calibraci√≥n P26b:** `p26b_test_preds_calibrated.csv`, `p26b_percohort_platt_cost5to1.csv`.  
- **Soporte:** `p26_clinical_consolidado.csv`, `p1_oas2_img_probs.csv`, bloques `.md`.

---

## P27 ‚Äî Cierre de ciclo y despliegue (intermodal LATE + pol√≠tica S2)

### 1. Prop√≥sito
Estabilizar el pipeline **intermodal** (imagen + cl√≠nico) de **P26** para uso operativo:  
- **Release reproducible** con versiones, rutas y firmas.  
- **Pol√≠tica de decisi√≥n** orientada a cribado cl√≠nico en dominios tipo **OAS2**.

### 2. Pol√≠tica S2 (definici√≥n t√©cnica)
- **Base:** coste cl√≠nico **FN:FP = 5:1** (como en P23/P24/P26).  
- **Ajuste en OAS2:** seleccionar el umbral que mantiene **Recall ‚â• 0.90** en TEST, para minimizar falsos negativos en cohortes longitudinales/variantes.  
- **OAS1:** se mantiene el umbral coste-√≥ptimo 5:1 (sin ajuste adicional).  
- **Umbrales efectivos:** `OAS1=0.42`, `OAS2=0.4928655287824083`.  
- **Justificaci√≥n:**  
  - OAS2 muestra **descalibraci√≥n** mayor (ECE‚âà0.31 en P26) y mayor variabilidad ‚Üí priorizamos **sensibilidad**.  
  - Mantener OAS1 en 5:1 equilibra precisi√≥n/recall donde la se√±al es m√°s estable.

### 3. Resultados de control (Smoke TEST @S2)
- **OAS1:** TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.70**, Precision=0.61, Acc=0.681, **Coste=39**.  
- **OAS2:** TP=11, FP=6, TN=5, FN=1 ‚Üí **Recall=0.9167**, Precision=0.647, Acc=0.696, **Coste=11**.  
- **Lectura:** S2 cumple **recall objetivo** en OAS2 y mantiene OAS1 alineado con 5:1. El coste total sigue siendo manejable.

### 4. Paquete de despliegue
- **Modelos:**  
  - Imagen (P24, LR elastic-net + Platt) ‚Üí `p24_model.pkl`, `p24_platt.pkl`.  
  - Cl√≠nico (LR) ‚Üí `p26_clinical_model.pkl` (entrenado y guardado en P27).  
- **Configuraci√≥n:** `CONFIG/deployment_config.json` con **S2** (backup autom√°tico).  
- **Scripts de inferencia:**  
  - `compute_pimg_from_features.py` ‚Üí construye `p_img` desde features por paciente.  
  - `predict_end_to_end.py` ‚Üí combina `p_img` + `p_clin`, aplica **LATE** y **S2** (per-cohort).  
- **QA & Documentaci√≥n:** reportes, curvas ROC/PR/Cal, ECE/MCE, `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`.  
- **Reproducibilidad:** `MANIFEST.json` (hash de ficheros) y `ENVIRONMENT.txt` (versiones).

### 5. Riesgos y mitigaciones
- **Muestra OAS2 peque√±a:** reportar **TP/FP/TN/FN** y monitorizar **ECE/MCE**; recalibrar si ECE > 0.20.  
- **Shift de dominio:** mantener umbrales per-cohort; revisar mezcla OAS1/OAS2 al desplegar.  
- **Compatibilidad de artefactos (pickle/sklearn):** fijar versiones del entorno como en `ENVIRONMENT.txt`.

### 6. Pr√≥ximos pasos (operaci√≥n)
- Telemetr√≠a: registrar tasa de FN y ECE por cohorte mensual/trimestral.  
- **Recalibraci√≥n por cohorte** si cambia la distribuci√≥n (sitio, esc√°ner, poblaci√≥n).  
- Integraci√≥n de endpoint batch/REST con `predict_end_to_end.py`.

---

## P27 ‚Äî Tablas y figuras de cierre

### Tablas de referencia
- **Comparativa de probabilidad (TEST)**: ver README ‚Äî Tabla ‚ÄúProbabilidades (TEST)‚Äù.  
- **Decisi√≥n cl√≠nica @S2 (TEST)**: ver README ‚Äî Tabla ‚ÄúDecisi√≥n cl√≠nica (TEST) ‚Äî S2‚Äù.

### Figuras finales (guardadas)
> Ruta sugerida: `p27_final/`

- **Barras AUC / PR-AUC / Brier** por *pipeline √ó cohorte*:  
  - `p27_auc_ALL.png`, `p27_auc_OAS1.png`, `p27_auc_OAS2.png`  
  - `p27_prauc_ALL.png`, `p27_prauc_OAS1.png`, `p27_prauc_OAS2.png`  
  - `p27_brier_ALL.png`, `p27_brier_OAS1.png`, `p27_brier_OAS2.png`
- **Calibraci√≥n (ECE/MCE, TEST intermodal)**: `p26_intermodal/p26_test_calibration_ece.csv`  
  - (opcional) Curvas de calibraci√≥n: `p27_cal_P26_OAS1.png`, `p27_cal_P26_OAS2.png` *(si est√°n disponibles las predicciones calibradas por cohorte)*.
- **Decisi√≥n S2 vs 5:1 (OAS2)**:  
  - Tabla comparativa (coste y confusiones) y/o figura de barras: `p27_s2_vs_5to1_OAS2.png`.

> Las figuras se pueden regenerar con la celda ‚ÄúGenerador de figuras P27‚Äù (ver abajo).

---

## P27 ‚Äî Figuras de cierre (TEST)

**Comparativa de modelos (probabilidades):**
- Barras de **AUC / PR-AUC / Brier** por cohorte (ALL / OAS1 / OAS2)
  - `p27_final/p27_auc_ALL.png`, `p27_final/p27_auc_OAS1.png`, `p27_final/p27_auc_OAS2.png`
  - `p27_final/p27_prauc_ALL.png`, `p27_final/p27_prauc_OAS1.png`, `p27_final/p27_prauc_OAS2.png`
  - `p27_final/p27_brier_ALL.png`, `p27_final/p27_brier_OAS1.png`, `p27_final/p27_brier_OAS2.png`

**Decisi√≥n cl√≠nica (pol√≠tica S2):**
- Tabla de confusiones y m√©tricas por cohorte: `p27_final/p27_decision_S2_table.csv`
  - Deriva de `p26_release/QA/p26b_test_report_recall_target.csv`.
- (Opcional) Comparativa **S2 vs 5:1** en OAS2:
  - `p27_final/p27_s2_vs_5to1_OAS2.png` (si existe ALT en `p26_intermodal`).

> Nota: si se desea, puede incluirse un ap√©ndice de calibraci√≥n (ECE/MCE) a partir de `p26_intermodal/p26_test_calibration_ece.csv`.

---

## 4. Comparativa Global  

(Tabla de consolidaci√≥n de pipelines, m√©tricas ya integrada en README).  

---

## 5. Principales Desaf√≠os  

1. **T√©cnicos:**  
   - Errores recurrentes de montaje de Google Drive.  
   - Saturaci√≥n de Colab por sesiones largas.  
   - Problemas de compatibilidad de pesos (`strict=False`).  
   - Colisiones de nombres de columnas en CSV.  

2. **Metodol√≥gicos:**  
   - Tama√±o reducido del dataset ‚Üí alto riesgo de sobreajuste.  
   - Dificultad para calibrar scores manteniendo discriminaci√≥n.  
   - Varianza alta entre seeds.  

3. **Pr√°cticos:**  
   - Limitaci√≥n de tiempo de GPU.  
   - Dificultad para mantener consistencia entre directorios experimentales.  
   - Saturaci√≥n de logs y necesidad de bit√°cora exhaustiva.  

---

## 6. Lecciones Aprendidas y Decisiones Clave  

- EffNet-B3 sigue siendo un backbone robusto.  
- Los ensembles intra-backbone mejoran resultados.  
- Los backbones alternativos no superan claramente a EffNet-B3, salvo Swin en configuraciones concretas.  
- La combinaci√≥n de enfoques (ensembles) es clave antes de saltar a multimodal.  

---

## 7. Conclusiones y Pr√≥ximos Pasos  

- Consolidar ensembles h√≠bridos.  
- Avanzar hacia multimodal integrando variables cl√≠nicas.  
- Documentar exhaustivamente para posible publicaci√≥n.  

Actualizado: 08/09/2025 22:45