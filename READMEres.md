# üß† Cognitiva-AI: Exploraci√≥n de modelos para predicci√≥n de Alzheimer con datos cl√≠nicos y de resonancia magn√©tica

## üìå Contexto y objetivos

El proyecto **Cognitiva-AI** nace con la motivaci√≥n de estudiar la **predicci√≥n del Alzheimer** utilizando tanto **datos cl√≠nicos tabulares** como **im√°genes cerebrales (MRI)**.  
La hip√≥tesis central que gu√≠a todo el trabajo es que **distintas fuentes de informaci√≥n y distintas arquitecturas de modelos pueden capturar facetas complementarias del proceso neurodegenerativo**.  

A lo largo de m√°s de diez pipelines (P1‚ÄìP11) se ha seguido una filosof√≠a de **experimentaci√≥n incremental**:  
- comenzar con modelos sencillos sobre datos cl√≠nicos,  
- avanzar hacia CNNs entrenadas sobre im√°genes MRI,  
- introducir calibraci√≥n, normalizaci√≥n y estrategias de ensemble,  
- explorar arquitecturas modernas de visi√≥n,  
- y finalmente preparar el terreno hacia un modelo multimodal.

El dataset de referencia ha sido **OASIS** (Open Access Series of Imaging Studies), en particular sus cohortes OASIS-2 y derivados.  

---

## üöÄ Evoluci√≥n por Pipelines

A continuaci√≥n, se detallan los diferentes pipelines experimentales desarrollados en el proyecto. Cada uno introduce una idea nueva, una arquitectura diferente o una estrategia de evaluaci√≥n alternativa.

### üîπ P1 ‚Äì Modelo cl√≠nico OASIS-2
- Datos: variables cl√≠nicas tabulares de OASIS-2.  
- Modelo: XGBoost.  
- Objetivo: establecer baseline con datos cl√≠nicos sin im√°genes.  
- Resultado: AUC ‚âà 0.897. Buen rendimiento inicial, pero limitado en capacidad de generalizaci√≥n.

### üîπ P2 ‚Äì Modelo cl√≠nico fusionado
- Datos: combinaci√≥n de cohortes cl√≠nicas.  
- Modelo: XGBoost.  
- Observaci√≥n: el aumento de datos cl√≠nicos mejora la capacidad predictiva.  
- Resultado: AUC ‚âà 0.991. Rendimiento casi perfecto, pero sospechoso de overfitting.

### üîπ P3 ‚Äì Im√°genes OASIS-2 con ResNet50
- Primer acercamiento a MRI.  
- Backbone: ResNet50, entrenado desde cero sobre im√°genes OASIS-2.  
- Resultado: AUC ‚âà 0.938. Buen desempe√±o, pero dataset muy peque√±o.

### üîπ P5 ‚Äì MRI Colab con ResNet18 + calibraci√≥n
- Migraci√≥n a Colab para usar GPUs.  
- Modelo: ResNet18 con calibraci√≥n posterior.  
- Resultado: AUC = 0.724. Recall alto (0.80), precisi√≥n limitada (0.52).

### üîπ P6 ‚Äì MRI Colab con EfficientNet-B3 (embeddings)
- Uso de embeddings preentrenados con EfficientNet-B3.  
- Resultado: AUC = 0.704. Recall elevado (0.90), precisi√≥n = 0.60.

### üîπ P7 ‚Äì MRI Colab con EfficientNet-B3 (fine-tuning)
- Se entrena EfficientNet-B3 completo sobre MRI.  
- Resultado: AUC = 0.876. Excelente recall (1.0) y precisi√≥n aceptable (0.625).  

### üîπ P9 ‚Äì MRI Colab con EfficientNet-B3 Stable
- Introducci√≥n de variantes con normalizaci√≥n y seeds m√°s estables.  
- Resultado: AUC ‚âà 0.740.  
- Observaci√≥n: se gana estabilidad pero no mejora de forma radical.

### üîπ P10 ‚Äì MRI Colab con EfficientNet-B3 Stable + calibraci√≥n
- Se introduce calibraci√≥n expl√≠cita (Platt scaling, temperature scaling).  
- Resultados moderados: AUC entre 0.546‚Äì0.583.  
- Recall alto pero precisi√≥n baja.  
- Se documentan dificultades de estabilidad y saturaci√≥n de logits.

### üîπ P10-ext ‚Äì Extensiones de ensembles sobre EfficientNet-B3
- Variantes TRIMMED, mean y top-k sobre diferentes seeds.  
- Mejoras modestas:  
  - TRIMMED: AUC = 0.744.  
  - Ensemble (M+T+7): AUC = 0.754.  
- Conclusi√≥n: el ensembling estabiliza pero no revoluciona.

### üîπ P11 ‚Äì Backbones alternativos
- Motivaci√≥n: comprobar si otras arquitecturas modernas superaban a EfficientNet-B3.  
- Modelos probados:  
  - **ResNet-50 (baseline alt)**: AUC ‚âà 0.740.  
  - **DenseNet-121**: bajo rendimiento, AUC ‚âà 0.343.  
  - **ConvNeXt-Tiny (in12k_ft_in1k)**: AUC ‚âà 0.509.  
  - **Swin-Tiny**: resultados mixtos, mejor variante top7 con AUC ‚âà 0.641.  
- Conclusi√≥n: ninguno supera claramente a EffNet-B3, aunque ResNet50 y SwinTiny muestran competitividad parcial.  
- Ensembles de backbones (Dirichlet, isotonic, stacking): mejoras parciales pero sin ‚Äúgame changer‚Äù.

---

## üìä Tabla de Resultados Globales

| Pipeline | Modalidad        | Modelo                                   | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|------------------------------------------|------------|--------|-------|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB                                      | 0.897      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB                                      | 0.991      | ‚Äî      | ‚Äî     | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50                                 | 0.938      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib                         | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed                          | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune                       | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable                         | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib                   | 0.546‚Äì0.583| 0.50‚Äì0.53 | 0.51‚Äì0.55 | 1.0 | 0.47‚Äì0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + TRIMMED                      | 0.744      | 0.746  | 0.64  | 0.75   | 0.56      |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble(M+T+7)              | 0.754      | 0.737  | 0.68  | 0.70   | 0.61      |
| P11      | MRI Colab       | ResNet-50 (baseline alt)                 | 0.740      | 0.730  | 0.64  | 0.70   | 0.56      |
| P11      | MRI Colab       | DenseNet-121 + trimmed20                 | 0.343      | 0.407  | 0.32  | 0.75   | 0.36      |
| P11      | MRI Colab       | ConvNeXt-Tiny (in12k_ft_in1k) + mean     | 0.509      | 0.479  | 0.49  | 1.00   | 0.45      |
| P11      | MRI Colab       | Swin-Tiny + top7                         | 0.641      | 0.597  | 0.55  | 0.95   | 0.95      |
| P11-Ens  | MRI Colab       | BackboneEnsemble_DIRICHLET_means         | 0.520      | 0.523  | 0.47  | 1.0    | 0.44      |
| P11-Ens  | MRI Colab       | BackboneEnsemble_DIRICHLET_EXT           | 0.361      | 0.405  | 0.45  | 0.85   | 0.42      |
| P11-Ens  | MRI Colab       | STACK_L1_STRONG (L1-regularized stacking)| 0.500      | 0.426  | 0.43  | 1.0    | 0.43      |
| P11-Ens  | MRI Colab       | SwinTiny_top7_ISOTONIC                   | 0.566      | 0.458  | 0.55  | 0.95   | 0.49      |

---

## üìå Conclusiones globales

1. **EfficientNet-B3** sigue siendo el backbone m√°s robusto y estable en este dataset.  
2. **ResNet-50** es competitivo y sorprendentemente s√≥lido en comparaci√≥n con modelos m√°s recientes.  
3. **DenseNet-121** no ha mostrado buen rendimiento en este dominio.  
4. **ConvNeXt y Swin** presentan inter√©s, pero su rendimiento es irregular y dependiente del pooling.  
5. Los **ensembles de backbones** son prometedores pero, en este dataset peque√±o, sufren de sobreajuste y m√©tricas inconsistentes.  
6. El trade-off entre **recall alto y precisi√≥n baja** es recurrente y debe tenerse en cuenta para aplicaciones cl√≠nicas.  

---

## ‚ö†Ô∏è Desaf√≠os principales del proyecto

1. **Limitaciones del dataset**  
   - Pocas muestras en comparaci√≥n con el tama√±o de los modelos.  
   - Cohorte no balanceada.  
   - Dificultad para extraer conclusiones generalizables.  

2. **Problemas t√©cnicos en Colab/Drive**  
   - Fallos frecuentes en el montaje de Google Drive.  
   - Archivos no detectados hasta reiniciar entornos.  
   - Interrupciones en ejecuciones largas.  

3. **Estabilidad de entrenamiento**  
   - Seeds distintos produc√≠an resultados muy dispares.  
   - Necesidad de normalizar logits y calibrar salidas.  

4. **Backbones modernos**  
   - ConvNeXt y Swin no superaron a ResNet o EfficientNet en este contexto.  
   - Requieren datasets m√°s grandes o tuning avanzado.  

5. **Estrategias de ensemble**  
   - Dirichlet y stacking mostraron mejoras en validaci√≥n, pero ca√≠das fuertes en test.  
   - Se evidencia sobreajuste al conjunto de validaci√≥n.  

6. **Recall vs Precisi√≥n**  
   - Muchos modelos sacrifican precisi√≥n para alcanzar recall de 1.0.  
   - En contexto cl√≠nico, esto puede ser aceptable, pero requiere m√°s refinamiento de umbrales.  

---

## üîÆ Pr√≥ximos pasos

1. **Exploraci√≥n multimodal**: combinar cl√≠nico + MRI en un mismo modelo.  
2. **Refinamiento de ensembles**: probar m√©todos bayesianos y calibraci√≥n jer√°rquica.  
3. **Curaci√≥n del dataset**: aumentar tama√±o o usar pretraining m√°s cercano al dominio biom√©dico.  
4. **Optimizaci√≥n cl√≠nica**: ajustar m√©tricas de evaluaci√≥n para alinearlas con necesidades reales (ej. F1 ponderado, m√©tricas de utilidad cl√≠nica).  

---

# ‚ú® Cierre

Este README resume el largo proceso de investigaci√≥n de **Cognitiva-AI**, desde pipelines iniciales con XGBoost hasta exploraciones recientes con arquitecturas modernas y ensembles complejos.  
Aunque no se ha encontrado un modelo que supere con claridad a EfficientNet-B3, se ha construido una base s√≥lida para la siguiente fase: **el aprendizaje multimodal**.

