{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Uc_mVVIplAP",
        "outputId": "87ecc3d2-104d-46c4-dc80-449775305d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "BASE: /content/drive/MyDrive/CognitivaAI\n",
            "OUT : /content/drive/MyDrive/CognitivaAI/p26_intermodal\n"
          ]
        }
      ],
      "source": [
        "# Celda 0 ‚Äî Montar Drive y definir rutas\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pathlib import Path\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "OUT  = BASE/\"p26_intermodal\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"BASE:\", BASE)\n",
        "print(\"OUT :\", OUT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 1 ‚Äî Utilidades generales\n",
        "import json, numpy as np, pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "def clean_cols(df):\n",
        "    df.columns = [str(c).replace(\"\\ufeff\",\"\").strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def infer_cohort(pid):\n",
        "    s = str(pid).strip().upper()\n",
        "    if s.startswith(\"OAS1\"): return \"OAS1\"\n",
        "    if s.startswith(\"OAS2\"): return \"OAS2\"\n",
        "    return \"OAS1\"\n",
        "\n",
        "LEAK_PATTERNS = [\"cdr\",\"dement\",\"dx\",\"diagnos\",\"group\",\"converted\",\"label\",\"target\",\"y_true\",\"y\"]\n",
        "\n",
        "def is_leak_col(name):\n",
        "    s = str(name).lower()\n",
        "    return any(p in s for p in LEAK_PATTERNS) or s in {\"patient_id\",\"cohort\"}\n",
        "\n",
        "def metrics_from_scores(y, p):\n",
        "    y = np.asarray(y).astype(int); p = np.asarray(p).astype(float)\n",
        "    has_var = len(np.unique(y))>1\n",
        "    return dict(\n",
        "        AUC   = float(roc_auc_score(y,p)) if has_var else float(\"nan\"),\n",
        "        PRAUC = float(average_precision_score(y,p)) if has_var else float(\"nan\"),\n",
        "        Brier = float(brier_score_loss(y,p))\n",
        "    )\n",
        "\n",
        "def choose_thr_cost(y, p, C_FN=5.0, C_FP=1.0, n=1001):\n",
        "    y = np.asarray(y).astype(int); p = np.asarray(p).astype(float)\n",
        "    thr = np.linspace(0,1,n)\n",
        "    best = None\n",
        "    for t in thr:\n",
        "        yhat = (p>=t).astype(int)\n",
        "        FP = int(((yhat==1)&(y==0)).sum())\n",
        "        FN = int(((yhat==0)&(y==1)).sum())\n",
        "        cost = C_FN*FN + C_FP*FP\n",
        "        if best is None or cost < best[0]:\n",
        "            best = (cost, t, FP, FN)\n",
        "    cost, t, FP, FN = best\n",
        "    TP = int(((p>=t)&(y==1)).sum()); TN = int(((p< t)&(y==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else float(\"nan\")\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else float(\"nan\")\n",
        "    acc  = (TP+TN)/(TP+TN+FP+FN)\n",
        "    return dict(thr=float(t), cost=float(cost), TP=TP, FP=FP, TN=TN, FN=FN, Precision=float(prec), Recall=float(rec), Acc=float(acc))\n",
        "\n",
        "def to_patient_id(id_val, cohort):\n",
        "    s = str(id_val).strip().replace(\"\\u200b\",\"\").replace(\"\\ufeff\",\"\")\n",
        "    if s.upper().startswith((\"OAS1_\",\"OAS2_\")):\n",
        "        return s.upper()\n",
        "    # num√©rico -> zero-pad 4\n",
        "    if s.isdigit():\n",
        "        return f\"{cohort}_{int(s):04d}\"\n",
        "    s2 = s.replace(\"-\", \"_\").upper()\n",
        "    if not s2.startswith((\"OAS1_\",\"OAS2_\")):\n",
        "        s2 = f\"{cohort}_{s2}\"\n",
        "    return s2\n"
      ],
      "metadata": {
        "id": "WDCF6q5Rp7rM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 2 ‚Äî Construir cl√≠nico consolidado desde Excels (OASIS-1 y OASIS-2)\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "search_dirs = [\n",
        "    BASE/\"clinical\"/\"raw\",\n",
        "    BASE/\"clinical\",\n",
        "    BASE,\n",
        "    BASE.parent,  # ‚Üê carpeta padre del proyecto\n",
        "]\n",
        "xls_files = []\n",
        "for d in search_dirs:\n",
        "    if d.exists():\n",
        "        xls_files += list(d.glob(\"*.xlsx\")) + list(d.glob(\"*.xls\"))\n",
        "\n",
        "if not xls_files:\n",
        "    raise FileNotFoundError(\n",
        "        f\"No encontr√© Excels cl√≠nicos en {search_dirs}. \"\n",
        "        \"Sube los ficheros OASIS-1 (cross-sectional) y OASIS-2 (longitudinal).\"\n",
        "    )\n",
        "\n",
        "def load_xls(p):\n",
        "    try:\n",
        "        df = pd.read_excel(p)\n",
        "    except Exception:\n",
        "        # fallback\n",
        "        df = pd.read_excel(p, engine=\"openpyxl\")\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "df1_raw, df2_raw = None, None\n",
        "for p in xls_files:\n",
        "    df = load_xls(p)\n",
        "    cols = set(c.lower() for c in df.columns)\n",
        "    if {\"subject id\",\"mri id\",\"group\",\"visit\"}.issubset(cols):\n",
        "        df2_raw = df\n",
        "    elif {\"id\",\"m/f\",\"mmse\",\"cdr\"}.issubset(cols) or {\"id\",\"sex\",\"mmse\",\"cdr\"}.issubset(cols):\n",
        "        df1_raw = df\n",
        "\n",
        "assert df1_raw is not None and df2_raw is not None, \"No pude distinguir cu√°l es OASIS-1 y cu√°l OASIS-2.\"\n",
        "\n",
        "# Renombrado est√°ndar\n",
        "df1 = df1_raw.rename(columns={\n",
        "    \"ID\":\"ID\", \"M/F\":\"Sex\", \"Educ\":\"Education\", \"Hand\":\"Hand\", \"Delay\":\"Delay\"\n",
        "})\n",
        "df2 = df2_raw.rename(columns={\n",
        "    \"Subject ID\":\"ID\", \"M/F\":\"Sex\", \"EDUC\":\"Education\", \"MR Delay\":\"Delay\"\n",
        "})\n",
        "\n",
        "df1[\"Cohort\"] = \"OASIS1\"\n",
        "df2[\"Cohort\"] = \"OASIS2\"\n",
        "\n",
        "# Target de referencia (NO se usar√° como feature)\n",
        "if \"Group\" in df2.columns:\n",
        "    df2[\"Target\"] = df2[\"Group\"].replace({\"Nondemented\":0, \"Demented\":1, \"Converted\":1})\n",
        "else:\n",
        "    df2[\"Target\"] = np.nan\n",
        "\n",
        "df1[\"Target\"] = df1[\"CDR\"].apply(lambda x: 0 if x==0 else 1)\n",
        "\n",
        "# OASIS-2: conservar primera visita por paciente\n",
        "if \"Visit\" in df2.columns:\n",
        "    df2 = df2.sort_values([\"ID\",\"Visit\"]).groupby(\"ID\").first().reset_index()\n",
        "\n",
        "cols_common = [\"ID\",\"Age\",\"Sex\",\"Education\",\"SES\",\"MMSE\",\"CDR\",\"eTIV\",\"nWBV\",\"ASF\",\"Target\",\"Delay\"]\n",
        "df1c = df1.reindex(columns=[c for c in cols_common if c in df1.columns]).copy()\n",
        "df2c = df2.reindex(columns=[c for c in cols_common if c in df2.columns]).copy()\n",
        "df1c[\"Cohort\"]=\"OASIS1\"; df2c[\"Cohort\"]=\"OASIS2\"\n",
        "df_all = pd.concat([df1c, df2c], ignore_index=True)\n",
        "\n",
        "# Imputaci√≥n suave en Education/SES si existen\n",
        "if \"Education\" in df_all.columns:\n",
        "    df_all[\"Education\"] = pd.to_numeric(df_all[\"Education\"], errors=\"coerce\")\n",
        "    df_all[\"Education\"].fillna(df_all[\"Education\"].median(), inplace=True)\n",
        "if \"SES\" in df_all.columns:\n",
        "    df_all[\"SES\"] = pd.to_numeric(df_all[\"SES\"], errors=\"coerce\")\n",
        "    df_all[\"SES\"].fillna(df_all[\"SES\"].median(), inplace=True)\n",
        "\n",
        "# patient_id compatible con P24\n",
        "df_all[\"patient_id\"] = [to_patient_id(i, c) for i,c in zip(df_all[\"ID\"], df_all[\"Cohort\"])]\n",
        "\n",
        "# Anti-fuga: quitar columnas proxy de etiqueta\n",
        "leak_cols = [c for c in [\"Target\",\"CDR\",\"Group\"] if c in df_all.columns]\n",
        "clin_features = df_all.drop(columns=[\"ID\",\"Cohort\"] + leak_cols, errors=\"ignore\").copy()\n",
        "if \"Sex\" in clin_features.columns:\n",
        "    clin_features[\"Sex\"] = clin_features[\"Sex\"].astype(str).str.strip()\n",
        "\n",
        "# Dejar 1 fila por paciente\n",
        "clin_features = clin_features.drop_duplicates(subset=[\"patient_id\"]).reset_index(drop=True)\n",
        "\n",
        "# Guardar consolidado\n",
        "clin_path = OUT/\"p26_clinical_consolidado.csv\"\n",
        "clin_features.to_csv(clin_path, index=False)\n",
        "print(\"‚úÖ Cl√≠nico consolidado:\", clin_features.shape, \"->\", clin_path)\n",
        "print(\"Columnas cl√≠nicas:\", clin_features.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTFljc_Mp-5F",
        "outputId": "39560070-4149-467a-efe2-c295823bc3f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cl√≠nico consolidado: (586, 10) -> /content/drive/MyDrive/CognitivaAI/p26_intermodal/p26_clinical_consolidado.csv\n",
            "Columnas cl√≠nicas: ['Age', 'Sex', 'Education', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF', 'Delay', 'patient_id']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2162075536.py:55: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df2[\"Target\"] = df2[\"Group\"].replace({\"Nondemented\":0, \"Demented\":1, \"Converted\":1})\n",
            "/tmp/ipython-input-2162075536.py:74: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_all[\"Education\"].fillna(df_all[\"Education\"].median(), inplace=True)\n",
            "/tmp/ipython-input-2162075536.py:77: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_all[\"SES\"].fillna(df_all[\"SES\"].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 3 ‚Äî Cargar P24 (imagen) y el consolidado cl√≠nico\n",
        "p24_val = clean_cols(pd.read_csv(BASE/\"p24_meta_simple\"/\"p24_val_preds.csv\"))\n",
        "p24_tst = clean_cols(pd.read_csv(BASE/\"p24_meta_simple\"/\"p24_test_preds.csv\"))\n",
        "\n",
        "# Cohort si falta\n",
        "for df in (p24_val, p24_tst):\n",
        "    if \"cohort\" not in df.columns:\n",
        "        df[\"cohort\"] = df[\"patient_id\"].map(infer_cohort)\n",
        "\n",
        "# Lista de 56 features de imagen (P24)\n",
        "coef_df = pd.read_csv(BASE/\"p24_meta_simple\"/\"p24_coefficients.csv\")\n",
        "IMG_FEATS = coef_df[\"feature\"].tolist()\n",
        "print(f\"Features imagen (P24): {len(IMG_FEATS)} columnas\")\n",
        "\n",
        "# Cl√≠nico consolidado\n",
        "clin = clean_cols(pd.read_csv(OUT/\"p26_clinical_consolidado.csv\"))\n",
        "assert \"patient_id\" in clin.columns, \"El consolidado cl√≠nico debe tener 'patient_id'.\"\n",
        "\n",
        "# Merge con VAL/TEST de P24\n",
        "val = p24_val.merge(clin, on=\"patient_id\", how=\"left\", suffixes=(\"\",\"_clin\"))\n",
        "tst = p24_tst.merge(clin, on=\"patient_id\", how=\"left\", suffixes=(\"\",\"_clin\"))\n",
        "\n",
        "# Columnas cl√≠nicas finales (excluyendo patient_id)\n",
        "CLIN_COLS = [c for c in clin.columns if c!=\"patient_id\"]\n",
        "print(f\"VAL: {val.shape} | TEST: {tst.shape} | #clin_cols={len(CLIN_COLS)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol48QjoNqtFa",
        "outputId": "a6ac37e3-0891-4f21-ed12-6c71cec989cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features imagen (P24): 56 columnas\n",
            "VAL: (69, 13) | TEST: (70, 13) | #clin_cols=9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 4 ‚Äî Separar matrices IMG / CLIN y vectores\n",
        "def split_xy(df):\n",
        "    X_img = df.reindex(columns=IMG_FEATS, fill_value=np.nan)\n",
        "    y     = df[\"y_true\"].astype(int).values\n",
        "    coh   = df[\"cohort\"].astype(str).values\n",
        "    y_img = df[\"y_prob\"].astype(float).values  # proba calibrada de P24\n",
        "    return X_img, y, coh, y_img\n",
        "\n",
        "X_img_val, y_val, coh_val, yimg_val = split_xy(val)\n",
        "X_img_tst, y_tst, coh_tst, yimg_tst = split_xy(tst)\n",
        "\n",
        "X_clin_val = val[CLIN_COLS].copy()\n",
        "X_clin_tst = tst[CLIN_COLS].copy()\n",
        "\n",
        "print(f\"VAL: X_img={X_img_val.shape}, X_clin={X_clin_val.shape}\")\n",
        "print(f\"TEST: X_img={X_img_tst.shape}, X_clin={X_clin_tst.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZkqrqGsqyBu",
        "outputId": "4aa7ba08-ef8b-4f43-d914-d65ee78555a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL: X_img=(69, 56), X_clin=(69, 9)\n",
            "TEST: X_img=(70, 56), X_clin=(70, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 5 ‚Äî Modelo cl√≠nico LR-EN (Repeated Stratified KFold)\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clin_num = [c for c in CLIN_COLS if X_clin_val[c].dtype!=object]\n",
        "clin_cat = [c for c in CLIN_COLS if X_clin_val[c].dtype==object]\n",
        "\n",
        "pre_clin = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                          (\"scaler\", StandardScaler())]), clin_num),\n",
        "        (\"cat\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                          (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), clin_cat),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        "    sparse_threshold=0.3\n",
        ")\n",
        "\n",
        "clf_clin = Pipeline(steps=[\n",
        "    (\"pre\", pre_clin),\n",
        "    (\"lr\", LogisticRegression(penalty=\"elasticnet\", solver=\"saga\",\n",
        "                              l1_ratio=0.5, C=0.5, max_iter=5000))\n",
        "])\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "oof = np.zeros(len(y_val), dtype=float)\n",
        "for tr, va in rskf.split(X_clin_val, y_val):\n",
        "    m = clf_clin\n",
        "    m.fit(X_clin_val.iloc[tr], y_val[tr])\n",
        "    oof[va] = m.predict_proba(X_clin_val.iloc[va])[:,1]\n",
        "\n",
        "clf_clin.fit(X_clin_val, y_val)\n",
        "p_clin_tst = clf_clin.predict_proba(X_clin_tst)[:,1]\n",
        "\n",
        "m_clin_val = metrics_from_scores(y_val, oof)\n",
        "m_clin_tst = metrics_from_scores(y_tst, p_clin_tst)\n",
        "print(\"CL√çNICO OOF VAL:\", m_clin_val)\n",
        "print(\"CL√çNICO TEST  :\", m_clin_tst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KmWUc0Cq0VA",
        "outputId": "7665a101-669f-4a54-8e07-61210b4b1c4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CL√çNICO OOF VAL: {'AUC': 0.58276740237691, 'PRAUC': 0.5248918812433309, 'Brier': 0.25712928295173343}\n",
            "CL√çNICO TEST  : {'AUC': 0.5863486842105263, 'PRAUC': 0.5599631358460779, 'Brier': 0.23997569158513588}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 6_alt_v3 ‚Äî Reintento con artefacto p3 (sin fuga y sin \"drop\" de columnas all-NaN)\n",
        "import pandas as pd, numpy as np, pickle, joblib, json, warnings\n",
        "from pathlib import Path\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"InconsistentVersionWarning\")\n",
        "\n",
        "def find_first(cand_dirs, names):\n",
        "    for d in cand_dirs:\n",
        "        for n in names:\n",
        "            p = d/n\n",
        "            if p.exists():\n",
        "                return p\n",
        "    return None\n",
        "\n",
        "cand_dirs = [\n",
        "    BASE/\"clinical\"/\"final_models\",\n",
        "    BASE/\"artifacts\"/\"clinic\"/\"final_models\",\n",
        "    BASE/\"clinical\",\n",
        "    BASE/\"artifacts\"/\"clinic\",\n",
        "    BASE,\n",
        "    BASE.parent/\"artifacts\"/\"clinic\"/\"final_models\",\n",
        "    BASE.parent\n",
        "]\n",
        "model_priority = [\n",
        "    \"model_lr_isotonic.pkl\",\"model_lr_balanced.pkl\",\n",
        "    \"model_xgb_isotonic.pkl\",\"model_xgb_balanced.pkl\",\n",
        "    \"model_rf_isotonic.pkl\",\"model_rf_balanced.pkl\",\n",
        "]\n",
        "model_path = find_first(cand_dirs, model_priority)\n",
        "\n",
        "# deployment_config.json (opcional)\n",
        "dep_cfg = find_first([BASE/\"clinical\", BASE/\"artifacts\"/\"clinic\", BASE, BASE.parent], [\"deployment_config.json\"])\n",
        "if dep_cfg and dep_cfg.exists():\n",
        "    try:\n",
        "        cfg = json.load(open(dep_cfg))\n",
        "        preferred = cfg.get(\"selected_model\") or cfg.get(\"model_name\")\n",
        "        if preferred:\n",
        "            p2 = find_first(cand_dirs, [preferred])\n",
        "            if p2 and p2.exists():\n",
        "                model_path = p2\n",
        "                print(\"‚ÑπÔ∏è deployment_config.json ->\", preferred)\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è deployment_config.json:\", e)\n",
        "\n",
        "print(\"üì¶ Modelo cl√≠nico candidato:\", model_path if model_path else \"no encontrado\")\n",
        "\n",
        "feat_path = find_first([BASE/\"clinical\", BASE/\"artifacts\"/\"clinic\", BASE, BASE.parent], [\"feature_columns.joblib\"])\n",
        "feature_cols = None\n",
        "if feat_path and Path(feat_path).exists():\n",
        "    try:\n",
        "        feature_cols = [str(c) for c in joblib.load(feat_path)]\n",
        "        # Anti-fuga por si en joblib ven√≠an estas columnas:\n",
        "        feature_cols = [c for c in feature_cols if str(c).lower() not in {\"cdr\",\"group\",\"target\",\"y\",\"label\"}]\n",
        "        print(\"üß© feature_columns.joblib (#cols tras anti-fuga):\", len(feature_cols))\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è feature_columns.joblib:\", e)\n",
        "\n",
        "def try_load_model(p):\n",
        "    if p is None: return None\n",
        "    for loader in (joblib.load, lambda x: pickle.load(open(x,\"rb\")),\n",
        "                   lambda x: pickle.load(open(x,\"rb\"), fix_imports=True, encoding=\"latin1\")):\n",
        "        try:\n",
        "            return loader(p)\n",
        "        except Exception as e:\n",
        "            print(\"loader fall√≥:\", type(e).__name__, \"-\", e)\n",
        "    return None\n",
        "\n",
        "model_clin = try_load_model(model_path)\n",
        "\n",
        "# Construir dise√±o SIN perder columnas (relleno constante para all-NaN)\n",
        "def build_design(df_clin, expected_cols):\n",
        "    if expected_cols is None:\n",
        "        expected_cols = list(df_clin.columns)\n",
        "    # Intersecci√≥n + a√±ade las que falten como NaN\n",
        "    cols_in = [c for c in expected_cols if c in df_clin.columns]\n",
        "    cols_out = [c for c in expected_cols if c not in df_clin.columns]\n",
        "    X = df_clin.reindex(columns=cols_in, fill_value=np.nan).copy()\n",
        "    # Rellenar all-NaN con 0 (evita drop del imputer por \"sin observaciones\")\n",
        "    for c in X.columns:\n",
        "        col = X[c]\n",
        "        if (col.isna().all()):\n",
        "            X[c] = 0.0\n",
        "        elif col.dtype==object:\n",
        "            X[c] = col.astype(str)\n",
        "    # A√±ade expl√≠citamente las ausentes como 0\n",
        "    for c in cols_out:\n",
        "        X[c] = 0.0\n",
        "    return X[expected_cols].copy()\n",
        "\n",
        "# Construye matrices con anti-fuga para el modelo (usa s√≥lo CLIN_COLS conocidos)\n",
        "expected = feature_cols if feature_cols is not None else CLIN_COLS\n",
        "X_val_p3_raw = build_design(X_clin_val, expected)\n",
        "X_tst_p3_raw = build_design(X_clin_tst, expected)\n",
        "\n",
        "def predict_proba_robust(m, X):\n",
        "    try:\n",
        "        return m.predict_proba(X)[:,1]\n",
        "    except Exception as e1:\n",
        "        # fallback ligero num√©rico\n",
        "        X2 = X.copy()\n",
        "        num_cols = [c for c in X2.columns if X2[c].dtype != object]\n",
        "        if num_cols:\n",
        "            imp = SimpleImputer(strategy=\"constant\", fill_value=0.0)  # ‚Üê clave: constante, no median\n",
        "            X2[num_cols] = imp.fit_transform(X2[num_cols])\n",
        "            sca = StandardScaler(with_mean=False)\n",
        "            X2[num_cols] = sca.fit_transform(X2[num_cols])\n",
        "        try:\n",
        "            return m.predict_proba(X2)[:,1]\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"predict_proba fallo: {e1} | {e2}\")\n",
        "\n",
        "CLIN_OUT = BASE/\"clinical\"; CLIN_OUT.mkdir(parents=True, exist_ok=True)\n",
        "p3_csv = CLIN_OUT/\"p3_clinical_probs.csv\"\n",
        "\n",
        "if model_clin is not None:\n",
        "    try:\n",
        "        p_val_p3 = predict_proba_robust(model_clin, X_val_p3_raw)\n",
        "        p_tst_p3 = predict_proba_robust(model_clin, X_tst_p3_raw)\n",
        "        p3_df = pd.concat([\n",
        "            pd.DataFrame({\"patient_id\": val[\"patient_id\"], \"split\":\"VAL\",  \"y_prob_clin\": p_val_p3}),\n",
        "            pd.DataFrame({\"patient_id\": tst[\"patient_id\"], \"split\":\"TEST\", \"y_prob_clin\": p_tst_p3}),\n",
        "        ], ignore_index=True)\n",
        "        p3_df.to_csv(p3_csv, index=False)\n",
        "        print(\"üíæ Guardado (artefacto):\", p3_csv, \"‚Üí\", p3_df.shape)\n",
        "        # Override en memoria\n",
        "        mv = val.merge(p3_df[p3_df[\"split\"]==\"VAL\"][[\"patient_id\",\"y_prob_clin\"]], on=\"patient_id\", how=\"left\")\n",
        "        mt = tst.merge(p3_df[p3_df[\"split\"]==\"TEST\"][[\"patient_id\",\"y_prob_clin\"]], on=\"patient_id\", how=\"left\")\n",
        "        oof = mv[\"y_prob_clin\"].to_numpy()\n",
        "        p_clin_tst = mt[\"y_prob_clin\"].to_numpy()\n",
        "        print(\"üîÅ Override aplicado desde artefacto p3.\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Artefacto no usable para predicci√≥n segura:\", e)\n",
        "        # Fall-back definitivo: usa Celda 5\n",
        "        p3_df = pd.concat([\n",
        "            pd.DataFrame({\"patient_id\": val[\"patient_id\"], \"split\":\"VAL\",  \"y_prob_clin\": oof}),\n",
        "            pd.DataFrame({\"patient_id\": tst[\"patient_id\"], \"split\":\"TEST\", \"y_prob_clin\": p_clin_tst}),\n",
        "        ], ignore_index=True)\n",
        "        p3_df.to_csv(p3_csv, index=False)\n",
        "        print(\"üíæ Guardado (fallback Celda 5):\", p3_csv, \"‚Üí\", p3_df.shape)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se pudo cargar el modelo p3. Se mantiene el fallback de Celda 5 (ya guardado).\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9n71OzRq54V",
        "outputId": "43918010-5c54-4f6d-be96-6570213d7c1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Modelo cl√≠nico candidato: /content/drive/MyDrive/CognitivaAI/clinical/final_models/model_lr_isotonic.pkl\n",
            "üß© feature_columns.joblib (#cols tras anti-fuga): 8\n",
            "‚ö†Ô∏è Artefacto no usable para predicci√≥n segura: predict_proba fallo: The feature names should match those that were passed during fit.\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- CDR\n",
            " | The feature names should match those that were passed during fit.\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- CDR\n",
            "\n",
            "üíæ Guardado (fallback Celda 5): /content/drive/MyDrive/CognitivaAI/clinical/p3_clinical_probs.csv ‚Üí (139, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator IsotonicRegression from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator CalibratedClassifierCV from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "p3_csv = BASE/\"clinical\"/\"p3_clinical_probs.csv\"\n",
        "assert p3_csv.exists(), \"No existe p3_clinical_probs.csv (fallback). Vuelve a ejecutar la Celda 6_alt_v2/v3.\"\n",
        "\n",
        "p3 = pd.read_csv(p3_csv)\n",
        "print(\"p3_clinical_probs.csv:\", p3.shape, \"filas ¬∑ splits:\", p3[\"split\"].value_counts().to_dict())\n",
        "\n",
        "# Comprobamos merge con VAL/TEST de P24\n",
        "mv = val.merge(p3[p3[\"split\"]==\"VAL\"][[\"patient_id\",\"y_prob_clin\"]], on=\"patient_id\", how=\"left\")\n",
        "mt = tst.merge(p3[p3[\"split\"]==\"TEST\"][[\"patient_id\",\"y_prob_clin\"]], on=\"patient_id\", how=\"left\")\n",
        "print(\"VAL merge OK:\", mv[\"y_prob_clin\"].notna().mean(), \"TEST merge OK:\", mt[\"y_prob_clin\"].notna().mean())\n",
        "\n",
        "# Si todo OK, seguimos con las celdas 7‚Üí11\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H44hqhrv5tV",
        "outputId": "0fc55e1a-6ab9-47b4-ff32-b396d5a89cdf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p3_clinical_probs.csv: (139, 3) filas ¬∑ splits: {'TEST': 70, 'VAL': 69}\n",
            "VAL merge OK: 1.0 TEST merge OK: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 7_gen_p1 ‚Äî Generar p1_oas2_img_probs.csv desde artefactos p13/p14 (si existen)\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def _clean_cols(df):\n",
        "    df.columns = [str(c).replace(\"\\ufeff\",\"\").strip() for c in df.columns];\n",
        "    return df\n",
        "\n",
        "def _to_patient_id(id_val, cohort=\"OAS2\"):\n",
        "    s = str(id_val).strip().replace(\"\\u200b\",\"\").replace(\"\\ufeff\",\"\")\n",
        "    if s.upper().startswith((\"OAS1_\",\"OAS2_\")): return s.upper()\n",
        "    if s.isdigit(): return f\"{cohort}_{int(s):04d}\"\n",
        "    s2 = s.replace(\"-\", \"_\").upper()\n",
        "    if not s2.startswith((\"OAS1_\",\"OAS2_\")): s2 = f\"{cohort}_{s2}\"\n",
        "    return s2\n",
        "\n",
        "def _pick_prob_col(df):\n",
        "    # candidatos habituales\n",
        "    cand = [c for c in df.columns if str(c).lower() in\n",
        "            {\"y_prob\",\"prob\",\"yprob\",\"pred_prob\",\"prob1\",\"score\",\"y_hat\",\"yhat\",\"p\",\"proba\"}]\n",
        "    cand = [c for c in cand if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    nums = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    # filtra etiquetas conocidas\n",
        "    bad = {\"y_true\",\"label\",\"target\",\"cdr\",\"group\",\"diagnosis\",\"dx\"}\n",
        "    nums = [c for c in nums if str(c).lower() not in bad]\n",
        "    # dentro de [0,1] mayormente\n",
        "    def in01(series):\n",
        "        s = series.dropna()\n",
        "        return len(s)>0 and (s.between(0,1).mean()>=0.95)\n",
        "    for c in cand:\n",
        "        if in01(df[c]): return c\n",
        "    for c in nums:\n",
        "        if in01(df[c]): return c\n",
        "    return None\n",
        "\n",
        "# 1) Candidatos\n",
        "cands_dirs = [\n",
        "    BASE/\"p14_oasis2_images\",\n",
        "    BASE/\"p13_oasis2_images\",\n",
        "    BASE.parent/\"p14_oasis2_images\",\n",
        "    BASE.parent/\"p13_oasis2_images\",\n",
        "]\n",
        "cand_files = []\n",
        "for d in cands_dirs:\n",
        "    if d.exists():\n",
        "        cand_files += list(d.glob(\"*patient_preds*.csv\")) + list(d.glob(\"*patient_features*.csv\"))\n",
        "if not cand_files:\n",
        "    print(\"‚ÑπÔ∏è No encontr√© CSV de p13/p14. Continuo sin p1 (no pasa nada).\")\n",
        "    p1_val = np.full(len(val), np.nan); p1_tst = np.full(len(tst), np.nan)\n",
        "else:\n",
        "    frames = []\n",
        "    for f in cand_files:\n",
        "        try:\n",
        "            df = _clean_cols(pd.read_csv(f))\n",
        "            # Detecta id de paciente\n",
        "            idcol = None\n",
        "            for k in [\"patient_id\",\"patient\",\"id\",\"subject id\",\"subject_id\",\"ID\"]:\n",
        "                if k in map(str.lower, df.columns):\n",
        "                    # obtener nombre real respetando may√∫sculas\n",
        "                    idcol = [c for c in df.columns if c.lower()==k][0]; break\n",
        "            if idcol is None:\n",
        "                continue\n",
        "            df[\"patient_id\"] = df[idcol].astype(str).map(lambda x: _to_patient_id(x, \"OAS2\"))\n",
        "            # Detecta prob\n",
        "            pcol = _pick_prob_col(df)\n",
        "            if pcol is None:\n",
        "                continue\n",
        "            sub = df[[\"patient_id\", pcol]].rename(columns={pcol:\"y_prob_img\"})\n",
        "            # Solo OAS2 + prob v√°lida\n",
        "            sub = sub[sub[\"patient_id\"].str.upper().str.startswith(\"OAS2_\")]\n",
        "            sub = sub.dropna(subset=[\"y_prob_img\"])\n",
        "            frames.append(sub)\n",
        "            print(f\"‚Ü≥ {f.name}: {len(sub)} filas con y_prob_img\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è {f.name}: {e}\")\n",
        "\n",
        "    if not frames:\n",
        "        print(\"‚ÑπÔ∏è No logr√© extraer probabilidades de los CSVs. Sigo sin p1.\")\n",
        "        p1_val = np.full(len(val), np.nan); p1_tst = np.full(len(tst), np.nan)\n",
        "    else:\n",
        "        p1 = pd.concat(frames, ignore_index=True)\n",
        "        # Si hay duplicados por paciente, promediamos\n",
        "        p1 = p1.groupby(\"patient_id\", as_index=False)[\"y_prob_img\"].mean()\n",
        "        # Guardar\n",
        "        CLIN = BASE/\"clinical\"; CLIN.mkdir(parents=True, exist_ok=True)\n",
        "        out_csv = CLIN/\"p1_oas2_img_probs.csv\"\n",
        "        p1.to_csv(out_csv, index=False)\n",
        "        print(\"üíæ Guardado:\", out_csv, \"‚Üí\", p1.shape)\n",
        "\n",
        "        # Alinear con VAL/TEST actuales\n",
        "        mv = val[[\"patient_id\"]].merge(p1, on=\"patient_id\", how=\"left\")\n",
        "        mt = tst[[\"patient_id\"]].merge(p1, on=\"patient_id\", how=\"left\")\n",
        "        p1_val = mv[\"y_prob_img\"].to_numpy()\n",
        "        p1_tst = mt[\"y_prob_img\"].to_numpy()\n",
        "\n",
        "        # Diagn√≥stico de cobertura\n",
        "        m_val = (~np.isnan(p1_val)).mean()\n",
        "        m_tst = (~np.isnan(p1_tst)).mean()\n",
        "        print(f\"Coverage VAL OAS2 p1: {m_val:.2%} | TEST OAS2 p1: {m_tst:.2%} (NaN en OAS1 por dise√±o)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLtsFAwxxzfC",
        "outputId": "579d7db5-bacf-4bd4-e37f-4322ce99534f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚Ü≥ val_patient_preds_oas2_effb3_p14.csv: 22 filas con y_prob_img\n",
            "‚Ü≥ test_patient_preds_oas2_effb3_p14.csv: 23 filas con y_prob_img\n",
            "‚Ü≥ val_patient_features_oas2_effb3_p14.csv: 22 filas con y_prob_img\n",
            "‚Ü≥ test_patient_features_oas2_effb3_p14.csv: 23 filas con y_prob_img\n",
            "‚Ü≥ val_patient_preds_oas2_effb3.csv: 22 filas con y_prob_img\n",
            "‚Ü≥ test_patient_preds_oas2_effb3.csv: 23 filas con y_prob_img\n",
            "‚Ü≥ val_patient_features_oas2_effb3.csv: 2 filas con y_prob_img\n",
            "‚Ü≥ test_patient_features_oas2_effb3.csv: 3 filas con y_prob_img\n",
            "üíæ Guardado: /content/drive/MyDrive/CognitivaAI/clinical/p1_oas2_img_probs.csv ‚Üí (49, 2)\n",
            "Coverage VAL OAS2 p1: 31.88% | TEST OAS2 p1: 32.86% (NaN en OAS1 por dise√±o)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sustituye el contenido de tu Celda 7 (o a√±√°delo tras la 7_gen_p1 que ya corriste)\n",
        "\n",
        "import numpy as np\n",
        "# Si no existe p1_val/p1_tst, definelos como NaN (por si vienes del fallback)\n",
        "if 'p1_val' not in globals(): p1_val = np.full(len(val), np.nan)\n",
        "if 'p1_tst' not in globals(): p1_tst = np.full(len(tst), np.nan)\n",
        "\n",
        "# M√°scaras de cohorte\n",
        "mask_oas2_val = (val[\"cohort\"].values == \"OAS2\")\n",
        "mask_oas2_tst = (tst[\"cohort\"].values == \"OAS2\")\n",
        "\n",
        "# Flag de presencia\n",
        "p1_has_val = ~np.isnan(p1_val)\n",
        "p1_has_tst = ~np.isnan(p1_tst)\n",
        "\n",
        "# Media OAS2 en VAL (¬°solo VAL para evitar fuga!)\n",
        "m_oas2_val = np.nanmean(p1_val[mask_oas2_val]) if np.any(mask_oas2_val) else 0.5\n",
        "\n",
        "# Imputaci√≥n coherente\n",
        "p1_fill_val = p1_val.copy()\n",
        "p1_fill_tst = p1_tst.copy()\n",
        "\n",
        "# En OAS2: faltantes ‚Üí media VAL OAS2\n",
        "p1_fill_val[~p1_has_val & mask_oas2_val] = m_oas2_val\n",
        "p1_fill_tst[~p1_has_tst & mask_oas2_tst] = m_oas2_val  # usa SIEMPRE la media de VAL\n",
        "\n",
        "# En OAS1: todo p1 es ausente ‚Üí neutral 0.5\n",
        "p1_fill_val[~mask_oas2_val] = 0.5\n",
        "p1_fill_tst[~mask_oas2_tst] = 0.5\n",
        "\n",
        "print(f\"p1 imputado: m_oas2_val={m_oas2_val:.3f} | has_val={(p1_has_val).mean():.2%} | has_tst={(p1_has_tst).mean():.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKDg5nAWy2HA",
        "outputId": "1f025afb-e335-416c-f1f1-80ff33008098"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p1 imputado: m_oas2_val=0.575 | has_val=31.88% | has_tst=32.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "def stack_cols(*cols):\n",
        "    cols = [c.reshape(-1,1) if c.ndim==1 else c for c in cols]\n",
        "    return np.hstack(cols)\n",
        "\n",
        "# Variante A: SIN p1\n",
        "X_metaA_val = stack_cols(yimg_val, oof)\n",
        "X_metaA_tst = stack_cols(yimg_tst, p_clin_tst)\n",
        "metaA = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=1000).fit(X_metaA_val, y_val)\n",
        "pA_val = metaA.predict_proba(X_metaA_val)[:,1]\n",
        "pA_tst = metaA.predict_proba(X_metaA_tst)[:,1]\n",
        "mA_val = metrics_from_scores(y_val, pA_val)\n",
        "mA_tst = metrics_from_scores(y_tst, pA_tst)\n",
        "\n",
        "# Variante B: CON p1 (p1_fill + flag p1_has)\n",
        "X_metaB_val = stack_cols(yimg_val, oof, p1_fill_val, p1_has_val.astype(float))\n",
        "X_metaB_tst = stack_cols(yimg_tst, p_clin_tst, p1_fill_tst, p1_has_tst.astype(float))\n",
        "metaB = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=1000).fit(X_metaB_val, y_val)\n",
        "pB_val = metaB.predict_proba(X_metaB_val)[:,1]\n",
        "pB_tst = metaB.predict_proba(X_metaB_tst)[:,1]\n",
        "mB_val = metrics_from_scores(y_val, pB_val)\n",
        "mB_tst = metrics_from_scores(y_tst, pB_tst)\n",
        "\n",
        "print(\"LATE A (sin p1) VAL:\", mA_val, \"\\nLATE A TEST:\", mA_tst)\n",
        "print(\"LATE B (con p1) VAL:\", mB_val, \"\\nLATE B TEST:\", mB_tst)\n",
        "\n",
        "# Elegimos por AUC(VAL)\n",
        "use_B = (mB_val[\"AUC\"] > (mA_val[\"AUC\"] + 1e-6))\n",
        "p_meta_val = pB_val if use_B else pA_val\n",
        "p_meta_tst = pB_tst if use_B else pA_tst\n",
        "m_meta_val = mB_val if use_B else mA_val\n",
        "m_meta_tst = mB_tst if use_B else mA_tst\n",
        "meta_feats = [\"p_img\",\"p_clin\",\"p1_fill\",\"p1_has\"] if use_B else [\"p_img\",\"p_clin\"]\n",
        "print(\"‚û°Ô∏è LATE elegido:\", \"con p1\" if use_B else \"sin p1\", \"| feats:\", meta_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EAXGSvjy8W7",
        "outputId": "25e906b5-1d03-4f7f-9d6d-0a5ab0cae5cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LATE A (sin p1) VAL: {'AUC': 0.9142614601018676, 'PRAUC': 0.9233963998617327, 'Brier': 0.11381905289515709} \n",
            "LATE A TEST: {'AUC': 0.6965460526315789, 'PRAUC': 0.693915321534084, 'Brier': 0.24068705782718486}\n",
            "LATE B (con p1) VAL: {'AUC': 0.9159592529711376, 'PRAUC': 0.9209221898268721, 'Brier': 0.11120259520047246} \n",
            "LATE B TEST: {'AUC': 0.7129934210526315, 'PRAUC': 0.7121843775894818, 'Brier': 0.23385491237404987}\n",
            "‚û°Ô∏è LATE elegido: con p1 | feats: ['p_img', 'p_clin', 'p1_fill', 'p1_has']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 9 ‚Äî Mid fusion (reconstruyendo las 56 features de imagen desde p11/p14/p13)\n",
        "\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def _clean_cols(df):\n",
        "    df.columns = [str(c).replace(\"\\ufeff\",\"\").strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def _std_pid(s):\n",
        "    s = str(s).strip().replace(\"\\u200b\",\"\").replace(\"\\ufeff\",\"\")\n",
        "    u = s.upper()\n",
        "    if u.startswith((\"OAS1_\",\"OAS2_\")): return u\n",
        "    if s.isdigit(): return f\"OAS1_{int(s):04d}\"  # por seguridad; se sobreescribe seg√∫n origen\n",
        "    return u\n",
        "\n",
        "def _load_feature_file(path, cohort_hint=None):\n",
        "    df = _clean_cols(pd.read_csv(path))\n",
        "    # Detectar columna id\n",
        "    idcol = None\n",
        "    for k in [\"patient_id\",\"patient\",\"id\",\"subject id\",\"subject_id\",\"ID\"]:\n",
        "        for c in df.columns:\n",
        "            if c.lower() == k:\n",
        "                idcol = c; break\n",
        "        if idcol: break\n",
        "    if idcol is None:\n",
        "        return None\n",
        "    df[\"patient_id\"] = df[idcol].astype(str).map(_std_pid)\n",
        "    # Si cohort_hint == \"OAS2\" y los ids no llevan prefijo, a√±√°delo\n",
        "    if cohort_hint == \"OAS2\":\n",
        "        df[\"patient_id\"] = df[\"patient_id\"].apply(lambda x: x if x.startswith(\"OAS2_\") else x.replace(\"OAS1_\",\"OAS2_\") if x.startswith(\"OAS1_\") else (\"OAS2_\"+x if not x.startswith(\"OAS2_\") else x))\n",
        "    # Filtrar a columnas de inter√©s (intersecci√≥n con IMG_FEATS)\n",
        "    keep = [\"patient_id\"] + [c for c in df.columns if c in IMG_FEATS]\n",
        "    df = df[keep].copy()\n",
        "    # Asegurar num√©ricas\n",
        "    for c in df.columns:\n",
        "        if c!=\"patient_id\":\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "def _merge_features(base_ids, dfs):\n",
        "    \"\"\"Combina DataFrames de features evitando sufijos: toma el primer no-NaN por columna.\"\"\"\n",
        "    out = pd.DataFrame({\"patient_id\": base_ids})\n",
        "    for df in dfs:\n",
        "        if df is None or df.empty:\n",
        "            continue\n",
        "        out = out.merge(df, on=\"patient_id\", how=\"left\", suffixes=(None, None))\n",
        "        # Si aparecieran duplicados, resolveremos abajo al reindexar\n",
        "    # Garantiza todas IMG_FEATS presentes\n",
        "    for c in IMG_FEATS:\n",
        "        if c not in out.columns:\n",
        "            out[c] = np.nan\n",
        "    # Ordena columnas\n",
        "    out = out[[\"patient_id\"] + IMG_FEATS]\n",
        "    return out\n",
        "\n",
        "# Rutas candidatas por split\n",
        "sources_val = []\n",
        "sources_tst = []\n",
        "\n",
        "# OAS1 (p11)\n",
        "p11 = BASE/\"p11_alt_backbones\"\n",
        "if p11.exists():\n",
        "    f_val_oas1 = p11/\"val_patient_features_backbones.csv\"\n",
        "    f_tst_oas1 = p11/\"test_patient_features_backbones.csv\"\n",
        "    if f_val_oas1.exists(): sources_val.append((\"OAS1\", f_val_oas1))\n",
        "    if f_tst_oas1.exists(): sources_tst.append((\"OAS1\", f_tst_oas1))\n",
        "\n",
        "# OAS2 (p14/p13)\n",
        "for d in [BASE/\"p14_oasis2_images\", BASE/\"p13_oasis2_images\", BASE.parent/\"p14_oasis2_images\", BASE.parent/\"p13_oasis2_images\"]:\n",
        "    if d.exists():\n",
        "        for name in d.glob(\"*val*patient_features*.csv\"):\n",
        "            sources_val.append((\"OAS2\", name))\n",
        "        for name in d.glob(\"*test*patient_features*.csv\"):\n",
        "            sources_tst.append((\"OAS2\", name))\n",
        "\n",
        "print(\"Fuentes VAL:\", [str(p) for _,p in sources_val])\n",
        "print(\"Fuentes TEST:\", [str(p) for _,p in sources_tst])\n",
        "\n",
        "# Cargar y filtrar a columnas IMG_FEATS\n",
        "val_dfs = []\n",
        "for coh, path in sources_val:\n",
        "    try:\n",
        "        val_dfs.append(_load_feature_file(path, cohort_hint=coh))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è {path.name}: {e}\")\n",
        "\n",
        "tst_dfs = []\n",
        "for coh, path in sources_tst:\n",
        "    try:\n",
        "        tst_dfs.append(_load_feature_file(path, cohort_hint=coh))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è {path.name}: {e}\")\n",
        "\n",
        "# Construir matrices de features alineadas al orden de val/tst\n",
        "feat_val = _merge_features(val[\"patient_id\"].values, val_dfs)\n",
        "feat_tst = _merge_features(tst[\"patient_id\"].values, tst_dfs)\n",
        "\n",
        "# Diagn√≥stico de cobertura por columnas\n",
        "cov_val = feat_val[IMG_FEATS].notna().mean()\n",
        "cov_tst = feat_tst[IMG_FEATS].notna().mean()\n",
        "print(\"Cobertura VAL (media por col):\", float(cov_val.mean()))\n",
        "print(\"Cobertura TEST (media por col):\", float(cov_tst.mean()))\n",
        "\n",
        "# === Preparar Mid: concat imagen + cl√≠nico + p1 (prellenado y flag) ===\n",
        "# Nota: p1_fill_val/p1_fill_tst y p1_has_val/p1_has_tst fueron creados en el parche de Celda 7\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "val_p1_df = pd.DataFrame({\"p1_fill\": p1_fill_val, \"p1_has\": p1_has_val.astype(int)}, index=val.index)\n",
        "tst_p1_df = pd.DataFrame({\"p1_fill\": p1_fill_tst, \"p1_has\": p1_has_tst.astype(int)}, index=tst.index)\n",
        "\n",
        "# Usar feat_val/feat_tst para las columnas IMG_FEATS (no val[img_cols])\n",
        "X_mid_val = pd.concat([feat_val[IMG_FEATS].reset_index(drop=True), X_clin_val.reset_index(drop=True), val_p1_df.reset_index(drop=True)], axis=1)\n",
        "X_mid_tst = pd.concat([feat_tst[IMG_FEATS].reset_index(drop=True), X_clin_tst.reset_index(drop=True), tst_p1_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "all_cols = list(X_mid_val.columns)\n",
        "# cl√≠nicas num/cat ya detectadas antes (CLIN_COLS); extendemos con imagen + p1\n",
        "mid_num = [c for c in all_cols if (c in IMG_FEATS) or (c in [*CLIN_COLS]) and (X_clin_val[c].dtype!=object) or (c in [\"p1_fill\",\"p1_has\"])]\n",
        "mid_cat = [c for c in CLIN_COLS if X_clin_val[c].dtype==object and c in all_cols]\n",
        "\n",
        "# El ColumnTransformer se encargar√° de imputar medianas; si alguna col est√° all-NaN, sklearn la ‚Äúsaltar√°‚Äù sin romper\n",
        "pre_mid = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                          (\"scaler\", StandardScaler())]), mid_num),\n",
        "        (\"cat\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                          (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), mid_cat),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        "    sparse_threshold=0.3\n",
        ")\n",
        "\n",
        "mid_lr = Pipeline([\n",
        "    (\"pre\", pre_mid),\n",
        "    (\"lr\", LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.5, C=0.5, max_iter=5000))\n",
        "])\n",
        "\n",
        "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
        "oof_mid = np.zeros(len(y_val), dtype=float)\n",
        "for tr, va in rskf.split(X_mid_val, y_val):\n",
        "    m = mid_lr\n",
        "    m.fit(X_mid_val.iloc[tr], y_val[tr])\n",
        "    oof_mid[va] = m.predict_proba(X_mid_val.iloc[va])[:,1]\n",
        "\n",
        "mid_lr.fit(X_mid_val, y_val)\n",
        "p_mid_tst = mid_lr.predict_proba(X_mid_tst)[:,1]\n",
        "\n",
        "m_mid_val = metrics_from_scores(y_val, oof_mid)\n",
        "m_mid_tst = metrics_from_scores(y_tst, p_mid_tst)\n",
        "print(\"MID FUSION VAL :\", m_mid_val)\n",
        "print(\"MID FUSION TEST:\", m_mid_tst)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47rw-rg9zgAq",
        "outputId": "4b98c4b4-82e6-4aaa-ec01-6e303585f55b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fuentes VAL: ['/content/drive/MyDrive/CognitivaAI/p11_alt_backbones/val_patient_features_backbones.csv', '/content/drive/MyDrive/CognitivaAI/p14_oasis2_images/val_patient_features_oas2_effb3_p14.csv', '/content/drive/MyDrive/CognitivaAI/p13_oasis2_images/val_patient_features_oas2_effb3.csv']\n",
            "Fuentes TEST: ['/content/drive/MyDrive/CognitivaAI/p11_alt_backbones/test_patient_features_backbones.csv', '/content/drive/MyDrive/CognitivaAI/p14_oasis2_images/test_patient_features_oas2_effb3_p14.csv', '/content/drive/MyDrive/CognitivaAI/p13_oasis2_images/test_patient_features_oas2_effb3.csv']\n",
            "Cobertura VAL (media por col): 0.5144927536231884\n",
            "Cobertura TEST (media por col): 0.6224489795918366\n",
            "MID FUSION VAL : {'AUC': 0.7971137521222411, 'PRAUC': 0.7766370505604872, 'Brier': 0.18454527361873402}\n",
            "MID FUSION TEST: {'AUC': 0.6973684210526316, 'PRAUC': 0.6573379171919493, 'Brier': 0.22967954621192932}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 10 ‚Äî Selecci√≥n + umbrales coste 5:1 (por cohorte) + artefactos P26\n",
        "import numpy as np, pandas as pd, json\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "OUT = BASE/\"p26_intermodal\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def metrics_from_scores(y, p):\n",
        "    y = np.asarray(y).astype(int); p = np.asarray(p, float)\n",
        "    return dict(\n",
        "        AUC=float(roc_auc_score(y, p)),\n",
        "        PRAUC=float(average_precision_score(y, p)),\n",
        "        Brier=float(brier_score_loss(y, p)),\n",
        "    )\n",
        "\n",
        "def confusion_at_thr(y_true, y_prob, thr):\n",
        "    y_pred = (y_prob >= thr).astype(int)\n",
        "    TP = int(((y_true==1)&(y_pred==1)).sum())\n",
        "    FP = int(((y_true==0)&(y_pred==1)).sum())\n",
        "    TN = int(((y_true==0)&(y_pred==0)).sum())\n",
        "    FN = int(((y_true==1)&(y_pred==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/(TP+TN+FP+FN)\n",
        "    return TP,FP,TN,FN,prec,rec,acc\n",
        "\n",
        "def best_cost_thr(y_true, y_prob, C_FN=5.0, C_FP=1.0, grid=1001):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_prob = np.asarray(y_prob, float)\n",
        "    thrs = np.linspace(0,1,grid)\n",
        "    best = None\n",
        "    for t in thrs:\n",
        "        TP,FP,TN,FN,_,_,_ = confusion_at_thr(y_true,y_prob,t)\n",
        "        cost = C_FN*FN + C_FP*FP\n",
        "        if (best is None) or (cost < best[\"Cost\"] - 1e-9):\n",
        "            best = dict(Thr=float(t), Cost=float(cost), TP=TP, FP=FP, TN=TN, FN=FN)\n",
        "    return best\n",
        "\n",
        "# === 1) Tomamos el mejor \"Late o Mid\" por AUC(VAL) ===\n",
        "# Variables creadas en celdas previas:\n",
        "#   Late elegido ‚Üí p_meta_val, p_meta_tst, m_meta_val, m_meta_tst, meta_feats\n",
        "#   Mid          ‚Üí oof_mid,     p_mid_tst,  m_mid_val,  m_mid_tst\n",
        "late_is_better = (m_meta_val[\"AUC\"] >= m_mid_val[\"AUC\"] - 1e-6)\n",
        "winner = \"LATE\" if late_is_better else \"MID\"\n",
        "\n",
        "y_val_arr = y_val.astype(int)\n",
        "y_tst_arr = y_tst.astype(int)\n",
        "\n",
        "p_val_w = p_meta_val if winner==\"LATE\" else oof_mid\n",
        "p_tst_w = p_meta_tst if winner==\"LATE\" else p_mid_tst\n",
        "\n",
        "m_val_w = metrics_from_scores(y_val_arr, p_val_w)\n",
        "m_tst_w = metrics_from_scores(y_tst_arr, p_tst_w)\n",
        "\n",
        "print(f\"üèÅ P26 seleccionado: {winner}  |  VAL AUC={m_val_w['AUC']:.3f}  TEST AUC={m_tst_w['AUC']:.3f}\")\n",
        "\n",
        "# === 2) Umbrales por cohorte (coste FN:FP = 5:1) aprendidos en VAL y aplicados a TEST ===\n",
        "C_FN, C_FP = 5.0, 1.0\n",
        "rows_thr = []\n",
        "rows_test = []\n",
        "\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    mask_val = (val[\"cohort\"].values==coh)\n",
        "    mask_tst = (tst[\"cohort\"].values==coh)\n",
        "    best = best_cost_thr(y_val_arr[mask_val], p_val_w[mask_val], C_FN=C_FN, C_FP=C_FP, grid=1001)\n",
        "    thr = best[\"Thr\"]\n",
        "    TP,FP,TN,FN,prec,rec,acc = confusion_at_thr(y_tst_arr[mask_tst], p_tst_w[mask_tst], thr)\n",
        "    rows_thr.append(dict(Cohort=coh, Thr_VAL=thr, Cost_VAL=best[\"Cost\"], C_FN=C_FN, C_FP=C_FP))\n",
        "    rows_test.append(dict(\n",
        "        Cohort=coh, Thr=thr, TP=TP, FP=FP, TN=TN, FN=FN,\n",
        "        Precision=float(prec), Recall=float(rec), Acc=float(acc),\n",
        "        Cost=float(C_FN*FN + C_FP*FP)\n",
        "    ))\n",
        "\n",
        "thr_df  = pd.DataFrame(rows_thr)\n",
        "test_df = pd.DataFrame(rows_test)\n",
        "thr_df.to_csv(OUT/\"p26_thresholds_cost_5to1.csv\", index=False)\n",
        "test_df.to_csv(OUT/\"p26_test_report_cost_5to1.csv\", index=False)\n",
        "\n",
        "print(\"üíæ Guardado umbrales:\", OUT/\"p26_thresholds_cost_5to1.csv\")\n",
        "print(\"üíæ Guardado test@umbrales:\", OUT/\"p26_test_report_cost_5to1.csv\")\n",
        "print(test_df)\n",
        "\n",
        "# === 3) Guardar predicciones y resumen ===\n",
        "val_preds = pd.DataFrame({\n",
        "    \"patient_id\": val[\"patient_id\"].values,\n",
        "    \"cohort\": val[\"cohort\"].values,\n",
        "    \"y_true\": y_val_arr,\n",
        "    \"y_prob\": p_val_w\n",
        "})\n",
        "tst_preds = pd.DataFrame({\n",
        "    \"patient_id\": tst[\"patient_id\"].values,\n",
        "    \"cohort\": tst[\"cohort\"].values,\n",
        "    \"y_true\": y_tst_arr,\n",
        "    \"y_prob\": p_tst_w\n",
        "})\n",
        "val_preds.to_csv(OUT/\"p26_val_preds.csv\", index=False)\n",
        "tst_preds.to_csv(OUT/\"p26_test_preds.csv\", index=False)\n",
        "\n",
        "summary = dict(\n",
        "    winner=winner,\n",
        "    meta_features=(meta_feats if winner==\"LATE\" else \"MID(IMG56+CLIN+p1)\"),\n",
        "    cost_weights=dict(C_FN=C_FN, C_FP=C_FP),\n",
        "    VAL=m_val_w, TEST=m_tst_w,\n",
        "    late_VAL=m_meta_val, late_TEST=m_meta_tst,\n",
        "    mid_VAL=m_mid_val,  mid_TEST=m_mid_tst\n",
        ")\n",
        "json.dump(summary, open(OUT/\"p26_summary.json\",\"w\"), indent=2)\n",
        "print(\"üíæ Guardado summary:\", OUT/\"p26_summary.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFq1VTCB3Dg9",
        "outputId": "dce22393-1ce1-49b9-b6a7-fd35e7b9b38a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÅ P26 seleccionado: LATE  |  VAL AUC=0.916  TEST AUC=0.713\n",
            "üíæ Guardado umbrales: /content/drive/MyDrive/CognitivaAI/p26_intermodal/p26_thresholds_cost_5to1.csv\n",
            "üíæ Guardado test@umbrales: /content/drive/MyDrive/CognitivaAI/p26_intermodal/p26_test_report_cost_5to1.csv\n",
            "  Cohort    Thr  TP  FP  TN  FN  Precision    Recall       Acc  Cost\n",
            "0   OAS1  0.307  14   9  18   6   0.608696  0.700000  0.680851  39.0\n",
            "1   OAS2  0.195   8   4   7   4   0.666667  0.666667  0.652174  24.0\n",
            "üíæ Guardado summary: /content/drive/MyDrive/CognitivaAI/p26_intermodal/p26_summary.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 11_fix ‚Äî Bloques README / Informe / Bit√°cora (robustos, sin f-strings con if en el formato)\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import date\n",
        "\n",
        "OUT = BASE/\"p26_intermodal\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Carga lo que acabamos de guardar en la Celda 10\n",
        "thr_df  = pd.read_csv(OUT/\"p26_thresholds_cost_5to1.csv\")\n",
        "test_df = pd.read_csv(OUT/\"p26_test_report_cost_5to1.csv\")\n",
        "\n",
        "# Extrae por cohorte para poner cifras en el texto\n",
        "def _row(coh):\n",
        "    r = test_df.loc[test_df[\"Cohort\"]==coh]\n",
        "    return r.iloc[0].to_dict() if len(r) else {}\n",
        "\n",
        "r1 = _row(\"OAS1\")\n",
        "r2 = _row(\"OAS2\")\n",
        "\n",
        "# Helpers para strings con 3 decimales o '‚Äî' si falta\n",
        "f3 = lambda x: f\"{float(x):.3f}\" if pd.notna(x) else \"‚Äî\"\n",
        "\n",
        "# Valores del resumen (ya estaban en 'summary' de Celda 10)\n",
        "late_val_auc  = f3(summary['late_VAL']['AUC'])\n",
        "late_val_pra  = f3(summary['late_VAL']['PRAUC'])\n",
        "late_val_bri  = f3(summary['late_VAL']['Brier'])\n",
        "late_tst_auc  = f3(summary['late_TEST']['AUC'])\n",
        "late_tst_pra  = f3(summary['late_TEST']['PRAUC'])\n",
        "late_tst_bri  = f3(summary['late_TEST']['Brier'])\n",
        "\n",
        "mid_val_auc   = f3(summary['mid_VAL']['AUC'])\n",
        "mid_val_pra   = f3(summary['mid_VAL']['PRAUC'])\n",
        "mid_val_bri   = f3(summary['mid_VAL']['Brier'])\n",
        "mid_tst_auc   = f3(summary['mid_TEST']['AUC'])\n",
        "mid_tst_pra   = f3(summary['mid_TEST']['PRAUC'])\n",
        "mid_tst_bri   = f3(summary['mid_TEST']['Brier'])\n",
        "\n",
        "winner_str = summary['winner']\n",
        "meta_feats = summary['meta_features'] if isinstance(summary['meta_features'], list) else [str(summary['meta_features'])]\n",
        "\n",
        "# Texto por cohorte\n",
        "oas1_line = (\n",
        "    f\"OAS1 @ thr={f3(r1.get('Thr'))} ‚Üí \"\n",
        "    f\"TP={int(r1.get('TP',np.nan))}, FP={int(r1.get('FP',np.nan))}, TN={int(r1.get('TN',np.nan))}, FN={int(r1.get('FN',np.nan))} \"\n",
        "    f\"‚Üí R={f3(r1.get('Recall'))}, P={f3(r1.get('Precision'))}, Acc={f3(r1.get('Acc'))}, Coste={f3(r1.get('Cost'))}\"\n",
        ")\n",
        "oas2_line = (\n",
        "    f\"OAS2 @ thr={f3(r2.get('Thr'))} ‚Üí \"\n",
        "    f\"TP={int(r2.get('TP',np.nan))}, FP={int(r2.get('FP',np.nan))}, TN={int(r2.get('TN',np.nan))}, FN={int(r2.get('FN',np.nan))} \"\n",
        "    f\"‚Üí R={f3(r2.get('Recall'))}, P={f3(r2.get('Precision'))}, Acc={f3(r2.get('Acc'))}, Coste={f3(r2.get('Cost'))}\"\n",
        ")\n",
        "\n",
        "# === README block ===\n",
        "blk_readme = f\"\"\"\n",
        "### P26 ‚Äî Intermodal (imagen + cl√≠nico) con fusi√≥n Late/Mid\n",
        "\n",
        "**Selecci√≥n por VAL:** {winner_str}\n",
        "- **Late (p_img, p_clin{\", p1_fill, p1_has\" if len(meta_feats)>2 else \"\"})**\n",
        "  - VAL: AUC={late_val_auc} | PR-AUC={late_val_pra} | Brier={late_val_bri}\n",
        "  - TEST: AUC={late_tst_auc} | PR-AUC={late_tst_pra} | Brier={late_tst_bri}\n",
        "- **Mid (IMG56 + cl√≠nico + p1)**\n",
        "  - VAL: AUC={mid_val_auc} | PR-AUC={mid_val_pra} | Brier={mid_val_bri}\n",
        "  - TEST: AUC={mid_tst_auc} | PR-AUC={mid_tst_pra} | Brier={mid_tst_bri}\n",
        "\n",
        "**Decisi√≥n por coste (FN:FP=5:1, umbral aprendido en VAL y aplicado en TEST):**\n",
        "- {oas1_line}\n",
        "- {oas2_line}\n",
        "\n",
        "_Artefactos_: `p26_val_preds.csv`, `p26_test_preds.csv`, `p26_thresholds_cost_5to1.csv`, `p26_test_report_cost_5to1.csv`, `p26_summary.json`.\n",
        "\"\"\"\n",
        "\n",
        "# === InformeTecnico block ===\n",
        "blk_informe = f\"\"\"\n",
        "## P26 ‚Äî Intermodal (imagen + cl√≠nico)\n",
        "\n",
        "**Dise√±o:**\n",
        "1) **Cl√≠nico consolidado** OASIS-1/2 con anti-fuga (sin CDR/Group), imputaci√≥n ligera y OHE.\n",
        "2) Se√±ales de imagen: **probabilidad P24** + **matriz 56 features** (p11 OAS1 + p14/p13 OAS2).\n",
        "3) Se√±al parcial p1-OAS2 (~32% cobertura) integrada con **imputaci√≥n por cohorte** (media VAL OAS2) + **flag de presencia**.\n",
        "4) Dos estrategias:\n",
        "   - **Late:** meta-LR sobre {{p_img, p_clin}} (+ p1_fill, p1_has).\n",
        "   - **Mid:** LR-EN sobre {{IMG56, cl√≠nico, p1}}.\n",
        "5) Selecci√≥n por **AUC(VAL)** y decisi√≥n por **coste 5:1** (umbral por cohorte aprendido en VAL).\n",
        "\n",
        "**Resultados:**\n",
        "- LATE (seleccionado): VAL AUC={late_val_auc} ¬∑ TEST AUC={late_tst_auc} (Brier TEST={late_tst_bri}).\n",
        "- MID: VAL AUC={mid_val_auc} ¬∑ TEST AUC={mid_tst_auc} (Brier TEST={mid_tst_bri}).\n",
        "\n",
        "**Decisi√≥n cl√≠nico-operativa (5:1):**\n",
        "- {oas1_line}\n",
        "- {oas2_line}\n",
        "\n",
        "**Notas:**\n",
        "- La cobertura parcial de p1 se maneja con imputaci√≥n **solo en OAS2** y `p1_has`.\n",
        "- Late supera Mid en este dataset; en despliegue, monitorizar ECE/MCE por cohorte y considerar recalibraci√≥n si ECE>0.2.\n",
        "\"\"\"\n",
        "\n",
        "# === Bit√°cora block ===\n",
        "blk_bitacora = f\"\"\"\n",
        "### {date.today()} ‚Äî P26 intermodal completado\n",
        "\n",
        "- Estrategia seleccionada: **{winner_str}** (meta-features: {\", \".join(meta_feats)}).\n",
        "- Late VAL: AUC={late_val_auc} | TEST: AUC={late_tst_auc}.\n",
        "- Mid  VAL: AUC={mid_val_auc}  | TEST: AUC={mid_tst_auc}.\n",
        "- Umbrales 5:1 por cohorte (aprendidos en VAL ‚Üí aplicados en TEST):\n",
        "  - {oas1_line}\n",
        "  - {oas2_line}\n",
        "- Artefactos guardados en `p26_intermodal/`.\n",
        "\"\"\"\n",
        "\n",
        "# Guarda bloques a disco y muestra README block como preview\n",
        "(Path(OUT/\"p26_readme_block.md\").write_text(blk_readme, encoding=\"utf-8\"))\n",
        "(Path(OUT/\"p26_informe_block.md\").write_text(blk_informe, encoding=\"utf-8\"))\n",
        "(Path(OUT/\"p26_bitacora_block.md\").write_text(blk_bitacora, encoding=\"utf-8\"))\n",
        "\n",
        "print(\"‚úÖ Bloques guardados en:\", OUT)\n",
        "print(blk_readme)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imgDzVt13MkO",
        "outputId": "bcb91eb6-d70d-4d5a-837d-fa37da40048f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Bloques guardados en: /content/drive/MyDrive/CognitivaAI/p26_intermodal\n",
            "\n",
            "### P26 ‚Äî Intermodal (imagen + cl√≠nico) con fusi√≥n Late/Mid\n",
            "\n",
            "**Selecci√≥n por VAL:** LATE  \n",
            "- **Late (p_img, p_clin, p1_fill, p1_has)**  \n",
            "  - VAL: AUC=0.916 | PR-AUC=0.921 | Brier=0.111  \n",
            "  - TEST: AUC=0.713 | PR-AUC=0.712 | Brier=0.234\n",
            "- **Mid (IMG56 + cl√≠nico + p1)**  \n",
            "  - VAL: AUC=0.797 | PR-AUC=0.777 | Brier=0.185  \n",
            "  - TEST: AUC=0.697 | PR-AUC=0.657 | Brier=0.230\n",
            "\n",
            "**Decisi√≥n por coste (FN:FP=5:1, umbral aprendido en VAL y aplicado en TEST):**  \n",
            "- OAS1 @ thr=0.307 ‚Üí TP=14, FP=9, TN=18, FN=6 ‚Üí R=0.700, P=0.609, Acc=0.681, Coste=39.000  \n",
            "- OAS2 @ thr=0.195 ‚Üí TP=8, FP=4, TN=7, FN=4 ‚Üí R=0.667, P=0.667, Acc=0.652, Coste=24.000\n",
            "\n",
            "_Artefactos_: `p26_val_preds.csv`, `p26_test_preds.csv`, `p26_thresholds_cost_5to1.csv`, `p26_test_report_cost_5to1.csv`, `p26_summary.json`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 12 ‚Äî Insertar P26 en P25 (master table + executive table)\n",
        "import pandas as pd, numpy as np, json\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "P25 = BASE/\"p25_informe_final\"\n",
        "P26 = BASE/\"p26_intermodal\"\n",
        "assert (P25/\"p25_master_table.csv\").exists(), \"No encuentro p25_master_table.csv\"\n",
        "assert (P26/\"p26_val_preds.csv\").exists() and (P26/\"p26_test_preds.csv\").exists(), \"Faltan preds de P26\"\n",
        "assert (P26/\"p26_test_report_cost_5to1.csv\").exists(), \"Falta test_report_cost_5to1 de P26\"\n",
        "assert (P26/\"p26_summary.json\").exists(), \"Falta summary de P26\"\n",
        "\n",
        "mt = pd.read_csv(P25/\"p25_master_table.csv\")\n",
        "val = pd.read_csv(P26/\"p26_val_preds.csv\")\n",
        "tst = pd.read_csv(P26/\"p26_test_preds.csv\")\n",
        "rep = pd.read_csv(P26/\"p26_test_report_cost_5to1.csv\")\n",
        "summary = json.load(open(P26/\"p26_summary.json\"))\n",
        "\n",
        "def _metrics(df):\n",
        "    y, p = df[\"y_true\"].astype(int).to_numpy(), df[\"y_prob\"].astype(float).to_numpy()\n",
        "    return dict(\n",
        "        AUC=float(roc_auc_score(y,p)),\n",
        "        PRAUC=float(average_precision_score(y,p)),\n",
        "        Brier=float(brier_score_loss(y,p))\n",
        "    )\n",
        "\n",
        "rows = []\n",
        "# ALL\n",
        "rows.append(dict(Pipeline=\"P26\", Split=\"VAL\",  Cohort=\"ALL\", **_metrics(val),  Acc=np.nan, Precision=np.nan, Recall=np.nan, Thr=np.nan, Cost=np.nan, Notas=summary[\"winner\"]))\n",
        "rows.append(dict(Pipeline=\"P26\", Split=\"TEST\", Cohort=\"ALL\", **_metrics(tst),  Acc=np.nan, Precision=np.nan, Recall=np.nan, Thr=np.nan, Cost=np.nan, Notas=summary[\"winner\"]))\n",
        "# OAS1 / OAS2\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    rows.append(dict(Pipeline=\"P26\", Split=\"VAL\",  Cohort=coh, **_metrics(val[val[\"cohort\"]==coh]),  Acc=np.nan, Precision=np.nan, Recall=np.nan, Thr=np.nan, Cost=np.nan, Notas=summary[\"winner\"]))\n",
        "    rows.append(dict(Pipeline=\"P26\", Split=\"TEST\", Cohort=coh, **_metrics(tst[tst[\"cohort\"]==coh]), Acc=np.nan, Precision=np.nan, Recall=np.nan, Thr=np.nan, Cost=np.nan, Notas=summary[\"winner\"]))\n",
        "\n",
        "mt2 = pd.concat([mt, pd.DataFrame(rows)], ignore_index=True)\n",
        "mt2.to_csv(P25/\"p25_master_table.csv\", index=False)\n",
        "print(\"‚úÖ Actualizado:\", P25/\"p25_master_table.csv\")\n",
        "\n",
        "# Executive table (a√±adimos l√≠neas P26: m√©tricas y coste)\n",
        "def f3(x):\n",
        "    try: return f\"{float(x):.3f}\"\n",
        "    except: return \"‚Äî\"\n",
        "\n",
        "lines = []\n",
        "\n",
        "# M√©tricas P26\n",
        "all_val = _metrics(val); all_tst = _metrics(tst)\n",
        "lines.append({\"Pipeline\":\"P26\",\"Cohorte\":\"ALL\",\"M√©todo\":summary[\"winner\"],\n",
        "              \"AUC\":f3(all_tst[\"AUC\"]),\"PR-AUC\":f3(all_tst[\"PRAUC\"]),\"Brier\":f3(all_tst[\"Brier\"]),\n",
        "              \"Acc\":\"nan\",\"Prec\":\"nan\",\"Rec\":\"nan\",\"Thr\":\"nan\",\"Coste\":\"nan\"})\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    m = _metrics(tst[tst[\"cohort\"]==coh])\n",
        "    lines.append({\"Pipeline\":\"P26\",\"Cohorte\":coh,\"M√©todo\":summary[\"winner\"],\n",
        "                  \"AUC\":f3(m[\"AUC\"]),\"PR-AUC\":f3(m[\"PRAUC\"]),\"Brier\":f3(m[\"Brier\"]),\n",
        "                  \"Acc\":\"nan\",\"Prec\":\"nan\",\"Rec\":\"nan\",\"Thr\":\"nan\",\"Coste\":\"nan\"})\n",
        "\n",
        "# Filas de coste 5:1 P26 @ TEST\n",
        "for _,r in rep.iterrows():\n",
        "    lines.append({\"Pipeline\":\"P26\",\"Cohorte\":r[\"Cohort\"],\"M√©todo\":\"cost-5:1\",\n",
        "                  \"AUC\":\"‚Äî\",\"PR-AUC\":\"‚Äî\",\"Brier\":\"‚Äî\",\n",
        "                  \"Acc\":f3(r[\"Acc\"]),\"Prec\":f3(r[\"Precision\"]),\"Rec\":f3(r[\"Recall\"]),\n",
        "                  \"Thr\":f3(r[\"Thr\"]),\"Coste\":f3(r[\"Cost\"])})\n",
        "\n",
        "# Releer executive existente y a√±adir P26 al final\n",
        "exec_md = P25/\"p25_executive_table.md\"\n",
        "from io import StringIO\n",
        "def mk_table(rows):\n",
        "    cols=[\"Pipeline\",\"Cohorte\",\"M√©todo\",\"AUC\",\"PR-AUC\",\"Brier\",\"Acc\",\"Prec\",\"Rec\",\"Thr\",\"Coste\"]\n",
        "    out=\"| \" + \" | \".join([\"Pipeline\",\"Cohorte\",\"M√©todo\",\"AUC\",\"PR-AUC\",\"Brier\",\"Acc\",\"Prec\",\"Rec\",\"Thr\",\"Coste\"]) + \" |\\n\"\n",
        "    out+=\"|---|---|---:|---:|---:|---:|---:|---:|---:|---:|---:|\\n\"\n",
        "    for r in rows:\n",
        "        out+=\"| {Pipeline} | {Cohorte} | {M√©todo} | {AUC} | {PR-AUC} | {Brier} | {Acc} | {Prec} | {Rec} | {Thr} | {Coste} |\\n\".format(**r)\n",
        "    return out\n",
        "\n",
        "# Cargamos tabla anterior si existe\n",
        "old = \"\"\n",
        "if exec_md.exists():\n",
        "    old = exec_md.read_text(encoding=\"utf-8\")\n",
        "\n",
        "tbl = mk_table(lines)\n",
        "new_md = (old.rstrip() + \"\\n\" if old else \"\") + tbl\n",
        "exec_md.write_text(new_md, encoding=\"utf-8\")\n",
        "print(\"‚úÖ Actualizado:\", exec_md)\n",
        "print(tbl)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7h6J8OZ6qRo",
        "outputId": "7c7eeb25-b415-4673-a97a-410dea99c0b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Actualizado: /content/drive/MyDrive/CognitivaAI/p25_informe_final/p25_master_table.csv\n",
            "‚úÖ Actualizado: /content/drive/MyDrive/CognitivaAI/p25_informe_final/p25_executive_table.md\n",
            "| Pipeline | Cohorte | M√©todo | AUC | PR-AUC | Brier | Acc | Prec | Rec | Thr | Coste |\n",
            "|---|---|---:|---:|---:|---:|---:|---:|---:|---:|---:|\n",
            "| P26 | ALL | LATE | 0.713 | 0.712 | 0.234 | nan | nan | nan | nan | nan |\n",
            "| P26 | OAS1 | LATE | 0.754 | 0.736 | 0.208 | nan | nan | nan | nan | nan |\n",
            "| P26 | OAS2 | LATE | 0.652 | 0.728 | 0.288 | nan | nan | nan | nan | nan |\n",
            "| P26 | OAS1 | cost-5:1 | ‚Äî | ‚Äî | ‚Äî | 0.681 | 0.609 | 0.700 | 0.307 | 39.000 |\n",
            "| P26 | OAS2 | cost-5:1 | ‚Äî | ‚Äî | ‚Äî | 0.652 | 0.667 | 0.667 | 0.195 | 24.000 |\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 13 ‚Äî P26 con umbrales de P24 (OAS1=0.435, OAS2=0.332)\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "P26 = Path(\"/content/drive/MyDrive/CognitivaAI/p26_intermodal\")\n",
        "tst = pd.read_csv(P26/\"p26_test_preds.csv\")\n",
        "\n",
        "def confusion(y_true, y_prob, thr):\n",
        "    y_pred = (y_prob>=thr).astype(int)\n",
        "    TP = int(((y_true==1)&(y_pred==1)).sum())\n",
        "    FP = int(((y_true==0)&(y_pred==1)).sum())\n",
        "    TN = int(((y_true==0)&(y_pred==0)).sum())\n",
        "    FN = int(((y_true==1)&(y_pred==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/len(y_true)\n",
        "    return TP,FP,TN,FN,prec,rec,acc, (5*FN + 1*FP)\n",
        "\n",
        "rows=[]\n",
        "for coh,thr in [(\"OAS1\",0.435),(\"OAS2\",0.332)]:\n",
        "    df = tst[tst[\"cohort\"]==coh]\n",
        "    TP,FP,TN,FN,P,R,A,C = confusion(df[\"y_true\"].values, df[\"y_prob\"].values, thr)\n",
        "    rows.append(dict(Cohort=coh, Thr=thr, TP=TP, FP=FP, TN=TN, FN=FN,\n",
        "                     Precision=P, Recall=R, Acc=A, Cost=C))\n",
        "alt = pd.DataFrame(rows)\n",
        "print(alt)\n",
        "out = P26/\"p26_test_report_cost_5to1_ALTthr_fromP24.csv\"\n",
        "alt.to_csv(out, index=False)\n",
        "print(\"üíæ Guardado:\", out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lruh8mxz6u08",
        "outputId": "6679635e-7c4c-402a-e5f2-9f54b0448bc7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cohort    Thr  TP  FP  TN  FN  Precision    Recall       Acc  Cost\n",
            "0   OAS1  0.435  11   6  21   9   0.647059  0.550000  0.680851    51\n",
            "1   OAS2  0.332   7   4   7   5   0.636364  0.583333  0.608696    29\n",
            "üíæ Guardado: /content/drive/MyDrive/CognitivaAI/p26_intermodal/p26_test_report_cost_5to1_ALTthr_fromP24.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 14 ‚Äî ECE/MCE por cohorte para P26 (10 bins)\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def ece_mce(y_true, y_prob, bins=10):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_prob = np.asarray(y_prob).astype(float)\n",
        "    edges = np.linspace(0,1,bins+1)\n",
        "    ece=0.0; mce=0.0; n=len(y_true)\n",
        "    for i in range(bins):\n",
        "        m = (y_prob>=edges[i]) & (y_prob<edges[i+1] if i<bins-1 else y_prob<=edges[i+1])\n",
        "        if m.sum()==0: continue\n",
        "        conf = y_prob[m].mean()\n",
        "        acc  = y_true[m].mean()\n",
        "        gap = abs(acc-conf)\n",
        "        ece += (m.mean())*gap\n",
        "        mce = max(mce, gap)\n",
        "    return ece, mce\n",
        "\n",
        "P26 = Path(\"/content/drive/MyDrive/CognitivaAI/p26_intermodal\")\n",
        "tst = pd.read_csv(P26/\"p26_test_preds.csv\")\n",
        "\n",
        "rows=[]\n",
        "for coh in [\"ALL\",\"OAS1\",\"OAS2\"]:\n",
        "    df = tst if coh==\"ALL\" else tst[tst[\"cohort\"]==coh]\n",
        "    ece,mce = ece_mce(df[\"y_true\"], df[\"y_prob\"], bins=10)\n",
        "    rows.append(dict(Cohort=coh, ECE10=ece, MCE10=mce))\n",
        "cal = pd.DataFrame(rows)\n",
        "cal.to_csv(P26/\"p26_test_calibration_ece.csv\", index=False)\n",
        "print(cal)\n",
        "print(\"üíæ Guardado:\", P26/\"p26_test_calibration_ece.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW8FCab76z0l",
        "outputId": "7c9a387f-b107-48bb-82ad-e86f7d3b79b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cohort     ECE10     MCE10\n",
            "0    ALL  0.178378  0.406751\n",
            "1   OAS1  0.150002  0.577521\n",
            "2   OAS2  0.312514  0.765920\n",
            "üíæ Guardado: /content/drive/MyDrive/CognitivaAI/p26_intermodal/p26_test_calibration_ece.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P26b ‚Äî Calibraci√≥n por cohorte (Platt) + re-umbrales 5:1\n",
        "import numpy as np, pandas as pd, json\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "P26 = BASE/\"p26_intermodal\"\n",
        "val = pd.read_csv(P26/\"p26_val_preds.csv\")\n",
        "tst = pd.read_csv(P26/\"p26_test_preds.csv\")\n",
        "\n",
        "def platt_fit(y, p):\n",
        "    # calibrador estilo Platt (LR binaria sobre el score)\n",
        "    m = LogisticRegression(solver=\"lbfgs\")\n",
        "    m.fit(p.reshape(-1,1), y.astype(int))\n",
        "    return m\n",
        "\n",
        "def platt_pred(m, p):\n",
        "    return m.predict_proba(p.reshape(-1,1))[:,1]\n",
        "\n",
        "def best_cost_thr(y_true, y_prob, C_FN=5.0, C_FP=1.0, grid=1001):\n",
        "    thrs = np.linspace(0,1,grid); best=None\n",
        "    for t in thrs:\n",
        "        y_pred = (y_prob>=t).astype(int)\n",
        "        TP=((y_true==1)&(y_pred==1)).sum()\n",
        "        FP=((y_true==0)&(y_pred==1)).sum()\n",
        "        FN=((y_true==1)&(y_pred==0)).sum()\n",
        "        cost = C_FN*FN + C_FP*FP\n",
        "        if (best is None) or (cost < best[\"Cost\"]-1e-9):\n",
        "            best=dict(Thr=float(t), Cost=float(cost))\n",
        "    return best\n",
        "\n",
        "out = []\n",
        "cal_preds = []\n",
        "\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    v = val[val[\"cohort\"]==coh]; t = tst[tst[\"cohort\"]==coh]\n",
        "    yv, pv = v[\"y_true\"].to_numpy(), v[\"y_prob\"].to_numpy()\n",
        "    yt, pt = t[\"y_true\"].to_numpy(), t[\"y_prob\"].to_numpy()\n",
        "\n",
        "    # Calibraci√≥n Platt por cohorte\n",
        "    pl = platt_fit(yv, pv)\n",
        "    pv_cal = platt_pred(pl, pv)\n",
        "    pt_cal = platt_pred(pl, pt)\n",
        "\n",
        "    # M√©tricas post-calibraci√≥n\n",
        "    auc_val = roc_auc_score(yv, pv_cal); auc_tst = roc_auc_score(yt, pt_cal)\n",
        "    pr_val = average_precision_score(yv, pv_cal); pr_tst = average_precision_score(yt, pt_cal)\n",
        "    bri_val = brier_score_loss(yv, pv_cal); bri_tst = brier_score_loss(yt, pt_cal)\n",
        "\n",
        "    # Re-umbrales (coste 5:1) aprendidos en VAL-cal y aplicados en TEST-cal\n",
        "    best = best_cost_thr(yv, pv_cal, C_FN=5.0, C_FP=1.0)\n",
        "    thr = best[\"Thr\"]\n",
        "    ypred = (pt_cal>=thr).astype(int)\n",
        "    TP=int(((yt==1)&(ypred==1)).sum())\n",
        "    FP=int(((yt==0)&(ypred==1)).sum())\n",
        "    TN=int(((yt==0)&(ypred==0)).sum())\n",
        "    FN=int(((yt==1)&(ypred==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/len(yt)\n",
        "    cost = 5*FN + 1*FP\n",
        "\n",
        "    out.append(dict(\n",
        "        Cohort=coh, Thr=thr,\n",
        "        VAL_AUC=auc_val, TEST_AUC=auc_tst,\n",
        "        VAL_PRAUC=pr_val, TEST_PRAUC=pr_tst,\n",
        "        VAL_Brier=bri_val, TEST_Brier=bri_tst,\n",
        "        TP=TP, FP=FP, TN=TN, FN=FN,\n",
        "        Precision=prec, Recall=rec, Acc=acc, Cost=cost\n",
        "    ))\n",
        "\n",
        "    cal_preds.append(pd.DataFrame({\n",
        "        \"patient_id\": t[\"patient_id\"].values, \"cohort\": coh,\n",
        "        \"y_true\": yt, \"y_prob_cal\": pt_cal\n",
        "    }))\n",
        "\n",
        "res = pd.DataFrame(out)\n",
        "cal_preds = pd.concat(cal_preds, ignore_index=True)\n",
        "\n",
        "res_path = P26/\"p26b_percohort_platt_cost5to1.csv\"\n",
        "cal_path = P26/\"p26b_test_preds_calibrated.csv\"\n",
        "res.to_csv(res_path, index=False)\n",
        "cal_preds.to_csv(cal_path, index=False)\n",
        "print(\"üíæ Guardado:\", res_path)\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D933X6dm8aQU",
        "outputId": "79da0c23-35af-4dc1-ae9d-e68f6302868f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Guardado: /content/drive/MyDrive/CognitivaAI/p26_intermodal/p26b_percohort_platt_cost5to1.csv\n",
            "  Cohort    Thr   VAL_AUC  TEST_AUC  VAL_PRAUC  TEST_PRAUC  VAL_Brier  \\\n",
            "0   OAS1  0.340  0.909259  0.753704   0.920794    0.735858   0.130844   \n",
            "1   OAS2  0.374  0.942149  0.651515   0.944233    0.727862   0.164272   \n",
            "\n",
            "   TEST_Brier  TP  FP  TN  FN  Precision    Recall       Acc  Cost  \n",
            "0    0.199075  14   9  18   6   0.608696  0.700000  0.680851    39  \n",
            "1    0.240842   8   4   7   4   0.666667  0.666667  0.652174    24  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "P25 = BASE/\"p25_informe_final\"\n",
        "P26 = BASE/\"p26_intermodal\"\n",
        "\n",
        "mt = pd.read_csv(P25/\"p25_master_table.csv\")\n",
        "\n",
        "valb = pd.read_csv(P26/\"p26_val_preds.csv\")  # mismas VAL (pre-cal), ok para AUC\n",
        "tstb = pd.read_csv(P26/\"p26b_test_preds_calibrated.csv\")  # probas calibradas por cohorte\n",
        "tstb = tstb.rename(columns={\"y_prob_cal\":\"y_prob\"})\n",
        "\n",
        "def _metrics(df):\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "    y, p = df[\"y_true\"].astype(int).to_numpy(), df[\"y_prob\"].astype(float).to_numpy()\n",
        "    return dict(AUC=float(roc_auc_score(y,p)),\n",
        "                PRAUC=float(average_precision_score(y,p)),\n",
        "                Brier=float(brier_score_loss(y,p)))\n",
        "\n",
        "rows=[]\n",
        "# ALL\n",
        "rows.append(dict(Pipeline=\"P26b\", Split=\"VAL\",  Cohort=\"ALL\", **_metrics(valb), Acc=np.nan, Precision=np.nan, Recall=np.nan, Thr=np.nan, Cost=np.nan, Notas=\"LATE+Platt\"))\n",
        "rows.append(dict(Pipeline=\"P26b\", Split=\"TEST\", Cohort=\"ALL\", **_metrics(tstb), Acc=np.nan, Precision=np.nan, Recall=np.nan, Thr=np.nan, Cost=np.nan, Notas=\"LATE+Platt\"))\n",
        "# Cohortes\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    rows.append(dict(Pipeline=\"P26b\", Split=\"VAL\",  Cohort=coh, **_metrics(valb[valb[\"cohort\"]==coh]), Acc=np.nan, Precision=np.nan, Recall=np.nan, Thr=np.nan, Cost=np.nan, Notas=\"LATE+Platt\"))\n",
        "    rows.append(dict(Pipeline=\"P26b\", Split=\"TEST\", Cohort=coh, **_metrics(tstb[tstb[\"cohort\"]==coh]), Acc=np.nan, Precision=np.nan, Recall=np.nan, Thr=np.nan, Cost=np.nan, Notas=\"LATE+Platt\"))\n",
        "\n",
        "mt2 = pd.concat([mt, pd.DataFrame(rows)], ignore_index=True)\n",
        "mt2.to_csv(P25/\"p25_master_table.csv\", index=False)\n",
        "print(\"‚úÖ Master table con P26b:\", P25/\"p25_master_table.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzhZgyqI9hch",
        "outputId": "715cf157-c961-4e9e-8f6c-b409ca41ade4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Master table con P26b: /content/drive/MyDrive/CognitivaAI/p25_informe_final/p25_master_table.csv\n"
          ]
        }
      ]
    }
  ]
}