{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a852d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado labels en: data\\oas2_labels.csv | filas=37\n",
      "   patient_id        scan_id  target\n",
      "33  OAS2_0018  OAS2_0018_MR1     1.0\n",
      "34  OAS2_0018  OAS2_0018_MR3     1.0\n",
      "35  OAS2_0018  OAS2_0018_MR4     1.0\n",
      "36  OAS2_0020  OAS2_0020_MR1     1.0\n",
      "37  OAS2_0020  OAS2_0020_MR2     1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\o'\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_8892\\3939589743.py:5: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  EXCEL_PATH = Path(\"data\\oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ruta al Excel original\n",
    "EXCEL_PATH = Path(\"data\\oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx\")\n",
    "\n",
    "# Lee Excel y estandariza columnas clave\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "\n",
    "# Normaliza nombres esperados: ajusta si tu Excel difiere\n",
    "# Columnas típicas de OASIS-2:\n",
    "#   - \"Subject ID\": OAS2_0001\n",
    "#   - \"MRI ID\": OAS2_0001_MR1\n",
    "#   - \"Group\": \"Control\" / \"Dementia\" / (posible \"Converted\")\n",
    "cols = {c.lower().strip(): c for c in df.columns}\n",
    "def pick(name):\n",
    "    return cols.get(name, name)\n",
    "\n",
    "df = df.rename(columns={\n",
    "    pick(\"subject id\"): \"patient_id\",\n",
    "    pick(\"mri id\"): \"scan_id\",\n",
    "    pick(\"group\"): \"group\"\n",
    "})\n",
    "\n",
    "# Filtra filas con scan_id válido (evita NaN/filas agregadas)\n",
    "df = df[df[\"scan_id\"].notna()].copy()\n",
    "df[\"patient_id\"] = df[\"patient_id\"].astype(str).str.strip()\n",
    "df[\"scan_id\"]   = df[\"scan_id\"].astype(str).str.strip()\n",
    "df[\"group\"]     = df[\"group\"].astype(str).str.strip()\n",
    "\n",
    "# --- OPCIÓN A: convertir \"Converted\" a 1 (positivo) ---\n",
    "map_group_to_target = {\"Control\": 0, \"Dementia\": 1, \"Converted\": 1}\n",
    "# --- OPCIÓN B: excluir \"Converted\" ---\n",
    "# df = df[df[\"group\"].isin([\"Control\",\"Dementia\"])]\n",
    "# map_group_to_target = {\"Control\": 0, \"Dementia\": 1}\n",
    "\n",
    "df[\"target\"] = df[\"group\"].map(map_group_to_target)\n",
    "\n",
    "# Si alguna fila queda sin target (p.ej. grupos inesperados), elimínala\n",
    "df = df[df[\"target\"].isin([0,1])].copy()\n",
    "\n",
    "# Selección columnas finales (puedes añadir edad, sexo si están)\n",
    "labels = df[[\"patient_id\", \"scan_id\", \"target\"]].drop_duplicates()\n",
    "\n",
    "OUT = Path(\"data/oas2_labels.csv\")     # <- pon aquí donde quieres dejarlo\n",
    "labels.to_csv(OUT, index=False)\n",
    "print(f\"Guardado labels en: {OUT} | filas={len(labels)}\")\n",
    "print(labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8358019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\o'\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_2060\\1272998778.py:10: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  EXCEL_PATH = Path(\"data\\oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx\")\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_2060\\1272998778.py:13: SyntaxWarning: invalid escape sequence '\\O'\n",
      "  INV_CSV    = Path(\"data\\OAS2_PROCESSED\\oas2_slices_inventory.csv\")  # tiene scan_id, png_path, ...\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_2060\\1272998778.py:14: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  OUT_CSV    = Path(\"data\\oas2_labels.csv\")  # salida final (scan_id, patient_id, target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado labels en: data\\oas2_labels.csv | filas=150\n",
      "   patient_id        scan_id  target\n",
      "0   OAS2_0001  OAS2_0001_MR1       0\n",
      "4   OAS2_0002  OAS2_0002_MR3       1\n",
      "5   OAS2_0004  OAS2_0004_MR1       0\n",
      "7   OAS2_0005  OAS2_0005_MR1       0\n",
      "12  OAS2_0007  OAS2_0007_MR4       1\n",
      "13  OAS2_0008  OAS2_0008_MR1       0\n",
      "16  OAS2_0009  OAS2_0009_MR2       1\n",
      "18  OAS2_0010  OAS2_0010_MR2       1\n",
      "19  OAS2_0012  OAS2_0012_MR1       0\n",
      "22  OAS2_0013  OAS2_0013_MR1       0\n",
      "\n",
      "Cobertura contra inventario:\n",
      "  - scan_id en inventario: 367\n",
      "  - scan_id con label final: 150\n",
      "  - scan_id SIN label (muestras): ['OAS2_0001_MR2', 'OAS2_0002_MR1', 'OAS2_0002_MR2', 'OAS2_0004_MR2', 'OAS2_0005_MR2', 'OAS2_0005_MR3', 'OAS2_0007_MR1', 'OAS2_0007_MR3', 'OAS2_0008_MR2', 'OAS2_0009_MR1']\n",
      "\n",
      "Distribución de target:\n",
      "target\n",
      "1    78\n",
      "0    72\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_2060\\1272998778.py:163: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  labels_1sess = labels.groupby(\"patient_id\", as_index=False, group_keys=False).apply(pick_one_session).copy()\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Rutas de entrada / salida\n",
    "# -----------------------------\n",
    "EXCEL_PATH = Path(\"data\\oasis_longitudinal_demographics-8d83e569fa2e2d30.xlsx\")\n",
    "\n",
    "# inventario que generaste al exportar PNGs:\n",
    "INV_CSV    = Path(\"data\\OAS2_PROCESSED\\oas2_slices_inventory.csv\")  # tiene scan_id, png_path, ...\n",
    "OUT_CSV    = Path(\"data\\oas2_labels.csv\")  # salida final (scan_id, patient_id, target)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) Helpers de normalización de nombres y valores\n",
    "# ---------------------------------------------------\n",
    "def norm_colname(c: str) -> str:\n",
    "    \"\"\"normaliza nombres de columna: minúsculas, sin espacios/guiones/underscore repetidos\"\"\"\n",
    "    c = c.strip().lower()\n",
    "    c = re.sub(r\"[\\s\\-]+\", \"_\", c)\n",
    "    return c\n",
    "\n",
    "def pick_col(cols, *cands):\n",
    "    \"\"\"\n",
    "    Devuelve el primer nombre de columna presente en 'cols'\n",
    "    que matchee alguno de los candidatos (normalizando).\n",
    "    Ej: pick_col(df.columns, \"mri id\",\"mri_id\",\"mr id\")\n",
    "    \"\"\"\n",
    "    nmap = {norm_colname(c): c for c in cols}\n",
    "    for cand in cands:\n",
    "        nc = norm_colname(cand)\n",
    "        if nc in nmap:\n",
    "            return nmap[nc]\n",
    "    # intentar búsqueda 'fuzzy' por tokens\n",
    "    for c in cols:\n",
    "        if all(tok in norm_colname(c) for tok in norm_colname(cands[0]).split(\"_\")):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def map_group_to_target_raw(g):\n",
    "    \"\"\"Mapea valor textual del grupo a target binario, tolerante a variantes.\"\"\"\n",
    "    if g is None or (isinstance(g, float) and np.isnan(g)):\n",
    "        return np.nan\n",
    "    s = str(g).strip().lower()\n",
    "    # variantes típicas en OASIS\n",
    "    if s in {\"nondemented\", \"non-demented\", \"control\", \"cn\"}:\n",
    "        return 0\n",
    "    if s in {\"demented\", \"ad\", \"alzheimers\"}:\n",
    "        return 1\n",
    "    if s in {\"converted\", \"converter\", \"conversion\"}:\n",
    "        # << opción A: contar como 1 (positivo) >>\n",
    "        return 1\n",
    "        # << opción B: si prefieres excluir Converted, devuelve np.nan y luego filtras >>\n",
    "        # return np.nan\n",
    "    # valores inesperados -> nan\n",
    "    return np.nan\n",
    "\n",
    "# --------------------------------------\n",
    "# 3) Cargar Excel y normalizar columnas\n",
    "# --------------------------------------\n",
    "xl = pd.ExcelFile(EXCEL_PATH)\n",
    "# toma la primera hoja que contenga \"oasis\" o \"longitudinal\" o usa la primera\n",
    "sheet = None\n",
    "for s in xl.sheet_names:\n",
    "    ls = s.lower()\n",
    "    if (\"oasis\" in ls) or (\"longitud\" in ls) or (\"demograph\" in ls):\n",
    "        sheet = s\n",
    "        break\n",
    "if sheet is None:\n",
    "    sheet = xl.sheet_names[0]\n",
    "\n",
    "df = pd.read_excel(EXCEL_PATH, sheet_name=sheet)\n",
    "orig_cols = df.columns.tolist()\n",
    "\n",
    "# Renombrar columnas clave de forma robusta\n",
    "col_patient = pick_col(df.columns, \"Subject ID\", \"subject_id\", \"subject\")\n",
    "col_mri     = pick_col(df.columns, \"MRI ID\", \"MR ID\", \"mri_id\", \"mriid\", \"mrid\")\n",
    "col_group   = pick_col(df.columns, \"Group\", \"Diagnosis\", \"diag\", \"group\")\n",
    "\n",
    "if not col_patient or not col_mri or not col_group:\n",
    "    raise RuntimeError(\n",
    "        f\"No pude localizar columnas clave.\\n\"\n",
    "        f\"Encontré: patient={col_patient}, mri={col_mri}, group={col_group}\\n\"\n",
    "        f\"Columnas disponibles: {orig_cols}\"\n",
    "    )\n",
    "\n",
    "df = df.rename(columns={\n",
    "    col_patient: \"patient_id\",\n",
    "    col_mri:     \"scan_id\",\n",
    "    col_group:   \"group\",\n",
    "})\n",
    "\n",
    "# limpiar strings\n",
    "for c in [\"patient_id\", \"scan_id\", \"group\"]:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# eliminar filas sin scan_id válido\n",
    "df = df[df[\"scan_id\"].str.len() > 0].copy()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4) Generar target binario desde \"group\" robusto\n",
    "# ------------------------------------------------\n",
    "df[\"target\"] = df[\"group\"].apply(map_group_to_target_raw)\n",
    "\n",
    "# quitar filas sin target (si hubo grupos raros o si decidiste excluir \"Converted\")\n",
    "df = df[df[\"target\"].isin([0, 1])].copy()\n",
    "\n",
    "# normalizar formato de scan_id (OAS2_####_MR\\d)\n",
    "# si tu Excel lo trae perfecto, esto no toca nada.\n",
    "pat = re.compile(r\"^OAS2_\\d{4}_MR\\d$\", re.IGNORECASE)\n",
    "def fix_scan_id(x):\n",
    "    s = x.strip()\n",
    "    s = s.replace(\" \", \"_\")\n",
    "    s = s.upper()\n",
    "    # a veces ponen \"OAS2-0001 MR1\" → convertir a OAS2_0001_MR1\n",
    "    s = s.replace(\"-\", \"_\")\n",
    "    s = re.sub(r\"MR[_\\s]*\", \"MR\", s)\n",
    "    if \"OAS2_\" in s and \"_MR\" in s:\n",
    "        return s\n",
    "    # si no cuadra, lo dejamos tal cual\n",
    "    return s\n",
    "\n",
    "df[\"scan_id\"] = df[\"scan_id\"].apply(fix_scan_id)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5) Cruzar con inventario real de imágenes por scan_id\n",
    "# ------------------------------------------------------\n",
    "inv = pd.read_csv(INV_CSV)\n",
    "if \"scan_id\" not in inv.columns:\n",
    "    # En tu inventario venía seguro 'scan_id'; por si acaso:\n",
    "    guess = pick_col(inv.columns, \"scan_id\", \"mri id\", \"mri_id\", \"mr id\")\n",
    "    if not guess:\n",
    "        raise RuntimeError(f\"Inventario {INV_CSV} no tiene scan_id localizable. Cols={inv.columns}\")\n",
    "    inv = inv.rename(columns={guess: \"scan_id\"})\n",
    "\n",
    "inv[\"scan_id\"] = inv[\"scan_id\"].astype(str).str.strip().apply(fix_scan_id)\n",
    "\n",
    "# nos quedamos sólo con scan_id que EXISTEN en el inventario\n",
    "labels = df[df[\"scan_id\"].isin(inv[\"scan_id\"].unique())].copy()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6) (Opcional) 1 sesión por paciente\n",
    "#    Reglas:\n",
    "#     - si tiene alguna sesión \"Demented/Converted\" → nos quedamos con la última por MR#\n",
    "#     - si sólo tiene \"Nondemented\" → nos quedamos con la primera por MR#\n",
    "# -----------------------------------------\n",
    "def mr_number(sid: str) -> int:\n",
    "    m = re.search(r\"_MR(\\d+)$\", sid)\n",
    "    return int(m.group(1)) if m else 0\n",
    "\n",
    "labels[\"_mr\"] = labels[\"scan_id\"].apply(mr_number)\n",
    "\n",
    "def pick_one_session(g):\n",
    "    # g: dataframe por patient_id\n",
    "    g = g.sort_values(\"_mr\")\n",
    "    pos = g[g[\"target\"] == 1]\n",
    "    if len(pos):\n",
    "        return pos.iloc[[-1]]   # la última con target=1\n",
    "    return g.iloc[[0]]          # sino, la primera\n",
    "\n",
    "labels_1sess = labels.groupby(\"patient_id\", as_index=False, group_keys=False).apply(pick_one_session).copy()\n",
    "labels_1sess = labels_1sess.drop(columns=[\"_mr\"])\n",
    "\n",
    "# -----------------------------------------\n",
    "# 7) Guardar\n",
    "# -----------------------------------------\n",
    "labels_final = labels_1sess[[\"patient_id\", \"scan_id\", \"target\"]].drop_duplicates()\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "labels_final.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Guardado labels en: {OUT_CSV} | filas={len(labels_final)}\")\n",
    "print(labels_final.head(10))\n",
    "\n",
    "# -------------------------\n",
    "# 8) Diagnósticos útiles\n",
    "# -------------------------\n",
    "print(\"\\nCobertura contra inventario:\")\n",
    "print(\"  - scan_id en inventario:\", inv[\"scan_id\"].nunique())\n",
    "print(\"  - scan_id con label final:\", labels_final[\"scan_id\"].nunique())\n",
    "miss = sorted(set(inv[\"scan_id\"].unique()) - set(labels_final[\"scan_id\"].unique()))\n",
    "print(\"  - scan_id SIN label (muestras):\", miss[:10])\n",
    "\n",
    "print(\"\\nDistribución de target:\")\n",
    "print(labels_final[\"target\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb4b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpetas OASIS-2 MR1..MR4 encontradas: 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando OASIS-2: 100%|██████████| 367/367 [05:22<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✔ Procesados OK: 367 | ✖ Fallidos: 0 | PNG totales: 7340\n",
      "Inventario guardado en: data\\OAS2_PROCESSED\\oas2_slices_inventory.csv\n",
      "Dataset por-slice con target guardado en: data\\OAS2_PROCESSED\\oas2_slices_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scan_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>png_path</th>\n",
       "      <th>source_hdr</th>\n",
       "      <th>has_mask</th>\n",
       "      <th>mask_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>OAS2_0078_MR3</td>\n",
       "      <td>OAS2_0078</td>\n",
       "      <td>data\\OAS2_PROCESSED\\OAS2_0078_MR3_slice11.png</td>\n",
       "      <td>data\\OAS2_RAW\\OAS2_0078_MR3\\RAW\\mpr-1.nifti.hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>otsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>OAS2_0111_MR1</td>\n",
       "      <td>OAS2_0111</td>\n",
       "      <td>data\\OAS2_PROCESSED\\OAS2_0111_MR1_slice13.png</td>\n",
       "      <td>data\\OAS2_RAW\\OAS2_0111_MR1\\RAW\\mpr-1.nifti.hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>otsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>OAS2_0089_MR3</td>\n",
       "      <td>OAS2_0089</td>\n",
       "      <td>data\\OAS2_PROCESSED\\OAS2_0089_MR3_slice04.png</td>\n",
       "      <td>data\\OAS2_RAW\\OAS2_0089_MR3\\RAW\\mpr-1.nifti.hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>otsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>OAS2_0181_MR2</td>\n",
       "      <td>OAS2_0181</td>\n",
       "      <td>data\\OAS2_PROCESSED\\OAS2_0181_MR2_slice18.png</td>\n",
       "      <td>data\\OAS2_RAW\\OAS2_0181_MR2\\RAW\\mpr-1.nifti.hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>otsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>OAS2_0047_MR1</td>\n",
       "      <td>OAS2_0047</td>\n",
       "      <td>data\\OAS2_PROCESSED\\OAS2_0047_MR1_slice04.png</td>\n",
       "      <td>data\\OAS2_RAW\\OAS2_0047_MR1\\RAW\\mpr-1.nifti.hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>otsu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            scan_id patient_id                                       png_path  \\\n",
       "3311  OAS2_0078_MR3  OAS2_0078  data\\OAS2_PROCESSED\\OAS2_0078_MR3_slice11.png   \n",
       "4533  OAS2_0111_MR1  OAS2_0111  data\\OAS2_PROCESSED\\OAS2_0111_MR1_slice13.png   \n",
       "3664  OAS2_0089_MR3  OAS2_0089  data\\OAS2_PROCESSED\\OAS2_0089_MR3_slice04.png   \n",
       "7038  OAS2_0181_MR2  OAS2_0181  data\\OAS2_PROCESSED\\OAS2_0181_MR2_slice18.png   \n",
       "1864  OAS2_0047_MR1  OAS2_0047  data\\OAS2_PROCESSED\\OAS2_0047_MR1_slice04.png   \n",
       "\n",
       "                                           source_hdr  has_mask mask_source  \n",
       "3311  data\\OAS2_RAW\\OAS2_0078_MR3\\RAW\\mpr-1.nifti.hdr         1        otsu  \n",
       "4533  data\\OAS2_RAW\\OAS2_0111_MR1\\RAW\\mpr-1.nifti.hdr         1        otsu  \n",
       "3664  data\\OAS2_RAW\\OAS2_0089_MR3\\RAW\\mpr-1.nifti.hdr         1        otsu  \n",
       "7038  data\\OAS2_RAW\\OAS2_0181_MR2\\RAW\\mpr-1.nifti.hdr         1        otsu  \n",
       "1864  data\\OAS2_RAW\\OAS2_0047_MR1\\RAW\\mpr-1.nifti.hdr         1        otsu  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# P4-aplicado-a-OASIS2 (RAW → Slices PNG)\n",
    "#   - Entrada: /data/OAS2_RAW/OAS2_XXXX_MR{1..4}/RAW/*mpr-*.hdr\n",
    "#   - Salida : OUT_DIR con PNGs y oas2_slices_inventory.csv\n",
    "#   - Normalización: máscara FSL (si hay) + z-score + stretch [0.5..99.5]\n",
    "#   - Cortes: 20 axiales, equiespaciados, evitando extremos (edge_crop=0.08)\n",
    "# ========================================\n",
    "\n",
    "import os, sys, json, math, glob, warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# ---- Parámetros principales ----\n",
    "OAS2_RAW_DIR = Path(\"data/OAS2_RAW\")         # <--- tu raíz OAS2 RAW\n",
    "OUT_DIR      = Path(\"data/OAS2_PROCESSED\")   # <--- salida (cámbialo si quieres)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NUM_SLICES  = 20\n",
    "EDGE_CROP   = 0.08\n",
    "APPLY_CLAHE = False  # en P4 lo dejamos opcional (P2 lo aplicaba siempre)\n",
    "\n",
    "# Si tienes un CSV con etiquetas por scan_id (p.ej., OAS2_0001_MR1),\n",
    "# puedes indicarlo aquí para generar un CSV final unido a labels:\n",
    "LABELS_CSV: Optional[Path] = Path(\"data/oas2_labels.csv\")\n",
    "LABELS_SCAN_COL = \"scan_id\"\n",
    "LABELS_TARGET_COL = \"target\"\n",
    "\n",
    "# Dependencias opcionales (nilearn) para remuestrear máscara exacta por affine\n",
    "USE_NILEARN = True\n",
    "try:\n",
    "    from nilearn.image import resample_to_img\n",
    "except Exception:\n",
    "    USE_NILEARN = False\n",
    "    warnings.warn(\"nilearn no disponible; se hará remuestreo simple por forma (ndi.zoom).\")\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# -----------------------------------------\n",
    "# Utilidades (idénticas o equivalentes a P4)\n",
    "# -----------------------------------------\n",
    "CLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "def log(msg: str): print(msg, flush=True)\n",
    "\n",
    "def best_volume_path_oas2(mr_folder: Path) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    OAS2: usamos RAW/*mpr-*.hdr (no hay PROCESSED típico OAS1).\n",
    "    \"\"\"\n",
    "    raw_hdrs = sorted((mr_folder / \"RAW\").glob(\"*mpr-*.hdr\"))\n",
    "    if raw_hdrs:\n",
    "        return raw_hdrs[0]\n",
    "    return None\n",
    "\n",
    "def squeeze_to_3d(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Salida 3D (H,W,D) desde 2D/3D/4D:\n",
    "    - 2D → añade eje D=1\n",
    "    - 3D → igual\n",
    "    - 4D → si última dim=1 → squeeze; si >1 → primer volumen\n",
    "    \"\"\"\n",
    "    if arr.ndim == 2:  return arr[..., None]\n",
    "    if arr.ndim == 3:  return arr\n",
    "    if arr.ndim == 4:\n",
    "        if arr.shape[-1] == 1:\n",
    "            return np.squeeze(arr, axis=-1)\n",
    "        else:\n",
    "            return arr[..., 0]\n",
    "    raise ValueError(f\"Volumen con ndim no soportado: {arr.ndim}\")\n",
    "\n",
    "def load_volume_3d(vol_hdr_path: Path) -> Tuple[np.ndarray, nib.spatialimages.SpatialImage]:\n",
    "    img = nib.load(str(vol_hdr_path))\n",
    "    vol = img.get_fdata().astype(np.float32)\n",
    "    vol = squeeze_to_3d(vol)\n",
    "    return vol, img\n",
    "\n",
    "def _load_fsl_mask_any(mr_folder: Path) -> Tuple[Optional[np.ndarray], Optional[nib.Nifti1Image], str]:\n",
    "    \"\"\"\n",
    "    OAS2 puede tener FSL_SEG igual que OAS1. Priorizamos:\n",
    "      1) *_fseg*.hdr (segmentación tisular → bin>0)\n",
    "      2) *_mask*.hdr / *_brain*.hdr (binaria)\n",
    "    \"\"\"\n",
    "    seg_dir = mr_folder / \"FSL_SEG\"\n",
    "    if not seg_dir.exists():\n",
    "        return None, None, \"none\"\n",
    "    cands_fseg = sorted(seg_dir.glob(\"*fseg*.hdr\"))\n",
    "    cands_mask = sorted(list(seg_dir.glob(\"*mask*.hdr\")) + list(seg_dir.glob(\"*brain*.hdr\")))\n",
    "    try:\n",
    "        if cands_fseg:\n",
    "            mimg = nib.load(str(cands_fseg[0]))\n",
    "            mdat = mimg.get_fdata()\n",
    "            return (mdat > 0).astype(np.uint8), mimg, \"fseg>0\"\n",
    "        if cands_mask:\n",
    "            mimg = nib.load(str(cands_mask[0]))\n",
    "            mdat = mimg.get_fdata()\n",
    "            return (mdat > 0.5).astype(np.uint8), mimg, \"mask/bin\"\n",
    "    except Exception:\n",
    "        return None, None, \"none\"\n",
    "    return None, None, \"none\"\n",
    "\n",
    "def _resample_mask_to_shape(mask: np.ndarray, target_shape: Tuple[int,int,int]) -> np.ndarray:\n",
    "    if mask.shape == target_shape:\n",
    "        return (mask > 0.5).astype(np.uint8)\n",
    "    zx = target_shape[0] / mask.shape[0]\n",
    "    zy = target_shape[1] / mask.shape[1]\n",
    "    zz = target_shape[2] / mask.shape[2]\n",
    "    resized = ndi.zoom(mask.astype(np.uint8), zoom=(zx, zy, zz), order=0)\n",
    "    return (resized > 0.5).astype(np.uint8)\n",
    "\n",
    "def _resample_mask_to_img(mask_img: nib.Nifti1Image, target_img: nib.spatialimages.SpatialImage) -> np.ndarray:\n",
    "    mask_bin = (mask_img.get_fdata() > 0).astype(np.int16)\n",
    "    mask_bin_img = nib.Nifti1Image(mask_bin, affine=mask_img.affine)\n",
    "    mask_rs = resample_to_img(mask_bin_img, target_img, interpolation='nearest', force_resample=True)\n",
    "    return (squeeze_to_3d(mask_rs.get_fdata()) > 0.5).astype(np.uint8)\n",
    "\n",
    "def make_otsu_mask(vol_u8: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Otsu 2D sobre proyección media axial → expandida a 3D.\n",
    "    \"\"\"\n",
    "    avg2d = vol_u8.mean(axis=2).astype(np.uint8)\n",
    "    thr, _ = cv2.threshold(avg2d, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    mask2d = (avg2d > thr).astype(np.uint8)\n",
    "    return np.repeat(mask2d[:, :, None], vol_u8.shape[2], axis=2)\n",
    "\n",
    "def build_brain_mask(mr_folder: Path,\n",
    "                     vol_hdr_path: Path,\n",
    "                     vol_float: np.ndarray,\n",
    "                     target_img: nib.spatialimages.SpatialImage) -> Tuple[np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    1) Intenta FSL_SEG (remuestreo exacto por affine si hay nilearn; si no, por forma).\n",
    "    2) Valida tamaño (5%..95% voxels). Si falla → Otsu.\n",
    "    \"\"\"\n",
    "    m_arr, m_img, m_src = _load_fsl_mask_any(mr_folder)\n",
    "    if m_arr is not None:\n",
    "        try:\n",
    "            if USE_NILEARN and m_img is not None:\n",
    "                m_rs = _resample_mask_to_img(m_img, target_img)\n",
    "            else:\n",
    "                m_rs = _resample_mask_to_shape(m_arr, vol_float.shape)\n",
    "            frac = float(m_rs.mean())\n",
    "            if 0.05 <= frac <= 0.95:\n",
    "                return (m_rs.astype(np.uint8), m_src)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Fallback: Otsu (necesita u8 preliminar)\n",
    "    vmin, vmax = float(vol_float.min()), float(vol_float.max())\n",
    "    if vmax > vmin:\n",
    "        vol_u8_tmp = ((vol_float - vmin) / (vmax - vmin + 1e-8) * 255).astype(np.uint8)\n",
    "    else:\n",
    "        vol_u8_tmp = np.zeros_like(vol_float, dtype=np.uint8)\n",
    "    return (make_otsu_mask(vol_u8_tmp), \"otsu\")\n",
    "\n",
    "def normalize_volume_zscore_u8(vol_float: np.ndarray, mask: Optional[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Z-score dentro de máscara si existe; luego stretch robusto a [0..255] por percentiles (0.5, 99.5).\n",
    "    \"\"\"\n",
    "    v = vol_float.astype(np.float32)\n",
    "    if mask is not None and mask.shape == v.shape and mask.sum() >= 50:\n",
    "        m = mask.astype(bool)\n",
    "        mu, sd = v[m].mean(), v[m].std() + 1e-8\n",
    "        v = (v - mu) / sd\n",
    "    else:\n",
    "        mu, sd = v.mean(), v.std() + 1e-8\n",
    "        v = (v - mu) / sd\n",
    "\n",
    "    lo, hi = np.percentile(v, [0.5, 99.5])\n",
    "    v = np.clip((v - lo) / (hi - lo + 1e-8), 0, 1)\n",
    "    return (v * 255).astype(np.uint8)\n",
    "\n",
    "def select_slices_indices(depth: int, num_slices: int, edge_crop: float = 0.08) -> List[int]:\n",
    "    z0 = int(depth * edge_crop)\n",
    "    z1 = int(depth * (1 - edge_crop))\n",
    "    z1 = max(z1, z0 + num_slices)\n",
    "    idxs = np.linspace(z0, z1 - 1, num_slices).astype(int)\n",
    "    idxs = np.unique(np.clip(idxs, 0, depth - 1)).tolist()\n",
    "    return idxs\n",
    "\n",
    "def save_slices_png(volume_u8: np.ndarray,\n",
    "                    scan_id: str,\n",
    "                    out_dir: Path,\n",
    "                    num_slices: int,\n",
    "                    edge_crop: float,\n",
    "                    apply_clahe: bool) -> List[str]:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    saved = []\n",
    "    H, W, D = volume_u8.shape\n",
    "    idxs = select_slices_indices(D, num_slices, edge_crop)\n",
    "    for i, z in enumerate(idxs):\n",
    "        sl = volume_u8[:, :, z]\n",
    "        if apply_clahe:\n",
    "            sl = CLAHE.apply(sl)\n",
    "        sl_rgb = cv2.cvtColor(sl, cv2.COLOR_GRAY2RGB)\n",
    "        pth = out_dir / f\"{scan_id}_slice{i:02d}.png\"\n",
    "        cv2.imwrite(str(pth), sl_rgb)\n",
    "        saved.append(str(pth))\n",
    "    return saved\n",
    "\n",
    "# -----------------------------------------\n",
    "# Bucle principal OASIS-2\n",
    "# -----------------------------------------\n",
    "mr_folders = []\n",
    "for k in range(1, 5):\n",
    "    mr_folders += [p for p in OAS2_RAW_DIR.glob(f\"OAS2_*_MR{k}\") if p.is_dir()]\n",
    "mr_folders = sorted(mr_folders)\n",
    "log(f\"Carpetas OASIS-2 MR1..MR4 encontradas: {len(mr_folders)}\")\n",
    "\n",
    "rows = []\n",
    "n_ok, n_fail = 0, 0\n",
    "\n",
    "for folder in tqdm(mr_folders, desc=\"Procesando OASIS-2\"):\n",
    "    scan_id = folder.name  # p.ej. OAS2_0123_MR2\n",
    "    vol_hdr = best_volume_path_oas2(folder)\n",
    "    if vol_hdr is None:\n",
    "        n_fail += 1\n",
    "        print(f\"[WARN] {scan_id}: no se encontró RAW/*mpr-*.hdr\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # 1) Carga volumen y ref espacial\n",
    "        vol_float, target_img = load_volume_3d(vol_hdr)   # (H,W,D) float32\n",
    "\n",
    "        # 2) Máscara (FSL si hay; si no Otsu)\n",
    "        mask, mask_src = build_brain_mask(folder, vol_hdr, vol_float, target_img)\n",
    "\n",
    "        # 3) z-score+stretch → uint8\n",
    "        vol_u8 = normalize_volume_zscore_u8(vol_float, mask)\n",
    "\n",
    "        # 4) Guardar slices\n",
    "        paths = save_slices_png(\n",
    "            vol_u8, scan_id, OUT_DIR,\n",
    "            num_slices=NUM_SLICES, edge_crop=EDGE_CROP, apply_clahe=APPLY_CLAHE\n",
    "        )\n",
    "\n",
    "        # 5) Registrar inventario\n",
    "        for pth in paths:\n",
    "            rows.append({\n",
    "                \"scan_id\": scan_id,\n",
    "                \"patient_id\": scan_id.split(\"_MR\")[0],  # OAS2_0123\n",
    "                \"png_path\": pth,\n",
    "                \"source_hdr\": str(vol_hdr),\n",
    "                \"has_mask\": int(mask is not None),\n",
    "                \"mask_source\": mask_src,\n",
    "            })\n",
    "        n_ok += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        n_fail += 1\n",
    "        print(f\"[WARN] {scan_id}: error procesando {vol_hdr.name} → {e}\")\n",
    "\n",
    "df_inv = pd.DataFrame(rows)\n",
    "inv_csv = OUT_DIR / \"oas2_slices_inventory.csv\"\n",
    "df_inv.to_csv(inv_csv, index=False)\n",
    "\n",
    "log(f\"\\n✔ Procesados OK: {n_ok} | ✖ Fallidos: {n_fail} | PNG totales: {len(rows)}\")\n",
    "log(f\"Inventario guardado en: {inv_csv}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# (Opcional) Unir etiquetas, si LABELS_CSV existe\n",
    "# -----------------------------------------\n",
    "if LABELS_CSV is not None and LABELS_CSV.exists():\n",
    "    lab = pd.read_csv(LABELS_CSV)\n",
    "    assert LABELS_SCAN_COL in lab.columns, f\"Falta columna '{LABELS_SCAN_COL}' en labels\"\n",
    "    assert LABELS_TARGET_COL in lab.columns, f\"Falta columna '{LABELS_TARGET_COL}' en labels\"\n",
    "    out_df = df_inv.merge(lab[[LABELS_SCAN_COL, LABELS_TARGET_COL]],\n",
    "                          left_on=\"scan_id\", right_on=LABELS_SCAN_COL, how=\"left\")\n",
    "    # renombra target\n",
    "    out_df = out_df.rename(columns={LABELS_TARGET_COL: \"target\"})\n",
    "    # (si quieres filtrar solo los que tienen target no nulo)\n",
    "    # out_df = out_df[~out_df[\"target\"].isna()].copy()\n",
    "\n",
    "    # dataset completo (por-slice) con target\n",
    "    ds_csv = OUT_DIR / \"oas2_slices_dataset.csv\"\n",
    "    out_df.to_csv(ds_csv, index=False)\n",
    "    log(f\"Dataset por-slice con target guardado en: {ds_csv}\")\n",
    "\n",
    "# Pequeño resumen a ojo\n",
    "try:\n",
    "    display(df_inv.sample(min(len(df_inv), 5)))\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56072ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/OAS2_PROCESSED/oas2_slices_inventory.csv'),\n",
       " WindowsPath('data/oas2_labels.csv'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold, train_test_split\n",
    "\n",
    "BASE = Path(\"data\")\n",
    "INV  = BASE/\"OAS2_PROCESSED/oas2_slices_inventory.csv\"   # inventario que generaste\n",
    "LAB  = BASE/\"oas2_labels.csv\"                            # ¡el bueno! (150 filas)\n",
    "DS   = BASE/\"OAS2_PROCESSED/oas2_slices_dataset.csv\"     # saldrá aquí tras el merge\n",
    "\n",
    "INV, LAB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb20f2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventario total: 367 scans\n",
      "Labels: 150 scans\n",
      "Dataset etiquetado: 150 scans | filas: 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scan_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>png_path</th>\n",
       "      <th>source_hdr</th>\n",
       "      <th>has_mask</th>\n",
       "      <th>mask_source</th>\n",
       "      <th>patient_id_lbl</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>data\\OAS2_PROCESSED\\OAS2_0001_MR1_slice00.png</td>\n",
       "      <td>data\\OAS2_RAW\\OAS2_0001_MR1\\RAW\\mpr-1.nifti.hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>otsu</td>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>data\\OAS2_PROCESSED\\OAS2_0001_MR1_slice01.png</td>\n",
       "      <td>data\\OAS2_RAW\\OAS2_0001_MR1\\RAW\\mpr-1.nifti.hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>otsu</td>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>data\\OAS2_PROCESSED\\OAS2_0001_MR1_slice02.png</td>\n",
       "      <td>data\\OAS2_RAW\\OAS2_0001_MR1\\RAW\\mpr-1.nifti.hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>otsu</td>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scan_id patient_id                                       png_path  \\\n",
       "0  OAS2_0001_MR1  OAS2_0001  data\\OAS2_PROCESSED\\OAS2_0001_MR1_slice00.png   \n",
       "1  OAS2_0001_MR1  OAS2_0001  data\\OAS2_PROCESSED\\OAS2_0001_MR1_slice01.png   \n",
       "2  OAS2_0001_MR1  OAS2_0001  data\\OAS2_PROCESSED\\OAS2_0001_MR1_slice02.png   \n",
       "\n",
       "                                        source_hdr  has_mask mask_source  \\\n",
       "0  data\\OAS2_RAW\\OAS2_0001_MR1\\RAW\\mpr-1.nifti.hdr         1        otsu   \n",
       "1  data\\OAS2_RAW\\OAS2_0001_MR1\\RAW\\mpr-1.nifti.hdr         1        otsu   \n",
       "2  data\\OAS2_RAW\\OAS2_0001_MR1\\RAW\\mpr-1.nifti.hdr         1        otsu   \n",
       "\n",
       "  patient_id_lbl  target  \n",
       "0      OAS2_0001       0  \n",
       "1      OAS2_0001       0  \n",
       "2      OAS2_0001       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv = pd.read_csv(INV)\n",
    "lab = pd.read_csv(LAB)\n",
    "\n",
    "# Asegura tipos/campos\n",
    "for c in [\"scan_id\",\"patient_id\"]:\n",
    "    inv[c] = inv[c].astype(str).str.strip()\n",
    "    lab[c] = lab[c].astype(str).str.strip()\n",
    "\n",
    "# Merge por scan_id (1 sesión por paciente ya resuelta en LAB)\n",
    "ds = inv.merge(lab[[\"scan_id\",\"patient_id\",\"target\"]], on=\"scan_id\", how=\"inner\", suffixes=(\"\", \"_lbl\"))\n",
    "ds[\"target\"] = ds[\"target\"].astype(int)\n",
    "\n",
    "print(\"Inventario total:\", inv[\"scan_id\"].nunique(), \"scans\")\n",
    "print(\"Labels:\", len(lab), \"scans\")\n",
    "print(\"Dataset etiquetado:\", ds[\"scan_id\"].nunique(), \"scans | filas:\", len(ds))\n",
    "ds.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbfb901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Guardado dataset: data\\OAS2_PROCESSED\\oas2_slices_dataset.csv | filas= 3000\n"
     ]
    }
   ],
   "source": [
    "DS.parent.mkdir(parents=True, exist_ok=True)\n",
    "ds.to_csv(DS, index=False)\n",
    "print(\"✔ Guardado dataset:\", DS, \"| filas=\", len(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe13f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pacientes → train: 90 val: 30 test: 30\n",
      "Slices → train: 1800 val: 600 test: 600\n"
     ]
    }
   ],
   "source": [
    "# Paciente->target (un único valor por paciente)\n",
    "pt = ds.groupby(\"patient_id\", as_index=False).agg({\"target\":\"max\"})\n",
    "y  = pt[\"target\"].values\n",
    "groups = pt[\"patient_id\"].values\n",
    "\n",
    "# Split estratificado por paciente\n",
    "pt_train, pt_temp = train_test_split(pt, test_size=0.4, stratify=y, random_state=42)\n",
    "y_temp = pt_temp[\"target\"].values\n",
    "pt_val, pt_test = train_test_split(pt_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "def subset_by_patients(df, patient_ids):\n",
    "    return df[df[\"patient_id\"].isin(set(patient_ids))].copy()\n",
    "\n",
    "train_df = subset_by_patients(ds, pt_train[\"patient_id\"])\n",
    "val_df   = subset_by_patients(ds, pt_val[\"patient_id\"])\n",
    "test_df  = subset_by_patients(ds, pt_test[\"patient_id\"])\n",
    "\n",
    "print(\"Pacientes →\",\n",
    "      \"train:\", pt_train.shape[0],\n",
    "      \"val:\",   pt_val.shape[0],\n",
    "      \"test:\",  pt_test.shape[0])\n",
    "\n",
    "print(\"Slices →\",\n",
    "      \"train:\", len(train_df),\n",
    "      \"val:\",   len(val_df),\n",
    "      \"test:\",  len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8428afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 oas2_train_colab_mapped.csv | filas= 1800\n",
      "💾 oas2_val_colab_mapped.csv | filas= 600\n",
      "💾 oas2_test_colab_mapped.csv | filas= 600\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = Path(\"data/OAS2_PROCESSED\")  # local; en Colab será /content/datasets/OAS2_PROCESSED\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_map(df, name):\n",
    "    cols = [\"png_path\",\"target\",\"patient_id\",\"scan_id\",\"source_hdr\",\"has_mask\",\"mask_source\"]\n",
    "    m = df[cols].copy()\n",
    "    m.to_csv(OUT_DIR/name, index=False)\n",
    "    print(\"💾\", name, \"| filas=\", len(m))\n",
    "\n",
    "save_map(train_df, \"oas2_train_colab_mapped.csv\")\n",
    "save_map(val_df,   \"oas2_val_colab_mapped.csv\")\n",
    "save_map(test_df,  \"oas2_test_colab_mapped.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
