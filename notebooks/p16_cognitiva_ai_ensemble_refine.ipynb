{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11rmRtmtu_QL",
        "outputId": "ef2229b6-2b59-487f-ab30-f40da91a30f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "VAL: (69, 58) | cols: 58\n",
            "TEST: (70, 58) | cols: 58\n",
            "Total feats detectadas: 56\n",
            "\n",
            "NaN ratio (VAL) top 10:\n",
            " patient_preds_ensemble_trimmed20    0.855072\n",
            "patient_preds_ensemble_top7         0.855072\n",
            "patient_preds_ensemble_p2           0.855072\n",
            "patient_preds_ensemble_mean         0.855072\n",
            "patient_preds_trimmed20             0.855072\n",
            "patient_preds_top7                  0.855072\n",
            "patient_preds_p2                    0.855072\n",
            "patient_preds_mean                  0.855072\n",
            "slices_preds_mean                   0.855072\n",
            "slices_preds_p2                     0.855072\n",
            "dtype: float64\n",
            "\n",
            "âœ… Mantengo 36 columnas; âŒ descarto por NaN>0.4: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "â­ Blending Ã³ptimo en VAL: alpha=0.02 (LR weight) | AUC=0.9533\n",
            "Umbrales (VAL) ~F1max â†’ LR:0.45 | HGB:0.45 | Blend:0.45\n",
            "\n",
            "ðŸ’¾ Guardados:\n",
            " - /content/drive/MyDrive/CognitivaAI/p16_ensemble_refine/p16_val_patient_preds_ensemble.csv\n",
            " - /content/drive/MyDrive/CognitivaAI/p16_ensemble_refine/p16_test_patient_preds_ensemble.csv\n",
            " - /content/drive/MyDrive/CognitivaAI/p16_ensemble_refine/p16_ensemble_summary.json\n",
            "\n",
            "[Resumen]\n",
            "VAL-LR: OAS1:{'AUC': np.float64(0.9444), 'PRAUC': np.float64(0.9525), 'Acc': 0.8936, 'P': 0.8571, 'R': 0.9, 'thr': 0.45, 'n': 47} | OAS2:{'AUC': np.float64(0.5455), 'PRAUC': np.float64(0.5238), 'Acc': 0.5, 'P': 0.5, 'R': 1.0, 'thr': 0.45, 'n': 22} | ALL:{'AUC': np.float64(0.8812), 'PRAUC': np.float64(0.8564), 'Acc': 0.7681, 'P': 0.6744, 'R': 0.9355, 'thr': 0.45, 'n': 69}\n",
            "VAL-HGB: OAS1:{'AUC': np.float64(1.0), 'PRAUC': np.float64(1.0), 'Acc': 1.0, 'P': 1.0, 'R': 1.0, 'thr': 0.45, 'n': 47} | OAS2:{'AUC': np.float64(0.5), 'PRAUC': np.float64(0.5), 'Acc': 0.5, 'P': 0.5, 'R': 1.0, 'thr': 0.45, 'n': 22} | ALL:{'AUC': np.float64(0.9486), 'PRAUC': np.float64(0.9071), 'Acc': 0.8406, 'P': 0.7381, 'R': 1.0, 'thr': 0.45, 'n': 69}\n",
            "VAL-BLEND: OAS1:{'AUC': np.float64(1.0), 'PRAUC': np.float64(1.0), 'Acc': 1.0, 'P': 1.0, 'R': 1.0, 'thr': 0.45, 'n': 47} | OAS2:{'AUC': np.float64(0.5455), 'PRAUC': np.float64(0.5238), 'Acc': 0.5, 'P': 0.5, 'R': 1.0, 'thr': 0.45, 'n': 22} | ALL:{'AUC': np.float64(0.9533), 'PRAUC': np.float64(0.9135), 'Acc': 0.8406, 'P': 0.7381, 'R': 1.0, 'thr': 0.45, 'n': 69}\n",
            "TEST-LR: OAS1:{'AUC': np.float64(0.7667), 'PRAUC': np.float64(0.7471), 'Acc': 0.6596, 'P': 0.6111, 'R': 0.55, 'thr': 0.45, 'n': 47} | OAS2:{'AUC': np.float64(0.5038), 'PRAUC': np.float64(0.5236), 'Acc': 0.5217, 'P': 0.5217, 'R': 1.0, 'thr': 0.45, 'n': 23} | ALL:{'AUC': np.float64(0.683), 'PRAUC': np.float64(0.6634), 'Acc': 0.6143, 'P': 0.561, 'R': 0.7188, 'thr': 0.45, 'n': 70}\n",
            "TEST-HGB: OAS1:{'AUC': np.float64(0.7056), 'PRAUC': np.float64(0.649), 'Acc': 0.6809, 'P': 0.6316, 'R': 0.6, 'thr': 0.45, 'n': 47} | OAS2:{'AUC': np.float64(0.5), 'PRAUC': np.float64(0.5217), 'Acc': 0.5217, 'P': 0.5217, 'R': 1.0, 'thr': 0.45, 'n': 23} | ALL:{'AUC': np.float64(0.6842), 'PRAUC': np.float64(0.6237), 'Acc': 0.6286, 'P': 0.5714, 'R': 0.75, 'thr': 0.45, 'n': 70}\n",
            "TEST-BLEND: OAS1:{'AUC': np.float64(0.713), 'PRAUC': np.float64(0.653), 'Acc': 0.7021, 'P': 0.65, 'R': 0.65, 'thr': 0.45, 'n': 47} | OAS2:{'AUC': np.float64(0.5038), 'PRAUC': np.float64(0.5236), 'Acc': 0.5217, 'P': 0.5217, 'R': 1.0, 'thr': 0.45, 'n': 23} | ALL:{'AUC': np.float64(0.6879), 'PRAUC': np.float64(0.6267), 'Acc': 0.6429, 'P': 0.5814, 'R': 0.7812, 'thr': 0.45, 'n': 70}\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# p16_ensemble_refine.ipynb\n",
        "# Refinamiento de ensembles sobre features de p11/p14\n",
        "# ===========================\n",
        "import os, json, math, itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.impute import SimpleImputer, MissingIndicator\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# ---------------------------\n",
        "# A) Rutas y carga de datos\n",
        "# ---------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "DRIVE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "P11 = DRIVE / \"p11_alt_backbones\"\n",
        "P14 = DRIVE / \"p14_oasis2_images\"   # (sÃ³lo referencia; los features consolidados estÃ¡n en P11)\n",
        "OUT = DRIVE / \"p16_ensemble_refine\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "VAL_PATH  = P11 / \"val_patient_features_backbones.csv\"\n",
        "TEST_PATH = P11 / \"test_patient_features_backbones.csv\"\n",
        "\n",
        "val = pd.read_csv(VAL_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "\n",
        "print(\"VAL:\", val.shape, \"| cols:\", len(val.columns))\n",
        "print(\"TEST:\", test.shape, \"| cols:\", len(test.columns))\n",
        "\n",
        "# ---------------------------\n",
        "# B) Cohortes y columnas Ãºtiles\n",
        "# ---------------------------\n",
        "def tag_cohort(pid: str) -> str:\n",
        "    return \"OAS2\" if str(pid).startswith(\"OAS2_\") else \"OAS1\"\n",
        "\n",
        "for df in (val, test):\n",
        "    df[\"cohort\"] = df[\"patient_id\"].astype(str).map(tag_cohort)\n",
        "\n",
        "# Identificar columnas de features candidatas: agregados por slice\n",
        "def is_feat(c):\n",
        "    if c in [\"patient_id\", \"y_true\", \"cohort\"]:\n",
        "        return False\n",
        "    # tÃ­picamente vienen *_mean, *_trimmed20, *_top7, *_p2\n",
        "    tail_ok = any(c.endswith(suf) for suf in [\"_mean\",\"_trimmed20\",\"_top7\",\"_p2\"])\n",
        "    return tail_ok\n",
        "\n",
        "feat_cols_all = [c for c in val.columns if is_feat(c)]\n",
        "print(\"Total feats detectadas:\", len(feat_cols_all))\n",
        "\n",
        "# Opcional: filtrar por ratio de NaN aceptable mirando VAL (para no sobre-filtrar TEST)\n",
        "nan_ratio = val[feat_cols_all].isna().mean().sort_values(ascending=False)\n",
        "print(\"\\nNaN ratio (VAL) top 10:\\n\", nan_ratio.head(10))\n",
        "keep_cols = nan_ratio[nan_ratio <= 0.4].index.tolist()\n",
        "drop_cols = [c for c in feat_cols_all if c not in keep_cols]\n",
        "print(f\"\\nâœ… Mantengo {len(keep_cols)} columnas; âŒ descarto por NaN>0.4: {len(drop_cols)}\")\n",
        "\n",
        "X_val = val[keep_cols].copy()\n",
        "y_val = val[\"y_true\"].astype(int).values\n",
        "X_test = test[keep_cols].copy()\n",
        "y_test = test[\"y_true\"].astype(int).values\n",
        "\n",
        "# ---------------------------\n",
        "# C) MÃ©tricas\n",
        "# ---------------------------\n",
        "def metrics_from_scores(y_true, y_score, thr=0.5):\n",
        "    # AUC / PRAUC robustos si hay ambas clases\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, y_score)\n",
        "    except Exception:\n",
        "        auc = np.nan\n",
        "    try:\n",
        "        prauc = average_precision_score(y_true, y_score)\n",
        "    except Exception:\n",
        "        prauc = np.nan\n",
        "    y_pred = (y_score >= thr).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    P = precision_score(y_true, y_pred, zero_division=0)\n",
        "    R = recall_score(y_true, y_pred, zero_division=0)\n",
        "    return dict(AUC=auc, PRAUC=prauc, Acc=acc, P=P, R=R, thr=thr, n=len(y_true))\n",
        "\n",
        "def eval_by_cohort(df_pred, score_col=\"y_score\", thr=0.5):\n",
        "    out = {}\n",
        "    for k, g in df_pred.groupby(\"cohort\"):\n",
        "        out[k] = metrics_from_scores(g[\"y_true\"].values, g[score_col].values, thr=thr)\n",
        "    out[\"ALL\"] = metrics_from_scores(df_pred[\"y_true\"].values, df_pred[score_col].values, thr=thr)\n",
        "    return out\n",
        "\n",
        "# ---------------------------\n",
        "# D) Meta-modelo 1: LR (imputaciÃ³n+scaler)\n",
        "# ---------------------------\n",
        "num_cols = keep_cols\n",
        "\n",
        "pre_lr = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True), num_cols),\n",
        "        (\"scaler\", StandardScaler(with_mean=False), slice(0, 0))  # placeholder; escalamos dentro del pipeline\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "# Nota: MissingIndicator ya lo aÃ±ade SimpleImputer con add_indicator=True\n",
        "pipe_lr = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
        "    (\"scaler\", StandardScaler(with_mean=False)),\n",
        "    (\"clf\", LogisticRegression(solver=\"lbfgs\", max_iter=2000, class_weight=None))\n",
        "])\n",
        "\n",
        "pipe_lr.fit(X_val, y_val)\n",
        "p_val_lr  = pipe_lr.predict_proba(X_val)[:,1]\n",
        "p_test_lr = pipe_lr.predict_proba(X_test)[:,1]\n",
        "\n",
        "# ---------------------------\n",
        "# E) Meta-modelo 2: HGB (acepta NaNs) + calibraciÃ³n en VAL\n",
        "# ---------------------------\n",
        "hgb = HistGradientBoostingClassifier(\n",
        "    loss=\"log_loss\",\n",
        "    max_depth=None,\n",
        "    learning_rate=0.06,\n",
        "    max_iter=600,\n",
        "    min_samples_leaf=10,\n",
        "    l2_regularization=1e-3,\n",
        "    random_state=42\n",
        ")\n",
        "# Calibramos con CV interno en VAL (sigmoid tipo Platt)\n",
        "cal_hgb = CalibratedClassifierCV(hgb, method=\"sigmoid\", cv=5)\n",
        "cal_hgb.fit(X_val, y_val)\n",
        "\n",
        "p_val_hgb  = cal_hgb.predict_proba(X_val)[:,1]\n",
        "p_test_hgb = cal_hgb.predict_proba(X_test)[:,1]\n",
        "\n",
        "# ---------------------------\n",
        "# F) Blending simple LR-HGB: buscar Î± en VAL que maximiza AUC\n",
        "# ---------------------------\n",
        "alphas = np.linspace(0, 1, 51)  # 0.00..1.00\n",
        "best = (-np.inf, 0.5)  # (AUC, alpha)\n",
        "for a in alphas:\n",
        "    p_blend = a*p_val_lr + (1-a)*p_val_hgb\n",
        "    try:\n",
        "        auc = roc_auc_score(y_val, p_blend)\n",
        "    except Exception:\n",
        "        auc = -np.inf\n",
        "    if auc > best[0]:\n",
        "        best = (auc, a)\n",
        "\n",
        "alpha_opt = float(best[1])\n",
        "print(f\"\\nâ­ Blending Ã³ptimo en VAL: alpha={alpha_opt:.2f} (LR weight) | AUC={best[0]:.4f}\")\n",
        "\n",
        "p_val_blend  = alpha_opt*p_val_lr + (1-alpha_opt)*p_val_hgb\n",
        "p_test_blend = alpha_opt*p_test_lr + (1-alpha_opt)*p_test_hgb\n",
        "\n",
        "# ---------------------------\n",
        "# G) BÃºsqueda simple de umbral en VAL para maximizar F1 o balance P/R\n",
        "# ---------------------------\n",
        "def find_best_thr(y_true, y_score, grid=np.linspace(0.05,0.95,19)):\n",
        "    best = (0, 0.5)\n",
        "    for t in grid:\n",
        "        y_pred = (y_score>=t).astype(int)\n",
        "        P = precision_score(y_true, y_pred, zero_division=0)\n",
        "        R = recall_score(y_true, y_pred, zero_division=0)\n",
        "        if (P+R)>0:\n",
        "            f1 = 2*P*R/(P+R)\n",
        "        else:\n",
        "            f1 = 0\n",
        "        if f1 > best[0]:\n",
        "            best = (f1, float(t))\n",
        "    return {\"thr\": best[1], \"F1\": best[0]}\n",
        "\n",
        "thr_lr    = find_best_thr(y_val, p_val_lr )[\"thr\"]\n",
        "thr_hgb   = find_best_thr(y_val, p_val_hgb)[\"thr\"]\n",
        "thr_blend = find_best_thr(y_val, p_val_blend)[\"thr\"]\n",
        "print(f\"Umbrales (VAL) ~F1max â†’ LR:{thr_lr:.2f} | HGB:{thr_hgb:.2f} | Blend:{thr_blend:.2f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# H) EvaluaciÃ³n y guardado\n",
        "# ---------------------------\n",
        "pred_val = pd.DataFrame({\n",
        "    \"patient_id\": val[\"patient_id\"],\n",
        "    \"cohort\": val[\"cohort\"],\n",
        "    \"y_true\": y_val,\n",
        "    \"p_lr\": p_val_lr,\n",
        "    \"p_hgb\": p_val_hgb,\n",
        "    \"p_blend\": p_val_blend\n",
        "})\n",
        "pred_test = pd.DataFrame({\n",
        "    \"patient_id\": test[\"patient_id\"],\n",
        "    \"cohort\": test[\"cohort\"],\n",
        "    \"y_true\": y_test,\n",
        "    \"p_lr\": p_test_lr,\n",
        "    \"p_hgb\": p_test_hgb,\n",
        "    \"p_blend\": p_test_blend\n",
        "})\n",
        "\n",
        "# MÃ©tricas por modelo/conjunto\n",
        "summary = {\n",
        "    \"alpha_opt\": alpha_opt,\n",
        "    \"VAL\": {\n",
        "        \"LR\":    eval_by_cohort(pred_val.rename(columns={\"p_lr\":\"y_score\"}),  \"y_score\", thr=thr_lr),\n",
        "        \"HGB\":   eval_by_cohort(pred_val.rename(columns={\"p_hgb\":\"y_score\"}), \"y_score\", thr=thr_hgb),\n",
        "        \"BLEND\": eval_by_cohort(pred_val.rename(columns={\"p_blend\":\"y_score\"}),\"y_score\", thr=thr_blend),\n",
        "    },\n",
        "    \"TEST\": {\n",
        "        \"LR\":    eval_by_cohort(pred_test.rename(columns={\"p_lr\":\"y_score\"}),  \"y_score\", thr=thr_lr),\n",
        "        \"HGB\":   eval_by_cohort(pred_test.rename(columns={\"p_hgb\":\"y_score\"}), \"y_score\", thr=thr_hgb),\n",
        "        \"BLEND\": eval_by_cohort(pred_test.rename(columns={\"p_blend\":\"y_score\"}),\"y_score\", thr=thr_blend),\n",
        "    },\n",
        "    \"thresholds\": {\"VAL_LR\":thr_lr, \"VAL_HGB\":thr_hgb, \"VAL_BLEND\":thr_blend}\n",
        "}\n",
        "\n",
        "# Guardados\n",
        "pred_val.to_csv(OUT / \"p16_val_patient_preds_ensemble.csv\", index=False)\n",
        "pred_test.to_csv(OUT / \"p16_test_patient_preds_ensemble.csv\", index=False)\n",
        "with open(OUT / \"p16_ensemble_summary.json\", \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\nðŸ’¾ Guardados:\")\n",
        "print(\" -\", OUT / \"p16_val_patient_preds_ensemble.csv\")\n",
        "print(\" -\", OUT / \"p16_test_patient_preds_ensemble.csv\")\n",
        "print(\" -\", OUT / \"p16_ensemble_summary.json\")\n",
        "\n",
        "# Vista rÃ¡pida de mÃ©tricas clave\n",
        "def pretty_block(name, d):\n",
        "    def fmt(m):\n",
        "        return {k:(round(v,4) if isinstance(v,(int,float,np.floating)) and not math.isnan(v) else v) for k,v in m.items()}\n",
        "    print(f\"\\n[{name}]\")\n",
        "    for split in [\"VAL\",\"TEST\"]:\n",
        "        for model in [\"LR\",\"HGB\",\"BLEND\"]:\n",
        "            coh = d[split][model]\n",
        "            txt = \" | \".join(\n",
        "                f\"{ck}:{fmt(coh[ck])}\" for ck in [\"OAS1\",\"OAS2\",\"ALL\"] if ck in coh\n",
        "            )\n",
        "            print(f\"{split}-{model}: {txt}\")\n",
        "\n",
        "pretty_block(\"Resumen\", summary)\n"
      ]
    }
  ]
}