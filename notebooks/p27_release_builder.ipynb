{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BRoH6xee8Hs",
        "outputId": "6bd88fd3-fbd3-4c1a-b801-895b084be0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "BASE: /content/drive/MyDrive/CognitivaAI\n"
          ]
        }
      ],
      "source": [
        "# P27 — release builder (v1.1)\n",
        "from pathlib import Path\n",
        "import json, os, shutil, hashlib, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "REL  = BASE/\"p26_release\"\n",
        "\n",
        "random_state = 42\n",
        "np.random.seed(random_state)\n",
        "random.seed(random_state)\n",
        "\n",
        "def sha256_of_file(p: Path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"): h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def metrics(y, p):\n",
        "    return dict(\n",
        "        AUC=float(roc_auc_score(y,p)),\n",
        "        PRAUC=float(average_precision_score(y,p)),\n",
        "        Brier=float(brier_score_loss(y,p)),\n",
        "    )\n",
        "\n",
        "print(\"BASE:\", BASE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estructura release\n",
        "dirs = {\n",
        "  \"MODELS\": REL/\"MODELS\",\n",
        "  \"CONFIG\": REL/\"CONFIG\",\n",
        "  \"COLSIG\": REL/\"CONFIG/column_signatures\",\n",
        "  \"DOCS\":   REL/\"DOCS\",\n",
        "  \"QA\":     REL/\"QA\",\n",
        "  \"META\":   REL/\"META\",\n",
        "  \"TMP\":    REL/\"_tmp\"\n",
        "}\n",
        "for d in dirs.values(): d.mkdir(parents=True, exist_ok=True)\n",
        "print(\"OK → estructura creada en\", REL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mcSXgXMfX4Z",
        "outputId": "3254b5ca-bf57-4c88-a3d8-e5f1596f38e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK → estructura creada en /content/drive/MyDrive/CognitivaAI/p26_release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobaciones mínimas\n",
        "P24 = BASE/\"p24_meta_simple\"\n",
        "P26 = BASE/\"p26_intermodal\"\n",
        "CLN = BASE/\"clinical\"\n",
        "\n",
        "assert (P24/\"p24_model.pkl\").exists() and (P24/\"p24_platt.pkl\").exists(), \"Faltan p24_model.pkl o p24_platt.pkl\"\n",
        "assert (P24/\"p24_val_preds.csv\").exists() and (P24/\"p24_test_preds.csv\").exists(), \"Faltan p24_val/test_preds.csv\"\n",
        "assert (P24/\"p24_coefficients.csv\").exists(), \"Falta p24_coefficients.csv (para firma de columnas imagen)\"\n",
        "assert (P26/\"p26_clinical_consolidado.csv\").exists(), \"Falta p26_clinical_consolidado.csv\"\n",
        "assert (CLN/\"p3_clinical_probs.csv\").exists(), \"Falta p3_clinical_probs.csv (probas clínicas por patient_id)\"\n",
        "\n",
        "# Copiar P24 modelos al release\n",
        "shutil.copy2(P24/\"p24_model.pkl\", dirs[\"MODELS\"]/\"p24_model.pkl\")\n",
        "shutil.copy2(P24/\"p24_platt.pkl\", dirs[\"MODELS\"]/\"p24_platt.pkl\")\n",
        "print(\"OK → copiados modelos de P24\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4utcdQzXff71",
        "outputId": "1d85c089-dd03-416d-c6a3-77b88d4cf3c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK → copiados modelos de P24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos consolidado clínico y probas clínicas (VAL/TEST)\n",
        "df_clin = pd.read_csv(P26/\"p26_clinical_consolidado.csv\")  # 9 features + patient_id\n",
        "clin_probs = pd.read_csv(CLN/\"p3_clinical_probs.csv\")      # patient_id, split, y_prob_clin\n",
        "\n",
        "# Labels (desde P24 preds con y_true)\n",
        "p24_val = pd.read_csv(P24/\"p24_val_preds.csv\")  # patient_id, cohort, y_true, y_prob\n",
        "p24_tst = pd.read_csv(P24/\"p24_test_preds.csv\")\n",
        "\n",
        "# Unimos para armar (VAL/TEST) con y_true\n",
        "val_ids = p24_val[[\"patient_id\",\"cohort\",\"y_true\"]].copy()\n",
        "tst_ids = p24_tst[[\"patient_id\",\"cohort\",\"y_true\"]].copy()\n",
        "\n",
        "# Unir clínico con ids\n",
        "val_clin = val_ids.merge(df_clin, on=\"patient_id\", how=\"left\")\n",
        "tst_clin = tst_ids.merge(df_clin, on=\"patient_id\", how=\"left\")\n",
        "\n",
        "# Esquema clínico esperado (9 columnas brutas)\n",
        "clin_cols = [\"Age\",\"Sex\",\"Education\",\"SES\",\"MMSE\",\"eTIV\",\"nWBV\",\"ASF\",\"Delay\"]\n",
        "missing_cols = [c for c in clin_cols if c not in val_clin.columns]\n",
        "assert not missing_cols, f\"Faltan columnas clínicas: {missing_cols}\"\n",
        "\n",
        "# Armar X,y (VAL) para entrenar modelo clínico\n",
        "Xc_val = val_clin[clin_cols].copy()\n",
        "yc_val = val_clin[\"y_true\"].astype(int).values\n",
        "\n",
        "# Pipeline clínico (imputer numérico + OHE Sex + scaler + LR)\n",
        "num_cols = [c for c in clin_cols if c!=\"Sex\"]\n",
        "pre = [\n",
        "    (\"impute_num\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scale\", StandardScaler(with_mean=True, with_std=True)),\n",
        "]\n",
        "# OHE Sex -> convertimos a binaria 'Sex_M' aproximando: M/F (si viniera 0/1 también funciona)\n",
        "def sex_to_str(s):\n",
        "    if pd.isna(s): return np.nan\n",
        "    s = str(s).strip().upper()\n",
        "    if s in [\"M\",\"MALE\",\"H\"]: return \"M\"\n",
        "    if s in [\"F\",\"FEMALE\",\"Mujer\".upper()]: return \"F\"\n",
        "    return s\n",
        "\n",
        "for split_df in [Xc_val]:\n",
        "    split_df[\"Sex\"] = split_df[\"Sex\"].apply(sex_to_str)\n",
        "\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "# Construimos DataFrame num y cat por separado\n",
        "X_num = Xc_val[num_cols]\n",
        "X_sex = pd.DataFrame({\"Sex\": Xc_val[\"Sex\"]})\n",
        "\n",
        "num_pipe = Pipeline(pre)\n",
        "X_num_tr = num_pipe.fit_transform(X_num)\n",
        "sex_mat  = ohe.fit_transform(X_sex)\n",
        "\n",
        "# Unimos y entrenamos LR\n",
        "Xc_val_mat = np.hstack([X_num_tr, sex_mat])\n",
        "clin_lr = LogisticRegression(max_iter=1000, class_weight=None, solver=\"lbfgs\", random_state=random_state)\n",
        "clin_lr.fit(Xc_val_mat, yc_val)\n",
        "\n",
        "# Guardamos componentes del modelo clínico:\n",
        "import pickle\n",
        "with open(dirs[\"MODELS\"]/\"p26_clin_num_pipe.pkl\",\"wb\") as f: pickle.dump(num_pipe, f)\n",
        "with open(dirs[\"MODELS\"]/\"p26_clin_ohe.pkl\",\"wb\") as f: pickle.dump(ohe, f)\n",
        "with open(dirs[\"MODELS\"]/\"p26_clin_model.pkl\",\"wb\") as f: pickle.dump(clin_lr, f)\n",
        "\n",
        "print(\"✅ Modelo clínico entrenado y guardado (VAL).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfXfv5kifiFT",
        "outputId": "7e450221-6697-4ed5-89b9-4fdfa3514807"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo clínico entrenado y guardado (VAL).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# p_img: usar probas calibradas de P24 (y_prob)\n",
        "val_img = p24_val[[\"patient_id\",\"cohort\",\"y_true\",\"y_prob\"]].rename(columns={\"y_prob\":\"p_img\"})\n",
        "tst_img = p24_tst[[\"patient_id\",\"cohort\",\"y_true\",\"y_prob\"]].rename(columns={\"y_prob\":\"p_img\"})\n",
        "\n",
        "# p_clin: de p3_clinical_probs.csv\n",
        "val_clp = clin_probs[clin_probs[\"split\"]==\"VAL\"][[\"patient_id\",\"y_prob_clin\"]].rename(columns={\"y_prob_clin\":\"p_clin\"})\n",
        "tst_clp = clin_probs[clin_probs[\"split\"]==\"TEST\"][[\"patient_id\",\"y_prob_clin\"]].rename(columns={\"y_prob_clin\":\"p_clin\"})\n",
        "\n",
        "VAL = val_img.merge(val_clp, on=\"patient_id\", how=\"inner\")\n",
        "TST = tst_img.merge(tst_clp, on=\"patient_id\", how=\"inner\")\n",
        "\n",
        "print(\"VAL:\", VAL.shape, \"| TEST:\", TST.shape)\n",
        "assert VAL[\"patient_id\"].is_unique and TST[\"patient_id\"].is_unique\n",
        "print(VAL.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dJmR--ofo3Q",
        "outputId": "6321d9d1-760d-4b90-b965-5a7c92532795"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL: (69, 5) | TEST: (70, 5)\n",
            "  patient_id cohort  y_true     p_img    p_clin\n",
            "0  OAS1_0003   OAS1       1  0.672718  0.422624\n",
            "1  OAS1_0010   OAS1       0  0.433014  0.431642\n",
            "2  OAS1_0016   OAS1       1  0.621040  0.451515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta-LR sobre [p_img, p_clin]\n",
        "X_val = VAL[[\"p_img\",\"p_clin\"]].values\n",
        "y_val = VAL[\"y_true\"].astype(int).values\n",
        "\n",
        "meta = LogisticRegression(max_iter=1000, solver=\"lbfgs\", random_state=random_state)\n",
        "meta.fit(X_val, y_val)\n",
        "\n",
        "# Predicción cruda\n",
        "VAL[\"p_meta_raw\"] = meta.predict_proba(X_val)[:,1]\n",
        "\n",
        "# Evaluación cruda (pre-calibración)\n",
        "m_val = metrics(y_val, VAL[\"p_meta_raw\"].values)\n",
        "print(\"LATE (raw) VAL:\", m_val)\n",
        "\n",
        "# Guardar meta\n",
        "import pickle\n",
        "with open(dirs[\"MODELS\"]/\"p26_meta_late.pkl\",\"wb\") as f: pickle.dump(meta, f)\n",
        "\n",
        "# Predicción en TEST (cruda)\n",
        "X_tst = TST[[\"p_img\",\"p_clin\"]].values\n",
        "y_tst = TST[\"y_true\"].astype(int).values\n",
        "TST[\"p_meta_raw\"] = meta.predict_proba(X_tst)[:,1]\n",
        "m_tst = metrics(y_tst, TST[\"p_meta_raw\"].values)\n",
        "print(\"LATE (raw) TEST:\", m_tst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uInMWI7Uft7o",
        "outputId": "4113522a-6610-4d8c-94da-b3c098a3ce53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LATE (raw) VAL: {'AUC': 0.9040747028862479, 'PRAUC': 0.9251447096482674, 'Brier': 0.20186942272517908}\n",
            "LATE (raw) TEST: {'AUC': 0.7360197368421053, 'PRAUC': 0.7285510809902204, 'Brier': 0.2286766661338769}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Platt por cohorte = LR sobre score\n",
        "def fit_platt(y, s):\n",
        "    m = LogisticRegression(solver=\"lbfgs\", random_state=random_state)\n",
        "    m.fit(s.reshape(-1,1), y.astype(int))\n",
        "    return m\n",
        "\n",
        "coh_cal = {}\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    mask = VAL[\"cohort\"]==coh\n",
        "    m = fit_platt(VAL.loc[mask,\"y_true\"].values, VAL.loc[mask,\"p_meta_raw\"].values)\n",
        "    coh_cal[coh] = m\n",
        "\n",
        "# Guardar calibradores\n",
        "import pickle\n",
        "with open(dirs[\"MODELS\"]/\"p26b_platt_OAS1.pkl\",\"wb\") as f: pickle.dump(coh_cal[\"OAS1\"], f)\n",
        "with open(dirs[\"MODELS\"]/\"p26b_platt_OAS2.pkl\",\"wb\") as f: pickle.dump(coh_cal[\"OAS2\"], f)\n",
        "\n",
        "# Aplicar calibración a VAL y TEST\n",
        "def platt_pred(m, s): return m.predict_proba(s.reshape(-1,1))[:,1]\n",
        "\n",
        "VAL[\"p_cal\"] = np.nan\n",
        "TST[\"p_cal\"] = np.nan\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    vm = VAL[\"cohort\"]==coh\n",
        "    tm = TST[\"cohort\"]==coh\n",
        "    VAL.loc[vm,\"p_cal\"] = platt_pred(coh_cal[coh], VAL.loc[vm,\"p_meta_raw\"].values)\n",
        "    TST.loc[tm,\"p_cal\"] = platt_pred(coh_cal[coh], TST.loc[tm,\"p_meta_raw\"].values)\n",
        "\n",
        "print(\"VAL P26b:\", metrics(VAL[\"y_true\"], VAL[\"p_cal\"]))\n",
        "print(\"TST P26b:\", metrics(TST[\"y_true\"], TST[\"p_cal\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j93Jm3pHfyfW",
        "outputId": "9e43f980-61c3-4c59-8dd1-318f29769ec4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL P26b: {'AUC': 0.7614601018675721, 'PRAUC': 0.7293917476096345, 'Brier': 0.23428651719818258}\n",
            "TST P26b: {'AUC': 0.6842105263157895, 'PRAUC': 0.6595296459970565, 'Brier': 0.24072039406689189}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def best_cost_thr(y, p, C_FN=5.0, C_FP=1.0, grid=1001):\n",
        "    thrs = np.linspace(0,1,grid)\n",
        "    best = None\n",
        "    for t in thrs:\n",
        "        ypred = (p>=t).astype(int)\n",
        "        TP = ((y==1)&(ypred==1)).sum()\n",
        "        FP = ((y==0)&(ypred==1)).sum()\n",
        "        FN = ((y==1)&(ypred==0)).sum()\n",
        "        cost = C_FN*FN + C_FP*FP\n",
        "        if (best is None) or (cost < best[\"Cost\"]-1e-9):\n",
        "            best = dict(Thr=float(t), Cost=float(cost), TP=int(TP), FP=int(FP), FN=int(FN))\n",
        "    return best\n",
        "\n",
        "thr = {}\n",
        "rows=[]\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    m = VAL[\"cohort\"]==coh\n",
        "    b = best_cost_thr(VAL.loc[m,\"y_true\"].values, VAL.loc[m,\"p_cal\"].values, 5.0, 1.0)\n",
        "    thr[coh] = b[\"Thr\"]\n",
        "    rows.append({\"Cohort\":coh, **b})\n",
        "\n",
        "thr_json = {\"policy\":\"single\",\"cost_policy\":\"FN:FP=5:1\",\"thresholds\":thr}\n",
        "with open(dirs[\"CONFIG\"]/\"deployment_config.json\",\"w\") as f:\n",
        "    json.dump(thr_json, f, indent=2)\n",
        "\n",
        "pd.DataFrame(rows).to_csv(dirs[\"TMP\"]/\"val_thresholds_cost5to1.csv\", index=False)\n",
        "print(\"Umbrales (VAL):\", thr_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ubxIiftf5vH",
        "outputId": "547bbd1b-0875-4b18-abd8-aaf0759b0e3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Umbrales (VAL): {'policy': 'single', 'cost_policy': 'FN:FP=5:1', 'thresholds': {'OAS1': 0.42, 'OAS2': 0.49}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_report(df, thr):\n",
        "    y = df[\"y_true\"].values.astype(int)\n",
        "    p = df[\"p_cal\"].values.astype(float)\n",
        "    ypred = (p>=thr).astype(int)\n",
        "    TP = int(((y==1)&(ypred==1)).sum())\n",
        "    FP = int(((y==0)&(ypred==1)).sum())\n",
        "    TN = int(((y==0)&(ypred==0)).sum())\n",
        "    FN = int(((y==1)&(ypred==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/len(y)\n",
        "    cost = 5*FN + 1*FP\n",
        "    return dict(TP=TP,FP=FP,TN=TN,FN=FN,Precision=prec,Recall=rec,Acc=acc,Cost=cost)\n",
        "\n",
        "rows=[]\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    d = TST[TST[\"cohort\"]==coh]\n",
        "    rep = confusion_report(d, thr[coh])\n",
        "    rows.append(dict(Cohort=coh, Thr=thr[coh], **rep))\n",
        "\n",
        "rep_df = pd.DataFrame(rows)\n",
        "out_rep = REL/\"QA/p26b_test_report_cost_5to1.csv\"\n",
        "rep_df.to_csv(out_rep, index=False)\n",
        "print(rep_df)\n",
        "print(\"Guardado:\", out_rep)\n",
        "\n",
        "# Guardar preds calibradas para golden set\n",
        "VAL[[\"patient_id\",\"cohort\",\"y_true\",\"p_cal\"]].to_csv(REL/\"QA/p26b_val_preds_calibrated.csv\", index=False)\n",
        "TST[[\"patient_id\",\"cohort\",\"y_true\",\"p_cal\"]].to_csv(REL/\"QA/p26b_test_preds_calibrated.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6a4KTzgf-WV",
        "outputId": "b510273e-7766-42eb-d7bd-3d73b1cdff12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cohort   Thr  TP  FP  TN  FN  Precision  Recall       Acc  Cost\n",
            "0   OAS1  0.42  14   9  18   6   0.608696     0.7  0.680851    39\n",
            "1   OAS2  0.49  12  11   0   0   0.521739     1.0  0.521739    11\n",
            "Guardado: /content/drive/MyDrive/CognitivaAI/p26_release/QA/p26b_test_report_cost_5to1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clinical signature (nombres y tipos esperados)\n",
        "clinical_signature = {\n",
        "  \"fields\": [\n",
        "    {\"name\":\"Age\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"Sex\",\"dtype\":\"str\",\"allowed\":[\"M\",\"F\"]},\n",
        "    {\"name\":\"Education\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"SES\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"MMSE\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"eTIV\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"nWBV\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"ASF\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"Delay\",\"dtype\":\"float\"}\n",
        "  ],\n",
        "  \"notes\":\"Sex se normaliza a {'M','F'} internamente; numéricos con imputación mediana + StandardScaler.\"\n",
        "}\n",
        "with open(dirs[\"COLSIG\"]/\"clinical_signature.json\",\"w\") as f:\n",
        "    json.dump(clinical_signature, f, indent=2)\n",
        "\n",
        "# Image signature: leemos p24_coefficients.csv (índice = features)\n",
        "coef = pd.read_csv(P24/\"p24_coefficients.csv\")\n",
        "feat_col = \"Feature\" if \"Feature\" in coef.columns else coef.columns[0]\n",
        "img_features = coef[feat_col].tolist()\n",
        "image_signature = {\n",
        "  \"features\": img_features,\n",
        "  \"notes\":\"Orden/nombres deben coincidir con entrenamiento P24. Si se provee p_img directamente, esta firma puede no ser usada.\"\n",
        "}\n",
        "with open(dirs[\"COLSIG\"]/\"image_signature.json\",\"w\") as f:\n",
        "    json.dump(image_signature, f, indent=2)\n",
        "\n",
        "print(\"OK → firmas creadas.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO-MfhSdgE2o",
        "outputId": "113d01f1-393c-48de-f83c-eadf832270ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK → firmas creadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_card = f\"\"\"# MODEL CARD — CognitivaAI v1.1 (P26b single)\n",
        "\n",
        "**Arquitectura:**\n",
        "- Imagen (P24: modelo + Platt) → `p_img`\n",
        "- Clínico (LR con imputación+scaler) → `p_clin`\n",
        "- Fusión Late (meta-LR sobre `p_img`+`p_clin`)\n",
        "- Calibración Platt **por cohorte** (P26b) → `proba_cal`\n",
        "- Decisión por coste (FN:FP=5:1) con umbrales aprendidos en VAL:\n",
        "  - OAS1 = {thr['OAS1']:.3f}\n",
        "  - OAS2 = {thr['OAS2']:.3f}\n",
        "\n",
        "**Métricas (TEST, probs calibradas):**\n",
        "- ALL: AUC≈{roc_auc_score(TST['y_true'], TST['p_cal']):.3f} · PR-AUC≈{average_precision_score(TST['y_true'], TST['p_cal']):.3f} · Brier≈{brier_score_loss(TST['y_true'], TST['p_cal']):.3f}\n",
        "- OAS1 / OAS2: ver `QA/p26b_test_report_cost_5to1.csv`.\n",
        "\n",
        "**Suposiciones de entrada:**\n",
        "- Clínico: 9 campos (ver `clinical_signature.json`).\n",
        "- Imagen: usar pipeline P24 **o** aportar `p_img` directo.\n",
        "- Cohorte: 'OAS1'/'OAS2' (para calibrador/umbral). Si se desconoce, usar 'OAS1' por defecto y monitorizar calibración.\n",
        "\n",
        "**Riesgos & mitigaciones:**\n",
        "- Descalibración en dominios nuevos → recalibrar Platt por sitio con ≥50–100 casos y actualizar umbral 5:1.\n",
        "- Tamaño muestral reducido → reportar ICs y monitorizar ECE/MCE.\n",
        "\n",
        "**Archivos clave:** ver `META/MANIFEST.json`.\n",
        "\"\"\"\n",
        "howto = \"\"\"# HOW TO DEPLOY — CognitivaAI v1.1\n",
        "\n",
        "## 1) Entorno\n",
        "- Python 3.10+\n",
        "- Instala dependencias de `META/ENVIRONMENT.txt` (bloqueado sklearn).\n",
        "\n",
        "## 2) Inferencia por lote (CSV)\n",
        "- Prepara CSV con columnas clínicas (ver `clinical_signature.json`) y/o `p_img`.\n",
        "- Ejecuta `scripts/predict_batch.py` (opcional: crearlo) para leer CSV y generar `proba_cal` y `decision`.\n",
        "\n",
        "## 3) API (opcional)\n",
        "- Montar un endpoint `/predict` que:\n",
        "  - Valide `clinical` y/o calcule `p_img` con P24.\n",
        "  - Aplique fusión Late + Platt por cohorte.\n",
        "  - Devuelva `proba_cal`, `decision` y `threshold_used`.\n",
        "\n",
        "## 4) Monitorización\n",
        "- Guardar `proba_cal` y decisión por cohorte.\n",
        "- Semanal: ECE/MCE por cohorte; recall/precision cuando lleguen etiquetas.\n",
        "- Alarmas: ECE>0.20 (OAS1) / >0.25 (OAS2); recall OAS2<0.65.\n",
        "\"\"\"\n",
        "(dirs[\"DOCS\"]/\"MODEL_CARD.md\").write_text(model_card, encoding=\"utf-8\")\n",
        "(dirs[\"DOCS\"]/\"HOW_TO_DEPLOY.md\").write_text(howto, encoding=\"utf-8\")\n",
        "print(\"OK → DOCS creados.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etYtNgdVgHHq",
        "outputId": "2265b079-d8b1-4d63-e5da-3fded9ae0952"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK → DOCS creados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Golden set: usamos TEST calibrado (subset estable)\n",
        "gold = TST.sample(n=min(40, len(TST)), random_state=random_state)[[\"patient_id\",\"cohort\",\"y_true\",\"p_img\",\"p_clin\",\"p_cal\"]]\n",
        "gold.to_csv(dirs[\"QA\"]/\"golden_set.csv\", index=False)\n",
        "\n",
        "# Checksums de modelos\n",
        "chk = {}\n",
        "for p in (dirs[\"MODELS\"]).glob(\"*.pkl\"):\n",
        "    chk[p.name] = sha256_of_file(p)\n",
        "(pd.Series(chk, name=\"sha256\")\n",
        "   .to_frame().to_csv(dirs[\"QA\"]/\"qa_checksums.csv\"))\n",
        "\n",
        "print(\"OK → golden_set y checksums listos.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVVIr_DdgMaD",
        "outputId": "7e1335d9-3851-4fb8-ef46-53b62acf3cbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK → golden_set y checksums listos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "manifest = {\n",
        "  \"version\":\"v1.1\",\n",
        "  \"files\":[]\n",
        "}\n",
        "for root, _, files in os.walk(REL):\n",
        "    for fn in files:\n",
        "        p = Path(root)/fn\n",
        "        relp = p.relative_to(REL).as_posix()\n",
        "        if \"/_tmp/\" in relp:\n",
        "            continue\n",
        "        manifest[\"files\"].append({\n",
        "            \"path\": relp,\n",
        "            \"sha256\": sha256_of_file(p),\n",
        "            \"bytes\": p.stat().st_size\n",
        "        })\n",
        "with open(dirs[\"META\"]/\"MANIFEST.json\",\"w\") as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "print(\"OK → MANIFEST.json generado con\", len(manifest[\"files\"]), \"ficheros.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyg5n5pogRZz",
        "outputId": "a3a1982d-bf39-4c67-a21e-aef0bcf3a3c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK → MANIFEST.json generado con 19 ficheros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos pip freeze (para reproducibilidad)\n",
        "import subprocess, sys\n",
        "out = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode()\n",
        "# Recomendación: fijar scikit-learn==1.7.1 si coincide con tus pickles\n",
        "lines = out.strip().splitlines()\n",
        "(dirs[\"META\"]/\"ENVIRONMENT.txt\").write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "print(\"OK → ENVIRONMENT.txt escrito.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqX-x2ktgV7P",
        "outputId": "b56153cb-e7c3-423c-da10-93ae64701b47"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK → ENVIRONMENT.txt escrito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = REL.with_suffix(\".zip\")\n",
        "if zip_path.exists(): zip_path.unlink()\n",
        "shutil.make_archive(str(REL), \"zip\", root_dir=REL)\n",
        "print(\"🎁 Release ZIP listo:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89hJ3JRUgauM",
        "outputId": "f65ba24d-2dd5-47ba-acbe-1b4871968d0a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎁 Release ZIP listo: /content/drive/MyDrive/CognitivaAI/p26_release.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === S2.1: OAS2 con recall objetivo en VAL; OAS1 se mantiene 5:1 ===\n",
        "from pathlib import Path\n",
        "import json, numpy as np, pandas as pd\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "REL  = BASE/\"p26_release\"\n",
        "\n",
        "val = pd.read_csv(REL/\"QA/p26b_val_preds_calibrated.csv\")   # cols: patient_id, cohort, y_true, p_cal\n",
        "tst = pd.read_csv(REL/\"QA/p26b_test_preds_calibrated.csv\")\n",
        "\n",
        "def thr_for_recall(y, p, target=0.85):\n",
        "    \"\"\"Devuelve el mayor umbral t tal que recall(t) >= target (conservador en FP).\"\"\"\n",
        "    y = np.asarray(y).astype(int)\n",
        "    p = np.asarray(p).astype(float)\n",
        "    # Candidatos = valores únicos de p (y extremos 0,1)\n",
        "    cand = np.unique(np.concatenate([p, [0.0, 1.0]]))\n",
        "    best_t = 0.0\n",
        "    found = False\n",
        "    # Probamos de 1.0 -> 0.0 para quedarnos con el UMBRAL MÁS ALTO que cumpla recall>=target\n",
        "    for t in sorted(cand, reverse=True):\n",
        "        yhat = (p >= t).astype(int)\n",
        "        TP = ((y==1)&(yhat==1)).sum()\n",
        "        FN = ((y==1)&(yhat==0)).sum()\n",
        "        rec = TP / (TP + FN) if (TP+FN)>0 else 0.0\n",
        "        if rec >= target:\n",
        "            best_t = float(t)\n",
        "            found = True\n",
        "            break\n",
        "    # Si jamás alcanzamos el target, caemos a t=0.0 (todo positivo)\n",
        "    return best_t, found\n",
        "\n",
        "def confusion_at(df, t):\n",
        "    y = df[\"y_true\"].to_numpy(int)\n",
        "    p = df[\"p_cal\"].to_numpy(float)\n",
        "    yhat = (p >= t).astype(int)\n",
        "    TP = int(((y==1)&(yhat==1)).sum())\n",
        "    FP = int(((y==0)&(yhat==1)).sum())\n",
        "    TN = int(((y==0)&(yhat==0)).sum())\n",
        "    FN = int(((y==1)&(yhat==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/len(y) if len(y)>0 else np.nan\n",
        "    cost = 5*FN + 1*FP\n",
        "    return dict(TP=TP,FP=FP,TN=TN,FN=FN,Precision=prec,Recall=rec,Acc=acc,Cost=cost)\n",
        "\n",
        "# 1) Leer deployment_config actual (tiene 5:1)\n",
        "cfg_path = REL/\"CONFIG/deployment_config.json\"\n",
        "cfg = json.loads(cfg_path.read_text())\n",
        "\n",
        "# Guardamos copia de seguridad\n",
        "(REL/\"CONFIG/deployment_config.backup.json\").write_text(json.dumps(cfg, indent=2))\n",
        "\n",
        "# 2) Calcular umbral OAS2 @ recall objetivo en VAL\n",
        "target_recall = 0.85\n",
        "val_oas2 = val[val[\"cohort\"]==\"OAS2\"].copy()\n",
        "t_rec, ok = thr_for_recall(val_oas2[\"y_true\"], val_oas2[\"p_cal\"], target=target_recall)\n",
        "\n",
        "# 3) Mantener OAS1 desde 5:1 del config actual (no tocamos)\n",
        "thr_oas1_5to1 = float(cfg[\"thresholds\"][\"OAS1\"])\n",
        "thr_oas2_5to1 = float(cfg[\"thresholds\"][\"OAS2\"])\n",
        "\n",
        "# 4) Actualizamos config principal para usar S2 por defecto\n",
        "cfg[\"policy\"] = \"single\"\n",
        "cfg[\"cost_policy\"] = \"FN:FP=5:1 (OAS1) + recall_target (OAS2)\"\n",
        "cfg[\"thresholds\"] = {\n",
        "    \"OAS1\": thr_oas1_5to1,\n",
        "    \"OAS2\": float(t_rec)\n",
        "}\n",
        "# y preservamos umbrales 5:1 como alternativa explícita\n",
        "cfg[\"thresholds_5to1\"] = {\"OAS1\": thr_oas1_5to1, \"OAS2\": thr_oas2_5to1}\n",
        "cfg[\"thresholds_recall_target\"] = {\"OAS2\": {\"target\": target_recall, \"thr_val\": float(t_rec), \"found\": bool(ok)}}\n",
        "\n",
        "cfg_path.write_text(json.dumps(cfg, indent=2))\n",
        "print(\"✅ Config actualizada con S2:\",\n",
        "      json.dumps(cfg[\"thresholds\"], indent=2),\n",
        "      \"\\n(backup en CONFIG/deployment_config.backup.json)\")\n",
        "\n",
        "# 5) Report en TEST con los nuevos umbrales\n",
        "rows = []\n",
        "for coh, thr in [(\"OAS1\", thr_oas1_5to1), (\"OAS2\", float(t_rec))]:\n",
        "    d = tst[tst[\"cohort\"]==coh].copy()\n",
        "    rep = confusion_at(d, thr)\n",
        "    rows.append(dict(Cohort=coh, Thr=thr, **rep))\n",
        "rep_df = pd.DataFrame(rows)\n",
        "out = REL/\"QA/p26b_test_report_recall_target.csv\"\n",
        "rep_df.to_csv(out, index=False)\n",
        "print(\"\\nTEST @S2\")\n",
        "print(rep_df)\n",
        "print(\"\\n💾 Guardado:\", out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGtK75f5k4na",
        "outputId": "3c0c6439-1155-48fe-d7ad-e677a510cc45"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Config actualizada con S2: {\n",
            "  \"OAS1\": 0.42,\n",
            "  \"OAS2\": 0.4928655287824083\n",
            "} \n",
            "(backup en CONFIG/deployment_config.backup.json)\n",
            "\n",
            "TEST @S2\n",
            "  Cohort       Thr  TP  FP  TN  FN  Precision    Recall       Acc  Cost\n",
            "0   OAS1  0.420000  14   9  18   6   0.608696  0.700000  0.680851    39\n",
            "1   OAS2  0.492866  11   6   5   1   0.647059  0.916667  0.695652    11\n",
            "\n",
            "💾 Guardado: /content/drive/MyDrive/CognitivaAI/p26_release/QA/p26b_test_report_recall_target.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === S2.2: revertir a 5:1 en ambos cohortes (opcional) ===\n",
        "from pathlib import Path\n",
        "import json\n",
        "REL = Path(\"/content/drive/MyDrive/CognitivaAI/p26_release\")\n",
        "cfg_path = REL/\"CONFIG/deployment_config.json\"\n",
        "cfg = json.loads(cfg_path.read_text())\n",
        "\n",
        "# Recuperamos los de 5:1 (guardados en thresholds_5to1)\n",
        "t_5to1 = cfg.get(\"thresholds_5to1\", cfg[\"thresholds\"])  # por si no existe\n",
        "cfg[\"policy\"] = \"single\"\n",
        "cfg[\"cost_policy\"] = \"FN:FP=5:1\"\n",
        "cfg[\"thresholds\"] = {\"OAS1\": float(t_5to1[\"OAS1\"]), \"OAS2\": float(t_5to1[\"OAS2\"])}\n",
        "\n",
        "cfg_path.write_text(json.dumps(cfg, indent=2))\n",
        "print(\"↩️  Revertido a 5:1 puro:\", cfg[\"thresholds\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x4yLrxqk6_n",
        "outputId": "f3c84b06-635a-4573-9bb0-61338d9056e7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "↩️  Revertido a 5:1 puro: {'OAS1': 0.42, 'OAS2': 0.49}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json, pandas as pd, numpy as np\n",
        "\n",
        "REL = Path(\"/content/drive/MyDrive/CognitivaAI/p26_release\")\n",
        "cfg = json.loads((REL/\"CONFIG/deployment_config.json\").read_text())\n",
        "thr = cfg[\"thresholds\"]\n",
        "\n",
        "tst = pd.read_csv(REL/\"QA/p26b_test_preds_calibrated.csv\")  # patient_id, cohort, y_true, p_cal\n",
        "def report_for(df, t):\n",
        "    y, p = df[\"y_true\"].to_numpy(int), df[\"p_cal\"].to_numpy(float)\n",
        "    yhat = (p >= t).astype(int)\n",
        "    TP = int(((y==1)&(yhat==1)).sum()); FP = int(((y==0)&(yhat==1)).sum())\n",
        "    TN = int(((y==0)&(yhat==0)).sum()); FN = int(((y==1)&(yhat==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/len(y)\n",
        "    cost = 5*FN + 1*FP\n",
        "    return dict(TP=TP,FP=FP,TN=TN,FN=FN,Precision=prec,Recall=rec,Acc=acc,Cost=cost)\n",
        "\n",
        "rows=[]\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    d = tst[tst[\"cohort\"]==coh].copy()\n",
        "    rows.append(dict(Cohort=coh, Thr=thr[coh], **report_for(d, thr[coh])))\n",
        "print(pd.DataFrame(rows))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8lrrj_snX4H",
        "outputId": "59d00162-559e-4680-9810-dce26781525f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cohort       Thr  TP  FP  TN  FN  Precision    Recall       Acc  Cost\n",
            "0   OAS1  0.420000  14   9  18   6   0.608696  0.700000  0.680851    39\n",
            "1   OAS2  0.492866  11   6   5   1   0.647059  0.916667  0.695652    11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === P27 helper ===\n",
        "# Actualiza documentación con la \"Política activa (S2)\", regenera MANIFEST y el ZIP del release.\n",
        "from pathlib import Path\n",
        "import json, os, hashlib, shutil, re, subprocess, sys\n",
        "from datetime import datetime\n",
        "\n",
        "# 0) Paths\n",
        "REL = Path(\"/content/drive/MyDrive/CognitivaAI/p26_release\")\n",
        "DOCS = REL/\"DOCS\"\n",
        "CFG  = REL/\"CONFIG\"/\"deployment_config.json\"\n",
        "MANI = REL/\"META\"/\"MANIFEST.json\"\n",
        "ENV  = REL/\"META\"/\"ENVIRONMENT.txt\"\n",
        "\n",
        "assert REL.exists(), f\"No existe release: {REL}\"\n",
        "assert CFG.exists(), f\"No existe config: {CFG}\"\n",
        "DOCS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Cargar política/umbrales desde config\n",
        "cfg = json.loads(CFG.read_text())\n",
        "thr = cfg[\"thresholds\"]\n",
        "policy_str = cfg.get(\"cost_policy\", \"FN:FP=5:1 (OAS1) + recall_target (OAS2)\")\n",
        "t_oas1 = float(thr[\"OAS1\"])\n",
        "t_oas2 = float(thr[\"OAS2\"])\n",
        "recall_target = cfg.get(\"thresholds_recall_target\", {}).get(\"OAS2\", {}).get(\"target\", 0.85)\n",
        "\n",
        "# 2) Utilidades\n",
        "def sha256_of_file(p: Path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, \"rb\") as f:\n",
        "        for ch in iter(lambda: f.read(8192), b\"\"): h.update(ch)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def upsert_section(md_path: Path, title: str, body_md: str, level: int = 2):\n",
        "    \"\"\"\n",
        "    Inserta o reemplaza una sección Markdown completa:\n",
        "    - Busca '## title' (o nivel dado).\n",
        "    - Reemplaza hasta el siguiente encabezado del mismo nivel o superior.\n",
        "    - Si no existe, la añade al final con un separador.\n",
        "    \"\"\"\n",
        "    if md_path.exists():\n",
        "        text = md_path.read_text(encoding=\"utf-8\")\n",
        "    else:\n",
        "        text = \"\"\n",
        "    h = \"#\"*level\n",
        "    pattern = rf\"^{h}\\s+{re.escape(title)}\\s*$\"\n",
        "    lines = text.splitlines()\n",
        "    start = None\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.match(pattern, line.strip(), flags=re.IGNORECASE):\n",
        "            start = i\n",
        "            break\n",
        "    new_section = f\"{h} {title}\\n\\n{body_md.strip()}\\n\"\n",
        "    if start is None:\n",
        "        # append\n",
        "        if text.strip():\n",
        "            text = text.rstrip()+\"\\n\\n\"+new_section\n",
        "        else:\n",
        "            text = new_section\n",
        "    else:\n",
        "        # find end (next heading of same or higher level)\n",
        "        end = len(lines)\n",
        "        for j in range(start+1, len(lines)):\n",
        "            if re.match(r\"^#{1,%d}\\s+\" % level, lines[j]):\n",
        "                end = j\n",
        "                break\n",
        "        text = \"\\n\".join(lines[:start] + [new_section.rstrip()] + lines[end:])\n",
        "    md_path.write_text(text, encoding=\"utf-8\")\n",
        "\n",
        "# 3) Construir bloque de política activa (S2)\n",
        "policy_block = f\"\"\"**Política activa (S2)** — *single pipeline*\n",
        "- **OAS1:** decisión por coste **FN:FP=5:1**, umbral **thr = {t_oas1:.6f}**\n",
        "- **OAS2:** **umbral por objetivo de recall** (VAL), target = **{recall_target:.2f}**, umbral **thr = {t_oas2:.6f}**\n",
        "- Alternativas disponibles:\n",
        "  - **5:1 puro**: ver `thresholds_5to1` en `CONFIG/deployment_config.json`.\n",
        "- Nota operativa:\n",
        "  - Monitorizar **ECE/MCE** y **positivity rate** por cohorte; recalibrar y/o ajustar umbral si deriva el dominio.\n",
        "\"\"\"\n",
        "\n",
        "# 4) Marcar en MODEL_CARD.md y HOW_TO_DEPLOY.md\n",
        "model_card = DOCS/\"MODEL_CARD.md\"\n",
        "howto      = DOCS/\"HOW_TO_DEPLOY.md\"\n",
        "upsert_section(model_card, \"Política activa (S2)\", policy_block, level=2)\n",
        "upsert_section(howto, \"Política activa (S2)\", policy_block, level=2)\n",
        "\n",
        "# 5) Regenerar MANIFEST (hash/bytes de todos los ficheros salvo _tmp)\n",
        "manifest = {\"version\":\"v1.1\", \"generated_at\": datetime.utcnow().isoformat()+\"Z\", \"files\":[]}\n",
        "for root, _, files in os.walk(REL):\n",
        "    for fn in files:\n",
        "        p = Path(root)/fn\n",
        "        relp = p.relative_to(REL).as_posix()\n",
        "        if \"/_tmp/\" in relp:\n",
        "            continue\n",
        "        manifest[\"files\"].append({\n",
        "            \"path\": relp,\n",
        "            \"sha256\": sha256_of_file(p),\n",
        "            \"bytes\": p.stat().st_size\n",
        "        })\n",
        "MANI.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "# 6) (Opcional) refrescar ENVIRONMENT.txt si quieres congelar de nuevo\n",
        "try:\n",
        "    out = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode()\n",
        "    ENV.write_text(out, encoding=\"utf-8\")\n",
        "except Exception as e:\n",
        "    print(\"Aviso: no se pudo refrescar ENVIRONMENT.txt:\", e)\n",
        "\n",
        "# 7) Regenerar ZIP del release\n",
        "zip_path = REL.with_suffix(\".zip\")\n",
        "if zip_path.exists():\n",
        "    zip_path.unlink()\n",
        "shutil.make_archive(str(REL), \"zip\", root_dir=REL)\n",
        "\n",
        "print(\"✅ Política S2 marcada en DOCS.\")\n",
        "print(\"📄 MODEL_CARD.md y HOW_TO_DEPLOY.md actualizados.\")\n",
        "print(\"🧾 MANIFEST.json regenerado con\", len(manifest[\"files\"]), \"ficheros.\")\n",
        "print(\"🎁 ZIP listo:\", zip_path)\n",
        "print(\"→ Umbrales activos:\", json.dumps(cfg['thresholds'], indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYZvS5-poo9z",
        "outputId": "f35ba136-fb44-4078-8416-9e2e04219411"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-239857406.py:86: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  manifest = {\"version\":\"v1.1\", \"generated_at\": datetime.utcnow().isoformat()+\"Z\", \"files\":[]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Política S2 marcada en DOCS.\n",
            "📄 MODEL_CARD.md y HOW_TO_DEPLOY.md actualizados.\n",
            "🧾 MANIFEST.json regenerado con 23 ficheros.\n",
            "🎁 ZIP listo: /content/drive/MyDrive/CognitivaAI/p26_release.zip\n",
            "→ Umbrales activos: {\n",
            "  \"OAS1\": 0.42,\n",
            "  \"OAS2\": 0.4928655287824083\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RESET & RESUME (Colab) ---\n",
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Montar Drive (fuerza remount por si quedó colgado)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception as e:\n",
        "    print(\"Drive ya montado o no estás en Colab:\", e)\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "P25  = BASE/\"p25_informe_final\"\n",
        "P26R = BASE/\"p26_release\"\n",
        "OUT  = BASE/\"p27_final\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2) Resolver master table de forma robusta\n",
        "mt_path = P25/\"p25_master_table.csv\"\n",
        "if not mt_path.exists():\n",
        "    hits = list(BASE.rglob(\"p25_master_table.csv\"))\n",
        "    if not hits:\n",
        "        raise FileNotFoundError(\"No se encontró p25_master_table.csv en CognitivaAI/*\")\n",
        "    mt_path = hits[0]\n",
        "print(\"✅ Master table:\", mt_path)\n",
        "\n",
        "# 3) Cargar y filtrar TEST\n",
        "mt = pd.read_csv(mt_path)\n",
        "keep = [\"Pipeline\",\"Split\",\"Cohort\",\"Method\",\"AUC\",\"PRAUC\",\"Brier\"]\n",
        "mt_clean = mt[[c for c in keep if c in mt.columns]].copy()\n",
        "if \"Split\" in mt_clean:\n",
        "    mt_clean[\"Split\"] = mt_clean[\"Split\"].astype(str).str.upper()\n",
        "    mt_clean = mt_clean[mt_clean[\"Split\"]==\"TEST\"]\n",
        "\n",
        "# 4) Figuras AUC/PR-AUC/Brier\n",
        "def plot_bar(metric, cohort, fname):\n",
        "    df = mt_clean[mt_clean[\"Cohort\"]==cohort].copy()\n",
        "    if df.empty or metric not in df: return\n",
        "    df[\"_rank\"] = df.groupby(\"Pipeline\")[metric].transform(lambda s: s.rank(ascending=False, method=\"first\"))\n",
        "    top = df[df[\"_rank\"]==1].sort_values([\"Pipeline\"]).copy()\n",
        "    if top.empty: return\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.bar(top[\"Pipeline\"], top[metric])\n",
        "    plt.title(f\"{metric} — {cohort} (TEST)\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.ylim(0, 1 if metric!=\"Brier\" else max(0.3, float(top[metric].max())*1.1))\n",
        "    plt.grid(alpha=0.3, axis=\"y\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUT/fname, dpi=160)\n",
        "    plt.close()\n",
        "\n",
        "for coh in [\"ALL\",\"OAS1\",\"OAS2\"]:\n",
        "    plot_bar(\"AUC\",   coh, f\"p27_auc_{coh}.png\")\n",
        "    plot_bar(\"PRAUC\", coh, f\"p27_prauc_{coh}.png\")\n",
        "    plot_bar(\"Brier\", coh, f\"p27_brier_{coh}.png\")\n",
        "\n",
        "print(\"🎨 Figuras guardadas en:\", OUT)\n",
        "\n",
        "# 5) Tabla de decisión S2 (si está el QA del release)\n",
        "qa_candidates = list(P26R.rglob(\"p26b_test_report_recall_target.csv\"))\n",
        "if qa_candidates:\n",
        "    qa = pd.read_csv(qa_candidates[0])[[\"Cohort\",\"Thr\",\"TP\",\"FP\",\"TN\",\"FN\",\"Precision\",\"Recall\",\"Acc\",\"Cost\"]]\n",
        "    qa.to_csv(OUT/\"p27_decision_S2_table.csv\", index=False)\n",
        "    print(\"✅ Tabla decisión S2:\", qa_candidates[0])\n",
        "else:\n",
        "    print(\"ℹ️ No se encontró QA S2; omito tabla de decisión.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sxM8S9xI10k",
        "outputId": "5bf67d59-cd7f-47c5-c9e8-5f9d01ca1aaa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Master table: /content/drive/MyDrive/CognitivaAI/p25_informe_final/p25_master_table.csv\n",
            "🎨 Figuras guardadas en: /content/drive/MyDrive/CognitivaAI/p27_final\n",
            "✅ Tabla decisión S2: /content/drive/MyDrive/CognitivaAI/p26_release/QA/p26b_test_report_recall_target.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Write MODEL_CARD.md (P27) ===\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "REL  = BASE/\"p26_release\"\n",
        "REL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "mc_path = REL/\"MODEL_CARD.md\"\n",
        "backup  = mc_path.with_suffix(\".backup.md\")\n",
        "\n",
        "# 1) Backup si existe\n",
        "if mc_path.exists():\n",
        "    backup.write_text(mc_path.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
        "\n",
        "# 2) Contenido del Model Card (P27)\n",
        "mc = \"\"\"# Model Card — CognitivaAI Intermodal (P26/P27)\n",
        "\n",
        "**Versión:** P27 (intermodal LATE + calibración por cohorte + política S2)\n",
        "**Tarea:** Predicción binaria (0=Control, 1=Dementia/Converted) a nivel **paciente**.\n",
        "**Entradas:**\n",
        "- **Imagen → `p_img`** (probabilidad calibrada con Platt a partir de features por paciente; base P24).\n",
        "- **Clínico → `p_clin`** (LR sobre variables tabulares estandarizadas).\n",
        "**Fusión:** **LATE** (combinación sobre probabilidades calibradas).\n",
        "**Cohortes:** OASIS-1 (cross-sectional) y OASIS-2 (longitudinal, 1 visita/paciente).\n",
        "\n",
        "---\n",
        "\n",
        "## 1) Uso previsto\n",
        "Sistema de **cribado** para apoyar la decisión clínica en evaluación cognitiva, con especial énfasis en **sensibilidad** (minimizar FN) y **calibración** de probabilidades. No sustituye el juicio clínico; requiere validación local.\n",
        "\n",
        "---\n",
        "\n",
        "## 2) Datos y entrenamiento (resumen)\n",
        "- **Imagen**: 20 *slices* axiales/volumen, normalización z-score (+CLAHE opc.), agregación por paciente; meta-modelo P24 (LR elastic-net + Platt).\n",
        "- **Clínico**: columnas mínimas `Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay, patient_id` (imputación mediana/one-hot básico).\n",
        "- **P26**: intermodal **LATE**; **P26b**: recalibración **Platt por cohorte**.\n",
        "- **P27**: empaquetado reproducible, política de decisión **S2** y QA final.\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Métricas de probabilidad (TEST)\n",
        "**Intermodal LATE (P26):**\n",
        "- **ALL:** AUC **0.736**, PR-AUC **0.729**, Brier **0.229**\n",
        "- **OAS1:** AUC **0.754**, PR-AUC **0.736**, Brier **0.208**\n",
        "- **OAS2:** AUC **0.652**, PR-AUC **0.728**, Brier **0.288**\n",
        "\n",
        "> Fuente: `p25_informe_final/p25_master_table.csv` (filas P26) y figuras en `p27_final/`.\n",
        "\n",
        "---\n",
        "\n",
        "## 4) Política de decisión **S2** (activa)\n",
        "**Objetivo:** maximizar sensibilidad sin colapsar en “todo positivo” en dominios tipo OAS2.\n",
        "\n",
        "- **OAS1 → 5:1 (FN:FP)** con umbral aprendido en VAL → **thr = 0.42**\n",
        "- **OAS2 → “recall objetivo” (VAL, target≈0.85; aplicado en TEST)** → **thr ≈ 0.4928655**\n",
        "\n",
        "**Resultados TEST @S2 (confusiones y métricas):**\n",
        "- **OAS1 (0.42):** TP=14, FP=9, TN=18, FN=6 → **Recall=0.700**, Precision=0.609, Acc=0.681, **Coste=39**\n",
        "- **OAS2 (≈0.4929):** TP=11, FP=6, TN=5, FN=1 → **Recall=0.917**, Precision=0.647, Acc=0.696, **Coste=11**\n",
        "\n",
        "**Dónde cambiar:** `p26_release/CONFIG/deployment_config.json`\n",
        "- `thresholds = {\"OAS1\": 0.42, \"OAS2\": 0.4928655287824083}`\n",
        "- `thresholds_5to1 = {\"OAS1\": 0.42, \"OAS2\": 0.49}` *(fallback 5:1 puro)*\n",
        "\n",
        "---\n",
        "\n",
        "## 5) Calibración y monitorización\n",
        "- **ECE/MCE (TEST intermodal, P26):** ALL≈0.178 / OAS1≈0.150 / **OAS2≈0.313** → monitorizar y **recalibrar** por cohorte si **ECE>0.20** o hay drift (sitio/escáner/población).\n",
        "- Recomendar telemetría de **TP/FP/TN/FN**, **tasa de positivos** y **ECE** por cohorte. Recalibración con ventana móvil (≥50–100 casos).\n",
        "\n",
        "---\n",
        "\n",
        "## 6) Limitaciones\n",
        "- Tamaños por cohorte moderados → **IC amplios**.\n",
        "- **Shift** entre OAS1/OAS2 → aplicar **umbrales por cohorte** y validación local antes de uso asistencial.\n",
        "- El modelo **no** es un diagnóstico automático; es soporte a la decisión.\n",
        "\n",
        "---\n",
        "\n",
        "## 7) Cómo ejecutar (resumen)\n",
        "1. **Imagen → `p_img`:** `compute_pimg_from_features.py` sobre las matrices de features por paciente (catálogo P11 + OAS2 p14).\n",
        "2. **Clínico → `p_clin`:** CSV con columnas mínimas (arriba).\n",
        "3. **Inferencia E2E:** `predict_end_to_end.py` → combina `p_img + p_clin` (LATE), **calibra por cohorte** (P26b) y **aplica S2**.\n",
        "4. Salidas: CSV de probabilidades/calibradas, decisión (0/1), y **QA** con confusiones/Coste.\n",
        "\n",
        "---\n",
        "\n",
        "## 8) Versionado y reproducibilidad\n",
        "- **Release:** `p26_release/` (zip con 23 ficheros).\n",
        "- **Modelos:** `p24_model.pkl`, `p24_platt.pkl`, `p26_clinical_model.pkl`.\n",
        "- **Config:** `CONFIG/deployment_config.json` (+ backups).\n",
        "- **QA:** `QA/p26b_test_report_recall_target.csv`.\n",
        "- **Trazas:** `MANIFEST.json`, `ENVIRONMENT.txt`.\n",
        "\n",
        "---\n",
        "\n",
        "## 9) Figuras (collage rápido)\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"50%\">\n",
        "<b>AUC — ALL (TEST)</b><br>\n",
        "<img src=\"../p27_final/p27_auc_ALL.png\" alt=\"AUC ALL\" />\n",
        "</td>\n",
        "<td width=\"50%\">\n",
        "<b>OAS2 · S2 vs 5:1 (TEST)</b><br>\n",
        "<img src=\"../p27_final/p27_s2_vs_5to1_OAS2.png\" alt=\"S2 vs 5:1 OAS2\" />\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "> Más figuras en `p27_final/`:\n",
        "> - `p27_auc_*.png`, `p27_prauc_*.png`, `p27_brier_*.png`\n",
        "> - (si existe) `p27_s2_vs_5to1_OAS2.png`\n",
        "\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "# 3) Escribir nuevo contenido\n",
        "mc_path.write_text(mc, encoding=\"utf-8\")\n",
        "print(\"✅ MODEL_CARD.md escrito en:\", mc_path)\n",
        "print(\"🕒\", datetime.now(timezone.utc).isoformat())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA2Yb6cGRihd",
        "outputId": "f644c42e-206f-4e24-9b8b-7c460d14eba3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MODEL_CARD.md escrito en: /content/drive/MyDrive/CognitivaAI/p26_release/MODEL_CARD.md\n",
            "🕒 2025-09-08T21:40:46.211414+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Opcional: escribir HOW_TO_DEPLOY.md + README_RELEASE.md y reempaquetar ===\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "import hashlib, json, shutil\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "REL  = BASE/\"p26_release\"\n",
        "REL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "howto = REL/\"HOW_TO_DEPLOY.md\"\n",
        "readme_rel = REL/\"README_RELEASE.md\"\n",
        "\n",
        "HOWTO_MD = r\"\"\"# HOW_TO_DEPLOY — CognitivaAI Intermodal (P26/P27)\n",
        "[... pega aquí el bloque HOW_TO_DEPLOY.md de arriba si quieres editarlo a mano ...]\n",
        "\"\"\"\n",
        "README_REL_MD = r\"\"\"# README — Paquete de Release (P26/P27)\n",
        "[... pega aquí el bloque README_RELEASE.md de arriba si quieres editarlo a mano ...]\n",
        "\"\"\"\n",
        "\n",
        "# 1) Escribir archivos\n",
        "howto.write_text(HOWTO_MD.strip()+\"\\n\", encoding=\"utf-8\")\n",
        "readme_rel.write_text(README_REL_MD.strip()+\"\\n\", encoding=\"utf-8\")\n",
        "print(\"✅ HOW_TO_DEPLOY.md y README_RELEASE.md escritos.\")\n",
        "\n",
        "# 2) Regenerar MANIFEST.json\n",
        "def sha256(p: Path) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1024*1024), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "files = []\n",
        "for p in REL.rglob(\"*\"):\n",
        "    if p.is_file() and p.name != \"p26_release.zip\":\n",
        "        files.append({\"path\": str(p.relative_to(REL)), \"sha256\": sha256(p), \"size\": p.stat().st_size})\n",
        "\n",
        "manifest = {\n",
        "    \"version\": \"v1.2\",\n",
        "    \"generated_at\": datetime.now(timezone.utc).isoformat(),\n",
        "    \"files\": files\n",
        "}\n",
        "(REL/\"MANIFEST.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
        "print(\"🧾 MANIFEST.json regenerado.\")\n",
        "\n",
        "# 3) Reempaquetar ZIP\n",
        "zip_path = BASE/\"p26_release.zip\"\n",
        "if zip_path.exists():\n",
        "    zip_path.unlink()\n",
        "shutil.make_archive(str(zip_path.with_suffix(\"\")), \"zip\", REL)\n",
        "print(\"🎁 ZIP listo:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_on3tMHRyWo",
        "outputId": "7a9ecd1b-621c-4961-c9e2-8c93f71decae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ HOW_TO_DEPLOY.md y README_RELEASE.md escritos.\n",
            "🧾 MANIFEST.json regenerado.\n",
            "🎁 ZIP listo: /content/drive/MyDrive/CognitivaAI/p26_release.zip\n"
          ]
        }
      ]
    }
  ]
}