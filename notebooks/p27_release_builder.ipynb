{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BRoH6xee8Hs",
        "outputId": "6bd88fd3-fbd3-4c1a-b801-895b084be0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "BASE: /content/drive/MyDrive/CognitivaAI\n"
          ]
        }
      ],
      "source": [
        "# P27 ‚Äî release builder (v1.1)\n",
        "from pathlib import Path\n",
        "import json, os, shutil, hashlib, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "REL  = BASE/\"p26_release\"\n",
        "\n",
        "random_state = 42\n",
        "np.random.seed(random_state)\n",
        "random.seed(random_state)\n",
        "\n",
        "def sha256_of_file(p: Path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"): h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def metrics(y, p):\n",
        "    return dict(\n",
        "        AUC=float(roc_auc_score(y,p)),\n",
        "        PRAUC=float(average_precision_score(y,p)),\n",
        "        Brier=float(brier_score_loss(y,p)),\n",
        "    )\n",
        "\n",
        "print(\"BASE:\", BASE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estructura release\n",
        "dirs = {\n",
        "  \"MODELS\": REL/\"MODELS\",\n",
        "  \"CONFIG\": REL/\"CONFIG\",\n",
        "  \"COLSIG\": REL/\"CONFIG/column_signatures\",\n",
        "  \"DOCS\":   REL/\"DOCS\",\n",
        "  \"QA\":     REL/\"QA\",\n",
        "  \"META\":   REL/\"META\",\n",
        "  \"TMP\":    REL/\"_tmp\"\n",
        "}\n",
        "for d in dirs.values(): d.mkdir(parents=True, exist_ok=True)\n",
        "print(\"OK ‚Üí estructura creada en\", REL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mcSXgXMfX4Z",
        "outputId": "3254b5ca-bf57-4c88-a3d8-e5f1596f38e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK ‚Üí estructura creada en /content/drive/MyDrive/CognitivaAI/p26_release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobaciones m√≠nimas\n",
        "P24 = BASE/\"p24_meta_simple\"\n",
        "P26 = BASE/\"p26_intermodal\"\n",
        "CLN = BASE/\"clinical\"\n",
        "\n",
        "assert (P24/\"p24_model.pkl\").exists() and (P24/\"p24_platt.pkl\").exists(), \"Faltan p24_model.pkl o p24_platt.pkl\"\n",
        "assert (P24/\"p24_val_preds.csv\").exists() and (P24/\"p24_test_preds.csv\").exists(), \"Faltan p24_val/test_preds.csv\"\n",
        "assert (P24/\"p24_coefficients.csv\").exists(), \"Falta p24_coefficients.csv (para firma de columnas imagen)\"\n",
        "assert (P26/\"p26_clinical_consolidado.csv\").exists(), \"Falta p26_clinical_consolidado.csv\"\n",
        "assert (CLN/\"p3_clinical_probs.csv\").exists(), \"Falta p3_clinical_probs.csv (probas cl√≠nicas por patient_id)\"\n",
        "\n",
        "# Copiar P24 modelos al release\n",
        "shutil.copy2(P24/\"p24_model.pkl\", dirs[\"MODELS\"]/\"p24_model.pkl\")\n",
        "shutil.copy2(P24/\"p24_platt.pkl\", dirs[\"MODELS\"]/\"p24_platt.pkl\")\n",
        "print(\"OK ‚Üí copiados modelos de P24\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4utcdQzXff71",
        "outputId": "1d85c089-dd03-416d-c6a3-77b88d4cf3c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK ‚Üí copiados modelos de P24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos consolidado cl√≠nico y probas cl√≠nicas (VAL/TEST)\n",
        "df_clin = pd.read_csv(P26/\"p26_clinical_consolidado.csv\")  # 9 features + patient_id\n",
        "clin_probs = pd.read_csv(CLN/\"p3_clinical_probs.csv\")      # patient_id, split, y_prob_clin\n",
        "\n",
        "# Labels (desde P24 preds con y_true)\n",
        "p24_val = pd.read_csv(P24/\"p24_val_preds.csv\")  # patient_id, cohort, y_true, y_prob\n",
        "p24_tst = pd.read_csv(P24/\"p24_test_preds.csv\")\n",
        "\n",
        "# Unimos para armar (VAL/TEST) con y_true\n",
        "val_ids = p24_val[[\"patient_id\",\"cohort\",\"y_true\"]].copy()\n",
        "tst_ids = p24_tst[[\"patient_id\",\"cohort\",\"y_true\"]].copy()\n",
        "\n",
        "# Unir cl√≠nico con ids\n",
        "val_clin = val_ids.merge(df_clin, on=\"patient_id\", how=\"left\")\n",
        "tst_clin = tst_ids.merge(df_clin, on=\"patient_id\", how=\"left\")\n",
        "\n",
        "# Esquema cl√≠nico esperado (9 columnas brutas)\n",
        "clin_cols = [\"Age\",\"Sex\",\"Education\",\"SES\",\"MMSE\",\"eTIV\",\"nWBV\",\"ASF\",\"Delay\"]\n",
        "missing_cols = [c for c in clin_cols if c not in val_clin.columns]\n",
        "assert not missing_cols, f\"Faltan columnas cl√≠nicas: {missing_cols}\"\n",
        "\n",
        "# Armar X,y (VAL) para entrenar modelo cl√≠nico\n",
        "Xc_val = val_clin[clin_cols].copy()\n",
        "yc_val = val_clin[\"y_true\"].astype(int).values\n",
        "\n",
        "# Pipeline cl√≠nico (imputer num√©rico + OHE Sex + scaler + LR)\n",
        "num_cols = [c for c in clin_cols if c!=\"Sex\"]\n",
        "pre = [\n",
        "    (\"impute_num\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scale\", StandardScaler(with_mean=True, with_std=True)),\n",
        "]\n",
        "# OHE Sex -> convertimos a binaria 'Sex_M' aproximando: M/F (si viniera 0/1 tambi√©n funciona)\n",
        "def sex_to_str(s):\n",
        "    if pd.isna(s): return np.nan\n",
        "    s = str(s).strip().upper()\n",
        "    if s in [\"M\",\"MALE\",\"H\"]: return \"M\"\n",
        "    if s in [\"F\",\"FEMALE\",\"Mujer\".upper()]: return \"F\"\n",
        "    return s\n",
        "\n",
        "for split_df in [Xc_val]:\n",
        "    split_df[\"Sex\"] = split_df[\"Sex\"].apply(sex_to_str)\n",
        "\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "# Construimos DataFrame num y cat por separado\n",
        "X_num = Xc_val[num_cols]\n",
        "X_sex = pd.DataFrame({\"Sex\": Xc_val[\"Sex\"]})\n",
        "\n",
        "num_pipe = Pipeline(pre)\n",
        "X_num_tr = num_pipe.fit_transform(X_num)\n",
        "sex_mat  = ohe.fit_transform(X_sex)\n",
        "\n",
        "# Unimos y entrenamos LR\n",
        "Xc_val_mat = np.hstack([X_num_tr, sex_mat])\n",
        "clin_lr = LogisticRegression(max_iter=1000, class_weight=None, solver=\"lbfgs\", random_state=random_state)\n",
        "clin_lr.fit(Xc_val_mat, yc_val)\n",
        "\n",
        "# Guardamos componentes del modelo cl√≠nico:\n",
        "import pickle\n",
        "with open(dirs[\"MODELS\"]/\"p26_clin_num_pipe.pkl\",\"wb\") as f: pickle.dump(num_pipe, f)\n",
        "with open(dirs[\"MODELS\"]/\"p26_clin_ohe.pkl\",\"wb\") as f: pickle.dump(ohe, f)\n",
        "with open(dirs[\"MODELS\"]/\"p26_clin_model.pkl\",\"wb\") as f: pickle.dump(clin_lr, f)\n",
        "\n",
        "print(\"‚úÖ Modelo cl√≠nico entrenado y guardado (VAL).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfXfv5kifiFT",
        "outputId": "7e450221-6697-4ed5-89b9-4fdfa3514807"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo cl√≠nico entrenado y guardado (VAL).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# p_img: usar probas calibradas de P24 (y_prob)\n",
        "val_img = p24_val[[\"patient_id\",\"cohort\",\"y_true\",\"y_prob\"]].rename(columns={\"y_prob\":\"p_img\"})\n",
        "tst_img = p24_tst[[\"patient_id\",\"cohort\",\"y_true\",\"y_prob\"]].rename(columns={\"y_prob\":\"p_img\"})\n",
        "\n",
        "# p_clin: de p3_clinical_probs.csv\n",
        "val_clp = clin_probs[clin_probs[\"split\"]==\"VAL\"][[\"patient_id\",\"y_prob_clin\"]].rename(columns={\"y_prob_clin\":\"p_clin\"})\n",
        "tst_clp = clin_probs[clin_probs[\"split\"]==\"TEST\"][[\"patient_id\",\"y_prob_clin\"]].rename(columns={\"y_prob_clin\":\"p_clin\"})\n",
        "\n",
        "VAL = val_img.merge(val_clp, on=\"patient_id\", how=\"inner\")\n",
        "TST = tst_img.merge(tst_clp, on=\"patient_id\", how=\"inner\")\n",
        "\n",
        "print(\"VAL:\", VAL.shape, \"| TEST:\", TST.shape)\n",
        "assert VAL[\"patient_id\"].is_unique and TST[\"patient_id\"].is_unique\n",
        "print(VAL.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dJmR--ofo3Q",
        "outputId": "6321d9d1-760d-4b90-b965-5a7c92532795"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL: (69, 5) | TEST: (70, 5)\n",
            "  patient_id cohort  y_true     p_img    p_clin\n",
            "0  OAS1_0003   OAS1       1  0.672718  0.422624\n",
            "1  OAS1_0010   OAS1       0  0.433014  0.431642\n",
            "2  OAS1_0016   OAS1       1  0.621040  0.451515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta-LR sobre [p_img, p_clin]\n",
        "X_val = VAL[[\"p_img\",\"p_clin\"]].values\n",
        "y_val = VAL[\"y_true\"].astype(int).values\n",
        "\n",
        "meta = LogisticRegression(max_iter=1000, solver=\"lbfgs\", random_state=random_state)\n",
        "meta.fit(X_val, y_val)\n",
        "\n",
        "# Predicci√≥n cruda\n",
        "VAL[\"p_meta_raw\"] = meta.predict_proba(X_val)[:,1]\n",
        "\n",
        "# Evaluaci√≥n cruda (pre-calibraci√≥n)\n",
        "m_val = metrics(y_val, VAL[\"p_meta_raw\"].values)\n",
        "print(\"LATE (raw) VAL:\", m_val)\n",
        "\n",
        "# Guardar meta\n",
        "import pickle\n",
        "with open(dirs[\"MODELS\"]/\"p26_meta_late.pkl\",\"wb\") as f: pickle.dump(meta, f)\n",
        "\n",
        "# Predicci√≥n en TEST (cruda)\n",
        "X_tst = TST[[\"p_img\",\"p_clin\"]].values\n",
        "y_tst = TST[\"y_true\"].astype(int).values\n",
        "TST[\"p_meta_raw\"] = meta.predict_proba(X_tst)[:,1]\n",
        "m_tst = metrics(y_tst, TST[\"p_meta_raw\"].values)\n",
        "print(\"LATE (raw) TEST:\", m_tst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uInMWI7Uft7o",
        "outputId": "4113522a-6610-4d8c-94da-b3c098a3ce53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LATE (raw) VAL: {'AUC': 0.9040747028862479, 'PRAUC': 0.9251447096482674, 'Brier': 0.20186942272517908}\n",
            "LATE (raw) TEST: {'AUC': 0.7360197368421053, 'PRAUC': 0.7285510809902204, 'Brier': 0.2286766661338769}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Platt por cohorte = LR sobre score\n",
        "def fit_platt(y, s):\n",
        "    m = LogisticRegression(solver=\"lbfgs\", random_state=random_state)\n",
        "    m.fit(s.reshape(-1,1), y.astype(int))\n",
        "    return m\n",
        "\n",
        "coh_cal = {}\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    mask = VAL[\"cohort\"]==coh\n",
        "    m = fit_platt(VAL.loc[mask,\"y_true\"].values, VAL.loc[mask,\"p_meta_raw\"].values)\n",
        "    coh_cal[coh] = m\n",
        "\n",
        "# Guardar calibradores\n",
        "import pickle\n",
        "with open(dirs[\"MODELS\"]/\"p26b_platt_OAS1.pkl\",\"wb\") as f: pickle.dump(coh_cal[\"OAS1\"], f)\n",
        "with open(dirs[\"MODELS\"]/\"p26b_platt_OAS2.pkl\",\"wb\") as f: pickle.dump(coh_cal[\"OAS2\"], f)\n",
        "\n",
        "# Aplicar calibraci√≥n a VAL y TEST\n",
        "def platt_pred(m, s): return m.predict_proba(s.reshape(-1,1))[:,1]\n",
        "\n",
        "VAL[\"p_cal\"] = np.nan\n",
        "TST[\"p_cal\"] = np.nan\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    vm = VAL[\"cohort\"]==coh\n",
        "    tm = TST[\"cohort\"]==coh\n",
        "    VAL.loc[vm,\"p_cal\"] = platt_pred(coh_cal[coh], VAL.loc[vm,\"p_meta_raw\"].values)\n",
        "    TST.loc[tm,\"p_cal\"] = platt_pred(coh_cal[coh], TST.loc[tm,\"p_meta_raw\"].values)\n",
        "\n",
        "print(\"VAL P26b:\", metrics(VAL[\"y_true\"], VAL[\"p_cal\"]))\n",
        "print(\"TST P26b:\", metrics(TST[\"y_true\"], TST[\"p_cal\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j93Jm3pHfyfW",
        "outputId": "9e43f980-61c3-4c59-8dd1-318f29769ec4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL P26b: {'AUC': 0.7614601018675721, 'PRAUC': 0.7293917476096345, 'Brier': 0.23428651719818258}\n",
            "TST P26b: {'AUC': 0.6842105263157895, 'PRAUC': 0.6595296459970565, 'Brier': 0.24072039406689189}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def best_cost_thr(y, p, C_FN=5.0, C_FP=1.0, grid=1001):\n",
        "    thrs = np.linspace(0,1,grid)\n",
        "    best = None\n",
        "    for t in thrs:\n",
        "        ypred = (p>=t).astype(int)\n",
        "        TP = ((y==1)&(ypred==1)).sum()\n",
        "        FP = ((y==0)&(ypred==1)).sum()\n",
        "        FN = ((y==1)&(ypred==0)).sum()\n",
        "        cost = C_FN*FN + C_FP*FP\n",
        "        if (best is None) or (cost < best[\"Cost\"]-1e-9):\n",
        "            best = dict(Thr=float(t), Cost=float(cost), TP=int(TP), FP=int(FP), FN=int(FN))\n",
        "    return best\n",
        "\n",
        "thr = {}\n",
        "rows=[]\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    m = VAL[\"cohort\"]==coh\n",
        "    b = best_cost_thr(VAL.loc[m,\"y_true\"].values, VAL.loc[m,\"p_cal\"].values, 5.0, 1.0)\n",
        "    thr[coh] = b[\"Thr\"]\n",
        "    rows.append({\"Cohort\":coh, **b})\n",
        "\n",
        "thr_json = {\"policy\":\"single\",\"cost_policy\":\"FN:FP=5:1\",\"thresholds\":thr}\n",
        "with open(dirs[\"CONFIG\"]/\"deployment_config.json\",\"w\") as f:\n",
        "    json.dump(thr_json, f, indent=2)\n",
        "\n",
        "pd.DataFrame(rows).to_csv(dirs[\"TMP\"]/\"val_thresholds_cost5to1.csv\", index=False)\n",
        "print(\"Umbrales (VAL):\", thr_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ubxIiftf5vH",
        "outputId": "547bbd1b-0875-4b18-abd8-aaf0759b0e3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Umbrales (VAL): {'policy': 'single', 'cost_policy': 'FN:FP=5:1', 'thresholds': {'OAS1': 0.42, 'OAS2': 0.49}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_report(df, thr):\n",
        "    y = df[\"y_true\"].values.astype(int)\n",
        "    p = df[\"p_cal\"].values.astype(float)\n",
        "    ypred = (p>=thr).astype(int)\n",
        "    TP = int(((y==1)&(ypred==1)).sum())\n",
        "    FP = int(((y==0)&(ypred==1)).sum())\n",
        "    TN = int(((y==0)&(ypred==0)).sum())\n",
        "    FN = int(((y==1)&(ypred==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/len(y)\n",
        "    cost = 5*FN + 1*FP\n",
        "    return dict(TP=TP,FP=FP,TN=TN,FN=FN,Precision=prec,Recall=rec,Acc=acc,Cost=cost)\n",
        "\n",
        "rows=[]\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    d = TST[TST[\"cohort\"]==coh]\n",
        "    rep = confusion_report(d, thr[coh])\n",
        "    rows.append(dict(Cohort=coh, Thr=thr[coh], **rep))\n",
        "\n",
        "rep_df = pd.DataFrame(rows)\n",
        "out_rep = REL/\"QA/p26b_test_report_cost_5to1.csv\"\n",
        "rep_df.to_csv(out_rep, index=False)\n",
        "print(rep_df)\n",
        "print(\"Guardado:\", out_rep)\n",
        "\n",
        "# Guardar preds calibradas para golden set\n",
        "VAL[[\"patient_id\",\"cohort\",\"y_true\",\"p_cal\"]].to_csv(REL/\"QA/p26b_val_preds_calibrated.csv\", index=False)\n",
        "TST[[\"patient_id\",\"cohort\",\"y_true\",\"p_cal\"]].to_csv(REL/\"QA/p26b_test_preds_calibrated.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6a4KTzgf-WV",
        "outputId": "b510273e-7766-42eb-d7bd-3d73b1cdff12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cohort   Thr  TP  FP  TN  FN  Precision  Recall       Acc  Cost\n",
            "0   OAS1  0.42  14   9  18   6   0.608696     0.7  0.680851    39\n",
            "1   OAS2  0.49  12  11   0   0   0.521739     1.0  0.521739    11\n",
            "Guardado: /content/drive/MyDrive/CognitivaAI/p26_release/QA/p26b_test_report_cost_5to1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clinical signature (nombres y tipos esperados)\n",
        "clinical_signature = {\n",
        "  \"fields\": [\n",
        "    {\"name\":\"Age\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"Sex\",\"dtype\":\"str\",\"allowed\":[\"M\",\"F\"]},\n",
        "    {\"name\":\"Education\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"SES\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"MMSE\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"eTIV\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"nWBV\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"ASF\",\"dtype\":\"float\"},\n",
        "    {\"name\":\"Delay\",\"dtype\":\"float\"}\n",
        "  ],\n",
        "  \"notes\":\"Sex se normaliza a {'M','F'} internamente; num√©ricos con imputaci√≥n mediana + StandardScaler.\"\n",
        "}\n",
        "with open(dirs[\"COLSIG\"]/\"clinical_signature.json\",\"w\") as f:\n",
        "    json.dump(clinical_signature, f, indent=2)\n",
        "\n",
        "# Image signature: leemos p24_coefficients.csv (√≠ndice = features)\n",
        "coef = pd.read_csv(P24/\"p24_coefficients.csv\")\n",
        "feat_col = \"Feature\" if \"Feature\" in coef.columns else coef.columns[0]\n",
        "img_features = coef[feat_col].tolist()\n",
        "image_signature = {\n",
        "  \"features\": img_features,\n",
        "  \"notes\":\"Orden/nombres deben coincidir con entrenamiento P24. Si se provee p_img directamente, esta firma puede no ser usada.\"\n",
        "}\n",
        "with open(dirs[\"COLSIG\"]/\"image_signature.json\",\"w\") as f:\n",
        "    json.dump(image_signature, f, indent=2)\n",
        "\n",
        "print(\"OK ‚Üí firmas creadas.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO-MfhSdgE2o",
        "outputId": "113d01f1-393c-48de-f83c-eadf832270ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK ‚Üí firmas creadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_card = f\"\"\"# MODEL CARD ‚Äî CognitivaAI v1.1 (P26b single)\n",
        "\n",
        "**Arquitectura:**\n",
        "- Imagen (P24: modelo + Platt) ‚Üí `p_img`\n",
        "- Cl√≠nico (LR con imputaci√≥n+scaler) ‚Üí `p_clin`\n",
        "- Fusi√≥n Late (meta-LR sobre `p_img`+`p_clin`)\n",
        "- Calibraci√≥n Platt **por cohorte** (P26b) ‚Üí `proba_cal`\n",
        "- Decisi√≥n por coste (FN:FP=5:1) con umbrales aprendidos en VAL:\n",
        "  - OAS1 = {thr['OAS1']:.3f}\n",
        "  - OAS2 = {thr['OAS2']:.3f}\n",
        "\n",
        "**M√©tricas (TEST, probs calibradas):**\n",
        "- ALL: AUC‚âà{roc_auc_score(TST['y_true'], TST['p_cal']):.3f} ¬∑ PR-AUC‚âà{average_precision_score(TST['y_true'], TST['p_cal']):.3f} ¬∑ Brier‚âà{brier_score_loss(TST['y_true'], TST['p_cal']):.3f}\n",
        "- OAS1 / OAS2: ver `QA/p26b_test_report_cost_5to1.csv`.\n",
        "\n",
        "**Suposiciones de entrada:**\n",
        "- Cl√≠nico: 9 campos (ver `clinical_signature.json`).\n",
        "- Imagen: usar pipeline P24 **o** aportar `p_img` directo.\n",
        "- Cohorte: 'OAS1'/'OAS2' (para calibrador/umbral). Si se desconoce, usar 'OAS1' por defecto y monitorizar calibraci√≥n.\n",
        "\n",
        "**Riesgos & mitigaciones:**\n",
        "- Descalibraci√≥n en dominios nuevos ‚Üí recalibrar Platt por sitio con ‚â•50‚Äì100 casos y actualizar umbral 5:1.\n",
        "- Tama√±o muestral reducido ‚Üí reportar ICs y monitorizar ECE/MCE.\n",
        "\n",
        "**Archivos clave:** ver `META/MANIFEST.json`.\n",
        "\"\"\"\n",
        "howto = \"\"\"# HOW TO DEPLOY ‚Äî CognitivaAI v1.1\n",
        "\n",
        "## 1) Entorno\n",
        "- Python 3.10+\n",
        "- Instala dependencias de `META/ENVIRONMENT.txt` (bloqueado sklearn).\n",
        "\n",
        "## 2) Inferencia por lote (CSV)\n",
        "- Prepara CSV con columnas cl√≠nicas (ver `clinical_signature.json`) y/o `p_img`.\n",
        "- Ejecuta `scripts/predict_batch.py` (opcional: crearlo) para leer CSV y generar `proba_cal` y `decision`.\n",
        "\n",
        "## 3) API (opcional)\n",
        "- Montar un endpoint `/predict` que:\n",
        "  - Valide `clinical` y/o calcule `p_img` con P24.\n",
        "  - Aplique fusi√≥n Late + Platt por cohorte.\n",
        "  - Devuelva `proba_cal`, `decision` y `threshold_used`.\n",
        "\n",
        "## 4) Monitorizaci√≥n\n",
        "- Guardar `proba_cal` y decisi√≥n por cohorte.\n",
        "- Semanal: ECE/MCE por cohorte; recall/precision cuando lleguen etiquetas.\n",
        "- Alarmas: ECE>0.20 (OAS1) / >0.25 (OAS2); recall OAS2<0.65.\n",
        "\"\"\"\n",
        "(dirs[\"DOCS\"]/\"MODEL_CARD.md\").write_text(model_card, encoding=\"utf-8\")\n",
        "(dirs[\"DOCS\"]/\"HOW_TO_DEPLOY.md\").write_text(howto, encoding=\"utf-8\")\n",
        "print(\"OK ‚Üí DOCS creados.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etYtNgdVgHHq",
        "outputId": "2265b079-d8b1-4d63-e5da-3fded9ae0952"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK ‚Üí DOCS creados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Golden set: usamos TEST calibrado (subset estable)\n",
        "gold = TST.sample(n=min(40, len(TST)), random_state=random_state)[[\"patient_id\",\"cohort\",\"y_true\",\"p_img\",\"p_clin\",\"p_cal\"]]\n",
        "gold.to_csv(dirs[\"QA\"]/\"golden_set.csv\", index=False)\n",
        "\n",
        "# Checksums de modelos\n",
        "chk = {}\n",
        "for p in (dirs[\"MODELS\"]).glob(\"*.pkl\"):\n",
        "    chk[p.name] = sha256_of_file(p)\n",
        "(pd.Series(chk, name=\"sha256\")\n",
        "   .to_frame().to_csv(dirs[\"QA\"]/\"qa_checksums.csv\"))\n",
        "\n",
        "print(\"OK ‚Üí golden_set y checksums listos.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVVIr_DdgMaD",
        "outputId": "7e1335d9-3851-4fb8-ef46-53b62acf3cbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK ‚Üí golden_set y checksums listos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "manifest = {\n",
        "  \"version\":\"v1.1\",\n",
        "  \"files\":[]\n",
        "}\n",
        "for root, _, files in os.walk(REL):\n",
        "    for fn in files:\n",
        "        p = Path(root)/fn\n",
        "        relp = p.relative_to(REL).as_posix()\n",
        "        if \"/_tmp/\" in relp:\n",
        "            continue\n",
        "        manifest[\"files\"].append({\n",
        "            \"path\": relp,\n",
        "            \"sha256\": sha256_of_file(p),\n",
        "            \"bytes\": p.stat().st_size\n",
        "        })\n",
        "with open(dirs[\"META\"]/\"MANIFEST.json\",\"w\") as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "print(\"OK ‚Üí MANIFEST.json generado con\", len(manifest[\"files\"]), \"ficheros.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyg5n5pogRZz",
        "outputId": "a3a1982d-bf39-4c67-a21e-aef0bcf3a3c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK ‚Üí MANIFEST.json generado con 19 ficheros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos pip freeze (para reproducibilidad)\n",
        "import subprocess, sys\n",
        "out = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode()\n",
        "# Recomendaci√≥n: fijar scikit-learn==1.7.1 si coincide con tus pickles\n",
        "lines = out.strip().splitlines()\n",
        "(dirs[\"META\"]/\"ENVIRONMENT.txt\").write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "print(\"OK ‚Üí ENVIRONMENT.txt escrito.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqX-x2ktgV7P",
        "outputId": "b56153cb-e7c3-423c-da10-93ae64701b47"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK ‚Üí ENVIRONMENT.txt escrito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = REL.with_suffix(\".zip\")\n",
        "if zip_path.exists(): zip_path.unlink()\n",
        "shutil.make_archive(str(REL), \"zip\", root_dir=REL)\n",
        "print(\"üéÅ Release ZIP listo:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89hJ3JRUgauM",
        "outputId": "f65ba24d-2dd5-47ba-acbe-1b4871968d0a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéÅ Release ZIP listo: /content/drive/MyDrive/CognitivaAI/p26_release.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === S2.1: OAS2 con recall objetivo en VAL; OAS1 se mantiene 5:1 ===\n",
        "from pathlib import Path\n",
        "import json, numpy as np, pandas as pd\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "REL  = BASE/\"p26_release\"\n",
        "\n",
        "val = pd.read_csv(REL/\"QA/p26b_val_preds_calibrated.csv\")   # cols: patient_id, cohort, y_true, p_cal\n",
        "tst = pd.read_csv(REL/\"QA/p26b_test_preds_calibrated.csv\")\n",
        "\n",
        "def thr_for_recall(y, p, target=0.85):\n",
        "    \"\"\"Devuelve el mayor umbral t tal que recall(t) >= target (conservador en FP).\"\"\"\n",
        "    y = np.asarray(y).astype(int)\n",
        "    p = np.asarray(p).astype(float)\n",
        "    # Candidatos = valores √∫nicos de p (y extremos 0,1)\n",
        "    cand = np.unique(np.concatenate([p, [0.0, 1.0]]))\n",
        "    best_t = 0.0\n",
        "    found = False\n",
        "    # Probamos de 1.0 -> 0.0 para quedarnos con el UMBRAL M√ÅS ALTO que cumpla recall>=target\n",
        "    for t in sorted(cand, reverse=True):\n",
        "        yhat = (p >= t).astype(int)\n",
        "        TP = ((y==1)&(yhat==1)).sum()\n",
        "        FN = ((y==1)&(yhat==0)).sum()\n",
        "        rec = TP / (TP + FN) if (TP+FN)>0 else 0.0\n",
        "        if rec >= target:\n",
        "            best_t = float(t)\n",
        "            found = True\n",
        "            break\n",
        "    # Si jam√°s alcanzamos el target, caemos a t=0.0 (todo positivo)\n",
        "    return best_t, found\n",
        "\n",
        "def confusion_at(df, t):\n",
        "    y = df[\"y_true\"].to_numpy(int)\n",
        "    p = df[\"p_cal\"].to_numpy(float)\n",
        "    yhat = (p >= t).astype(int)\n",
        "    TP = int(((y==1)&(yhat==1)).sum())\n",
        "    FP = int(((y==0)&(yhat==1)).sum())\n",
        "    TN = int(((y==0)&(yhat==0)).sum())\n",
        "    FN = int(((y==1)&(yhat==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/len(y) if len(y)>0 else np.nan\n",
        "    cost = 5*FN + 1*FP\n",
        "    return dict(TP=TP,FP=FP,TN=TN,FN=FN,Precision=prec,Recall=rec,Acc=acc,Cost=cost)\n",
        "\n",
        "# 1) Leer deployment_config actual (tiene 5:1)\n",
        "cfg_path = REL/\"CONFIG/deployment_config.json\"\n",
        "cfg = json.loads(cfg_path.read_text())\n",
        "\n",
        "# Guardamos copia de seguridad\n",
        "(REL/\"CONFIG/deployment_config.backup.json\").write_text(json.dumps(cfg, indent=2))\n",
        "\n",
        "# 2) Calcular umbral OAS2 @ recall objetivo en VAL\n",
        "target_recall = 0.85\n",
        "val_oas2 = val[val[\"cohort\"]==\"OAS2\"].copy()\n",
        "t_rec, ok = thr_for_recall(val_oas2[\"y_true\"], val_oas2[\"p_cal\"], target=target_recall)\n",
        "\n",
        "# 3) Mantener OAS1 desde 5:1 del config actual (no tocamos)\n",
        "thr_oas1_5to1 = float(cfg[\"thresholds\"][\"OAS1\"])\n",
        "thr_oas2_5to1 = float(cfg[\"thresholds\"][\"OAS2\"])\n",
        "\n",
        "# 4) Actualizamos config principal para usar S2 por defecto\n",
        "cfg[\"policy\"] = \"single\"\n",
        "cfg[\"cost_policy\"] = \"FN:FP=5:1 (OAS1) + recall_target (OAS2)\"\n",
        "cfg[\"thresholds\"] = {\n",
        "    \"OAS1\": thr_oas1_5to1,\n",
        "    \"OAS2\": float(t_rec)\n",
        "}\n",
        "# y preservamos umbrales 5:1 como alternativa expl√≠cita\n",
        "cfg[\"thresholds_5to1\"] = {\"OAS1\": thr_oas1_5to1, \"OAS2\": thr_oas2_5to1}\n",
        "cfg[\"thresholds_recall_target\"] = {\"OAS2\": {\"target\": target_recall, \"thr_val\": float(t_rec), \"found\": bool(ok)}}\n",
        "\n",
        "cfg_path.write_text(json.dumps(cfg, indent=2))\n",
        "print(\"‚úÖ Config actualizada con S2:\",\n",
        "      json.dumps(cfg[\"thresholds\"], indent=2),\n",
        "      \"\\n(backup en CONFIG/deployment_config.backup.json)\")\n",
        "\n",
        "# 5) Report en TEST con los nuevos umbrales\n",
        "rows = []\n",
        "for coh, thr in [(\"OAS1\", thr_oas1_5to1), (\"OAS2\", float(t_rec))]:\n",
        "    d = tst[tst[\"cohort\"]==coh].copy()\n",
        "    rep = confusion_at(d, thr)\n",
        "    rows.append(dict(Cohort=coh, Thr=thr, **rep))\n",
        "rep_df = pd.DataFrame(rows)\n",
        "out = REL/\"QA/p26b_test_report_recall_target.csv\"\n",
        "rep_df.to_csv(out, index=False)\n",
        "print(\"\\nTEST @S2\")\n",
        "print(rep_df)\n",
        "print(\"\\nüíæ Guardado:\", out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGtK75f5k4na",
        "outputId": "3c0c6439-1155-48fe-d7ad-e677a510cc45"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Config actualizada con S2: {\n",
            "  \"OAS1\": 0.42,\n",
            "  \"OAS2\": 0.4928655287824083\n",
            "} \n",
            "(backup en CONFIG/deployment_config.backup.json)\n",
            "\n",
            "TEST @S2\n",
            "  Cohort       Thr  TP  FP  TN  FN  Precision    Recall       Acc  Cost\n",
            "0   OAS1  0.420000  14   9  18   6   0.608696  0.700000  0.680851    39\n",
            "1   OAS2  0.492866  11   6   5   1   0.647059  0.916667  0.695652    11\n",
            "\n",
            "üíæ Guardado: /content/drive/MyDrive/CognitivaAI/p26_release/QA/p26b_test_report_recall_target.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === S2.2: revertir a 5:1 en ambos cohortes (opcional) ===\n",
        "from pathlib import Path\n",
        "import json\n",
        "REL = Path(\"/content/drive/MyDrive/CognitivaAI/p26_release\")\n",
        "cfg_path = REL/\"CONFIG/deployment_config.json\"\n",
        "cfg = json.loads(cfg_path.read_text())\n",
        "\n",
        "# Recuperamos los de 5:1 (guardados en thresholds_5to1)\n",
        "t_5to1 = cfg.get(\"thresholds_5to1\", cfg[\"thresholds\"])  # por si no existe\n",
        "cfg[\"policy\"] = \"single\"\n",
        "cfg[\"cost_policy\"] = \"FN:FP=5:1\"\n",
        "cfg[\"thresholds\"] = {\"OAS1\": float(t_5to1[\"OAS1\"]), \"OAS2\": float(t_5to1[\"OAS2\"])}\n",
        "\n",
        "cfg_path.write_text(json.dumps(cfg, indent=2))\n",
        "print(\"‚Ü©Ô∏è  Revertido a 5:1 puro:\", cfg[\"thresholds\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x4yLrxqk6_n",
        "outputId": "f3c84b06-635a-4573-9bb0-61338d9056e7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚Ü©Ô∏è  Revertido a 5:1 puro: {'OAS1': 0.42, 'OAS2': 0.49}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json, pandas as pd, numpy as np\n",
        "\n",
        "REL = Path(\"/content/drive/MyDrive/CognitivaAI/p26_release\")\n",
        "cfg = json.loads((REL/\"CONFIG/deployment_config.json\").read_text())\n",
        "thr = cfg[\"thresholds\"]\n",
        "\n",
        "tst = pd.read_csv(REL/\"QA/p26b_test_preds_calibrated.csv\")  # patient_id, cohort, y_true, p_cal\n",
        "def report_for(df, t):\n",
        "    y, p = df[\"y_true\"].to_numpy(int), df[\"p_cal\"].to_numpy(float)\n",
        "    yhat = (p >= t).astype(int)\n",
        "    TP = int(((y==1)&(yhat==1)).sum()); FP = int(((y==0)&(yhat==1)).sum())\n",
        "    TN = int(((y==0)&(yhat==0)).sum()); FN = int(((y==1)&(yhat==0)).sum())\n",
        "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
        "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
        "    acc  = (TP+TN)/len(y)\n",
        "    cost = 5*FN + 1*FP\n",
        "    return dict(TP=TP,FP=FP,TN=TN,FN=FN,Precision=prec,Recall=rec,Acc=acc,Cost=cost)\n",
        "\n",
        "rows=[]\n",
        "for coh in [\"OAS1\",\"OAS2\"]:\n",
        "    d = tst[tst[\"cohort\"]==coh].copy()\n",
        "    rows.append(dict(Cohort=coh, Thr=thr[coh], **report_for(d, thr[coh])))\n",
        "print(pd.DataFrame(rows))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8lrrj_snX4H",
        "outputId": "59d00162-559e-4680-9810-dce26781525f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Cohort       Thr  TP  FP  TN  FN  Precision    Recall       Acc  Cost\n",
            "0   OAS1  0.420000  14   9  18   6   0.608696  0.700000  0.680851    39\n",
            "1   OAS2  0.492866  11   6   5   1   0.647059  0.916667  0.695652    11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === P27 helper ===\n",
        "# Actualiza documentaci√≥n con la \"Pol√≠tica activa (S2)\", regenera MANIFEST y el ZIP del release.\n",
        "from pathlib import Path\n",
        "import json, os, hashlib, shutil, re, subprocess, sys\n",
        "from datetime import datetime\n",
        "\n",
        "# 0) Paths\n",
        "REL = Path(\"/content/drive/MyDrive/CognitivaAI/p26_release\")\n",
        "DOCS = REL/\"DOCS\"\n",
        "CFG  = REL/\"CONFIG\"/\"deployment_config.json\"\n",
        "MANI = REL/\"META\"/\"MANIFEST.json\"\n",
        "ENV  = REL/\"META\"/\"ENVIRONMENT.txt\"\n",
        "\n",
        "assert REL.exists(), f\"No existe release: {REL}\"\n",
        "assert CFG.exists(), f\"No existe config: {CFG}\"\n",
        "DOCS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Cargar pol√≠tica/umbrales desde config\n",
        "cfg = json.loads(CFG.read_text())\n",
        "thr = cfg[\"thresholds\"]\n",
        "policy_str = cfg.get(\"cost_policy\", \"FN:FP=5:1 (OAS1) + recall_target (OAS2)\")\n",
        "t_oas1 = float(thr[\"OAS1\"])\n",
        "t_oas2 = float(thr[\"OAS2\"])\n",
        "recall_target = cfg.get(\"thresholds_recall_target\", {}).get(\"OAS2\", {}).get(\"target\", 0.85)\n",
        "\n",
        "# 2) Utilidades\n",
        "def sha256_of_file(p: Path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, \"rb\") as f:\n",
        "        for ch in iter(lambda: f.read(8192), b\"\"): h.update(ch)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def upsert_section(md_path: Path, title: str, body_md: str, level: int = 2):\n",
        "    \"\"\"\n",
        "    Inserta o reemplaza una secci√≥n Markdown completa:\n",
        "    - Busca '## title' (o nivel dado).\n",
        "    - Reemplaza hasta el siguiente encabezado del mismo nivel o superior.\n",
        "    - Si no existe, la a√±ade al final con un separador.\n",
        "    \"\"\"\n",
        "    if md_path.exists():\n",
        "        text = md_path.read_text(encoding=\"utf-8\")\n",
        "    else:\n",
        "        text = \"\"\n",
        "    h = \"#\"*level\n",
        "    pattern = rf\"^{h}\\s+{re.escape(title)}\\s*$\"\n",
        "    lines = text.splitlines()\n",
        "    start = None\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.match(pattern, line.strip(), flags=re.IGNORECASE):\n",
        "            start = i\n",
        "            break\n",
        "    new_section = f\"{h} {title}\\n\\n{body_md.strip()}\\n\"\n",
        "    if start is None:\n",
        "        # append\n",
        "        if text.strip():\n",
        "            text = text.rstrip()+\"\\n\\n\"+new_section\n",
        "        else:\n",
        "            text = new_section\n",
        "    else:\n",
        "        # find end (next heading of same or higher level)\n",
        "        end = len(lines)\n",
        "        for j in range(start+1, len(lines)):\n",
        "            if re.match(r\"^#{1,%d}\\s+\" % level, lines[j]):\n",
        "                end = j\n",
        "                break\n",
        "        text = \"\\n\".join(lines[:start] + [new_section.rstrip()] + lines[end:])\n",
        "    md_path.write_text(text, encoding=\"utf-8\")\n",
        "\n",
        "# 3) Construir bloque de pol√≠tica activa (S2)\n",
        "policy_block = f\"\"\"**Pol√≠tica activa (S2)** ‚Äî *single pipeline*\n",
        "- **OAS1:** decisi√≥n por coste **FN:FP=5:1**, umbral **thr = {t_oas1:.6f}**\n",
        "- **OAS2:** **umbral por objetivo de recall** (VAL), target = **{recall_target:.2f}**, umbral **thr = {t_oas2:.6f}**\n",
        "- Alternativas disponibles:\n",
        "  - **5:1 puro**: ver `thresholds_5to1` en `CONFIG/deployment_config.json`.\n",
        "- Nota operativa:\n",
        "  - Monitorizar **ECE/MCE** y **positivity rate** por cohorte; recalibrar y/o ajustar umbral si deriva el dominio.\n",
        "\"\"\"\n",
        "\n",
        "# 4) Marcar en MODEL_CARD.md y HOW_TO_DEPLOY.md\n",
        "model_card = DOCS/\"MODEL_CARD.md\"\n",
        "howto      = DOCS/\"HOW_TO_DEPLOY.md\"\n",
        "upsert_section(model_card, \"Pol√≠tica activa (S2)\", policy_block, level=2)\n",
        "upsert_section(howto, \"Pol√≠tica activa (S2)\", policy_block, level=2)\n",
        "\n",
        "# 5) Regenerar MANIFEST (hash/bytes de todos los ficheros salvo _tmp)\n",
        "manifest = {\"version\":\"v1.1\", \"generated_at\": datetime.utcnow().isoformat()+\"Z\", \"files\":[]}\n",
        "for root, _, files in os.walk(REL):\n",
        "    for fn in files:\n",
        "        p = Path(root)/fn\n",
        "        relp = p.relative_to(REL).as_posix()\n",
        "        if \"/_tmp/\" in relp:\n",
        "            continue\n",
        "        manifest[\"files\"].append({\n",
        "            \"path\": relp,\n",
        "            \"sha256\": sha256_of_file(p),\n",
        "            \"bytes\": p.stat().st_size\n",
        "        })\n",
        "MANI.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "# 6) (Opcional) refrescar ENVIRONMENT.txt si quieres congelar de nuevo\n",
        "try:\n",
        "    out = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode()\n",
        "    ENV.write_text(out, encoding=\"utf-8\")\n",
        "except Exception as e:\n",
        "    print(\"Aviso: no se pudo refrescar ENVIRONMENT.txt:\", e)\n",
        "\n",
        "# 7) Regenerar ZIP del release\n",
        "zip_path = REL.with_suffix(\".zip\")\n",
        "if zip_path.exists():\n",
        "    zip_path.unlink()\n",
        "shutil.make_archive(str(REL), \"zip\", root_dir=REL)\n",
        "\n",
        "print(\"‚úÖ Pol√≠tica S2 marcada en DOCS.\")\n",
        "print(\"üìÑ MODEL_CARD.md y HOW_TO_DEPLOY.md actualizados.\")\n",
        "print(\"üßæ MANIFEST.json regenerado con\", len(manifest[\"files\"]), \"ficheros.\")\n",
        "print(\"üéÅ ZIP listo:\", zip_path)\n",
        "print(\"‚Üí Umbrales activos:\", json.dumps(cfg['thresholds'], indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYZvS5-poo9z",
        "outputId": "f35ba136-fb44-4078-8416-9e2e04219411"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-239857406.py:86: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  manifest = {\"version\":\"v1.1\", \"generated_at\": datetime.utcnow().isoformat()+\"Z\", \"files\":[]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Pol√≠tica S2 marcada en DOCS.\n",
            "üìÑ MODEL_CARD.md y HOW_TO_DEPLOY.md actualizados.\n",
            "üßæ MANIFEST.json regenerado con 23 ficheros.\n",
            "üéÅ ZIP listo: /content/drive/MyDrive/CognitivaAI/p26_release.zip\n",
            "‚Üí Umbrales activos: {\n",
            "  \"OAS1\": 0.42,\n",
            "  \"OAS2\": 0.4928655287824083\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RESET & RESUME (Colab) ---\n",
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Montar Drive (fuerza remount por si qued√≥ colgado)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception as e:\n",
        "    print(\"Drive ya montado o no est√°s en Colab:\", e)\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "P25  = BASE/\"p25_informe_final\"\n",
        "P26R = BASE/\"p26_release\"\n",
        "OUT  = BASE/\"p27_final\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2) Resolver master table de forma robusta\n",
        "mt_path = P25/\"p25_master_table.csv\"\n",
        "if not mt_path.exists():\n",
        "    hits = list(BASE.rglob(\"p25_master_table.csv\"))\n",
        "    if not hits:\n",
        "        raise FileNotFoundError(\"No se encontr√≥ p25_master_table.csv en CognitivaAI/*\")\n",
        "    mt_path = hits[0]\n",
        "print(\"‚úÖ Master table:\", mt_path)\n",
        "\n",
        "# 3) Cargar y filtrar TEST\n",
        "mt = pd.read_csv(mt_path)\n",
        "keep = [\"Pipeline\",\"Split\",\"Cohort\",\"Method\",\"AUC\",\"PRAUC\",\"Brier\"]\n",
        "mt_clean = mt[[c for c in keep if c in mt.columns]].copy()\n",
        "if \"Split\" in mt_clean:\n",
        "    mt_clean[\"Split\"] = mt_clean[\"Split\"].astype(str).str.upper()\n",
        "    mt_clean = mt_clean[mt_clean[\"Split\"]==\"TEST\"]\n",
        "\n",
        "# 4) Figuras AUC/PR-AUC/Brier\n",
        "def plot_bar(metric, cohort, fname):\n",
        "    df = mt_clean[mt_clean[\"Cohort\"]==cohort].copy()\n",
        "    if df.empty or metric not in df: return\n",
        "    df[\"_rank\"] = df.groupby(\"Pipeline\")[metric].transform(lambda s: s.rank(ascending=False, method=\"first\"))\n",
        "    top = df[df[\"_rank\"]==1].sort_values([\"Pipeline\"]).copy()\n",
        "    if top.empty: return\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.bar(top[\"Pipeline\"], top[metric])\n",
        "    plt.title(f\"{metric} ‚Äî {cohort} (TEST)\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.ylim(0, 1 if metric!=\"Brier\" else max(0.3, float(top[metric].max())*1.1))\n",
        "    plt.grid(alpha=0.3, axis=\"y\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUT/fname, dpi=160)\n",
        "    plt.close()\n",
        "\n",
        "for coh in [\"ALL\",\"OAS1\",\"OAS2\"]:\n",
        "    plot_bar(\"AUC\",   coh, f\"p27_auc_{coh}.png\")\n",
        "    plot_bar(\"PRAUC\", coh, f\"p27_prauc_{coh}.png\")\n",
        "    plot_bar(\"Brier\", coh, f\"p27_brier_{coh}.png\")\n",
        "\n",
        "print(\"üé® Figuras guardadas en:\", OUT)\n",
        "\n",
        "# 5) Tabla de decisi√≥n S2 (si est√° el QA del release)\n",
        "qa_candidates = list(P26R.rglob(\"p26b_test_report_recall_target.csv\"))\n",
        "if qa_candidates:\n",
        "    qa = pd.read_csv(qa_candidates[0])[[\"Cohort\",\"Thr\",\"TP\",\"FP\",\"TN\",\"FN\",\"Precision\",\"Recall\",\"Acc\",\"Cost\"]]\n",
        "    qa.to_csv(OUT/\"p27_decision_S2_table.csv\", index=False)\n",
        "    print(\"‚úÖ Tabla decisi√≥n S2:\", qa_candidates[0])\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No se encontr√≥ QA S2; omito tabla de decisi√≥n.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sxM8S9xI10k",
        "outputId": "5bf67d59-cd7f-47c5-c9e8-5f9d01ca1aaa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Master table: /content/drive/MyDrive/CognitivaAI/p25_informe_final/p25_master_table.csv\n",
            "üé® Figuras guardadas en: /content/drive/MyDrive/CognitivaAI/p27_final\n",
            "‚úÖ Tabla decisi√≥n S2: /content/drive/MyDrive/CognitivaAI/p26_release/QA/p26b_test_report_recall_target.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Write MODEL_CARD.md (P27) ===\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "REL  = BASE/\"p26_release\"\n",
        "REL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "mc_path = REL/\"MODEL_CARD.md\"\n",
        "backup  = mc_path.with_suffix(\".backup.md\")\n",
        "\n",
        "# 1) Backup si existe\n",
        "if mc_path.exists():\n",
        "    backup.write_text(mc_path.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
        "\n",
        "# 2) Contenido del Model Card (P27)\n",
        "mc = \"\"\"# Model Card ‚Äî CognitivaAI Intermodal (P26/P27)\n",
        "\n",
        "**Versi√≥n:** P27 (intermodal LATE + calibraci√≥n por cohorte + pol√≠tica S2)\n",
        "**Tarea:** Predicci√≥n binaria (0=Control, 1=Dementia/Converted) a nivel **paciente**.\n",
        "**Entradas:**\n",
        "- **Imagen ‚Üí `p_img`** (probabilidad calibrada con Platt a partir de features por paciente; base P24).\n",
        "- **Cl√≠nico ‚Üí `p_clin`** (LR sobre variables tabulares estandarizadas).\n",
        "**Fusi√≥n:** **LATE** (combinaci√≥n sobre probabilidades calibradas).\n",
        "**Cohortes:** OASIS-1 (cross-sectional) y OASIS-2 (longitudinal, 1 visita/paciente).\n",
        "\n",
        "---\n",
        "\n",
        "## 1) Uso previsto\n",
        "Sistema de **cribado** para apoyar la decisi√≥n cl√≠nica en evaluaci√≥n cognitiva, con especial √©nfasis en **sensibilidad** (minimizar FN) y **calibraci√≥n** de probabilidades. No sustituye el juicio cl√≠nico; requiere validaci√≥n local.\n",
        "\n",
        "---\n",
        "\n",
        "## 2) Datos y entrenamiento (resumen)\n",
        "- **Imagen**: 20 *slices* axiales/volumen, normalizaci√≥n z-score (+CLAHE opc.), agregaci√≥n por paciente; meta-modelo P24 (LR elastic-net + Platt).\n",
        "- **Cl√≠nico**: columnas m√≠nimas `Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay, patient_id` (imputaci√≥n mediana/one-hot b√°sico).\n",
        "- **P26**: intermodal **LATE**; **P26b**: recalibraci√≥n **Platt por cohorte**.\n",
        "- **P27**: empaquetado reproducible, pol√≠tica de decisi√≥n **S2** y QA final.\n",
        "\n",
        "---\n",
        "\n",
        "## 3) M√©tricas de probabilidad (TEST)\n",
        "**Intermodal LATE (P26):**\n",
        "- **ALL:** AUC **0.736**, PR-AUC **0.729**, Brier **0.229**\n",
        "- **OAS1:** AUC **0.754**, PR-AUC **0.736**, Brier **0.208**\n",
        "- **OAS2:** AUC **0.652**, PR-AUC **0.728**, Brier **0.288**\n",
        "\n",
        "> Fuente: `p25_informe_final/p25_master_table.csv` (filas P26) y figuras en `p27_final/`.\n",
        "\n",
        "---\n",
        "\n",
        "## 4) Pol√≠tica de decisi√≥n **S2** (activa)\n",
        "**Objetivo:** maximizar sensibilidad sin colapsar en ‚Äútodo positivo‚Äù en dominios tipo OAS2.\n",
        "\n",
        "- **OAS1 ‚Üí 5:1 (FN:FP)** con umbral aprendido en VAL ‚Üí **thr = 0.42**\n",
        "- **OAS2 ‚Üí ‚Äúrecall objetivo‚Äù (VAL, target‚âà0.85; aplicado en TEST)** ‚Üí **thr ‚âà 0.4928655**\n",
        "\n",
        "**Resultados TEST @S2 (confusiones y m√©tricas):**\n",
        "- **OAS1 (0.42):** TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.700**, Precision=0.609, Acc=0.681, **Coste=39**\n",
        "- **OAS2 (‚âà0.4929):** TP=11, FP=6, TN=5, FN=1 ‚Üí **Recall=0.917**, Precision=0.647, Acc=0.696, **Coste=11**\n",
        "\n",
        "**D√≥nde cambiar:** `p26_release/CONFIG/deployment_config.json`\n",
        "- `thresholds = {\"OAS1\": 0.42, \"OAS2\": 0.4928655287824083}`\n",
        "- `thresholds_5to1 = {\"OAS1\": 0.42, \"OAS2\": 0.49}` *(fallback 5:1 puro)*\n",
        "\n",
        "---\n",
        "\n",
        "## 5) Calibraci√≥n y monitorizaci√≥n\n",
        "- **ECE/MCE (TEST intermodal, P26):** ALL‚âà0.178 / OAS1‚âà0.150 / **OAS2‚âà0.313** ‚Üí monitorizar y **recalibrar** por cohorte si **ECE>0.20** o hay drift (sitio/esc√°ner/poblaci√≥n).\n",
        "- Recomendar telemetr√≠a de **TP/FP/TN/FN**, **tasa de positivos** y **ECE** por cohorte. Recalibraci√≥n con ventana m√≥vil (‚â•50‚Äì100 casos).\n",
        "\n",
        "---\n",
        "\n",
        "## 6) Limitaciones\n",
        "- Tama√±os por cohorte moderados ‚Üí **IC amplios**.\n",
        "- **Shift** entre OAS1/OAS2 ‚Üí aplicar **umbrales por cohorte** y validaci√≥n local antes de uso asistencial.\n",
        "- El modelo **no** es un diagn√≥stico autom√°tico; es soporte a la decisi√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "## 7) C√≥mo ejecutar (resumen)\n",
        "1. **Imagen ‚Üí `p_img`:** `compute_pimg_from_features.py` sobre las matrices de features por paciente (cat√°logo P11 + OAS2 p14).\n",
        "2. **Cl√≠nico ‚Üí `p_clin`:** CSV con columnas m√≠nimas (arriba).\n",
        "3. **Inferencia E2E:** `predict_end_to_end.py` ‚Üí combina `p_img + p_clin` (LATE), **calibra por cohorte** (P26b) y **aplica S2**.\n",
        "4. Salidas: CSV de probabilidades/calibradas, decisi√≥n (0/1), y **QA** con confusiones/Coste.\n",
        "\n",
        "---\n",
        "\n",
        "## 8) Versionado y reproducibilidad\n",
        "- **Release:** `p26_release/` (zip con 23 ficheros).\n",
        "- **Modelos:** `p24_model.pkl`, `p24_platt.pkl`, `p26_clinical_model.pkl`.\n",
        "- **Config:** `CONFIG/deployment_config.json` (+ backups).\n",
        "- **QA:** `QA/p26b_test_report_recall_target.csv`.\n",
        "- **Trazas:** `MANIFEST.json`, `ENVIRONMENT.txt`.\n",
        "\n",
        "---\n",
        "\n",
        "## 9) Figuras (collage r√°pido)\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"50%\">\n",
        "<b>AUC ‚Äî ALL (TEST)</b><br>\n",
        "<img src=\"../p27_final/p27_auc_ALL.png\" alt=\"AUC ALL\" />\n",
        "</td>\n",
        "<td width=\"50%\">\n",
        "<b>OAS2 ¬∑ S2 vs 5:1 (TEST)</b><br>\n",
        "<img src=\"../p27_final/p27_s2_vs_5to1_OAS2.png\" alt=\"S2 vs 5:1 OAS2\" />\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "> M√°s figuras en `p27_final/`:\n",
        "> - `p27_auc_*.png`, `p27_prauc_*.png`, `p27_brier_*.png`\n",
        "> - (si existe) `p27_s2_vs_5to1_OAS2.png`\n",
        "\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "# 3) Escribir nuevo contenido\n",
        "mc_path.write_text(mc, encoding=\"utf-8\")\n",
        "print(\"‚úÖ MODEL_CARD.md escrito en:\", mc_path)\n",
        "print(\"üïí\", datetime.now(timezone.utc).isoformat())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA2Yb6cGRihd",
        "outputId": "f644c42e-206f-4e24-9b8b-7c460d14eba3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MODEL_CARD.md escrito en: /content/drive/MyDrive/CognitivaAI/p26_release/MODEL_CARD.md\n",
            "üïí 2025-09-08T21:40:46.211414+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Opcional: escribir HOW_TO_DEPLOY.md + README_RELEASE.md y reempaquetar ===\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "import hashlib, json, shutil\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/CognitivaAI\")\n",
        "REL  = BASE/\"p26_release\"\n",
        "REL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "howto = REL/\"HOW_TO_DEPLOY.md\"\n",
        "readme_rel = REL/\"README_RELEASE.md\"\n",
        "\n",
        "HOWTO_MD = r\"\"\"# HOW_TO_DEPLOY ‚Äî CognitivaAI Intermodal (P26/P27)\n",
        "[... pega aqu√≠ el bloque HOW_TO_DEPLOY.md de arriba si quieres editarlo a mano ...]\n",
        "\"\"\"\n",
        "README_REL_MD = r\"\"\"# README ‚Äî Paquete de Release (P26/P27)\n",
        "[... pega aqu√≠ el bloque README_RELEASE.md de arriba si quieres editarlo a mano ...]\n",
        "\"\"\"\n",
        "\n",
        "# 1) Escribir archivos\n",
        "howto.write_text(HOWTO_MD.strip()+\"\\n\", encoding=\"utf-8\")\n",
        "readme_rel.write_text(README_REL_MD.strip()+\"\\n\", encoding=\"utf-8\")\n",
        "print(\"‚úÖ HOW_TO_DEPLOY.md y README_RELEASE.md escritos.\")\n",
        "\n",
        "# 2) Regenerar MANIFEST.json\n",
        "def sha256(p: Path) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1024*1024), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "files = []\n",
        "for p in REL.rglob(\"*\"):\n",
        "    if p.is_file() and p.name != \"p26_release.zip\":\n",
        "        files.append({\"path\": str(p.relative_to(REL)), \"sha256\": sha256(p), \"size\": p.stat().st_size})\n",
        "\n",
        "manifest = {\n",
        "    \"version\": \"v1.2\",\n",
        "    \"generated_at\": datetime.now(timezone.utc).isoformat(),\n",
        "    \"files\": files\n",
        "}\n",
        "(REL/\"MANIFEST.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
        "print(\"üßæ MANIFEST.json regenerado.\")\n",
        "\n",
        "# 3) Reempaquetar ZIP\n",
        "zip_path = BASE/\"p26_release.zip\"\n",
        "if zip_path.exists():\n",
        "    zip_path.unlink()\n",
        "shutil.make_archive(str(zip_path.with_suffix(\"\")), \"zip\", REL)\n",
        "print(\"üéÅ ZIP listo:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_on3tMHRyWo",
        "outputId": "7a9ecd1b-621c-4961-c9e2-8c93f71decae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ HOW_TO_DEPLOY.md y README_RELEASE.md escritos.\n",
            "üßæ MANIFEST.json regenerado.\n",
            "üéÅ ZIP listo: /content/drive/MyDrive/CognitivaAI/p26_release.zip\n"
          ]
        }
      ]
    }
  ]
}