# üìñ Cuaderno de Bit√°cora ‚Äì Proyecto COGNITIVA-AI

Este documento act√∫a como **diario detallado de investigaci√≥n**, complementando al `README.md` (resumen ejecutivo) y al `InformeTecnico.md` (documentaci√≥n formal).  

Aqu√≠ se incluyen **todas las fases del proyecto** y **entradas diarias (dailys)** con resultados, problemas t√©cnicos y conclusiones.

---

# üóÇÔ∏è Fases Globales

## Fase 1 ‚Äì Datos cl√≠nicos OASIS-2 (pipeline inicial)

**Contexto:**  
Se comenz√≥ con un enfoque tabular sencillo sobre OASIS-2, trabajando con variables cl√≠nicas est√°ndar.

**Variables principales:**
- `AGE`: edad del paciente.  
- `M/F`: sexo biol√≥gico.  
- `EDUC`: a√±os de educaci√≥n formal (relacionado con reserva cognitiva).  
- `SES`: estatus socioecon√≥mico.  
- `MMSE`: Mini-Mental State Examination (test cognitivo).  
- `CDR`: Clinical Dementia Rating (gravedad cl√≠nica).  
- `eTIV`: volumen intracraneal estimado.  
- `nWBV`: volumen cerebral normalizado.  
- `ASF`: factor de escala anat√≥mico.  

**Resultados clave:**

| Modelo | AUC (CV 5-fold) | AUC Test |
|--------|-----------------|----------|
| Logistic Regression | 0.912 ¬± 0.050 | ‚Äî |
| Random Forest        | 0.925 ¬± 0.032 | ‚Äî |
| XGBoost              | 0.907 ¬± 0.032 | **0.897** |

**Gr√°fico:**  
![Resultados cl√≠nicos OASIS-2](./graficos/clinic_oasis2.png)

**Conclusi√≥n:**  
Pipeline sencillo y robusto, pero dataset limitado (150 sujetos).

---

## Fase 2 ‚Äì Fusi√≥n cl√≠nica OASIS-1 + OASIS-2

**Contexto:**  
Para ganar robustez, se unieron OASIS-1 (transversal) y OASIS-2 (longitudinal). Se homogenizaron columnas y se unific√≥ el criterio de la variable objetivo (`Group` vs `CDR`). Esto ampli√≥ significativamente el tama√±o muestral para entrenar modelos cl√≠nicos. 

**Pasos clave:**
- Homogeneizaci√≥n de columnas (`snake_case`).  
- Selecci√≥n de un mismo baseline (OASIS-2) para ajustar distribuci√≥n de OASIS-1.  
- Target unificado (`0 = Nondemented`, `1 = Demented/Converted`).  
- Imputaci√≥n SES/Educaci√≥n con mediana cuando faltantes.  
- Etiqueta de cohorte para diferenciar sujetos de OASIS-1 vs OASIS-2 (usada en an√°lisis).  

**Resultados clave:**

| Modelo | Hold-out (80/20) | CV 5-fold | Nested CV (10x5) |
|--------|-----------------|-----------|------------------|
| Logistic Regression | 1.000 | 0.979 ¬± 0.012 | ‚Äî |
| Random Forest        | 0.986 | 0.974 ¬± 0.018 | ‚Äî |
| XGBoost              | 0.991 | 0.975 ¬± 0.021 | ‚Äî |
| Ensemble (LR+RF+XGB) | ‚Äî     | ‚Äî             | **0.995** |

**Gr√°fico:**  
![Fusion cl√≠nica OASIS1+2](./graficos/clinic_fusion.png)

**Conclusi√≥n:**  
Dataset combinado muy estable, modelos calibrados y con gran generalizaci√≥n. Interpretabilidad cl√≠nica: **CDR + MMSE** resultaron variables cr√≠ticas. Se logra un techo de rendimiento muy alto (AUC ~0.99), dejando poco margen de mejora con datos cl√≠nicos solos.

---

## Fase 3 ‚Äì MRI en CPU local (ResNet50 baseline)

**Contexto:**  
Primeros experimentos con MRI provenientes de OASIS-2 (150 sujetos). Se procesaron im√°genes estructurales cerebrales para alimentar un modelo de Deep Learning (ResNet50) y evaluar si la informaci√≥n visual aporta a la detecci√≥n de Alzheimer.  

**Resultados clave:**

| Configuraci√≥n | AUC (Test) |
|---------------|------------|
| ResNet50 (5 slices, sin CLAHE) | **0.938** |
| ResNet50 (20 slices, z-score) | 0.858 |

**Gr√°fico:**  
![MRI baseline ResNet50](./graficos/mri_resnet50_baseline.png)

**Conclusi√≥n:**  
Buen desempe√±o inicial con pocos cortes (5) por paciente, indicando que la red capta se√±ales relevantes. Al aumentar a 20 slices normalizados, sube el recall pero baja la AUC, sugiriendo ruido adicional. Experimento costoso en CPU local ‚Üí se decide migrar a **Google Colab con GPU** para acelerar siguientes fases.

---

## Fase 4 ‚Äì Google Colab GPU (ResNet18 embeddings + calibrado)

**Contexto:**  
Migraci√≥n a Google Colab (GPU T4). Para aprovechar la aceleraci√≥n, se cambia el enfoque a extracci√≥n de **embeddings**: usar ResNet18 pre-entrenada para obtener vectores por slice y luego entrenar un clasificador ligero (Logistic Regression) sobre esos vectores. Esto reduce el tiempo de entrenamiento y permite calibrar probabilidades.

**Resultados clave:**

| Nivel        | Dataset | AUC  | PR-AUC | Acc  | Recall | Precision | Brier |
|--------------|---------|------|--------|------|--------|-----------|-------|
| Slice        | VAL     | 0.627 | 0.538 | 0.62 | 0.43   | 0.57      | 0.296 |
| Slice        | TEST    | 0.661 | 0.535 | 0.62 | 0.47   | 0.57      | 0.289 |
| Paciente (thr=0.204) | VAL | 0.722 | 0.634 | 0.70 | 0.90 | 0.60 | ‚Äî |
| Paciente (thr=0.204) | TEST | 0.724 | 0.606 | 0.60 | 0.80 | 0.52 | ‚Äî |

**Gr√°fico:**  
![ROC Curves ‚Äì Colab GPU ResNet18](./graficos/roc_colab_resnet18.png)

**Conclusi√≥n:**  
El calibrado isot√≥nico **mejora el Brier Score** (probabilidades m√°s confiables), y con un umbral cl√≠nico bajo logramos **recall alto (0.80 en test)** ‚Üí adecuado para cribado inicial. Este pipeline mostr√≥ que combinar deep features con ML cl√°sico es efectivo y eficiente en GPU, estableciendo un piso fuerte para sensibilidad.

---

## Fase 5 ‚Äì Clasificadores alternativos y ensemble (slice‚Üípatient)

**Contexto:**  
Sobre los embeddings de MRI (ResNet18), se prueban clasificadores adicionales (SVM, XGBoost) y combinaciones para mejorar el desempe√±o a nivel paciente. Se busca aprovechar distintos sesgos de modelos y evaluar si un ensemble supera a la regresi√≥n log√≠stica sola.

**Resultados clave:**

| Modelo | AUC (Val) | AUC (Test) | PR-AUC (Val) | PR-AUC (Test) |
|--------|-----------|------------|--------------|---------------|
| SVM    | 0.731     | 0.746      | 0.618        | 0.628         |
| XGB    | 0.743     | 0.733      | 0.644        | 0.605         |
| Ensemble (LR+SVM+XGB) | 0.728 | 0.728 | 0.641 | 0.605 |

**Gr√°fico:**  
![Comparativa SVM-XGB-Ensemble](./graficos/ensemble_resnet18.png)

**Conclusi√≥n:**  
El ensemble (voto blando promedio) mejora ligeramente la estabilidad pero no supera claramente a los individuales. Se mantiene recall ~0.80 en test. La simplicidad de LR calibrada ya capturaba bien la se√±al; modelos m√°s complejos tienden a sobreajustar. Se decide entonces explorar mejoras en la generaci√≥n de features (paso siguiente: embeddings m√°s ricos con otra CNN).

---

## Fase 6 ‚Äì EfficientNet-B3 embeddings

**Contexto:**  
Se generan embeddings m√°s ricos (1536 dimensiones) con EfficientNet-B3 para cada slice, esperando mejorar la separabilidad. Con estos, se entrenan clasificadores a nivel paciente (LR, MLP, XGB) y su ensemble. Tambi√©n se refuerza la separaci√≥n Train/Val/Test por paciente. 

**Resultados clave (paciente-nivel):**

| Modelo | VAL AUC | VAL PR-AUC | TEST AUC | TEST PR-AUC | Recall (Test) | Precision (Test) |
|--------|---------|------------|----------|-------------|---------------|------------------|
| LR     | 0.786   | 0.732      | 0.685    | 0.539       | 0.80          | 0.52             |
| MLP    | 0.870   | 0.886      | 0.648    | 0.556       | 0.95          | 0.53             |
| XGB    | 0.782   | 0.633      | 0.670    | 0.617       | 0.75          | 0.56             |
| **Ensemble (LR+XGB)** | **0.815**   | **0.705**      | **0.704**    | **0.623**       | **0.90**          | **0.60**             |

**Gr√°fico:**  
![EfficientNet-B3 comparativa](./graficos/effnetb3_val_test.png)

**Conclusi√≥n:**  
EffNet-B3 genera embeddings m√°s informativos; los clasificadores simples tienden a sobreajustar (ej. MLP val>>test), pero el **ensemble logra equilibrio** con recall cl√≠nico aceptable (90%). Este pipeline aument√≥ la sensibilidad manteniendo precisi√≥n ~0.60, se√±alando un avance respecto a fases previas.

---

## **Fase 7 ‚Äì EfficientNet-B3 Fine-tuning parcial**
- **Contexto:** Se migra de utilizar embeddings fijos a fine-tunear parcialmente EfficientNet-B3 directamente con las MRI, permitiendo que la red ajuste sus filtros a patrones espec√≠ficos de Alzheimer. Se descongelan las √∫ltimas capas de EffNet-B3 y se entrena con data augmentation moderada, usando Colab GPU.
- **Notebook**: `cognitiva_ai_finetuning.ipynb`.  
- **Agregaci√≥n paciente**: *mean pooling*.  
- **Calibraci√≥n**: *temperature scaling* **T=2.673**; **thr=0.3651**.  
- **Artefactos**:  
  - `ft_effb3_colab/best_ft_effb3.pth`  
  - `ft_effb3_colab/train_history.json`  
  - `ft_effb3_colab/ft_effb3_patient_eval.json`  
  - `ft_effb3_colab/graphs_from_metrics/*.png`  
- **Resultados (n=47)**:  
  - **VAL**: AUC **0.748** | PR-AUC **0.665** | Acc **0.702** | P **0.588** | R **1.0**  
  - **TEST**: AUC **0.876** | PR-AUC **0.762** | Acc **0.745** | P **0.625** | R **1.0**  
- **Confusi√≥n TEST (thr=0.3651)**: TP=8, FP=5, TN=34, FN=0.  
- **Resultados clave**
  - **AUC (Test) ‚âà 0.87**, significativamente mayor que pipelines previos (~0.70).
  - **PR-AUC (Test)** ‚âà 0.76, tambi√©n mejorado.
  - **Recall (Test, thr=0.5)** = 0.55 | **Precisi√≥n (Test)** ‚âà 0.85 (umbral por defecto).
  - Nota: Con threshold est√°ndar 0.5, el modelo pierde ~45% de casos (recall 55%), evidenciando la necesidad de calibrar/ajustar umbral.
**Conclusi√≥n**: 
El fine-tuning de EffNet-B3 **potenci√≥ la discriminaci√≥n** (AUC‚Üë) de las MRI, acerc√°ndose al rendimiento de modelos cl√≠nicos. No obstante, el modelo afinado tendi√≥ a ser conservador en sus predicciones positivas (muchos falsos negativos con thr=0.5). Se identific√≥ la **necesidad de calibrar** sus probabilidades y definir un umbral m√°s bajo orientado a alta sensibilidad.

---

## **Fase 8 ‚Äì EfficientNet-B3 Fine-tuning parcial**
- **Contexto:** 
Se aplica **calibraci√≥n de temperaturas** al modelo fine-tune para corregir su tendencia a infraestimar probabilidades de la clase positiva. Adem√°s, se confirma el uso de **pooling por atenci√≥n** para agrupar las predicciones por paciente, dado que mostr√≥ mejor PR-AUC en validaci√≥n que el promedio simple.

- **Resultados clave:**
  - **Probabilidades calibradas:** distribuci√≥n m√°s acorde a tasas reales; Brier Score mejorado (m√°s bajo).
  - **Pooling atenci√≥n vs media:** PR-AUC_val 0.66 vs 0.64 ‚Üí se elige atenci√≥n (ligera mejora).
  - **M√©tricas post-calibraci√≥n (antes de umbral):** AUC_test ~0.88 | PR-AUC_test ~0.76 (sin cambios dr√°sticos, calibraci√≥n no afecta orden).
  - Se determin√≥ **umbral cl√≠nico ~0.36** en VAL para garantizar recall‚â•90%. Con este: **Recall_val = 1.0**, Precision_val ~0.59.

- **Conclusi√≥n:**
Tras calibrar, el modelo fine-tune provee **scores confiables**. La estrategia de atenci√≥n destaca slices informativos por paciente, optimizando la detecci√≥n. Ya calibrado y con umbral seleccionado en validaci√≥n, el modelo est√° listo para evaluaci√≥n final con alta sensibilidad.

---

## **Fase 9 ‚Äì Fine-tuning estable (modelo final MRI)**
- **Contexto:** 
Evaluaci√≥n del modelo EfficientNet-B3 fine-tune **calibrado** con el **umbral cl√≠nico √≥ptimo** en el conjunto de test hold-out. Este es el pipeline MRI definitivo antes de integraci√≥n multimodal.

- **Resultados clave:**
  - **Threshold aplicado:** ~0.365 (derivado de val).
  - **TEST: Recall = 1.00**|Precision ‚âà 0.62 | AUC = 0.876 | PR-AUC = 0.762.
  - Se lograron **0 falsos negativos en test** (detect√≥ todos los casos), a cambio de algunos falsos positivos (precision ~62%).
  - La Acc_test ~0.74 refleja que pese a bajar el umbral, m√°s de 70% de las predicciones totales fueron correctas.

- **Conclusi√≥n:**
Pipeline 9 constituye el **mejor modelo MRI** hasta la fecha, alcanzando **sensibilidad del 100%** en test y mejorando sustancialmente la AUC respecto a pipelines anteriores. Este modelo fine-tune estable, aunque genera m√°s alarmas falsas que los modelos cl√≠nicos, es ideal como herramienta de **cribado** que no deja pasar casos de demencia incipiente. Marca el cierre de la fase unimodal de im√°genes, dando paso a la siguiente etapa: combinar este potente modelo MRI con el igualmente fuerte modelo cl√≠nico, en un enfoque multimodal.

---

## Fase 10 ‚Äì Stable Plus (checkpoint limpio + calibraci√≥n final)

**Contexto:**  
Tras el pipeline estable (fase 9), se detectaron problemas de compatibilidad entre el checkpoint guardado y la arquitectura usada. Esto generaba cargas parciales (<1% en algunos intentos) y m√©tricas inconsistentes. La fase 10 surge para **reconstruir el checkpoint a un formato limpio (99.7% pesos cargados), aplicar calibraci√≥n final y consolidar el modelo MRI**.

**Acciones:**  
- Normalizaci√≥n del checkpoint entrenado, eliminando capas obsoletas (`head.classifier`) y adaptando pesos a la nueva `head`.  
- Evaluaci√≥n de estrategias de pooling (mean, median, top-k).  
- Aplicaci√≥n de calibraci√≥n mediante *temperature scaling*.  
- Guardado de artefactos completos (CSV por slice, CSV por paciente, JSON con m√©tricas, gr√°ficas comparativas).  

**Resultados clave:**
- Pooling **mean**: VAL AUC=0.630, TEST AUC=0.546.  
- Pooling **median**: TEST AUC=0.541.  
- Pooling **top-k=0.2**: TEST AUC=0.583.  
- Recall en TEST siempre 1.0, con precisi√≥n 0.47‚Äì0.49.

**Gr√°fico:**  
![Stable Plus comparativa](./graficos/stable_plus.png)

**Conclusi√≥n:**  
Pipeline m√°s robusto en recall absoluto, pero con AUC m√°s bajo que el pipeline 9. Se plantea usarlo como **baseline cl√≠nico seguro** en cribado poblacional.

---

## Comparativa Global

<p align="center">
  <img src="./graficos/comparativapipelines7-10.png" alt="Comparativa P1-P7 ‚Äî ROC-AUC por Pipeline" width="880"/>
</p>

Gr√°fico de barras con ROC-AUC y PR-AUC en TEST para los tres pipelines m√°s representativos:

- P7 (finetuning cl√°sico con B3).

- P9 (stable, sin calibraci√≥n).

- P10 (stable plus con checkpoint limpio + calibraci√≥n).

---
<p align="center">
  <img src="./graficos/comparativapipelines7-10B.png" alt="Comparativa P1-P7 ‚Äî Precisi√≥n-Recall por Pipeline" width="880"/>
</p>

Comparativa para Precisi√≥n y Recall de los tres pipelines MRI (P7, P9 y P10)

---

## üîÑ Fase complementaria ‚Äì Pipeline 10 (Stable Plus con agregaciones avanzadas)

En esta fase se exploraron variantes adicionales sobre el pipeline 10, sin cambiar de notebook pero ampliando las t√©cnicas de agregaci√≥n y evaluaci√≥n.

- **Acci√≥n**: Implementar pooling robustos (TRIMMED, TOP-k) y un ensemble MRI.  
- **Metodolog√≠a**:  
  - Ajuste de pesos del ensemble (mean=0.30, trimmed=0.10, top7=0.60) mediante grid search sobre validaci√≥n.  
  - Calibraci√≥n final de logits con *temperature scaling* (T‚âà0.28).  
- **Resultados principales**:  
  - TRIMMED: Recall=0.75, Precisi√≥n=0.56, PR-AUC=0.746 (TEST).  
  - Ensemble: Recall=0.70, Precisi√≥n=0.61, PR-AUC=0.737 (TEST).  
- **Conclusi√≥n**: Aunque TRIMMED asegura mayor sensibilidad, el ensemble proporciona un balance cl√≠nico m√°s realista al aumentar la precisi√≥n, reduciendo falsos positivos sin comprometer excesivamente la detecci√≥n. Se adopta como baseline final de la etapa MRI.

## Comparativa(P1-P10)

## üìä Comparativa Global (pipelines 1‚Äì10)

| Pipeline | Modalidad        | Modelo                   | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|--------------------------|------------|--------|-------|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB                      | 0.897      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB                      | 0.991      | ‚Äî      | ‚Äî     | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50                 | 0.938      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib         | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed          | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune       | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable         | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib   | 0.546‚Äì0.583| 0.50‚Äì0.53 | 0.51‚Äì0.55 | 1.0 | 0.47‚Äì0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + TRIMMED      | 0.744      | 0.746  | 0.64  | 0.75   | 0.56      |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble(M+T+7) | 0.754   | 0.737  | 0.68  | 0.70   | 0.61      |

---
# üìÖ Entradas Diarias (Agosto 2025)

### üìÖ 18/08/2025 ‚Äì Migraci√≥n a Colab GPU
- **Acci√≥n**: Montaje de Google Drive en Colab, carga de embeddings ResNet18 precomputados, entrenamiento de LogReg con calibraci√≥n isot√≥nica. 
- **Resultado**: Pipeline de im√°genes funcionando en GPU; AUC ~0.72 estable en test, con recall mejorado al ~0.80 aplicando umbral bajo. 
- **Problemas**: Colab desconect√≥ la sesi√≥n a mitad ‚Üí se tuvieron que reconstruir celdas y montar de nuevo el entorno (lecci√≥n: guardar modelos intermedios). 
- **Conclusi√≥n**: Base s√≥lida para MRI en GPU establecida, sentando groundwork para experimentar con modelos m√°s complejos.

### üìÖ 21/08/2025 ‚Äì Experimentaci√≥n con EfficientNet-B3
- **Acci√≥n**: Generaci√≥n de embeddings de 1536 dimensiones con EfficientNet-B3 para cada slice; entrenamiento de clasificadores LR, MLP y XGB a nivel paciente; comparaci√≥n de pooling por promedio vs estrategias por paciente. 
- **Resultado**: LR mostr√≥ desempe√±o estable (menos overfitting), MLP tuvo alto overfitting (train >> val), XGB mejor√≥ algo en slices informativos. Un ensemble simple (LR+XGB) increment√≥ recall en test a 0.90 con precision ~0.60.
- **Conclusi√≥n**: Embeddings m√°s ricos abren la puerta a ensembles m√°s sofisticados, pero tambi√©n pueden sobreajustar con facilidad. Se logra alta sensibilidad (0.90) manteniendo precisi√≥n aceptable, validando la estrategia h√≠brida de combinar modelos. Esto sugiere que para avanzar se requerir√° o m√°s datos o t√©cnicas que aprovechen mejor los patrones de im√°genes (‚Üí fine-tuning).

### üìÖ 23/08/2025 ‚Äì Ensemble h√≠brido
- **Acci√≥n**: Prueba de combinaci√≥n ‚Äúh√≠brida‚Äù entre modelos de slice y de paciente: se combin√≥ un XGBoost entrenado directamente a nivel slice (promediando sus scores por paciente) con un MLP entrenado sobre features agregadas de paciente, para capturar informaci√≥n a dos escalas.
- **Resultado**: El ensemble h√≠brido alcanz√≥ **Recall_test = 0.90** y Precision_test ~0.60, similar al pipeline anterior pero confirmando la aportaci√≥n complementaria de ambos enfoques (el MLP recuper√≥ algunos positivos que XGBoost solo-slice perd√≠a). 
- **Conclusi√≥n**: Se valida la estrategia **multiescala** (slice + paciente) para integrar informaci√≥n. Esto apunta a la relevancia de fusionar diferentes representaciones. Los aprendizajes aqu√≠ alimentar√°n la fase multimodal futura (combinar cl√≠nica+MRI). Antes, se decide intentar extraer a√∫n m√°s de las MRI v√≠a fine-tuning de la CNN, ahora que la infraestructura en GPU est√° probada.

### üìÖ 24/08/2025 ‚Äì Fine-tuning EffNet-B3 en MRI
- **Acciones**:  Se llev√≥ a cabo el fine-tuning parcial de EfficientNet-B3: descongelar √∫ltimas capas y reentrenar con datos MRI (Train OASIS-2), usando early stopping seg√∫n PR-AUC en val. Se implement√≥ pooling de atenci√≥n para destacar slices relevantes por paciente.
  - Montaje de Drive; generaci√≥n `best_ft_effb3.pth` y `train_history.json`.  
  - *Temperature scaling* ‚Üí **T=2.673**.  
  - *Pooling* paciente: `mean`.  
- **Rendimiento**:  
  - Copia a SSD local: **~53 f/s** (940 ficheros en ~18 s).  
  - Lectura Drive: **~4.5 img/s**; SSD: **~695 img/s** (muestra 256).  
- **Resultados (paciente, n=47):**  
  - VAL: AUC=0.748 | PR-AUC=0.665 | Acc=0.702 | P=0.588 | R=1.0  
  - TEST: AUC=0.876 | PR-AUC=0.762 | Acc=0.745 | P=0.625 | R=1.0  
- **Matriz de confusi√≥n (TEST, thr=0.3651):** TP=8, FP=5, TN=34, FN=0.  
- **Resultados parciales**: m√©tricas estables; generaci√≥n de `ft_effb3_patient_eval.json`.  
- **Archivos generados:** gr√°ficas en `graphs_from_metrics/` (confusi√≥n, punto PR, barras AUC/PR-AUC).  
- **Problemas**:  
  - `ValueError: mountpoint must not already contain files` ‚Üí resuelto con `force_remount=True`.  
  - *Warning* DataLoader: exceso de workers ‚Üí fijar `num_workers=2`.  
  - Deprecation `torch.cuda.amp.autocast` ‚Üí migrado a `torch.amp.autocast('cuda')`.
- **Resultados:** El modelo fine-tune entren√≥ ~10 √©pocas antes de converger. AUC_test subi√≥ a ~0.87, un incremento notable vs embeddings fijos (~0.70). Sin embargo, con threshold=0.5 solo logr√≥ recall_test ~0.55 (precision ~0.85). Es decir, clasific√≥ con alta certeza algunos positivos, pero dej√≥ muchos sin detectar a ese umbral.
- **Conclusi√≥n:** Fine-tuning demostr√≥ ser muy efectivo en potenciar la se√±al (mejor AUC), pero evidenci√≥ la necesidad de recalibrar el modelo para cumplir el requisito cl√≠nico de alta sensibilidad. Se planific√≥ calibrar sus probabilidades y ajustar el threshold en la siguiente sesi√≥n. 

### üìÖ **25/08/2025 ‚Äì Calibraci√≥n y umbral cl√≠nico (EffNet-B3 fine-tune)**
- **Acciones**:  
  - Bucle de inferencia optimizado; memoization en SSD local.  
  - retraining reproducible en Colab (EffNet‚ÄëB3), cach√© SSD, AMP (`torch.amp`), early‚Äëstopping por AUC en holdout, calibraci√≥n (T=2.048), pooling `mean` y selecci√≥n de umbral 0.3400 con recall‚â•0.95 en VAL.  
  - Reutilizaci√≥n de **T=2.673** y **thr=0.3651** del JSON estable.  
  - Exportaci√≥n de **CSV por paciente** (VAL/TEST) y **gr√°ficas** a `ft_effb3_colab/graphs_from_metrics`.  
  - Aplicaci√≥n de Temperature Scaling en validaci√≥n para recalibrar las probabilidades de EffNet-B3 fine-tune; c√°lculo de curva Precision-Recall en val y selecci√≥n de umbral m√≠nimo con recall ‚â• 90%. Luego, evaluaci√≥n final en test con dicho umbral.
- **Throughput**:  
  - VAL: **~176‚Äì198 img/s** | TEST: **~140‚Äì150 img/s**.  
- **Resultados consolidados (paciente, n=47)**:  
  - **VAL**: AUC **0.748**, PR-AUC **0.665**, Acc **0.702**, P **0.588**, R **1.0**.  
  - **TEST**: AUC **0.876**, PR-AUC **0.762**, Acc **0.745**, P **0.625**, R **1.0**.  
- **Resultados:**  
  - VAL ‚Üí AUC=1.000 | PR-AUC=1.000 | Acc=1.000 | P=1.000 | R=1.000 | thr=0.3400 | n=10  
  - TEST ‚Üí AUC=0.663 | PR-AUC=0.680 | Acc=0.574 | P=0.500 | R=0.650 | thr=0.3400 | n=47 
  - La calibraci√≥n ajust√≥ ligeramente las probabilidades (T ‚âà 1.5). Se identific√≥ **thr ~0.36** para recall_val ‚â• 0.90. Con ese threshold, **Recall_test = 1.00** (detect√≥ todos los casos) con **Precision_test ~0.62**. AUC_test se mantuvo en ~0.876. En n√∫meros absolutos, ning√∫n paciente con Alzheimer en test fue pasado por alto, a costa de ~12 falsos positivos. 
- **Notas**: si se reescribe `ft_effb3_patient_eval.json` con otros CSV/umbral, las m√©tricas pueden variar; se congela este snapshot como **oficial** para el repo.
- **Comparativa con P7:** ver `comparison_p7_p9_*` (AUC/PR‚ÄëAUC).
- **Artefactos:** `best_effb3_stable.pth`, `effb3_stable_patient_eval.json`, CSVs por slice/paciente y gr√°ficas en `graphs_from_metrics/`.  
- **Conclusi√≥n:** Se obtuvo un **pipeline MRI √≥ptimo:** modelo calibrado, sin falsos negativos en test. La sensibilidad alcanzada (100%) cumple con creces la meta de cribado. Este resultado supera en equilibrio a todos los intentos previos y deja al modelo listo para integrarse con datos cl√≠nicos. Pr√≥ximo paso: **fusi√≥n multimodal** (combinar predicci√≥n cl√≠nica y de MRI) y validar en cohortes externas (OASIS-3, ADNI) para verificar su generalizaci√≥n.

### üìÖ 25/08/2025 ‚Äì 03:04 ‚Äì Pipeline 9 (EffB3 estable)
- **Acci√≥n:** retraining reproducible en Colab (EffNet‚ÄëB3), cach√© SSD, AMP (`torch.amp`), early‚Äëstopping por AUC en holdout, calibraci√≥n (T=2.048), pooling `mean` y selecci√≥n de umbral 0.3400 con recall‚â•0.95 en VAL.  
- **Resultados:**  
  - VAL ‚Üí AUC=1.000 | PR-AUC=1.000 | Acc=1.000 | P=1.000 | R=1.000 | thr=0.3400 | n=10  
  - TEST ‚Üí AUC=0.663 | PR-AUC=0.680 | Acc=0.574 | P=0.500 | R=0.650 | thr=0.3400 | n=47  
- **Comparativa con P7:** ver `comparison_p7_p9_*` (AUC/PR‚ÄëAUC).
- **Artefactos:** `best_effb3_stable.pth`, `effb3_stable_patient_eval.json`, CSVs por slice/paciente y gr√°ficas en `graphs_from_metrics/`.  
- **Conclusi√≥n:** setup estable listo para el salto a **multimodal** y validaci√≥n externa.-

---

### üìÖ 26/08/2025 ‚Äì Stable Plus (checkpoint limpio + calibraci√≥n)

- **Acci√≥n:**  
  - Reconstrucci√≥n del checkpoint (`effb3_stable_seed42.pth`) a un formato limpio y compatible. 
  - Carga de pesos (99.7% √©xito), eliminando discrepancias de capas.  
  - Aplicaci√≥n de *temperature scaling* y ajuste de pooling: Pruebas de inferencia con pooling mean, median y top-k.  

- **Resultados:**  
  - VAL: AUC=0.63 | PR-AUC=0.67 | Recall‚âà0.85  
  - TEST: AUC=0.55 | PR-AUC=0.53 | Recall=1.0  
  - Recall=1.0 en TEST para todas las variantes, AUC entre 0.54‚Äì0.58.  
  - Se confirm√≥ estabilidad en los artefactos (CSV, JSON, gr√°ficas).  

- **Artefactos:**  
  - Checkpoint limpio en `best_effb3_stable.pth`.  
  - CSV por slice y paciente.  
  - JSON de evaluaci√≥n calibrada.  
  - Gr√°ficas comparativas en `graphs_from_metrics/`.  

- **Conclusi√≥n:**  
  Pipeline estable y calibrado, recuperando recall perfecto en test, aunque precisi√≥n moderada (~0.47). Sirve como versi√≥n **ultra-conservadora** para detecci√≥n precoz.  

---

### üìÖ 26/08/2025 17:35 ‚Äì Validaci√≥n extendida de Stable Plus

- **Acci√≥n:**  
  - Revisi√≥n completa de los artefactos generados en `ft_effb3_stable_colab_plus`.  
  - Confirmaci√≥n de que los CSV (slice/paciente) y JSON calibrado se cargaban sin errores.  
  - Verificaci√≥n de m√©tricas con distintos poolings (mean, median, top-k).  
  - Ajuste de umbral F1 (‚âà0.50) y validaci√≥n de recall absoluto.  

- **Resultados:**  
  - Recall en TEST=1.0 bajo todos los poolings.  
  - AUC oscil√≥ entre 0.54 y 0.58; precisi√≥n 0.47‚Äì0.49.  
  - Artefactos gr√°ficos confirmados en `graphs_from_metrics/`.  

- **Artefactos:**  
  - Checkpoint limpio y validado: `best_effb3_stable.pth`.  
  - CSV val/test (slices y pacientes).  
  - Eval JSON calibrado (`effb3_stable_patient_eval_calibrated.json`).  

- **Conclusi√≥n:**  
  La fase 10 queda consolidada como el cierre de la etapa MRI. Este pipeline representa la versi√≥n m√°s **ultra-conservadora**, maximizando recall aunque a costa de precisi√≥n. Servir√° de base para la futura etapa multimodal.

---

### [2025-08-28] ‚Äì Avance en ensemble MRI
- Probados m√©todos TRIMMED, TOP3, TOP7 y un ensemble de agregaciones.  
- El ensemble alcanz√≥ mejor equilibrio: recall=0.70 y precisi√≥n=0.61 en test.  
- Guardadas curvas ROC y PR comparativas (trimmed vs ensemble).  
- Actualizados los resultados en `comparison_patient_level_eval.csv`.  

---

# üìå Conclusi√≥n global
- **Cl√≠nico (fusionado OASIS1+2)** ‚Üí proporciona el mejor AUC global (‚âà0.99) gracias a fuertes marcadores como CDR/MMSE, aunque puede complementarse en sensibilidad.
- **MRI (GPU)** ‚Üí los pipelines evolucionaron de AUC ~0.72 a ~0.88, alcanzando recall 1.0 tras calibraci√≥n; esto demuestra que la informaci√≥n visual aporta detecci√≥n temprana (atrofia incipiente) que puede adelantarse a signos cl√≠nicos, aunque con m√°s falsos positivos.
- **EffNet-B3 fine-tune** ‚Üí supuso el mayor salto en MRI, cerrando la brecha con lo cl√≠nico. Un modelo profundo entrenado con nuestros datos sumado a calibraci√≥n logr√≥ equilibrio √≥ptimo para cribado (sensibilidad alta con precisi√≥n moderada). 
- **Pr√≥ximos pasos** ‚Üí encarar la **integraci√≥n multimodal (cl√≠nico + MRI)** para aprovechar lo mejor de ambos mundos, y realizar validaci√≥n externa en datos independientes (p. ej. OASIS-3, ADNI) que ratifique la robustez del enfoque. Se espera que la modalidad cl√≠nica aporte especificidad y la MRI sensibilidad, para juntos lograr un sistema de apoyo al diagn√≥stico m√°s preciso y generalizable..

---

**Autor√≠a:** Fran Ram√≠rez  
**√öltima actualizaci√≥n:** 28/08/2025 ‚Äì 18:07