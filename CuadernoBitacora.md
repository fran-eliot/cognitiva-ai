# üß≠ Cuaderno de Bit√°cora del Proyecto Cognitiva-AI 

Este cuaderno recopila **todo el recorrido del proyecto Cognitiva-AI**, desde los primeros experimentos con datos cl√≠nicos hasta los pipelines m√°s recientes con arquitecturas alternativas y ensembles de backbones.  

Se ha mantenido un registro exhaustivo de cada fase, anotando decisiones t√©cnicas, dificultades encontradas, soluciones aplicadas y reflexiones tras cada bloque de resultados.  

El objetivo es que act√∫e como un **diario detallado de investigaci√≥n**, √∫til tanto para revisiones futuras como para terceros interesados en reproducir o extender el trabajo.

Aqu√≠ se incluyen **todas las fases del proyecto** y **entradas diarias (dailys)** con resultados, problemas t√©cnicos y conclusiones.

---

## üìå Convenciones y notas r√°pidas

- **Estructura de datos**:
  - `BASE_DIR = /content/drive/MyDrive/CognitivaAI`
  - `DATA_DIR = BASE_DIR/oas1_data`
  - `OUT_DIR` por pipeline (p.ej. `ft_effb3_stable_colab_plus`, `p11_alt_backbones`, etc.)
- **Mapas OASIS**: `oas1_val_colab_mapped.csv`, `oas1_test_colab_mapped.csv` (columnas claves: `png_path`, `target`, `patient_id`, ‚Ä¶).
- **Columnas de predicci√≥n**:
  - Formatos detectados: `y_score`, `sigmoid(logit)`, `sigmoid(logits)`, `pred`.
  - Se unifica a **`y_score`** internamente durante la carga.
- **Pooling a nivel paciente**: `mean`, `trimmed20`, `top7`, `pmean_2` (power mean con p=2).
- **M√©tricas**: AUC, PR-AUC, Acc, Recall, Precision. Umbral por:
  - **F1-opt** (maximiza F1 en VAL),
  - **Youden** (maximiza sensibilidad+especificidad-1),
  - **REC90/REC100** (recall fijado).

---

# üóÇÔ∏è Fases Globales

## Fase 1 ‚Äì Datos cl√≠nicos OASIS-2 (pipeline inicial)

**Contexto:**  
Se comenz√≥ con un enfoque tabular sencillo sobre OASIS-2, trabajando con variables cl√≠nicas est√°ndar.

**Variables principales:**
- `AGE`: edad del paciente.  
- `M/F`: sexo biol√≥gico.  
- `EDUC`: a√±os de educaci√≥n formal (relacionado con reserva cognitiva).  
- `SES`: estatus socioecon√≥mico.  
- `MMSE`: Mini-Mental State Examination (test cognitivo).  
- `CDR`: Clinical Dementia Rating (gravedad cl√≠nica).  
- `eTIV`: volumen intracraneal estimado.  
- `nWBV`: volumen cerebral normalizado.  
- `ASF`: factor de escala anat√≥mico.  

**Resultados clave:**

| Modelo | AUC (CV 5-fold) | AUC Test |
|--------|-----------------|----------|
| Logistic Regression | 0.912 ¬± 0.050 | ‚Äî |
| Random Forest        | 0.925 ¬± 0.032 | ‚Äî |
| XGBoost              | 0.907 ¬± 0.032 | **0.897** |

**Conclusi√≥n:**  
Pipeline sencillo y robusto, pero dataset limitado (150 sujetos).

---

## Fase 2 ‚Äì Fusi√≥n cl√≠nica OASIS-1 + OASIS-2

**Contexto:**  
Para ganar robustez, se unieron OASIS-1 (transversal) y OASIS-2 (longitudinal). Se homogenizaron columnas y se unific√≥ el criterio de la variable objetivo (`Group` vs `CDR`). Esto ampli√≥ significativamente el tama√±o muestral para entrenar modelos cl√≠nicos. 

**Pasos clave:**
- Homogeneizaci√≥n de columnas (`snake_case`).  
- Selecci√≥n de un mismo baseline (OASIS-2) para ajustar distribuci√≥n de OASIS-1.  
- Target unificado (`0 = Nondemented`, `1 = Demented/Converted`).  
- Imputaci√≥n SES/Educaci√≥n con mediana cuando faltantes.  
- Etiqueta de cohorte para diferenciar sujetos de OASIS-1 vs OASIS-2 (usada en an√°lisis).  

**Resultados clave:**

| Modelo | Hold-out (80/20) | CV 5-fold | Nested CV (10x5) |
|--------|-----------------|-----------|------------------|
| Logistic Regression | 1.000 | 0.979 ¬± 0.012 | ‚Äî |
| Random Forest        | 0.986 | 0.974 ¬± 0.018 | ‚Äî |
| XGBoost              | 0.991 | 0.975 ¬± 0.021 | ‚Äî |
| Ensemble (LR+RF+XGB) | ‚Äî     | ‚Äî             | **0.995** |

**Conclusi√≥n:**  
Dataset combinado muy estable, modelos calibrados y con gran generalizaci√≥n. Interpretabilidad cl√≠nica: **CDR + MMSE** resultaron variables cr√≠ticas. Se logra un techo de rendimiento muy alto (AUC ~0.99), dejando poco margen de mejora con datos cl√≠nicos solos.

---

## Fase 3 ‚Äì MRI en CPU local (ResNet50 baseline)

**Contexto:**  
Primeros experimentos con MRI provenientes de OASIS-2 (150 sujetos). Se procesaron im√°genes estructurales cerebrales para alimentar un modelo de Deep Learning (ResNet50) y evaluar si la informaci√≥n visual aporta a la detecci√≥n de Alzheimer.  

**Resultados clave:**

| Configuraci√≥n | AUC (Test) |
|---------------|------------|
| ResNet50 (5 slices, sin CLAHE) | **0.938** |
| ResNet50 (20 slices, z-score) | 0.858 |

**Conclusi√≥n:**  
Buen desempe√±o inicial con pocos cortes (5) por paciente, indicando que la red capta se√±ales relevantes. Al aumentar a 20 slices normalizados, sube el recall pero baja la AUC, sugiriendo ruido adicional. Experimento costoso en CPU local ‚Üí se decide migrar a **Google Colab con GPU** para acelerar siguientes fases.

---

## Fase 4 ‚Äì Google Colab GPU (ResNet18 embeddings + calibrado)

**Contexto:**  
Migraci√≥n a Google Colab (GPU T4). Para aprovechar la aceleraci√≥n, se cambia el enfoque a extracci√≥n de **embeddings**: usar ResNet18 pre-entrenada para obtener vectores por slice y luego entrenar un clasificador ligero (Logistic Regression) sobre esos vectores. Esto reduce el tiempo de entrenamiento y permite calibrar probabilidades.

**Resultados clave:**

| Nivel        | Dataset | AUC  | PR-AUC | Acc  | Recall | Precision | Brier |
|--------------|---------|------|--------|------|--------|-----------|-------|
| Slice        | VAL     | 0.627 | 0.538 | 0.62 | 0.43   | 0.57      | 0.296 |
| Slice        | TEST    | 0.661 | 0.535 | 0.62 | 0.47   | 0.57      | 0.289 |
| Paciente (thr=0.204) | VAL | 0.722 | 0.634 | 0.70 | 0.90 | 0.60 | ‚Äî |
| Paciente (thr=0.204) | TEST | 0.724 | 0.606 | 0.60 | 0.80 | 0.52 | ‚Äî |

**Conclusi√≥n:**  
El calibrado isot√≥nico **mejora el Brier Score** (probabilidades m√°s confiables), y con un umbral cl√≠nico bajo logramos **recall alto (0.80 en test)** ‚Üí adecuado para cribado inicial. Este pipeline mostr√≥ que combinar deep features con ML cl√°sico es efectivo y eficiente en GPU, estableciendo un piso fuerte para sensibilidad.

---

## Fase 5 ‚Äì Clasificadores alternativos y ensemble (slice‚Üípatient)

**Contexto:**  
Sobre los embeddings de MRI (ResNet18), se prueban clasificadores adicionales (SVM, XGBoost) y combinaciones para mejorar el desempe√±o a nivel paciente. Se busca aprovechar distintos sesgos de modelos y evaluar si un ensemble supera a la regresi√≥n log√≠stica sola.

**Resultados clave:**

| Modelo | AUC (Val) | AUC (Test) | PR-AUC (Val) | PR-AUC (Test) |
|--------|-----------|------------|--------------|---------------|
| SVM    | 0.731     | 0.746      | 0.618        | 0.628         |
| XGB    | 0.743     | 0.733      | 0.644        | 0.605         |
| Ensemble (LR+SVM+XGB) | 0.728 | 0.728 | 0.641 | 0.605 |

**Conclusi√≥n:**  
El ensemble (voto blando promedio) mejora ligeramente la estabilidad pero no supera claramente a los individuales. Se mantiene recall ~0.80 en test. La simplicidad de LR calibrada ya capturaba bien la se√±al; modelos m√°s complejos tienden a sobreajustar. Se decide entonces explorar mejoras en la generaci√≥n de features (paso siguiente: embeddings m√°s ricos con otra CNN).

---

## Fase 6 ‚Äì EfficientNet-B3 embeddings

**Contexto:**  
Se generan embeddings m√°s ricos (1536 dimensiones) con EfficientNet-B3 para cada slice, esperando mejorar la separabilidad. Con estos, se entrenan clasificadores a nivel paciente (LR, MLP, XGB) y su ensemble. Tambi√©n se refuerza la separaci√≥n Train/Val/Test por paciente. 

**Resultados clave (paciente-nivel):**

| Modelo | VAL AUC | VAL PR-AUC | TEST AUC | TEST PR-AUC | Recall (Test) | Precision (Test) |
|--------|---------|------------|----------|-------------|---------------|------------------|
| LR     | 0.786   | 0.732      | 0.685    | 0.539       | 0.80          | 0.52             |
| MLP    | 0.870   | 0.886      | 0.648    | 0.556       | 0.95          | 0.53             |
| XGB    | 0.782   | 0.633      | 0.670    | 0.617       | 0.75          | 0.56             |
| **Ensemble (LR+XGB)** | **0.815**   | **0.705**      | **0.704**    | **0.623**       | **0.90**          | **0.60**             |

**Conclusi√≥n:**  
EffNet-B3 genera embeddings m√°s informativos; los clasificadores simples tienden a sobreajustar (ej. MLP val>>test), pero el **ensemble logra equilibrio** con recall cl√≠nico aceptable (90%). Este pipeline aument√≥ la sensibilidad manteniendo precisi√≥n ~0.60, se√±alando un avance respecto a fases previas.

---

## **Fase 7 ‚Äì EfficientNet-B3 Fine-tuning parcial**
- **Contexto:** Se migra de utilizar embeddings fijos a fine-tunear parcialmente EfficientNet-B3 directamente con las MRI, permitiendo que la red ajuste sus filtros a patrones espec√≠ficos de Alzheimer. Se descongelan las √∫ltimas capas de EffNet-B3 y se entrena con data augmentation moderada, usando Colab GPU.
- **Notebook**: `cognitiva_ai_finetuning.ipynb`.  
- **Agregaci√≥n paciente**: *mean pooling*.  
- **Calibraci√≥n**: *temperature scaling* **T=2.673**; **thr=0.3651**.  
- **Resultados (n=47)**:  
  - **VAL**: AUC **0.748** | PR-AUC **0.665** | Acc **0.702** | P **0.588** | R **1.0**  
  - **TEST**: AUC **0.876** | PR-AUC **0.762** | Acc **0.745** | P **0.625** | R **1.0**  
- **Confusi√≥n TEST (thr=0.3651)**: TP=8, FP=5, TN=34, FN=0.  
- **Resultados clave**
  - **AUC (Test) ‚âà 0.87**, significativamente mayor que pipelines previos (~0.70).
  - **PR-AUC (Test)** ‚âà 0.76, tambi√©n mejorado.
  - **Recall (Test, thr=0.5)** = 0.55 | **Precisi√≥n (Test)** ‚âà 0.85 (umbral por defecto).
  - Nota: Con threshold est√°ndar 0.5, el modelo pierde ~45% de casos (recall 55%), evidenciando la necesidad de calibrar/ajustar umbral.
**Conclusi√≥n**: 
El fine-tuning de EffNet-B3 **potenci√≥ la discriminaci√≥n** (AUC‚Üë) de las MRI, acerc√°ndose al rendimiento de modelos cl√≠nicos. No obstante, el modelo afinado tendi√≥ a ser conservador en sus predicciones positivas (muchos falsos negativos con thr=0.5). Se identific√≥ la **necesidad de calibrar** sus probabilidades y definir un umbral m√°s bajo orientado a alta sensibilidad.

---

## Fase 7 ‚Äì OASIS-2 (p13, p14 y p15)

**Contexto:**  
Exploraci√≥n y explotaci√≥n del dataset OASIS-2 con EfficientNet-B3.  
Se implementaron tres pipelines consecutivos:

- **p13:** entrenamiento base con criterio de una sola visita por paciente.  
- **p14:** entrenamiento balanceado en Colab GPU, copiando im√°genes a SSD para mejorar la E/S.  
- **p15:** consolidaci√≥n de resultados de OASIS-2 (p13 y p14) junto a OASIS-1 (p11), integrando todos los backbones en un cat√°logo com√∫n y generando features de ensamble.

**Detalles t√©cnicos:**
- 20 slices por volumen, equiespaciados y normalizados (z-score + CLAHE).  
- Labels obtenidos del Excel cl√≠nico, convertidos a binario (Control=0, Dementia/Converted=1).  
- Split fijo: 105 train, 22 val, 23 test (1 sesi√≥n por paciente).  
- P14: entrenamiento con **class weights** y datos en **SSD local de Colab**.  
- P15: consolidaci√≥n en cat√°logo, eliminaci√≥n de features con NaN‚â•40%, uso de Logistic Regression (con imputaci√≥n) y HistGradientBoosting (manejo nativo de NaN).

**Resultados:**
- **p13:** recall alto, dataset limitado (150 pacientes).  
- **p14:** VAL AUC‚âà0.88, TEST AUC‚âà0.71 con recall=100%.  
- **p15:** consolidaci√≥n con ensamble ‚Üí VAL AUC‚âà0.94, TEST AUC‚âà0.71; recall alto sostenido.  
- Integraci√≥n completa en el cat√°logo de backbones (`oas2_effb3`, `oas2_effb3_p14`) y en las features consolidadas con OASIS-1.

---
## **Fase 8 ‚Äì EfficientNet-B3 Fine-tuning parcial**
- **Contexto:** 
Se aplica **calibraci√≥n de temperaturas** al modelo fine-tune para corregir su tendencia a infraestimar probabilidades de la clase positiva. Adem√°s, se confirma el uso de **pooling por atenci√≥n** para agrupar las predicciones por paciente, dado que mostr√≥ mejor PR-AUC en validaci√≥n que el promedio simple.

- **Resultados clave:**
  - **Probabilidades calibradas:** distribuci√≥n m√°s acorde a tasas reales; Brier Score mejorado (m√°s bajo).
  - **Pooling atenci√≥n vs media:** PR-AUC_val 0.66 vs 0.64 ‚Üí se elige atenci√≥n (ligera mejora).
  - **M√©tricas post-calibraci√≥n (antes de umbral):** AUC_test ~0.88 | PR-AUC_test ~0.76 (sin cambios dr√°sticos, calibraci√≥n no afecta orden).
  - Se determin√≥ **umbral cl√≠nico ~0.36** en VAL para garantizar recall‚â•90%. Con este: **Recall_val = 1.0**, Precision_val ~0.59.

- **Conclusi√≥n:**
Tras calibrar, el modelo fine-tune provee **scores confiables**. La estrategia de atenci√≥n destaca slices informativos por paciente, optimizando la detecci√≥n. Ya calibrado y con umbral seleccionado en validaci√≥n, el modelo est√° listo para evaluaci√≥n final con alta sensibilidad.

---

## **Fase 9 ‚Äì Fine-tuning estable (modelo final MRI)**
- **Contexto:** 
Evaluaci√≥n del modelo EfficientNet-B3 fine-tune **calibrado** con el **umbral cl√≠nico √≥ptimo** en el conjunto de test hold-out. Este es el pipeline MRI definitivo antes de integraci√≥n multimodal.

- **Resultados clave:**
  - **Threshold aplicado:** ~0.365 (derivado de val).
  - **TEST: Recall = 1.00**|Precision ‚âà 0.62 | AUC = 0.876 | PR-AUC = 0.762.
  - Se lograron **0 falsos negativos en test** (detect√≥ todos los casos), a cambio de algunos falsos positivos (precision ~62%).
  - La Acc_test ~0.74 refleja que pese a bajar el umbral, m√°s de 70% de las predicciones totales fueron correctas.

- **Conclusi√≥n:**
Pipeline 9 constituye el **mejor modelo MRI** hasta la fecha, alcanzando **sensibilidad del 100%** en test y mejorando sustancialmente la AUC respecto a pipelines anteriores. Este modelo fine-tune estable, aunque genera m√°s alarmas falsas que los modelos cl√≠nicos, es ideal como herramienta de **cribado** que no deja pasar casos de demencia incipiente. Marca el cierre de la fase unimodal de im√°genes, dando paso a la siguiente etapa: combinar este potente modelo MRI con el igualmente fuerte modelo cl√≠nico, en un enfoque multimodal.

---

# Fase 10 ‚Äì OASIS-2 (p15 y p16)

**Contexto general:**  
Tras los avances logrados con p13 y p14, donde exploramos el dataset OASIS-2 y conseguimos un modelo base s√≥lido con EfficientNet-B3, surgi√≥ la necesidad de dar un paso m√°s:  
1. **Consolidar la preparaci√≥n de datos (p15)** para asegurar coherencia y cobertura completa del dataset.  
2. **Refinar la estrategia de ensembles (p16)**, combinando backbones heterog√©neos en un esquema patient-level con m√©tricas robustas.

---

## Fase 11 ‚Äì Ensemble Calibration (p17)

**Contexto:**  
Tras p16, el siguiente paso fue calibrar las probabilidades del ensemble para aumentar la interpretabilidad y la utilidad cl√≠nica.

**Detalles t√©cnicos:**  
- Construcci√≥n de un meta-ensemble con Logistic Regression sobre outputs base.  
- Aplicaci√≥n de Platt scaling y optimizaci√≥n de umbral (F1).  
- Evaluaci√≥n con Brier Score para medir calibraci√≥n.  

**Resultados:**  
- Validaci√≥n: AUC‚âà0.78, Recall=0.94, F1=0.76, Brier=0.176.  
- Test: AUC‚âà0.70, Recall=0.78, F1=0.66, Brier=0.227.  
- Cohortes: OAS1 consistente; OAS2 limitado.  

**Conclusi√≥n:**  
La calibraci√≥n refina el ensemble, mantiene sensibilidad alta y mejora la calidad de las probabilidades, aunque la robustez en OAS2 a√∫n requiere trabajo.

---

# Fase 12 ‚Äì Comparativa p16 vs p17

**p16 ‚Äì Blending cl√°sico:**  
- LR + HGB combinados con un peso √≥ptimo (Œ±=0.02).  
- Validaci√≥n espectacular (AUC‚âà0.95, Recall=1.0), pero riesgo de sobreajuste.  
- En test, buen recall (0.78) pero sin calibraci√≥n de probabilidades.  

**p17 ‚Äì Ensemble calibrado:**  
- Stacking con Logistic Regression y Platt scaling.  
- AUC m√°s modesto en validaci√≥n (0.78) y test (0.70).  
- Mantiene recall‚âà0.78 y adem√°s optimiza la calibraci√≥n (Brier=0.227 en test).  
- Probabilidades m√°s interpretables, mejor preparadas para escenarios cl√≠nicos.  

**Conclusi√≥n de la fase:**  
- p16 = **mejor raw performance** (m√°ximo AUC).  
- p17 = **mejor calibraci√≥n y estabilidad cl√≠nica** (probabilidades confiables).  
- Ambos complementan la estrategia de ensembles: uno explota rendimiento, otro asegura interpretabilidad.

---

## Fase 13 ‚Äì Stacking avanzado (p18)

**Contexto:**  
Tras calibrar ensembles en p17, se dise√±√≥ un stacking multicapa para explorar la combinaci√≥n de m√∫ltiples clasificadores heterog√©neos.  

**Detalles t√©cnicos:**  
- **Base learners:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.  
- **Meta learner:** regresi√≥n log√≠stica con blending Œ±=0.02.  
- **Estrategia:**  
  - Generaci√≥n de predicciones OOF con 5-fold cross-validation.  
  - Validaci√≥n de umbral √≥ptimo en F1.  
  - Evaluaci√≥n separada para OAS1 y OAS2.  
- **M√©tricas adicionales:** Brier Score para calibraci√≥n, coeficientes de meta-LR y permutaci√≥n de importancias para interpretar contribuciones.

**Resultados:**  
- [VAL] AUC=0.92, Recall‚âà0.90, F1‚âà0.83, Precision‚âà0.78.  
- [TEST] AUC=0.67, Recall‚âà0.78, F1‚âà0.67, Precision‚âà0.59.  
- Cohorte OAS1 aport√≥ la mayor estabilidad, mientras que OAS2 mantuvo recall alto pero sin se√±al discriminativa clara (AUC‚âà0.5).

**Conclusiones:**  
El stacking multicapa permiti√≥ validar la viabilidad de **meta-modelos complejos** en un dataset MRI limitado.  
Gradient Boosting y Random Forest emergieron como pilares, aunque la brecha entre validaci√≥n y test evidencia el reto de generalizaci√≥n en cohortes peque√±as.

---

## Fase 14 ‚Äì Meta-Ablation y calibraci√≥n avanzada (P22)

**Contexto:**  
Tras consolidar los ensembles y aplicar calibraciones b√°sicas en fases previas (p20‚Äìp21), se dise√±√≥ P22 como un *ablation study* para comparar m√©todos de calibraci√≥n y medir su efecto en la estabilidad de las probabilidades y en la sensibilidad de los modelos.

**Dise√±o y ejecuci√≥n:**  
- Features: 56 columnas iniciales; tras filtrar NaN>40% se mantuvieron 36.  
- Cohortes: 69 pacientes en validaci√≥n, 70 en test.  
- Modelos calibrados:  
  - Logistic Regression (LR) con imputaci√≥n y escalado.  
  - HistGradientBoosting (HGB), tolerante a NaNs.  
- M√©todos de calibraci√≥n aplicados:  
  - **Platt scaling (sigmoid).**  
  - **Isotonic regression.**  
- Validaci√≥n con OOF por StratifiedKFold (sin fugas).  
- Selecci√≥n de umbral F1-m√°x en validaci√≥n (‚âà0.30‚Äì0.35).  

**Resultados principales:**  
- LR-Platt: VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
- LR-Isotonic: VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
- HGB-Platt: VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
- HGB-Isotonic: VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
- Blend (Isotonic): VAL AUC‚âà0.90, F1‚âà0.79 | TEST AUC‚âà0.68, F1‚âà0.62  

**Interpretaci√≥n:**  
- La calibraci√≥n isot√≥nica aporta mejor ajuste en validaci√≥n (Brier bajo), pero pierde robustez en test.  
- Platt mantiene recall alto, lo que lo hace m√°s apto para escenarios de cribado cl√≠nico.  
- El blend confirma robustez en validaci√≥n, pero sigue presente el gap entre cohortes OAS1 y OAS2.  

**Conclusi√≥n:**  
P22 aport√≥ claridad sobre qu√© t√©cnicas de calibraci√≥n son m√°s fiables en entornos cl√≠nicos peque√±os y heterog√©neos. Constituye la base para P23, donde se buscar√° integrar estas calibraciones dentro de meta-ensembles finales y analizar umbrales de decisi√≥n espec√≠ficos por cohorte.

---

## Fase 15 ‚Äì Estrategia OASIS-1 y OASIS-2 en ensembles (p16‚Äìp22)

Durante los pipelines de ensembles avanzados (p16‚Äìp22) se trabaj√≥ con datos de
**OASIS-1 y OASIS-2** simult√°neamente. 

**Decisi√≥n clave:**
- No fusionar ambos datasets en uno √∫nico.
- Mantener la cohorte identificada (`cohort = OAS1 / OAS2`) en todos los
  DataFrames.
- Entrenar meta-modelos (LR, HGB, XGB, blends, calibraciones) sobre los datos
  combinados, pero **siempre evaluando por cohorte y global**.

**Beneficios:**
- Evita leakage entre cohortes.
- Permite comparar rendimiento en escenarios distintos:
  - OAS1: cross-sectional, mayor homogeneidad.
  - OAS2: longitudinal, m√°s ruido y variabilidad.
- Informa sobre la robustez del ensemble frente a shift de dominio.

**Resultado observado:**
- En validaci√≥n (VAL), OAS1 logra m√©tricas m√°s altas (AUC, Acc).
- En test (TEST), OAS2 muestra recall elevado pero menor calibraci√≥n y precisi√≥n.
- Globalmente (ALL), se obtiene una media ponderada que refleja mejor la
  dificultad del problema.

**Conclusi√≥n:**
El tratamiento separado de OASIS-1 y OASIS-2 dentro de los ensembles es esencial
para interpretar los resultados cl√≠nicos y dise√±ar calibraciones espec√≠ficas
para cada cohorte en los pipelines posteriores (p20‚Äìp22).

---

## Fase 16 ‚Äî P26 / P26b (intermodal)

**Entrada:**  
- Imagen (prob. P24 por paciente) + 56 features de imagen (p11+p14/p13).  
- Cl√≠nico consolidado (Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay).  
- Se√±al p1 (OAS2) con imputaci√≥n por cohorte + flag.

**Arquitectura:**  
- **P26 (Late):** meta-LR sobre `{p_img, p_clin, p1_fill, p1_has}`.  
- **P26b:** P26 + **calibraci√≥n Platt por cohorte** en VAL y re-umbrales 5:1.

**M√©tricas (TEST):**  
- P26 ‚Äî ALL AUC=0.713 ¬∑ PR-AUC=0.712 ¬∑ Brier=0.234; OAS1 AUC=0.754 ¬∑ OAS2 AUC=0.652.  
- P26b ‚Äî mejora Brier (OAS1 0.199, OAS2 0.241) sin cambiar confusi√≥n a coste 5:1.

**Umbrales recomendados:**  
- **P26:** OAS1=0.307 ¬∑ OAS2=0.195 (coste m√≠nimo).  
- **P26b (√∫nico):** OAS1=0.340 ¬∑ OAS2=0.374.  
- **Mixto (recall OAS2):** OAS1‚ÜíP26b@0.340 ¬∑ OAS2‚ÜíP24@0.332.

**Riesgos:** descalibraci√≥n en OAS2; tama√±o muestral.  
**Mitigaciones:** monitorizar **ECE/MCE**, recalibrar con ventana m√≥vil; reportar intervalos; mantener umbrales por cohorte.

**Artefactos clave:** ver `p26_intermodal/` (predicciones, calibraciones, umbrales, tablas ejecutivas, bloques).

---

# üìÖ Diario cronol√≥gico


## üìÖ 01/08/2025 ‚Äì Inicio del proyecto

- **Fase inicial**: planteamiento general del proyecto.  
- Se define que Cognitiva-AI explorar√° **clasificaci√≥n de enfermedad de Alzheimer** usando datos cl√≠nicos (OASIS-2) y resonancias magn√©ticas.  
- Se establecen los objetivos:  
  1. Validar la viabilidad con modelos cl√≠nicos tabulares (XGBoost).  
  2. Extender a MRI con backbones CNN/transformers.  
  3. Explorar calibraci√≥n, ensembles y, finalmente, multimodalidad.

---

## üìÖ 03/08/2025 ‚Äì Pipeline 1 (Cl√≠nico OASIS-2)

- **Notebook:** `p1_clinico_oasis2.ipynb`.  
- **Datos:** cohortes cl√≠nicas de OASIS-2.  
- **Modelo:** XGBoost.  
- **Resultados preliminares:**  
  - AUC ‚âà 0.897.  
  - Buenas m√©tricas en validaci√≥n, confirmando que los datos cl√≠nicos son predictivos.  

**Reflexi√≥n:** excelente punto de partida, sirve de baseline. Se decide extender a fusi√≥n y multimodalidad m√°s adelante.

---

## üìÖ 06/08/2025 ‚Äì Pipeline 2 (Cl√≠nico Fusi√≥n)

- **Notebook:** `p2_clinico_fusion.ipynb`.  
- **Estrategia:** se fusionan variables cl√≠nicas tabulares adicionales.  
- **Modelo:** XGBoost mejorado.  
- **Resultados:**  
  - AUC ‚âà 0.991.  
  - Recall casi perfecto (~1.0).  

**Reflexi√≥n:** m√©tricas alt√≠simas, posible riesgo de overfitting, pero muestra el potencial de fusi√≥n de datos tabulares.  
Se decide dar el salto a MRI.

---

## üìÖ 10/08/2025 ‚Äì Pipeline 3 (MRI OASIS-2 con ResNet50)

- **Notebook:** `p3_mri_oasis2_resnet50.ipynb`.  
- **Datos:** im√°genes MRI de OASIS-2.  
- **Backbone:** ResNet50 preentrenada en ImageNet.  
- **Resultados:**  
  - AUC (test) ‚âà 0.938.  

**Reflexi√≥n:** confirmaci√≥n de que los modelos CNN est√°ndar son viables en MRI.  
Este pipeline sirve de puente hacia la fase Colab (con datos m√°s grandes y pipelines posteriores).

---

## üìÖ 18/08/2025 ‚Äì Pipeline 5 (MRI Colab con ResNet18 + Calibraci√≥n)

- **Motivaci√≥n:** probar pipeline en Colab con mayor escala y calibraci√≥n.  
- **Acci√≥n**: Montaje de Google Drive en Colab, carga de embeddings ResNet18 precomputados, entrenamiento de LogReg con calibraci√≥n isot√≥nica. 
- **Resultado**: Pipeline de im√°genes funcionando en GPU; AUC ~0.72 estable en test, con recall mejorado al ~0.80 aplicando umbral bajo. 
- **Problemas**: Colab desconect√≥ la sesi√≥n a mitad ‚Üí se tuvieron que reconstruir celdas y montar de nuevo el entorno (lecci√≥n: guardar modelos intermedios). 
- **Conclusi√≥n**: Base s√≥lida para MRI en GPU establecida, sentando groundwork para experimentar con modelos m√°s complejos.
- **Resultados:**  
  - AUC ‚âà 0.724.  
  - PR-AUC ‚âà 0.606.  
  - Accuracy ‚âà 0.60.  
  - Recall 0.80 | Precision 0.52.  

**Reflexi√≥n:** m√©tricas m√°s bajas que en OASIS-2, debido a mayor complejidad. Se confirma la necesidad de arquitecturas m√°s potentes (EfficientNet).

---

## üìÖ 21/08/2025 ‚Äì Pipeline 6 (EfficientNet-B3 embeddings)
- **Enfoque:** usar EffNet-B3 como extractor de embeddings, clasificando con capa adicional.  
- **Acci√≥n**: Generaci√≥n de embeddings de 1536 dimensiones con EfficientNet-B3 para cada slice; entrenamiento de clasificadores LR, MLP y XGB a nivel paciente; comparaci√≥n de pooling por promedio vs estrategias por paciente. 
- **Resultado**: LR mostr√≥ desempe√±o estable (menos overfitting), MLP tuvo alto overfitting (train >> val), XGB mejor√≥ algo en slices informativos. Un ensemble simple (LR+XGB) increment√≥ recall en test a 0.90 con precision ~0.60.
- **Conclusi√≥n**: Embeddings m√°s ricos abren la puerta a ensembles m√°s sofisticados, pero tambi√©n pueden sobreajustar con facilidad. Se logra alta sensibilidad (0.90) manteniendo precisi√≥n aceptable, validando la estrategia h√≠brida de combinar modelos. Esto sugiere que para avanzar se requerir√° o m√°s datos o t√©cnicas que aprovechen mejor los patrones de im√°genes (‚Üí fine-tuning).  

- **Resultados:**  
  - AUC ‚âà 0.704.  
  - PR-AUC ‚âà 0.623.  
  - Accuracy ‚âà 0.70.  
  - Recall 0.90 | Precision 0.60.  

**Reflexi√≥n:** mejora en recall, aunque el modelo a√∫n no se estabiliza.  
Se plantea probar fine-tuning completo.

---

### üìÖ 23/08/2025 ‚Äì Ensemble h√≠brido
- **Acci√≥n**: Prueba de combinaci√≥n ‚Äúh√≠brida‚Äù entre modelos de slice y de paciente: se combin√≥ un XGBoost entrenado directamente a nivel slice (promediando sus scores por paciente) con un MLP entrenado sobre features agregadas de paciente, para capturar informaci√≥n a dos escalas.
- **Resultado**: El ensemble h√≠brido alcanz√≥ **Recall_test = 0.90** y Precision_test ~0.60, similar al pipeline anterior pero confirmando la aportaci√≥n complementaria de ambos enfoques (el MLP recuper√≥ algunos positivos que XGBoost solo-slice perd√≠a). 
- **Conclusi√≥n**: Se valida la estrategia **multiescala** (slice + paciente) para integrar informaci√≥n. Esto apunta a la relevancia de fusionar diferentes representaciones. Los aprendizajes aqu√≠ alimentar√°n la fase multimodal futura (combinar cl√≠nica+MRI). Antes, se decide intentar extraer a√∫n m√°s de las MRI v√≠a fine-tuning de la CNN, ahora que la infraestructura en GPU est√° probada.

---

## üìÖ 24/08/2025 ‚Äì Pipeline 7 (EfficientNet-B3 fine-tune)

- **Motivaci√≥n:** pasar de embeddings fijos a fine-tuning completo.  
- **Acciones**:  Se llev√≥ a cabo el fine-tuning parcial de EfficientNet-B3: descongelar √∫ltimas capas y reentrenar con datos MRI (Train OASIS-2), usando early stopping seg√∫n PR-AUC en val. Se implement√≥ pooling de atenci√≥n para destacar slices relevantes por paciente.
  - Montaje de Drive; generaci√≥n `best_ft_effb3.pth` y `train_history.json`.  
  - *Temperature scaling* ‚Üí **T=2.673**.  
  - *Pooling* paciente: `mean`.  
- **Rendimiento**:  
  - Copia a SSD local: **~53 f/s** (940 ficheros en ~18 s).  
  - Lectura Drive: **~4.5 img/s**; SSD: **~695 img/s** (muestra 256).  
- **Resultados (paciente, n=47):**  
  - VAL: AUC=0.748 | PR-AUC=0.665 | Acc=0.702 | P=0.588 | R=1.0  
  - TEST: AUC=0.876 | PR-AUC=0.762 | Acc=0.745 | P=0.625 | R=1.0  
- **Matriz de confusi√≥n (TEST, thr=0.3651):** TP=8, FP=5, TN=34, FN=0.  
- **Problemas**:  
  - `ValueError: mountpoint must not already contain files` ‚Üí resuelto con `force_remount=True`.  
  - *Warning* DataLoader: exceso de workers ‚Üí fijar `num_workers=2`.  
  - Deprecation `torch.cuda.amp.autocast` ‚Üí migrado a `torch.amp.autocast('cuda')`.
- **Resultados:** El modelo fine-tune entren√≥ ~10 √©pocas antes de converger. AUC_test subi√≥ a ~0.87, un incremento notable vs embeddings fijos (~0.70). Sin embargo, con threshold=0.5 solo logr√≥ recall_test ~0.55 (precision ~0.85). Es decir, clasific√≥ con alta certeza algunos positivos, pero dej√≥ muchos sin detectar a ese umbral.
- **Conclusi√≥n:** Fine-tuning demostr√≥ ser muy efectivo en potenciar la se√±al (mejor AUC), pero evidenci√≥ la necesidad de recalibrar el modelo para cumplir el requisito cl√≠nico de alta sensibilidad. Se planific√≥ calibrar sus probabilidades y ajustar el threshold en la siguiente sesi√≥n. 

- **Resultados resumen:**  
  - AUC ‚âà 0.876.  
  - PR-AUC ‚âà 0.762.  
  - Accuracy ‚âà 0.745.  
  - Recall 1.0 | Precision 0.625.  

**Reflexi√≥n:** salto cualitativo, confirma que EffNet-B3 es un backbone s√≥lido para MRI.  Se establece como baseline.

---

## üìÖ 25/08/2025 ‚Äì Calibraci√≥n y umbral cl√≠nico (EffNet-B3 fine-tune)
- **Acciones**:  
  - Bucle de inferencia optimizado; memoization en SSD local.  
  - retraining reproducible en Colab (EffNet‚ÄëB3), cach√© SSD, AMP (`torch.amp`), early‚Äëstopping por AUC en holdout, calibraci√≥n (T=2.048), pooling `mean` y selecci√≥n de umbral 0.3400 con recall‚â•0.95 en VAL.  
  - Reutilizaci√≥n de **T=2.673** y **thr=0.3651** del JSON estable.  
  - Exportaci√≥n de **CSV por paciente** (VAL/TEST) y **gr√°ficas** a `ft_effb3_colab/graphs_from_metrics`.  
  - Aplicaci√≥n de Temperature Scaling en validaci√≥n para recalibrar las probabilidades de EffNet-B3 fine-tune; c√°lculo de curva Precision-Recall en val y selecci√≥n de umbral m√≠nimo con recall ‚â• 90%. Luego, evaluaci√≥n final en test con dicho umbral.
- **Throughput**:  
  - VAL: **~176‚Äì198 img/s** | TEST: **~140‚Äì150 img/s**.  
- **Resultados consolidados (paciente, n=47)**:  
  - **VAL**: AUC **0.748**, PR-AUC **0.665**, Acc **0.702**, P **0.588**, R **1.0**.  
  - **TEST**: AUC **0.876**, PR-AUC **0.762**, Acc **0.745**, P **0.625**, R **1.0**.  
- **Resultados:**  
  - VAL ‚Üí AUC=1.000 | PR-AUC=1.000 | Acc=1.000 | P=1.000 | R=1.000 | thr=0.3400 | n=10  
  - TEST ‚Üí AUC=0.663 | PR-AUC=0.680 | Acc=0.574 | P=0.500 | R=0.650 | thr=0.3400 | n=47 
  - La calibraci√≥n ajust√≥ ligeramente las probabilidades (T ‚âà 1.5). Se identific√≥ **thr ~0.36** para recall_val ‚â• 0.90. Con ese threshold, **Recall_test = 1.00** (detect√≥ todos los casos) con **Precision_test ~0.62**. AUC_test se mantuvo en ~0.876. En n√∫meros absolutos, ning√∫n paciente con Alzheimer en test fue pasado por alto, a costa de ~12 falsos positivos. 
- **Notas**: si se reescribe `ft_effb3_patient_eval.json` con otros CSV/umbral, las m√©tricas pueden variar; se congela este snapshot como **oficial** para el repo.
- **Conclusi√≥n:** Se obtuvo un **pipeline MRI √≥ptimo:** modelo calibrado, sin falsos negativos en test. La sensibilidad alcanzada (100%) cumple con creces la meta de cribado. Este resultado supera en equilibrio a todos los intentos previos y deja al modelo listo para integrarse con datos cl√≠nicos. Pr√≥ximo paso: **fusi√≥n multimodal** (combinar predicci√≥n cl√≠nica y de MRI) y validar en cohortes externas (OASIS-3, ADNI) para verificar su generalizaci√≥n.

---

### üìÖ 25/08/2025 ‚Äì 03:04 ‚Äì Pipeline 9 (EffB3 estable)
- **Motivaci√≥n:** buscar estabilidad entre runs, reduciendo variabilidad.  
- **Acci√≥n:** retraining reproducible en Colab (EffNet‚ÄëB3), cach√© SSD, AMP (`torch.amp`), early‚Äëstopping por AUC en holdout, calibraci√≥n (T=2.048), pooling `mean` y selecci√≥n de umbral 0.3400 con recall‚â•0.95 en VAL.  
- **Resultados:**  
  - VAL ‚Üí AUC=1.000 | PR-AUC=1.000 | Acc=1.000 | P=1.000 | R=1.000 | thr=0.3400 | n=10  
  - TEST ‚Üí AUC=0.663 | PR-AUC=0.680 | Acc=0.574 | P=0.500 | R=0.650 | thr=0.3400 | n=47  
- **Conclusi√≥n:** setup estable listo para el salto a **multimodal** y validaci√≥n externa.-

---

## üìÖ 28/08/2025 ‚Äî P10: EffNet-B3 stable + calibraci√≥n
- **Objetivo:** a√±adir calibraci√≥n (temperature scaling, isotonic). 
- **Incidencia**: grandes magnitudes de **logits** ‚Üí overflow en `exp`.
- Se aplic√≥ **temperature scaling** y **isotonic regression**.
- Implementaci√≥n de `safe_sigmoid` con `clip[-50,50]` para evitar overflow.

 - **Resultado(rango):** **AUC test 0.546‚Äì0.583**, PR-AUC ~0.50‚Äì0.53, Acc ~0.51‚Äì0.55, **Recall=1.0**, Precision ~0.47‚Äì0.49.
 - **Conclusi√≥n:** ca√≠da de m√©tricas tras calibraci√≥n, pero resultados m√°s interpretables.  
Se descubre la importancia de ensembles para recuperar rendimiento.

 ---

## üìÖ 28/08/2025 ‚Äî P10-ext: TRIMMED y seed-ensemble
- **Semillas 41/42/43** con agregaciones por paciente.
- **Seed-ensemble (media/TRIMMED/TOP7)** (sin calibrar) dio AUC test ‚âà 0.50‚Äì0.51 en algunos runs (semillas no aportaron mejora directa).
- **Stacking / Random weights (mean+trimmed20+top7+p2):**
  - **RF** y **STACK(no-neg)** sobre 4 features de pooling:
    - **VAL:** AUC ~0.90‚Äì0.91, PR-AUC ~0.92, Acc ~0.85‚Äì0.87, R ~0.75‚Äì0.95.
    - **TEST:** **AUC ~0.75**, PR-AUC ~0.73‚Äì0.75, Acc ~0.64‚Äì0.70, R ~0.50‚Äì0.70, P ~0.58‚Äì0.71.
  - **Ej. RAND(500 samples)** (mean/trimmed20/top7/p2):
    - Pesos ejemplo: mean 0.325, trimmed20 0.315, top7 0.322, p2 0.038.
    - **VAL:** AUC=0.909, PR-AUC=0.920, Acc=0.872, R=0.95, P=0.792.
    - **TEST:** **AUC=0.754**, PR-AUC=0.748, Acc=0.660, R=0.70, P=0.583.
 - **STACK_LR(mean+trimmed20+top7+p2):**
    - * Coefs ‚âà [0.407, 0.409, 0.485, 0.416], **intercept ‚àí0.923**.
    - **VAL**: AUC=0.909, PR-AUC=0.920, Acc=0.872, R=0.95, P=0.792.
    - **TEST**: AUC=0.754, PR-AUC=0.748, Acc=0.660, R=0.70, P=0.583.
- **Resultados:**  
  - TRIMMED: AUC ‚âà 0.744, PR-AUC ‚âà 0.746.  
  - Ensemble: AUC ‚âà 0.754, PR-AUC ‚âà 0.737.  
- **Conclusi√≥n:**
    - **Consolidado**: a nivel paciente, **ensembles de pooling** (4 features) mejoran notablemente sobre seed-ensemble puro.
    - Ensembles simples logran mejoras claras.  
Refuerza la idea de avanzar hacia ensembles m√°s sofisticados.

---

### üìÖ 28/08/2025 ‚Äî Documentaci√≥n y limpieza

- Inclusi√≥n de resultados de P10 y P10-ext en README e Informe T√©cnico.
- Normalizaci√≥n de columnas en CSV (y_score, sigmoid(logit), pred).

 ---

## üìÖ 30/08/2025 ‚Äî P11: Backbones alternativos (inicio)

* Notebook: `cognitiva_ai_backbones.ipynb`.
- Configuraci√≥n de `/p11_alt_backbones`.
- **Incidencia**: ‚ÄúMountpoint must not already contain files‚Äù ‚Üí soluci√≥n: no remount si ya montado.
- **Incidencia**: DATA_DIR marcado como inexistente pese a estar ‚Üí soluci√≥n: reinicio del entorno.
- Validaci√≥n de mapas OK, config guardada.
- **Motivaci√≥n:** verificar si otros backbones pueden superar a EffNet-B3.  
- **Backbones probados:**  
  - ResNet-50.  
  - DenseNet-121.  
  - ConvNeXt-Tiny.  
  - Swin-Tiny.  

### Resultados preliminares:
- **ResNet-50:** AUC ‚âà 0.740, PR-AUC ‚âà 0.730.  
- **DenseNet-121:** AUC ‚âà 0.343, PR-AUC ‚âà 0.407.  
- **ConvNeXt-Tiny:** AUC ‚âà 0.509, PR-AUC ‚âà 0.479.  
- **Swin-Tiny:** AUC ‚âà 0.641, PR-AUC ‚âà 0.597.  

**Reflexi√≥n:** ning√∫n backbone supera claramente a EffNet-B3. Swin-Tiny destaca levemente, DenseNet decepciona.  
La evidencia refuerza el inter√©s en **ensembles de backbones**.

---

### üìÖ 04/09/2025 ‚Äî Cat√°logo multi-backbone + normalizaci√≥n columnas

* Escaneo de `p11_alt_backbones` y carpetas previas:
    * Detectados `SwinTiny`, `ConvNeXt slices`, `DenseNet-121`, y adem√°s `efb3` de pipelines anteriores (`ft_effb3_*`).
* Unificaci√≥n de columnas: mapeo a+uto (`y_score`, `sigmoid(logit[s])`, `pred` ‚Üí `y_score`).
* Construcci√≥n features por paciente (VAL/TEST (47, 6) por fuente), guardados:
    * `val_patient_features_backbones.csv`
    * `test_patient_features_backbones.csv`
* Validaci√≥n:
    * `SwinTiny` OK (940 filas ‚Üí 47 pacientes).
    * `ConvNeXt slices` OK (940 ‚Üí 47).
    * `DenseNet` OK (940 ‚Üí 47).
    * Preds a nivel paciente de pipelines previos (47 directos) incluidas como features extra.

---

### üìÖ 04/08/2025 ‚Äî Ensemble de backbones (promedios y stacking base)

- **Objetivo:** combinar predicciones slice-level y patient-level de varios backbones (Swin, ConvNeXt, DenseNet).  
- **M√©todos:**  
  - Promedios simples.  
  - Random weights (Dirichlet).  
  - Stacking (logistic regression, isotonic calibration).  

* **AVG** de 12 se√±ales `‚Äú*_mean‚Äù` (Swin/ConvNeXt/DenseNet + se√±ales paciente/effect):
    * **VAL (F1-opt)**: `AUC` 0.476 | `PR-AUC` 0.389 | `Acc` 0.40 | `R`=1.0 | `P`=0.333 | `thr`=0.3525 | `n`=10.
    * **TEST (F1-opt)**: `AUC` 0.713, `PR-AUC` 0.724 | `Acc` 0.426 | `R`=1.0 | `P`=0.426 | `thr`=0.3525 | `n`=47.
* **Observaci√≥n**: `AUC` test alto vs val bajo ‚Üí val (`n`=10) muy peque√±o; umbral podr√≠a transferirse demasiado ‚Äúoptimista‚Äù.
* **STACK\_LR(all\_features)**:
    * **VAL**: `AUC` 0.810 | `PR-AUC` 0.700 | `Acc` 0.800 | `R`=1.0 | `P`=0.600.
    * **TEST**: `AUC` 0.298 | `PR-AUC` 0.397 | `Acc` 0.383 | `P` 0.304 | `R` 0.35.
* **Overfitting claro a VAL**.

---

### üìÖ 04/09/2025 ‚Äî Dirichlet (3 backbones, means)

* **FEATURES**: `SwinTiny_mean`, `convnext_tiny..._mean`, `png_preds_d121_mean`.
* `N_SAMPLES`=800 (semilla 42).
* Mejor combinaci√≥n (ejemplo):
    * Pesos ‚âà Swin 0.972, ConvNeXt 0.004, Dense 0.024.
    * **VAL (F1-opt)**: `Acc` 0.70 | `P` 0.50 | `R` 1.0 | `thr` 0.474 | `AUC` 0.714, `PR-AUC` 0.633 (`n`=10).
    * **TEST (F1-opt)**: `Acc` 0.468 | `P` 0.444 | `R` 1.0 | `thr` 0.435 | `AUC` 0.520, `PR-AUC` 0.523 (`n`=47).
* **Youden TEST**: `Acc` 0.617 | `P` 0.667 | `R` 0.20 (umbral 0.481).
* **Conclusi√≥n**: mejora leve vs ConvNeXt-mean/DenseNet, pero por debajo de Swin-top7 y muy lejos de los ensembles de EffNet-B3 del P10-ext.

---

### üìÖ 04/09/2025 ‚Äî Ensemble Dirichlet EXT (12 features)

* **FEATURES**: `{Swin[mean/trimmed/top7], ConvNeXt_slices[mean/trimmed/top7], DenseNet[mean/trimmed/top7]}` + se√±ales agregadas (`patient_preds_plus_mean`, `slice_preds_plus_mean`, `slice_preds_seedENS_mean`).
* **Resultado**:
    * **VAL**: `AUC` 0.714, `PR-AUC` 0.681.
    * **TEST**: `AUC` 0.361, `PR-AUC` 0.405.
* **Conclusi√≥n**: sobreajuste; demasiados grados de libertad para `n(VAL)` = 10.

---

### üìÖ 04/09/2025 ‚Äî Stacking L1 fuerte (sparsidad forzada)

* **FEATURES candidatas (ej.)**: `SwinTiny_top7`, `convnext..._top7`, `png_preds_d121_trimmed20`, `patient_preds_plus_mean`, `slice_preds_plus_mean`, `slice_preds_seedENS_mean`.
* **Resultado**: todos `coef=0` (modelo trivial), `intercept=0`.
* **VAL/TEST**: `AUC=0.5`; F1 ligado a prior por umbral 0.
* **Interpretaci√≥n**: el penalizador ‚Äúfuerte‚Äù anul√≥ todas las se√±ales (`n(VAL)`=10 demasiado peque√±o + correlaci√≥n alta).

---

### üìÖ 04/09/2025 ‚Äî Isotonic sobre Swin-Tiny (top7)

* **Resultado**:
    * **VAL**: `AUC` 0.714 | `PR-AUC` 0.556 | `Acc` 0.400 | `R` 1.0 | `P` 0.333 | `thr` 0.0025.
    * **TEST**: `AUC` 0.566 | `PR-AUC` 0.458 | `Acc` 0.553 | `R` 0.95 | `P` 0.487 | `thr` 0.0025.
* **Conclusi√≥n**: la calibraci√≥n isot√≥nica ayuda ligeramente en test y fija un recall alto con precisi√≥n moderada.

---

### Resultados:
- **Dirichlet (3 backbones, means):**  
  - VAL: AUC ‚âà 0.71, PRAUC ‚âà 0.63.  
  - TEST: AUC ‚âà 0.52, PRAUC ‚âà 0.52.  

- **Dirichlet EXT (12 features):**  
  - VAL: AUC ‚âà 0.71, PRAUC ‚âà 0.68.  
  - TEST: AUC ‚âà 0.36, PRAUC ‚âà 0.40.  

- **Stack_LR (all_features):**  
  - VAL: AUC ‚âà 0.81, PRAUC ‚âà 0.70.  
  - TEST: AUC ‚âà 0.29, PRAUC ‚âà 0.39.  

- **Swin-Tiny isotonic:**  
  - VAL: AUC ‚âà 0.71, PRAUC ‚âà 0.55.  
  - TEST: AUC ‚âà 0.56, PRAUC ‚âà 0.45.  

**Reflexi√≥n:** aunque los ensembles no logran mejorar consistentemente el test, s√≠ confirman la complementariedad entre modelos.  
El reto ser√° combinar estabilidad de EffNet-B3 con la diversidad de backbones.

---

### üìÖ 05/09/2025 ‚Äî Cat√°logo ampliado y parsers robustos

* Se indexan tambi√©n directorios previos:
    * `oas1_resnet18_linearprobe/‚Ä¶`
    * `ft_effb3_colab/‚Ä¶`, `ft_effb3_stable_colab_plus/‚Ä¶`, etc.
* Validaci√≥n autom√°tica de columnas y tama√±os; cualquier CSV no conforme se re-mapea.

---

### üìÖ 05/09/2025 ‚Äî Revisi√≥n de README/Informe/Cuaderno

* Se vuelcan resultados preliminares a la documentaci√≥n, con filas por pipeline (P1‚ÄìP11), incluyendo ConvNeXt-Tiny, Swin-Tiny y DenseNet-121.
* Se documenta que la estrategia de semillas en solitario no aport√≥ (`AUC` ‚âà 0.5), mientras que ensembles de pooling (4 features) s√≠ mejoraron hasta `AUC` test ‚âà 0.75.

---

### üìÖ 06/09/2025 ‚Äî Ajustes finales P11 y ensembles

* Normalizado definitivo de nombres en `comparison_backbones_eval.csv`.
* Confirmaci√≥n de Swin-Tiny (`top7`) como mejor alternativo aislado.
* Resumen de ensembles P11:
    * **Dirichlet (3 means)**: TEST `AUC` ‚âà 0.52.
    * **Dirichlet EXT (12)**: TEST `AUC` ‚âà 0.36.
    * **STACK\_LR(all)**: TEST `AUC` ‚âà 0.30 (overfit).
    * **Swin-Tiny isotonic**: TEST `AUC` ‚âà 0.566; `Acc` ‚âà 0.553; `R` 0.95; `P` 0.487.

---

### üìÖ 06/09/2025 ‚Äì Pipeline p13
- Procesamiento OASIS-2 ‚Üí 20 slices equiespaciados por scan.  
- Dataset reducido a 150 pacientes (una visita por paciente).  
- Entrenamiento base en Colab (EfficientNet-B3 (105/22/23).) ‚Üí resultados preliminares positivos, pero limitados.  

---

### üìÖ 06/09/2025 ‚Äì Pipeline p14
- Reentrenamiento con im√°genes (7340 slices) copiadas a SSD local de Colab.  
- A√±adido balanceo de clases con `class weights`.  
- Validaci√≥n fuerte (AUC‚âà0.88), recall en test=100%.  
- Integrado al cat√°logo de backbones.

---

### üìÖ 06/09/2025 ‚Äì Pipeline p15 (Consolidaci√≥n)
- Integraci√≥n de resultados p13 y p14 en el cat√°logo global de backbones.  
- Generaci√≥n de features combinadas con OASIS-1 (p11).  
- Dificultades: manejo de NaN en features y necesidad de descartar/ imputar columnas.  
- Modelos finales: Logistic Regression con imputaci√≥n y HistGradientBoosting (NaN nativo).  
- Resultado: VAL AUC‚âà0.94, TEST AUC‚âà0.71 con recall alto.

---

### üìÖ 06/09/2025 ‚Äì Pipeline p15 (Consolidaci√≥n de dataset OASIS-2)
- Se revisaron de nuevo todos los **367 scans** procesados de OASIS-2.  
- Confirmamos que solo **150 scans** contaban con etiquetas cl√≠nicas v√°lidas (Control/Dementia/Converted).  
- Se reafirm√≥ el criterio de **una √∫nica sesi√≥n por paciente** para evitar *data leakage* entre splits.  
- Se generaron **20 slices axiales equiespaciados** por volumen, eliminando los extremos (8%) y aplicando **normalizaci√≥n z-score + CLAHE opcional**.  
- Resultado: **150 pacientes √ó 20 slices = 3.000 im√°genes etiquetadas**.  
- Dificultad importante: el acceso a im√°genes desde Google Drive segu√≠a penalizando el entrenamiento por la latencia de E/S.  
  - **Soluci√≥n:** replicar todo el dataset en el **SSD local de Colab** antes de cada entrenamiento, lo que redujo dr√°sticamente los tiempos.  
- Con esta consolidaci√≥n, el dataset qued√≥ consistente, balanceado y preparado para ser integrado en ensembles.

---

### üìÖ 06/09/2025 ‚Äì Pipeline p16 (Refinamiento de ensembles)
- Se construyeron features **patient-level** a partir de m√∫ltiples backbones:  
  - `oas2_effb3`, `oas2_effb3_p14`, `SwinTiny`, `ConvNeXt_tiny`, `DenseNet121`, entre otros.  
- Durante la integraci√≥n, se detect√≥ un alto n√∫mero de columnas con valores faltantes (**NaNs**).  
  - Se aplic√≥ un criterio estricto: **descartar columnas con >40% NaN**.  
  - Para las restantes:  
    - **Logistic Regression (LR):** imputaci√≥n + columnas-flag de missingness.  
    - **HistGradientBoosting (HGB):** manejo nativo de NaNs, sin necesidad de imputar.  
- Se explor√≥ un esquema de **blending** LR+HGB, optimizado en validaci√≥n con Œ±=0.02 (casi todo el peso en HGB).  
- **Resultados clave:**  
  - **Validaci√≥n:**  
    - AUC‚âà0.95 global, con recall=100% en cohortes OAS1.  
    - En OAS2, las m√©tricas fueron m√°s bajas (AUC‚âà0.54) debido al reducido tama√±o de muestra, pero se mantuvo recall=100%.  
  - **Test:**  
    - AUC‚âà0.69 global.  
    - Recall‚âà78%, lo que representa una mejora respecto a modelos individuales.  
    - El blending aport√≥ mayor estabilidad en comparaci√≥n con usar un solo clasificador.  
- Conclusi√≥n: los ensembles **aumentan la sensibilidad del sistema y reducen el riesgo de overfitting**, consolid√°ndose como la mejor estrategia para explotar m√∫ltiples backbones en paralelo.

---
### üìÖ 07/09/2025 ‚Äì Pipeline p17

- **Objetivo:** Refinar los ensembles con calibraci√≥n de probabilidades.  
- **T√©cnicas aplicadas:**  
  - Stacking de outputs base (LR + HGB).  
  - Logistic Regression como meta-modelo.  
  - Platt scaling para calibraci√≥n probabil√≠stica.  
  - Optimizaci√≥n del umbral con F1 en validaci√≥n.  
- **Resultados globales:**  
  - [VAL] AUC‚âà0.78 | Recall=0.94 | F1=0.76 | Brier=0.176.  
  - [TEST] AUC‚âà0.70 | Recall=0.78 | F1=0.66 | Brier=0.227.  
- **An√°lisis por cohortes:**  
  - OAS1 se mantiene estable (val/test ‚âà0.84/0.77).  
  - OAS2 contin√∫a siendo inestable, con AUC ‚âà0.5 en test.  
- **Conclusi√≥n:**  
  - El ensemble calibrado aporta **confianza probabil√≠stica mejorada**.  
  - Se prioriza recall alto, sacrificando algo de precisi√≥n.  
  - El reto sigue siendo el tama√±o reducido de OAS2.  

 --- 

### üìÖ 07/09/2025 ‚Äì Pipeline p18
- Implementado **stacking multicapa** con cinco clasificadores base (LR, HGB, GB, RF, ET) y un meta-modelo log√≠stico.  
- Generaci√≥n de predicciones **OOF con 5 folds** para evitar fuga de informaci√≥n.  
- Ajuste de blending Œ±=0.02.  
- Evaluaci√≥n detallada por cohortes (OAS1, OAS2) y global.  
- **Resultados:**  
  - VAL AUC‚âà0.92 | Recall‚âà0.90 | F1‚âà0.83.  
  - TEST AUC‚âà0.67 | Recall‚âà0.78 | F1‚âà0.67.  
- Insight: GB y RF fueron los m√°s influyentes como modelos base, pero la generalizaci√≥n en OAS2 sigue limitada (AUC‚âà0.5).  

---

### üìÖ 07/09/2025 ‚Äì Pipeline p19

**Fase 8: Ensembles y calibraci√≥n (P18‚ÄìP19)**  

- **Qu√© hice:** ejecut√© P19 con stack de base learners (LR, HGB, GB, RF, LGBM, XGB) y meta-XGB. Constru√≠ OOF sin fuga con KFold, arm√© meta-features y evalu√© en VAL/TEST.  
- **Datos y features:** 56 columnas v√°lidas tras filtrar NaN>40%; representaci√≥n por paciente (mean/trimmed/top-k/p2).  
- **Resultados:**  
  - VAL: AUC=0.964; PRAUC=0.966; Acc=0.913; F1=0.897; Brier=0.071.  
  - TEST: AUC=0.729; PRAUC=0.688; Acc=0.714; F1=0.630; Brier=0.226.  
- **Aprendizajes:** meta fuerte en VAL pero recall bajo en TEST; hay shift (OAS1 vs OAS2) y el umbral global no es √≥ptimo. LightGBM sin splits √∫tiles sugiere simplificar meta y seleccionar features.  
- **Siguiente paso (p20):** calibrar meta, umbrales por cohorte, meta m√°s simple y Repeated KFold para robustez.

---

### üìÖ 07/09/2025 ‚Äì Fase 9: Meta-calibraci√≥n (P20)

**Qu√© hice:**  
Ejecut√© P20 sobre el meta-ensemble de p19, aplicando calibraci√≥n de probabilidades con Platt e isot√≥nica, tanto global como por cohorte (OAS1/OAS2).  

**Datos y setup:**  
36 columnas finales tras descartar NaN>40%. Modelos calibrados: HGB y LR. Guard√© predicciones calibradas en VAL/TEST y JSON de resumen.  

**Resultados clave:**  
- HGB-Isotonic-PerC: VAL AUC=0.840 | F1=0.753 | Brier=0.156  
- LR-Platt-Global: TEST AUC=0.686 | F1=0.658 | Brier=0.221  
- En TEST, recall‚âà0.78 con precisi√≥n moderada (‚âà0.54‚Äì0.57).  

**Aprendizajes:**  
La calibraci√≥n reduce el error de probabilidad (Brier), sobre todo en validaci√≥n.  
El umbral global no captura bien las diferencias entre cohortes; per-cohort mejora ligeramente.  
El modelo calibrado mantiene recall alto ‚Üí √∫til en escenario cl√≠nico de cribado.  

**Siguiente paso:**  
Integrar calibraciones en el ensemble completo, probar Elastic-Net como meta y explorar selecci√≥n de umbrales orientada a coste cl√≠nico.

---

### üìÖ 07/09/2025 ‚Äì Fase 8 ¬∑ P21 (Meta-refine)

**Qu√© hice.** Ejecut√© p21 con un stacking compacto (LR, HGB, LGBM, XGB) y meta a partir de 4 OOFs; filtr√© NaN>40% (36 columnas finales) y apliqu√© umbral F1-m√°x=0.45.

**Datos.** VAL=69, TEST=70; features por paciente procedentes de m√∫ltiples backbones (mean/trimmed/top-k/p2), con columna de cohorte (OAS1/OAS2).

**Resultados.**
- VAL: AUC 0.955, PRAUC 0.931, Acc 0.870, F1 0.862, Brier 0.082.
- TEST: AUC 0.653, PRAUC 0.587, Acc 0.643, F1 0.627, Brier 0.285.

**Observaciones.**
- LGBM sin splits con ganancia positiva ‚Üí complejidad excesiva frente a muestra disponible.
- Buen VAL pero ca√≠da en TEST (shift OAS1/OAS2 + umbral global).

**Siguiente.**
- p22: calibraci√≥n/umbrales por cohorte y por coste; meta m√°s regularizado; Repeated KFold para robustez.

---

### üìÖ 07/09/2025 ‚Äì Pipeline P22 (Meta-Ablation con calibraci√≥n avanzada)

- **Acci√≥n:** ejecut√© P22 aplicando calibraci√≥n Platt e Isot√≥nica a los modelos LR y HGB.  
- **Datos:** 69 pacientes en validaci√≥n y 70 en test, con 36 features seleccionadas (descartadas 20 por NaN>40%).  
- **Resultados clave:**  
  - LR-Platt: VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
  - LR-Isotonic: VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
  - HGB-Platt: VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
  - HGB-Isotonic: VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
  - Blend isot√≥nico: VAL AUC‚âà0.90, F1‚âà0.79 | TEST AUC‚âà0.68, F1‚âà0.62  
- **Aprendizaje:** la calibraci√≥n isot√≥nica mejora la fiabilidad de las probabilidades en validaci√≥n, pero en test muestra menor robustez (shift OAS1/OAS2). Platt mantiene recall m√°s alto.  
- **Conclusi√≥n:** P22 funcion√≥ como **estudio de ablaci√≥n** previo a la integraci√≥n final de calibraciones en meta-ensembles (p23).

---

### üìÖ 07/09/2025 ‚Äì Pipeline P23 (Meta-calibraci√≥n coste-cohorte)

- **Acci√≥n:** ejecut√© P23 aplicando calibraci√≥n Platt e Isot√≥nica con umbrales coste-√≥ptimos por cohorte (OAS1/OAS2).  
- **Criterio:** coste cl√≠nico FN=5, FP=1 ‚Üí penaliza falsos negativos.  
- **Artefactos guardados:**  
  - `p23_val_preds_calibrated.csv`  
  - `p23_test_preds_calibrated.csv`  
  - `p23_thresholds.json`  
  - `p23_calibrators.pkl`  
  - `p23_summary.json`  

**Resultados:**  
- **OAS1 (TEST):**  
  - Isotonic ‚Üí AUC=0.743 | PR-AUC=0.657 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
  - Platt ‚Üí AUC=0.724 | PR-AUC=0.649 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
- **OAS2 (TEST):**  
  - Ambos calibradores ‚Üí AUC=0.50 | PR-AUC‚âà0.52 | Recall=1.0 | Precision‚âà0.52 | Cost=11.0.  

**Conclusi√≥n:**  
- En OAS1, la calibraci√≥n isot√≥nica logra mejor AUC, pero Platt es competitivo.  
- En OAS2, el modelo no discrimina (AUC=0.5) pero alcanza recall=1.0, lo que elimina FN (clave cl√≠nicamente).  
- Se confirma la necesidad de **umbrales diferenciados por cohorte**.  
- P23 sienta la base para un meta-final m√°s simple y robusto (Elastic-Net + Repeated KFold).

---

### üìÖ 07/09/2025 ‚Äî P24 ejecutado (LR elastic-net + KFold repetido + Platt)

- Features paciente fusionadas (p11+p14).  
- CV(5√ó5): AUC=0.880¬±0.090; mejores params: {'clf__C': 0.1, 'clf__l1_ratio': 0.7}.  
- TEST Global: AUC=0.727, PR-AUC=0.717, Brier=0.220.  
- TEST OAS1: AUC=0.754, PR-AUC=0.736, Brier=0.211.  
- TEST OAS2: AUC=0.750, PR-AUC=0.805, Brier=0.238.  
- Umbrales coste per-cohorte: OAS1 thr=0.435 ‚Üí Coste=39.0 (R=0.70, P=0.61, Acc=0.68) | OAS2 thr=0.332 ‚Üí Coste=12.0 (R=0.92, P=0.61, Acc=0.65)

_Artefactos_: `p24_meta_simple/` (preds, coeficientes, modelo, calibrador, summary, thresholds, report).

---

### üìÖ 07/09/2025 ‚Äî P25 (construcci√≥n del informe final)

- Consolid√© P19/P22/P23/P24 en `p25_master_table.csv`.
- Gener√© bloques finales para README/Informe/Bit√°cora.
- Figuras: ROC/PR/Calibraci√≥n, curvas de coste, sensibilidad de coste, ICs bootstrap; coeficientes top.
- Predicciones demo: `p25_predictions_labeled.csv` / `p25_predictions_unlabeled.csv`.
- Release reproducible: `p25_release/` (MANIFEST.json, ENVIRONMENT.json, MODEL_CARD.md).

**Modelo final sugerido:** P24 (LR elastic-net + Platt) con umbrales por cohorte (FN:FP=5:1).  
**TEST @ umbral:** OAS1‚Üí R=0.70, P=0.61 (Coste=39) ¬∑ OAS2‚Üí R=0.917, P=0.611 (Coste=12).

---

### üìÖ 07/09/2025 ‚Äî P26 intermodal (imagen + cl√≠nico)

- Consolidado cl√≠nico OASIS-1/2 (anti-fuga), OHE y medianas; 56 features de imagen (p11+p14/p13) alineadas.  
- Se√±al **p1** (OAS2) con cobertura ‚âà32% ‚Üí imputaci√≥n por cohorte (media VAL OAS2) + flag `p1_has`.  
- **Late vs Mid**:  
  - Late (p_img, p_clin, p1_fill, p1_has) ‚Äî **VAL AUC=0.916**, TEST **AUC=0.713**.  
  - Mid (IMG56+cl√≠nico+p1) ‚Äî VAL AUC=0.797, TEST 0.697.  
  - Selecci√≥n: **Late**.  
- **Coste 5:1 (umbral de VAL aplicado en TEST):**  
  - OAS1 @ 0.307 ‚Üí R=0.700, P=0.609, Acc=0.681, Coste=39.  
  - OAS2 @ 0.195 ‚Üí R=0.667, P=0.667, Acc=0.652, Coste=24.  
- **Calibraci√≥n (TEST, 10 bins):** ALL ECE=0.178; OAS1 0.150; **OAS2 0.313**.

---

### üìÖ 07/09/2025 ‚Äî P26b (Platt por cohorte)

- Calibraci√≥n Platt por cohorte entrenada en VAL, aplicada en TEST; re-umbrales 5:1 por cohorte.  
- **OAS1:** Brier 0.208 ‚Üí **0.199** (AUC‚âà0.754); **thr_VAL=0.340**; confusi√≥n/coste id√©nticos a P26.  
- **OAS2:** Brier 0.288 ‚Üí **0.241** (AUC‚âà0.652); **thr_VAL=0.374**; confusi√≥n/coste id√©nticos a P26.  
- Decisi√≥n de producto:  
  - **√önico:** P26b (OAS1=0.340, OAS2=0.374).  
  - **Mixto (cribado):** OAS1‚ÜíP26b@0.340 ¬∑ OAS2‚ÜíP24@0.332 (‚Üë recall).

_Artefactos:_ `p26_intermodal/` (preds, ece/mce, umbrales, report, summary, calibrados, bloques).

---

### üìÖ 08/09/2025 ‚Äî P27 (release + pol√≠tica S2)

**Hecho**
- Gener√© `p26_release.zip` con modelos, config, QA y documentaci√≥n.  
- Actualic√© **MODEL_CARD.md** y **HOW_TO_DEPLOY.md** con la **pol√≠tica S2** activa.  
- Regener√© `MANIFEST.json` y `ENVIRONMENT.txt` (trazabilidad completa).

**Pol√≠tica S2 (marcada)**
- Umbrales activos: `OAS1=0.42`, `OAS2=0.4928655287824083`.  
- Criterio: 5:1 (FN:FP) + ajuste OAS2 para **Recall ‚â• 0.90**.  
- Motivo: minimizar FN en dominio OAS2 (m√°s variable/descalibrado), manteniendo el balance 5:1 en OAS1.

**Smoke (TEST @S2)**
- OAS1 ‚Üí TP=14, FP=9, TN=18, FN=6 ‚áí R=0.70, P=0.61, Acc=0.681, Coste=39.  
- OAS2 ‚Üí TP=11, FP=6, TN=5, FN=1 ‚áí R=0.917, P=0.647, Acc=0.696, Coste=11.  
- Archivo: `p26_release/QA/p26b_test_report_recall_target.csv`.

**Archivos clave**
- `p26_release.zip` (23 ficheros, con MANIFEST).  
- Scripts: `compute_pimg_from_features.py`, `predict_end_to_end.py`.  
- Config activa: `CONFIG/deployment_config.json` (backup autom√°tico).

**Notas**
- ECE P26: ALL‚âà0.178, OAS1‚âà0.150, OAS2‚âà0.313 ‚Üí seguir monitorizando.  
- Mantener evaluaci√≥n por cohorte al desplegar; recalibrar si deriva.

**Siguiente**
- (Opcional) Endpoint batch/CLI y plantilla REST.  
- Checklist de producci√≥n: logs de FN y ECE, re-calibraci√≥n por ventana m√≥vil.

---

## üß≠ Chuleta r√°pida ‚Äî Pol√≠tica S2 y umbrales

**Pol√≠tica activa (S2)**  
- **OAS1 ‚Üí 5:1 (FN:FP)** con umbral aprendido en VAL ‚Üí **thr = 0.42**  
- **OAS2 ‚Üí ‚Äúrecall objetivo‚Äù en VAL (target = 0.85)** ‚Üí **thr ‚âà 0.492866**

**Archivo de configuraci√≥n:**  
`p26_release/CONFIG/deployment_config.json`

**Claves relevantes dentro del JSON:**
- `policy: "single"`
- `cost_policy: "FN:FP=5:1 (OAS1) + recall_target (OAS2)"`
- `thresholds: { "OAS1": 0.42, "OAS2": 0.4928655287824083 }`
- `thresholds_5to1: { "OAS1": 0.42, "OAS2": 0.49 }`  ‚Üê *fallback 5:1 puro*
- `thresholds_recall_target: { "OAS2": { "target": 0.85, "thr_val": 0.4928655‚Ä¶, "found": true } }`

**C√≥mo cambiar temporalmente de pol√≠tica:**
- **A 5:1 puro:** editar `cost_policy` y copiar `thresholds_5to1` a `thresholds`.
- **Volver a S2:** restablecer `cost_policy` anterior y los `thresholds` de S2.

> Tras editar el JSON, se recomienda un **smoke test** y (opcional) regenerar el ZIP del release.

---

### üìÖ 08/09/2025 - P27 ‚Äî Intermodal (Late) + Pol√≠tica S2 (TEST)

| Pipeline | Cohorte | M√©todo |   AUC | PR-AUC | Brier |   Acc |  Prec |   Rec |    Thr | Coste |
|:--------:|:------:|:------:|------:|------:|------:|------:|------:|------:|------:|-----:|
| **P27** | **ALL** | LATE | **0.736** | **0.729** | **0.229** | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
| **P27** | **OAS1** | **S2 (5:1)** | ‚Äî | ‚Äî | ‚Äî | **0.681** | **0.609** | **0.700** | **0.420** | **39** |
| **P27** | **OAS2** | **S2 (recall‚â•0.85)** | ‚Äî | ‚Äî | ‚Äî | **0.696** | **0.647** | **0.917** | **0.492866** | **11** |

**Notas:**
- Fila **ALL/LATE**: m√©tricas de probabilidad (AUC/PR-AUC/Brier) del modelo intermodal (Late).  
- Filas **OAS1/OAS2 (S2)**: decisi√≥n cl√≠nica tras calibraci√≥n por cohorte + pol√≠tica S2 (umbrales por cohorte).

---
### üìÖ 08/09/2025 P27 ‚Äî Tablas globales finales

### 1) Probabilidades (TEST) ‚Äî Comparativa por pipeline y cohorte
> Fuente: `p25_informe_final/p25_master_table.csv` (incluye P19, P22, P23, P24, P26).

| Pipeline | Cohorte | M√©todo        |   AUC | PR-AUC | Brier |
|:--------:|:------:|:--------------|------:|------:|------:|
| P19      | ALL    | XGB           | 0.671 | 0.606 | 0.292 |
| P19      | OAS1   | XGB           | 0.663 | 0.588 | 0.310 |
| P19      | OAS2   | XGB           | 0.663 | 0.683 | 0.257 |
| P22      | ALL    | **HGB_platt** | **0.702** | 0.629 | 0.222 |
| P22      | OAS1   | HGB_platt     | 0.724 | 0.649 | 0.209 |
| P22      | OAS2   | LR_platt      | 0.504 | 0.524 | 0.252 |
| P23      | OAS1   | isotonic      | 0.743 | 0.657 | 0.223 |
| P23      | OAS2   | platt         | 0.500 | 0.522 | 0.250 |
| P24      | ALL    | Platt         | 0.727 | 0.717 | 0.220 |
| P24      | OAS1   | Platt         | 0.754 | 0.736 | 0.211 |
| P24      | OAS2   | Platt         | 0.750 | 0.805 | 0.238 |
| P26      | ALL    | LATE          | 0.713 | 0.712 | 0.234 |
| P26      | OAS1   | LATE          | 0.754 | 0.736 | 0.208 |
| P26      | OAS2   | LATE          | 0.652 | 0.728 | 0.288 |

> Nota: P26=LATE intermodal (p\_img + p\_clin). P22 muestra varias calibraciones; arriba se listan las m√°s representativas.

### 2) Decisi√≥n cl√≠nica (TEST) ‚Äî Pol√≠tica activa **S2**
> Fuentes: `p26_release/QA/p26b_test_report_recall_target.csv` (S2) + `CONFIG/deployment_config.json`.

| Pipeline | Cohorte | Pol√≠tica        |  Acc  |  Prec |  Rec  |    Thr   | Coste |
|:--------:|:------:|:----------------|------:|------:|------:|---------:|-----:|
| P27      | OAS1   | **S2 (5:1)**    | 0.681 | 0.609 | 0.700 | 0.420000 |  39  |
| P27      | OAS2   | **S2 (R‚â•0.85)** | 0.696 | 0.647 | 0.917 | 0.492866 |  11  |

**Chuleta de umbrales S2 (d√≥nde cambiar):** `p26_release/CONFIG/deployment_config.json`  
`thresholds = {"OAS1": 0.42, "OAS2": 0.4928655‚Ä¶}` ¬∑ `thresholds_5to1` como fallback

---

### üìÖ 08/09/2025 ‚Äî P27 (tablas globales y gr√°ficos finales)

- Consolid√© tabla **global** de probabilidades (TEST) por *pipeline √ó cohorte*.  
- A√±ad√≠ tabla de **decisi√≥n cl√≠nica @S2** (TEST) con TP/FP/TN/FN, m√©tricas y umbrales por cohorte.  
- Gener√© **figuras** de AUC/PR-AUC/Brier por cohorte y dej√© referencia a ECE/MCE (P26 intermodal).  
- Actualic√© documentaci√≥n con **pol√≠tica S2** vigente (umbrales en `deployment_config.json`).

_Artefactos:_ `p25_informe_final/p25_master_table.csv`, `p26_release/QA/p26b_test_report_recall_target.csv`, `p26_intermodal/p26_test_calibration_ece.csv`, `p27_final/*.png`.

---

### üìÖ 08/09/2025 - P27 (figuras y tablas finales)

- Generadas figuras de barras **AUC / PR-AUC / Brier** por cohorte desde `p25_master_table.csv`.
- Exportada tabla de **decisi√≥n S2** (`p27_final/p27_decision_S2_table.csv`) a partir del QA del release.
- (Si disponible) Creada figura comparativa **S2 vs 5:1** en OAS2.
- Ruta de salida: `p27_final/`.

_Artefactos:_ `p27_final/*.png`, `p27_final/p27_decision_S2_table.csv`.

---

### üìÖ 10/09/2025 - P27: Scripts de inferencia + GUI y pol√≠tica S2

- A√±adidos **scripts operativos**:
  - `compute_pimg_from_features.py` ‚Üí genera `p_img` (imagen + Platt)
  - `predict_end_to_end.py` ‚Üí fusi√≥n LATE + **S2** (umbrales por cohorte)
- A√±adida **app Streamlit (`app.py`)** para ejecutar el pipeline v√≠a navegador.
- **Pol√≠tica activa S2** documentada (OAS1=0.42, OAS2‚âà0.4928655287824083) en `p26_release/CONFIG/deployment_config.json`.
- Preparado material de documentaci√≥n (`docs/*.md`) y rutas de modelos (P24/P26).
- Pr√≥ximos pasos: API REST (FastAPI), Docker, QA automatizado (golden set), monitorizaci√≥n ECE/MCE y coste.

---

### üìÖ 14/09/2025 - ‚Äî P27 (Release + Pol√≠tica S2 + QA + Apps)

## ‚úÖ Pol√≠tica de decisi√≥n activa (S2)
- **Regla:** mantener OAS1 en el umbral coste-√≥ptimo 5:1 y **ajustar OAS2** para forzar **Recall ‚â• 0.90** manteniendo FN muy bajos.
- **Umbrales activos (CONFIG/deployment_config.json):**
  - **OAS1 = 0.42**
  - **OAS2 = 0.4928655287824083**
- **Verificaci√≥n en TEST (p26b):**
  - **OAS1 @ 0.42** ‚Üí TP=14, FP=9, TN=18, FN=6 ‚Üí Precision=0.609 ¬∑ **Recall=0.700** ¬∑ Acc=0.681 ¬∑ Cost=39
  - **OAS2 @ 0.492865** ‚Üí TP=11, FP=6, TN=5, FN=1 ‚Üí Precision=0.647 ¬∑ **Recall=0.917** ¬∑ Acc=0.696 ¬∑ Cost=11
- **Motivaci√≥n:** priorizar **sensibilidad** en OAS2 (entorno m√°s ‚Äúdif√≠cil‚Äù) sin penalizar en exceso el coste operativo.

> Los ficheros de QA correspondientes se guardaron en: `p26_release/QA/p26b_test_report_recall_target.csv`.

## üì¶ Empaquetado (P26 release)
Se gener√≥ **`p26_release.zip`** con:
- `MODELS/` ‚Üí `p24_model.pkl`, `p24_platt.pkl`, `p24_coefficients.csv` (meta LR + Platt)
- `CONFIG/` ‚Üí `deployment_config.json` (umbrales S2) + copia de seguridad
- `GOLDEN/` ‚Üí lote m√≠nimo de prueba y **checksums**
- `DOCS/` ‚Üí `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`
- `QA/` ‚Üí tablas de matriz de confusi√≥n/curvas coste
- `MANIFEST.json`, `ENVIRONMENT.txt`

## üß™ QA adicional
- **Calibraci√≥n (TEST, p26):** ECE@10=0.178 (ALL) ¬∑ OAS1=0.150 ¬∑ **OAS2=0.313** ‚Üí vigilar recalibraci√≥n peri√≥dica por cohorte.
- **Comparativa con P24:** LATE intermodal aporta **mejor Recall** en OAS2 al mismo coste objetivo; AUC global similar (~0.71‚Äì0.73).

## üõ†Ô∏è Scripts operativos
- `compute_pimg_from_features.py` ‚Üí computa **p_img** a partir de matrices por-paciente (cat√°logo p11/p14). *I/O:* CSV de features ‚Üí CSV con `patient_id, p_img`.
- `predict_end_to_end.py` ‚Üí **pipeline completo** (imagen + cl√≠nico): carga `p24_model.pkl`+`p24_platt.pkl`, fusiona con cl√≠nico, aplica pol√≠tica por cohorte (S2) y guarda predicciones/decisiones.
- `predict_batch.py` (opcional) ‚Üí lotes con **s√≥lo** imagen (si ya existe `X_img` por-paciente).

**Ejemplos de uso r√°pidos:**
```bash
# 1) p_img desde features
python compute_pimg_from_features.py --val_csv p11_alt_backbones/val_patient_features_backbones.csv \
  --out p26_release/QA/pred_val_pimg.csv

# 2) end-to-end (imagen+cl√≠nico) con pol√≠tica S2
python predict_end_to_end.py --X_img p26_release/QA/pred_val_pimg.csv --X_clin data/clinical_consolidated.csv \  --model MODELS/p24_model.pkl --cal MODELS/p24_platt.pkl --config CONFIG/deployment_config.json --out ./preds_val.csv
```

## üñ•Ô∏è App Streamlit (demo + real)
- **Demo:** carga un CSV de muestra y permite **jugar** con la pol√≠tica (switch 5:1 vs S2) y **sliders** de umbral por cohorte; muestra TP/FP/TN/FN, **Coste** y curvas (ROC/PR/Calibraci√≥n).
- **Real:** sube CSV con columnas cl√≠nicas est√°ndar + `p_img` o activa el c√≥mputo de `p_img` si hay features. Usa los modelos de `MODELS/` y la pol√≠tica de `CONFIG/`.

**Ejecutar:**
```bash
streamlit run app.py
```

## üåê FastAPI (serving ligero)
- Endpoints `/predict` (JSON/CSV) con pol√≠tica S2, `/healthz`, `/version`.  
- Recomendado como **microservicio** detr√°s de Streamlit o de un front externo.

## ‚úÖ Checklist de cierre
- [x] Pol√≠tica S2 documentada en README/Informe/Bit√°cora y **reflejada** en `deployment_config.json`.
- [x] QA reproducible (confusiones por cohorte, coste, ECE).
- [x] Artefactos firmados y **MANIFEST** actualizado.
- [x] Demo interactiva lista (Streamlit).
- [x] Gu√≠a de FastAPI y scripts de batch.

----

...
### üß™ Extractos de logs √∫tiles

* Logits extremos y z-score (cuando aplic√≥):
    ```
    VAL (pre) logits: min=-7.78e5 | max=5.45e5 | mean‚âà-1.52e4 | std‚âà9.0e4
    VAL (post-z) logits: min‚âà-8.49 | max‚âà6.23 | std‚âà1.00
    TEST (pre) logits: min=-6.43e5 | max=4.92e5 | mean‚âà-1.28e4 | std‚âà8.87e4
    TEST (post-z) logits: min‚âà-7.10 | max‚âà5.69 | std‚âà1.00
    ```
* `safe_sigmoid` aplicado siempre antes de calibraci√≥n/ensembles que consumen logits.

---

### ‚ö†Ô∏è Incidencias recurrentes y soluciones

* **Drive ya montado**:
    * Error: `‚ÄúMountpoint must not already contain files‚Äù`.
    * Soluci√≥n: si `drive.mount()` falla, NO forzar; reiniciar entorno o usar `force_remount=True` s√≥lo cuando sea estrictamente necesario.
* **`DATA_DIR`/`VAL_MAP`/`TEST_MAP` ‚Äúno existen‚Äù aun existiendo**:
    * Causa: estado inconsistente de sesi√≥n (muchas horas/d√≠as sin reiniciar).
    * Soluci√≥n: reinicio completo; volver a montar; re-evaluar `Path.exists()`.
* **Columnas heterog√©neas** (`y_score`, `sigmoid(logit)`, `pred`):
    * Soluci√≥n: diccionario de normalizaci√≥n y validaci√≥n de esquemas, forzando `y_score`.
* **Overflow en `exp` (sigmoid)**:
    * Soluci√≥n: `safe_sigmoid` con `clip[-50, 50]`.
* **Sobreajuste de ensembles complejos** (Dirichlet EXT, STACK\_LR all-features):
    * Causa: `n(VAL)`=10, muchas features correlacionadas.
    * Mitigaci√≥n: reducir features, validaci√≥n cruzada a paciente, o usar regularizaci√≥n/priors m√°s informativos.

---

# üìä Resumen num√©rico (hitos clave, test)
| Bloque | M√©todo / Configuraci√≥n | AUC | PR-AUC | Acc | Recall | Precision |
|--------|------------------------|-----|--------|-----|--------|-----------|
| P7     | EffNet-B3 finetune     | .876| .762   | .745| 1.00   | .625      |
| P9     | EffNet-B3 stable       | .740| .630   | .72 | .65    | .62       |
| P10    | EffB3 stable + calib   | .546‚Äì.583 | .50‚Äì.53 | .51‚Äì.55 | 1.00 | .47‚Äì.49 |
| P10-ext| Ensemble pooling       | .754| .748   | .66‚Äì.70 | .50‚Äì.70 | .58‚Äì.71 |
| P11    | ConvNeXt-Tiny (mean)   | .509| .479   | .489| 1.00   | .455      |
| P11    | DenseNet-121 (trimmed) | .343| .407   | .319| .75    | .36       |
| P11    | Swin-Tiny (top7)       | .641| .597   | .553| .95    | .95       |
| P11-ens| Dirichlet (3 means)    | .520| .523   | .468| 1.00   | .444      |
| P11-ens| Dirichlet EXT (12)     | .361| .405   | .447| .85    | .425      |
| P11-ens| Swin-Tiny + isotonic   | .566| .458   | .553| .95    | .487      |

**Lectura**: los mejores ensembles paciente-level siguen siendo los construidos sobre EffNet-B3 (P10-ext).
Entre backbones alternativos, Swin-Tiny (`top7`) es el mejor individual; con isotonic gana algo de robustez.

---


# üìé Ap√©ndice: utilidades clave
Incluye `safe_sigmoid`, `fit_temperature`, `normalize_score`, `agg_patient`.

---

### üìé Ap√©ndice: fragmentos y utilidades

#### `safe_sigmoid` y `temperature scaling`

```python
import numpy as np
from scipy.optimize import minimize

def safe_sigmoid(z):
    z = np.clip(z, -50, 50)
    return 1/(1+np.exp(-z))

def fit_temperature(logits, y_true, init_T=1.0, bounds=(0.05,10.0)):
    logits = np.asarray(logits,float); y_true = np.asarray(y_true,float)
    def nll(T):
        p = safe_sigmoid(logits/T); eps=1e-7
        return -np.mean(y_true*np.log(p+eps)+(1-y_true)*np.log(1-p+eps))
    return float(minimize(lambda t: nll(t[0]), x0=[init_T], bounds=[bounds], method="L-BFGS-B").x[0])
```

#### Normalizaci√≥n de columnas de score

```python
SCORE_ALIASES = ['y_score','sigmoid(logit)','sigmoid(logits)','pred']

def normalize_score(df):
    for c in SCORE_ALIASES:
        if c in df.columns:
            df = df.rename(columns={c:'y_score'})
            break
    assert 'y_score' in df.columns, "No encuentro columna de score."
    return df
```

#### Pooling a paciente (`mean`/`trimmed20`/`top7`/`pmean_2`)

```python
import pandas as pd
import numpy as np

def agg_patient(df):
    g = df.groupby('patient_id')['y_score']
    return pd.DataFrame({
        'mean': g.mean(),
        'trimmed20': g.apply(lambda s: s.sort_values().iloc[int(len(s)*.1):int(len(s)*.9)].mean() if len(s)>=10 else s.mean()),
        'top7': g.apply(lambda s: s.sort_values(ascending=False).head(7).mean()),
        'pmean_2': g.apply(lambda s: (np.mean(np.power(np.clip(s,0,1),2)))**0.5)
    }).reset_index()
```

---


## üîç Desaf√≠os principales encontrados

1. **Inestabilidad en Colab:** sesiones largas provocaban errores o p√©rdida de conexi√≥n. Reinicios forzados solucionaron varios problemas.  
2. **Gesti√≥n de Google Drive:** errores frecuentes de montaje/desmontaje y rutas inconsistentes, resueltos con reinicios y verificaciones expl√≠citas.  
3. **Variabilidad de resultados:** seeds distintas produc√≠an m√©tricas diferentes; se resolvi√≥ con ensembles y calibraci√≥n.  
4. **Dificultad en calibraci√≥n:** temperature scaling mejoraba interpretabilidad pero bajaba AUC. Hubo que combinar con ensembles.  
5. **Backbones alternativos:** algunos decepcionaron (DenseNet) o no superaron a EffNet, confirmando que no hay ‚Äúganador absoluto‚Äù.  
6. **Complejidad de ensembles:** m√©todos como Dirichlet o Stacking mostraron sobreajuste en validaci√≥n y peores m√©tricas en test.  
7. **Limitaci√≥n de datos:** tama√±o reducido del dataset afect√≥ a generalizaci√≥n, especialmente en arquitecturas grandes como Swin.  
8. **Gesti√≥n de logs y CSV:** m√∫ltiples formatos distintos (`y_score`, `sigmoid(logit)`, etc.), lo que exigi√≥ unificaci√≥n manual en varios experimentos.

