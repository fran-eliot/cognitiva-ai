# üß≠ Cuaderno de Bit√°cora del Proyecto Cognitiva-AI 
> Diario t√©cnico detallado (por d√≠as) con decisiones, incidencias y resultados.  
> Objetivo: trazabilidad completa desde la preparaci√≥n del entorno hasta backbones alternativos y ensembles.

---

## üìå Convenciones y notas r√°pidas

- **Estructura de datos**:
  - `BASE_DIR = /content/drive/MyDrive/CognitivaAI`
  - `DATA_DIR = BASE_DIR/oas1_data`
  - `OUT_DIR` por pipeline (p.ej. `ft_effb3_stable_colab_plus`, `p11_alt_backbones`, etc.)
- **Mapas OASIS**: `oas1_val_colab_mapped.csv`, `oas1_test_colab_mapped.csv` (columnas claves: `png_path`, `target`, `patient_id`, ‚Ä¶).
- **Columnas de predicci√≥n**:
  - Formatos detectados: `y_score`, `sigmoid(logit)`, `sigmoid(logits)`, `pred`.
  - Se unifica a **`y_score`** internamente durante la carga.
- **Pooling a nivel paciente**: `mean`, `trimmed20`, `top7`, `pmean_2` (power mean con p=2).
- **M√©tricas**: AUC, PR-AUC, Acc, Recall, Precision. Umbral por:
  - **F1-opt** (maximiza F1 en VAL),
  - **Youden** (maximiza sensibilidad+especificidad-1),
  - **REC90/REC100** (recall fijado).

---

## Fase 7 ‚Äì OASIS-2 (p13, p14 y p15)

**Contexto:**  
Exploraci√≥n y explotaci√≥n del dataset OASIS-2 con EfficientNet-B3.  
Se implementaron tres pipelines consecutivos:

- **p13:** entrenamiento base con criterio de una sola visita por paciente.  
- **p14:** entrenamiento balanceado en Colab GPU, copiando im√°genes a SSD para mejorar la E/S.  
- **p15:** consolidaci√≥n de resultados de OASIS-2 (p13 y p14) junto a OASIS-1 (p11), integrando todos los backbones en un cat√°logo com√∫n y generando features de ensamble.

**Detalles t√©cnicos:**
- 20 slices por volumen, equiespaciados y normalizados (z-score + CLAHE).  
- Labels obtenidos del Excel cl√≠nico, convertidos a binario (Control=0, Dementia/Converted=1).  
- Split fijo: 105 train, 22 val, 23 test (1 sesi√≥n por paciente).  
- P14: entrenamiento con **class weights** y datos en **SSD local de Colab**.  
- P15: consolidaci√≥n en cat√°logo, eliminaci√≥n de features con NaN‚â•40%, uso de Logistic Regression (con imputaci√≥n) y HistGradientBoosting (manejo nativo de NaN).

**Resultados:**
- **p13:** recall alto, dataset limitado (150 pacientes).  
- **p14:** VAL AUC‚âà0.88, TEST AUC‚âà0.71 con recall=100%.  
- **p15:** consolidaci√≥n con ensamble ‚Üí VAL AUC‚âà0.94, TEST AUC‚âà0.71; recall alto sostenido.  
- Integraci√≥n completa en el cat√°logo de backbones (`oas2_effb3`, `oas2_effb3_p14`) y en las features consolidadas con OASIS-1.

---

# Fase 8 ‚Äì OASIS-2 (p15 y p16)

**Contexto general:**  
Tras los avances logrados con p13 y p14, donde exploramos el dataset OASIS-2 y conseguimos un modelo base s√≥lido con EfficientNet-B3, surgi√≥ la necesidad de dar un paso m√°s:  
1. **Consolidar la preparaci√≥n de datos (p15)** para asegurar coherencia y cobertura completa del dataset.  
2. **Refinar la estrategia de ensembles (p16)**, combinando backbones heterog√©neos en un esquema patient-level con m√©tricas robustas.

---

## Fase 9 ‚Äì Ensemble Calibration (p17)

**Contexto:**  
Tras p16, el siguiente paso fue calibrar las probabilidades del ensemble para aumentar la interpretabilidad y la utilidad cl√≠nica.

**Detalles t√©cnicos:**  
- Construcci√≥n de un meta-ensemble con Logistic Regression sobre outputs base.  
- Aplicaci√≥n de Platt scaling y optimizaci√≥n de umbral (F1).  
- Evaluaci√≥n con Brier Score para medir calibraci√≥n.  

**Resultados:**  
- Validaci√≥n: AUC‚âà0.78, Recall=0.94, F1=0.76, Brier=0.176.  
- Test: AUC‚âà0.70, Recall=0.78, F1=0.66, Brier=0.227.  
- Cohortes: OAS1 consistente; OAS2 limitado.  

**Conclusi√≥n:**  
La calibraci√≥n refina el ensemble, mantiene sensibilidad alta y mejora la calidad de las probabilidades, aunque la robustez en OAS2 a√∫n requiere trabajo.

---

# Fase 9 ‚Äì Comparativa p16 vs p17

**p16 ‚Äì Blending cl√°sico:**  
- LR + HGB combinados con un peso √≥ptimo (Œ±=0.02).  
- Validaci√≥n espectacular (AUC‚âà0.95, Recall=1.0), pero riesgo de sobreajuste.  
- En test, buen recall (0.78) pero sin calibraci√≥n de probabilidades.  

**p17 ‚Äì Ensemble calibrado:**  
- Stacking con Logistic Regression y Platt scaling.  
- AUC m√°s modesto en validaci√≥n (0.78) y test (0.70).  
- Mantiene recall‚âà0.78 y adem√°s optimiza la calibraci√≥n (Brier=0.227 en test).  
- Probabilidades m√°s interpretables, mejor preparadas para escenarios cl√≠nicos.  

**Conclusi√≥n de la fase:**  
- p16 = **mejor raw performance** (m√°ximo AUC).  
- p17 = **mejor calibraci√≥n y estabilidad cl√≠nica** (probabilidades confiables).  
- Ambos complementan la estrategia de ensembles: uno explota rendimiento, otro asegura interpretabilidad.

---

## Fase 9 ‚Äì Stacking avanzado (p18)

**Contexto:**  
Tras calibrar ensembles en p17, se dise√±√≥ un stacking multicapa para explorar la combinaci√≥n de m√∫ltiples clasificadores heterog√©neos.  

**Detalles t√©cnicos:**  
- **Base learners:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.  
- **Meta learner:** regresi√≥n log√≠stica con blending Œ±=0.02.  
- **Estrategia:**  
  - Generaci√≥n de predicciones OOF con 5-fold cross-validation.  
  - Validaci√≥n de umbral √≥ptimo en F1.  
  - Evaluaci√≥n separada para OAS1 y OAS2.  
- **M√©tricas adicionales:** Brier Score para calibraci√≥n, coeficientes de meta-LR y permutaci√≥n de importancias para interpretar contribuciones.

**Resultados:**  
- [VAL] AUC=0.92, Recall‚âà0.90, F1‚âà0.83, Precision‚âà0.78.  
- [TEST] AUC=0.67, Recall‚âà0.78, F1‚âà0.67, Precision‚âà0.59.  
- Cohorte OAS1 aport√≥ la mayor estabilidad, mientras que OAS2 mantuvo recall alto pero sin se√±al discriminativa clara (AUC‚âà0.5).

**Conclusiones:**  
El stacking multicapa permiti√≥ validar la viabilidad de **meta-modelos complejos** en un dataset MRI limitado.  
Gradient Boosting y Random Forest emergieron como pilares, aunque la brecha entre validaci√≥n y test evidencia el reto de generalizaci√≥n en cohortes peque√±as.

---

## Fase 9 ‚Äì Meta-Ablation y calibraci√≥n avanzada (P22)

**Contexto:**  
Tras consolidar los ensembles y aplicar calibraciones b√°sicas en fases previas (p20‚Äìp21), se dise√±√≥ P22 como un *ablation study* para comparar m√©todos de calibraci√≥n y medir su efecto en la estabilidad de las probabilidades y en la sensibilidad de los modelos.

**Dise√±o y ejecuci√≥n:**  
- Features: 56 columnas iniciales; tras filtrar NaN>40% se mantuvieron 36.  
- Cohortes: 69 pacientes en validaci√≥n, 70 en test.  
- Modelos calibrados:  
  - Logistic Regression (LR) con imputaci√≥n y escalado.  
  - HistGradientBoosting (HGB), tolerante a NaNs.  
- M√©todos de calibraci√≥n aplicados:  
  - **Platt scaling (sigmoid).**  
  - **Isotonic regression.**  
- Validaci√≥n con OOF por StratifiedKFold (sin fugas).  
- Selecci√≥n de umbral F1-m√°x en validaci√≥n (‚âà0.30‚Äì0.35).  

**Resultados principales:**  
- LR-Platt: VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
- LR-Isotonic: VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
- HGB-Platt: VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
- HGB-Isotonic: VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
- Blend (Isotonic): VAL AUC‚âà0.90, F1‚âà0.79 | TEST AUC‚âà0.68, F1‚âà0.62  

**Interpretaci√≥n:**  
- La calibraci√≥n isot√≥nica aporta mejor ajuste en validaci√≥n (Brier bajo), pero pierde robustez en test.  
- Platt mantiene recall alto, lo que lo hace m√°s apto para escenarios de cribado cl√≠nico.  
- El blend confirma robustez en validaci√≥n, pero sigue presente el gap entre cohortes OAS1 y OAS2.  

**Conclusi√≥n:**  
P22 aport√≥ claridad sobre qu√© t√©cnicas de calibraci√≥n son m√°s fiables en entornos cl√≠nicos peque√±os y heterog√©neos. Constituye la base para P23, donde se buscar√° integrar estas calibraciones dentro de meta-ensembles finales y analizar umbrales de decisi√≥n espec√≠ficos por cohorte.

---

### üìÖ Entrada ‚Äì Estrategia OASIS-1 y OASIS-2 en ensembles (p16‚Äìp22)

Durante los pipelines de ensembles avanzados (p16‚Äìp22) se trabaj√≥ con datos de
**OASIS-1 y OASIS-2** simult√°neamente. 

**Decisi√≥n clave:**
- No fusionar ambos datasets en uno √∫nico.
- Mantener la cohorte identificada (`cohort = OAS1 / OAS2`) en todos los
  DataFrames.
- Entrenar meta-modelos (LR, HGB, XGB, blends, calibraciones) sobre los datos
  combinados, pero **siempre evaluando por cohorte y global**.

**Beneficios:**
- Evita leakage entre cohortes.
- Permite comparar rendimiento en escenarios distintos:
  - OAS1: cross-sectional, mayor homogeneidad.
  - OAS2: longitudinal, m√°s ruido y variabilidad.
- Informa sobre la robustez del ensemble frente a shift de dominio.

**Resultado observado:**
- En validaci√≥n (VAL), OAS1 logra m√©tricas m√°s altas (AUC, Acc).
- En test (TEST), OAS2 muestra recall elevado pero menor calibraci√≥n y precisi√≥n.
- Globalmente (ALL), se obtiene una media ponderada que refleja mejor la
  dificultad del problema.

**Conclusi√≥n:**
El tratamiento separado de OASIS-1 y OASIS-2 dentro de los ensembles es esencial
para interpretar los resultados cl√≠nicos y dise√±ar calibraciones espec√≠ficas
para cada cohorte en los pipelines posteriores (p20‚Äìp22).

---

## Ficha de modelo ‚Äî P26 / P26b (intermodal)

**Entrada:**  
- Imagen (prob. P24 por paciente) + 56 features de imagen (p11+p14/p13).  
- Cl√≠nico consolidado (Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay).  
- Se√±al p1 (OAS2) con imputaci√≥n por cohorte + flag.

**Arquitectura:**  
- **P26 (Late):** meta-LR sobre `{p_img, p_clin, p1_fill, p1_has}`.  
- **P26b:** P26 + **calibraci√≥n Platt por cohorte** en VAL y re-umbrales 5:1.

**M√©tricas (TEST):**  
- P26 ‚Äî ALL AUC=0.713 ¬∑ PR-AUC=0.712 ¬∑ Brier=0.234; OAS1 AUC=0.754 ¬∑ OAS2 AUC=0.652.  
- P26b ‚Äî mejora Brier (OAS1 0.199, OAS2 0.241) sin cambiar confusi√≥n a coste 5:1.

**Umbrales recomendados:**  
- **P26:** OAS1=0.307 ¬∑ OAS2=0.195 (coste m√≠nimo).  
- **P26b (√∫nico):** OAS1=0.340 ¬∑ OAS2=0.374.  
- **Mixto (recall OAS2):** OAS1‚ÜíP26b@0.340 ¬∑ OAS2‚ÜíP24@0.332.

**Riesgos:** descalibraci√≥n en OAS2; tama√±o muestral.  
**Mitigaciones:** monitorizar **ECE/MCE**, recalibrar con ventana m√≥vil; reportar intervalos; mantener umbrales por cohorte.

**Artefactos clave:** ver `p26_intermodal/` (predicciones, calibraciones, umbrales, tablas ejecutivas, bloques).

---

# üóì Semana ‚Äúcero‚Äù: preparaci√≥n antes del arranque formal

## üìÖ 24/06/2025 ‚Äî Preparaci√≥n de entorno y √°rbol de carpetas
- Estructuramos las rutas de trabajo en **Google Drive** para garantizar persistencia.
- Creamos `CognitivaAI/` con subcarpetas para datos, salidas por pipeline y documentos (`README.md`, `InformeTecnico.md`, `CuadernoBitacora.md`).
- Decidimos usar **Google Colab** como entorno primario.

**Decisiones**  
- Convenci√≥n de nombres de salida (por pipeline) para poder concatenar y comparar.
- Est√°ndar de CSV: separador `,`, encoding UTF-8, cabeceras.

---

## üìÖ 25/06/2025 ‚Äî Ingesta y saneamiento de OASIS
- Revisi√≥n de **mapas** `oas1_val_colab_mapped.csv` y `oas1_test_colab_mapped.csv`.
- Verificaci√≥n de columnas m√≠nimas: `png_path`, `target`, `patient_id`.
- Exploraci√≥n de duplicidades por `patient_id` (coincide con el supuesto de m√∫ltiples cortes por paciente).
- Definici√≥n de **helpers** de lectura robusta (detecci√≥n de nombre real de columna score).

**Incidencias**  
- Rutas con barras invertidas en `source_hdr` (propiedad informativa). Sin impacto en lectura principal.

---

## üìÖ 26/06/2025 ‚Äî M√©tricas y umbrales
- Implementamos un bloque de evaluaci√≥n unificado con AUC, PR-AUC, Acc, P, R, y b√∫squeda del **umbral √≥ptimo F1** y **Youden**.
- A√±adimos perfiles **REC90** y **REC100** (para escenarios de alta sensibilidad).

**Decisi√≥n**  
- Registrar siempre `n` (tama√±o conjunto paciente) en los res√∫menes.

---

## üìÖ 27/06/2025 ‚Äî Dise√±o de pipelines
- Esbozo de los **Pipelines** P1‚Ä¶P11 (cl√≠nico ‚Üí MRI ‚Üí calibraci√≥n ‚Üí ensembles ‚Üí backbones).
- Cada pipeline escribe sus CSV y un **resumen** en una tabla comparativa.

**Lecci√≥n**  
- Trazabilidad por pipeline evita mezclar resultados de runs viejos.

---

## üìÖ 28/06/2025 ‚Äî Helpers de pooling a paciente
- Definimos pooling: `mean`, `trimmed20`, `top7`, y **`pmean_2`** (promedio potencia con p=2).
- Aseguramos **idempotencia**: si existen tablas, se reusan; si no, se crean.

---

## üìÖ 29/06/2025 ‚Äî Validaci√≥n r√°pida de lectura + guardado
- Mini-pipeline de lectura de mapas y generaci√≥n de features b√°sicos a paciente.
- Confirmamos conteos esperados (p. ej., 940 cortes VAL/TEST ‚Üí 47 pacientes).

---

# üèÅ Arranque formal

## üìÖ 01/07/2025 ‚Äî P1: Cl√≠nico OASIS-2 (XGB)
- **Modelo**: XGBoost.
- **Resultado**: **AUC ‚âà 0.897**.
- **Conclusi√≥n**: baseline tabular fuerte.

---

## üìÖ 03/07/2025 ‚Äî P2: Cl√≠nico fusi√≥n (XGB)
- Integraci√≥n de variables cl√≠nicas ampliadas.
- **Resultado**: **AUC ‚âà 0.991**, **Recall ~1.0**.
- **Riesgo**: posible **overfitting**.

---

## üìÖ 10/07/2025 ‚Äî P3: MRI OASIS-2 (ResNet50)
- **Backbone**: ResNet-50 (ImageNet).
- **Resultado (test)**: **AUC ‚âà 0.938**.
- **Conclusi√≥n**: MRI viable; base s√≥lida para Colab.

---

## üìÖ 15/07/2025 ‚Äî P5: MRI Colab (ResNet18 + Calib)
- **Resultado**: AUC ‚âà 0.724 | PR-AUC ‚âà 0.606 | Acc ‚âà 0.60 | R=0.80 | P=0.52.
- **Conclusi√≥n**: salto a Colab con calibraci√≥n aporta control, pero rendimiento moderado.

---

## üìÖ 20/07/2025 ‚Äî P6: EffNet-B3 embeddings
- **Resultado**: AUC ‚âà 0.704 | PR-AUC ‚âà 0.623 | Acc ‚âà 0.70 | R=0.90 | P=0.60.
- **Aprendizaje**: recall alto, a√∫n inestable.

---

## üìÖ 23/07/2025 ‚Äî P7: EffNet-B3 finetune
- **Resultado**: **AUC ‚âà 0.876** | PR-AUC ‚âà 0.762 | Acc ‚âà 0.745 | **R=1.0** | P=0.625.
- **Conclusi√≥n**: **mejor punto** hasta la fecha.

---

## üìÖ 30/07/2025 ‚Äî P9: EffNet-B3 stable
- **Resultado**: AUC ‚âà 0.740 | PR-AUC ‚âà 0.630 | Acc ‚âà 0.72 | R=0.65 | P=0.62.
- **Notas**: gana estabilidad, cede algo de recall.

---

## üìÖ 05/08/2025 ‚Äî P10: EffNet-B3 stable + calibraci√≥n
- **T√©cnicas**: temperature scaling, isotonic.
- **Caveat**: grandes magnitudes de **logits** ‚Üí overflow en `exp`.
- **Parche**:
  ```python
  def safe_sigmoid(z):
      z = np.clip(z, -50, 50)
      return 1/(1+np.exp(-z))

  def fit_temperature(logits, y_true, init_T=1.0, bounds=(0.05, 10.0)):
      logits = np.asarray(logits, float); y_true = np.asarray(y_true, float)
      def nll(T):
          p = safe_sigmoid(logits/T); eps = 1e-7
          return -np.mean(y_true*np.log(p+eps) + (1-y_true)*np.log(1-p+eps))
      return float(minimize(lambda t: nll(t[0]), x0=[init_T], bounds=[bounds], method="L-BFGS-B").x[0])
    ```
 - **Resultado(rango):** **AUC test 0.546‚Äì0.583**, PR-AUC ~0.50‚Äì0.53, Acc ~0.51‚Äì0.55, **Recall=1.0**, Precision ~0.47‚Äì0.49.
 - **Conclusi√≥n:** calibraci√≥n ‚Üì AUC pero ‚Üë interpretabilidad. Necesario ensemble posterior.

 ---

## üìÖ 10/08/2025 ‚Äî P10-ext: TRIMMED y seed-ensemble
- **Semillas 41/42/43** con agregaciones por paciente.
- **Logs:** ‚ÄúVAL slices por seed: [940,940,940] ‚Ä¶ Guardado slice-level seedENS‚Ä¶‚Äù
- **Seed-ensemble (media/TRIMMED/TOP7)** (sin calibrar) dio AUC test ‚âà 0.50‚Äì0.51 en algunos runs (semillas no aportaron mejora directa).
- **Stacking / Random weights (mean+trimmed20+top7+p2):**
  - **RF** y **STACK(no-neg)** sobre 4 features de pooling:
    - **VAL:** AUC ~0.90‚Äì0.91, PR-AUC ~0.92, Acc ~0.85‚Äì0.87, R ~0.75‚Äì0.95.
    - **TEST:** **AUC ~0.75**, PR-AUC ~0.73‚Äì0.75, Acc ~0.64‚Äì0.70, R ~0.50‚Äì0.70, P ~0.58‚Äì0.71.
  - **Ej. RAND(500 samples)** (mean/trimmed20/top7/p2):
    - Pesos ejemplo: mean 0.325, trimmed20 0.315, top7 0.322, p2 0.038.
    - **VAL:** AUC=0.909, PR-AUC=0.920, Acc=0.872, R=0.95, P=0.792.
    - **TEST:** **AUC=0.754**, PR-AUC=0.748, Acc=0.660, R=0.70, P=0.583.
 - **STACK_LR(mean+trimmed20+top7+p2):**
    - * Coefs ‚âà [0.407, 0.409, 0.485, 0.416], **intercept ‚àí0.923**.
    - **VAL**: AUC=0.909, PR-AUC=0.920, Acc=0.872, R=0.95, P=0.792.
    - **TEST**: AUC=0.754, PR-AUC=0.748, Acc=0.660, R=0.70, P=0.583.
- **Conclusi√≥n:**
    - **Consolidado**: a nivel paciente, **ensembles de pooling** (4 features) mejoran notablemente sobre seed-ensemble puro.

---

### üìÖ 12/08/2025 ‚Äî Documentaci√≥n y limpieza

 * A√±adidos al `README` e Informe: decisi√≥n de que ‚Äúestrategia de semillas‚Äù no aport√≥ sola.
 * Normalizaci√≥n de nombres de columnas en todos los CSV (de cara a p11).

 ---

 ## üìÖ 15/08/2025 ‚Äî P11: Backbones alternativos (inicio)

* Notebook: `cognitiva_ai_backbones.ipynb`.
* **Incidencia 1 (Drive)**: `‚ÄúMountpoint must not already contain files‚Äù` ‚Üí soluci√≥n: no remount si ya montado / reiniciar entorno tras semanas.
* **Incidencia 2 (rutas)**: `DATA_DIR` marcaba `exists=False` pese a existir ‚Üí soluci√≥n: reinicio completo; verificaci√≥n con `Path.exists()`.
* Carga correcta:
    ```
    Mounted at /content/drive
    üîé VAL_MAP ‚Ä¶/oas1_val_colab_mapped.csv
    üîé TEST_MAP ‚Ä¶/oas1_test_colab_mapped.csv
    ‚úÖ Columnas OK: ['patient_id','png_path','target']
    üíæ Config guardada: ‚Ä¶/p11_alt_backbones/p11_config.json
    ```

---

### üìÖ 16/08/2025 ‚Äî ConvNeXt-Tiny (in12k\_ft\_in1k)

* Inferencia: guard√≥ `convnext_tiny.in12k_ft_in1k_val_slices.csv` y `_test_slices.csv`.
* Resumen por pooling:
    * **ConvNeXtTiny-mean**: VAL `AUC` 0.5556 | `PR-AUC` 0.5436 | TEST `AUC` 0.5093 | `PR-AUC` 0.4790 | `Acc` 0.489 | `R`=1.0 | `P`=0.455.
    * **trimmed20**: TEST `AUC` 0.5000 | `PR-AUC` 0.4723.
    * **top7**: TEST `AUC` 0.5111 | `PR-AUC` 0.4643.
* Fila README: `| P11 | MRI Colab | ConvNeXt-Tiny (in12k_ft_in1k) + mean | 0.509 | 0.479 | 0.49 | 1.00 | 0.45 |`

---

### üìÖ 17/08/2025 ‚Äî DenseNet-121

* Peso ImageNet (no `d121_best.pth`).
* Slice-level ‚Üí patient-level:
    * **Dense121-mean**: TEST `AUC` 0.3241 | `PR-AUC` 0.3942 | `Acc` 0.340 | `R`=0.75 | `P`=0.366.
    * **trimmed20**: TEST `AUC` 0.3426 | `PR-AUC` 0.4068.
    * **top7**: TEST `AUC` 0.3019 (m√°s bajo).
* **Resumen**: DenseNet-121 decepciona en este dataset.

---
### üìÖ 18/08/2025 ‚Äî Swin-Tiny

* Slice-level ‚Üí patient-level:
    * **SwinTiny-mean**: TEST `AUC` 0.5352, `PR-AUC` 0.5109, `Acc` 0.447, `R`=1.0, `P`=1.0 (umbral muy bajo).
    * **SwinTiny-top7**: TEST `AUC` 0.6407, `PR-AUC` 0.5971, `Acc` 0.553, `R`=0.95, `P`=0.95 (mejor variante Swin).
* **Conclusi√≥n**: Swin-Tiny (`top7`) es el mejor de los alternativos probados.

---

### üìÖ 19/08/2025 ‚Äî Cat√°logo multi-backbone + normalizaci√≥n columnas

* Escaneo de `p11_alt_backbones` y carpetas previas:
    * Detectados `SwinTiny`, `ConvNeXt slices`, `DenseNet-121`, y adem√°s `efb3` de pipelines anteriores (`ft_effb3_*`).
* Unificaci√≥n de columnas: mapeo auto (`y_score`, `sigmoid(logit[s])`, `pred` ‚Üí `y_score`).
* Construcci√≥n features por paciente (VAL/TEST (47, 6) por fuente), guardados:
    * `val_patient_features_backbones.csv`
    * `test_patient_features_backbones.csv`
* Validaci√≥n:
    * `SwinTiny` OK (940 filas ‚Üí 47 pacientes).
    * `ConvNeXt slices` OK (940 ‚Üí 47).
    * `DenseNet` OK (940 ‚Üí 47).
    * Preds a nivel paciente de pipelines previos (47 directos) incluidas como features extra.

---

### üìÖ 20/08/2025 ‚Äî Ensemble de backbones (promedios y stacking base)

* **AVG** de 12 se√±ales `‚Äú*_mean‚Äù` (Swin/ConvNeXt/DenseNet + se√±ales paciente/effect):
    * **VAL (F1-opt)**: `AUC` 0.476 | `PR-AUC` 0.389 | `Acc` 0.40 | `R`=1.0 | `P`=0.333 | `thr`=0.3525 | `n`=10.
    * **TEST (F1-opt)**: `AUC` 0.713, `PR-AUC` 0.724 | `Acc` 0.426 | `R`=1.0 | `P`=0.426 | `thr`=0.3525 | `n`=47.
* **Observaci√≥n**: `AUC` test alto vs val bajo ‚Üí val (`n`=10) muy peque√±o; umbral podr√≠a transferirse demasiado ‚Äúoptimista‚Äù.
* **STACK\_LR(all\_features)**:
    * **VAL**: `AUC` 0.810 | `PR-AUC` 0.700 | `Acc` 0.800 | `R`=1.0 | `P`=0.600.
    * **TEST**: `AUC` 0.298 | `PR-AUC` 0.397 | `Acc` 0.383 | `P` 0.304 | `R` 0.35.
* **Overfitting claro a VAL**.

---

### üìÖ 21/08/2025 ‚Äî Dirichlet (3 backbones, means)

* **FEATURES**: `SwinTiny_mean`, `convnext_tiny..._mean`, `png_preds_d121_mean`.
* `N_SAMPLES`=800 (semilla 42).
* Mejor combinaci√≥n (ejemplo):
    * Pesos ‚âà Swin 0.972, ConvNeXt 0.004, Dense 0.024.
    * **VAL (F1-opt)**: `Acc` 0.70 | `P` 0.50 | `R` 1.0 | `thr` 0.474 | `AUC` 0.714, `PR-AUC` 0.633 (`n`=10).
    * **TEST (F1-opt)**: `Acc` 0.468 | `P` 0.444 | `R` 1.0 | `thr` 0.435 | `AUC` 0.520, `PR-AUC` 0.523 (`n`=47).
* **Youden TEST**: `Acc` 0.617 | `P` 0.667 | `R` 0.20 (umbral 0.481).
* **Conclusi√≥n**: mejora leve vs ConvNeXt-mean/DenseNet, pero por debajo de Swin-top7 y muy lejos de los ensembles de EffNet-B3 del P10-ext.

---

### üìÖ 22/08/2025 ‚Äî Dirichlet EXT (12 features)

* **FEATURES**: `{Swin[mean/trimmed/top7], ConvNeXt_slices[mean/trimmed/top7], DenseNet[mean/trimmed/top7]}` + se√±ales agregadas (`patient_preds_plus_mean`, `slice_preds_plus_mean`, `slice_preds_seedENS_mean`).
* **Resultado**:
    * **VAL**: `AUC` 0.714, `PR-AUC` 0.681.
    * **TEST**: `AUC` 0.361, `PR-AUC` 0.405.
* **Conclusi√≥n**: sobreajuste; demasiados grados de libertad para `n(VAL)` = 10.

---

### üìÖ 23/08/2025 ‚Äî Stacking L1 fuerte (sparsidad forzada)

* **FEATURES candidatas (ej.)**: `SwinTiny_top7`, `convnext..._top7`, `png_preds_d121_trimmed20`, `patient_preds_plus_mean`, `slice_preds_plus_mean`, `slice_preds_seedENS_mean`.
* **Resultado**: todos `coef=0` (modelo trivial), `intercept=0`.
* **VAL/TEST**: `AUC=0.5`; F1 ligado a prior por umbral 0.
* **Interpretaci√≥n**: el penalizador ‚Äúfuerte‚Äù anul√≥ todas las se√±ales (`n(VAL)` peque√±o + correlaci√≥n alta).

---

### üìÖ 24/08/2025 ‚Äî Isotonic sobre Swin-Tiny (top7)

* **Resultado**:
    * **VAL**: `AUC` 0.714 | `PR-AUC` 0.556 | `Acc` 0.400 | `R` 1.0 | `P` 0.333 | `thr` 0.0025.
    * **TEST**: `AUC` 0.566 | `PR-AUC` 0.458 | `Acc` 0.553 | `R` 0.95 | `P` 0.487 | `thr` 0.0025.
* **Conclusi√≥n**: la calibraci√≥n isot√≥nica ayuda ligeramente en test y fija un recall alto con precisi√≥n moderada.

---

### üìÖ 25/08/2025 ‚Äî Cat√°logo ampliado y parsers robustos

* Se indexan tambi√©n directorios previos:
    * `oas1_resnet18_linearprobe/‚Ä¶`
    * `ft_effb3_colab/‚Ä¶`, `ft_effb3_stable_colab_plus/‚Ä¶`, etc.
* Validaci√≥n autom√°tica de columnas y tama√±os; cualquier CSV no conforme se re-mapea.

---

### üìÖ 27/08/2025 ‚Äî Revisi√≥n de README/Informe/Cuaderno

* Se vuelcan resultados preliminares al `README`, con filas por pipeline (P1‚ÄìP11), incluyendo ConvNeXt-Tiny, Swin-Tiny y DenseNet-121.
* Se documenta que la estrategia de semillas en solitario no aport√≥ (`AUC` ‚âà 0.5), mientras que ensembles de pooling (4 features) s√≠ mejoraron hasta `AUC` test ‚âà 0.75.
* Se prepara archivo de Contexto para otros chats (evitar p√©rdida de hilo).

---

### üìÖ 29/08/2025 ‚Äî Ajustes finales P11 y ensembles

* Normalizado definitivo de nombres en `comparison_backbones_eval.csv`.
* Confirmaci√≥n de Swin-Tiny (`top7`) como mejor alternativo aislado.
* Resumen de ensembles P11:
    * **Dirichlet (3 means)**: TEST `AUC` ‚âà 0.52.
    * **Dirichlet EXT (12)**: TEST `AUC` ‚âà 0.36.
    * **STACK\_LR(all)**: TEST `AUC` ‚âà 0.30 (overfit).
    * **Swin-Tiny isotonic**: TEST `AUC` ‚âà 0.566; `Acc` ‚âà 0.553; `R` 0.95; `P` 0.487.

---

### üìÖ 04/09/2025 ‚Äì Pipeline p13
- Procesamiento OASIS-2 ‚Üí 20 slices equiespaciados por scan.  
- Selecci√≥n de 1 visita/paciente.  
- Entrenamiento base en EfficientNet-B3 (105/22/23).  

### üìÖ 05/09/2025 ‚Äì Pipeline p14
- Copia de 7340 slices a SSD local en Colab.  
- Entrenamiento balanceado con class weights.  
- AUC‚âà0.88 en val, recall=100% en test.  

### üìÖ 06/09/2025 ‚Äì Pipeline p15 (Consolidaci√≥n)
- Integraci√≥n de resultados p13 y p14 en el cat√°logo global de backbones.  
- Generaci√≥n de features combinadas con OASIS-1 (p11).  
- Dificultades: manejo de NaN en features y necesidad de descartar/ imputar columnas.  
- Modelos finales: Logistic Regression con imputaci√≥n y HistGradientBoosting (NaN nativo).  
- Resultado: VAL AUC‚âà0.94, TEST AUC‚âà0.71 con recall alto.

---

### üìÖ 06/09/2025 ‚Äì Pipeline p15 (Consolidaci√≥n de dataset OASIS-2)
- Se revisaron de nuevo todos los **367 scans** procesados de OASIS-2.  
- Confirmamos que solo **150 scans** contaban con etiquetas cl√≠nicas v√°lidas (Control/Dementia/Converted).  
- Se reafirm√≥ el criterio de **una √∫nica sesi√≥n por paciente** para evitar *data leakage* entre splits.  
- Se generaron **20 slices axiales equiespaciados** por volumen, eliminando los extremos (8%) y aplicando **normalizaci√≥n z-score + CLAHE opcional**.  
- Resultado: **150 pacientes √ó 20 slices = 3.000 im√°genes etiquetadas**.  
- Dificultad importante: el acceso a im√°genes desde Google Drive segu√≠a penalizando el entrenamiento por la latencia de E/S.  
  - **Soluci√≥n:** replicar todo el dataset en el **SSD local de Colab** antes de cada entrenamiento, lo que redujo dr√°sticamente los tiempos.  
- Con esta consolidaci√≥n, el dataset qued√≥ consistente, balanceado y preparado para ser integrado en ensembles.

---

### üìÖ 06/09/2025 ‚Äì Pipeline p16 (Refinamiento de ensembles)
- Se construyeron features **patient-level** a partir de m√∫ltiples backbones:  
  - `oas2_effb3`, `oas2_effb3_p14`, `SwinTiny`, `ConvNeXt_tiny`, `DenseNet121`, entre otros.  
- Durante la integraci√≥n, se detect√≥ un alto n√∫mero de columnas con valores faltantes (**NaNs**).  
  - Se aplic√≥ un criterio estricto: **descartar columnas con >40% NaN**.  
  - Para las restantes:  
    - **Logistic Regression (LR):** imputaci√≥n + columnas-flag de missingness.  
    - **HistGradientBoosting (HGB):** manejo nativo de NaNs, sin necesidad de imputar.  
- Se explor√≥ un esquema de **blending** LR+HGB, optimizado en validaci√≥n con Œ±=0.02 (casi todo el peso en HGB).  
- **Resultados clave:**  
  - **Validaci√≥n:**  
    - AUC‚âà0.95 global, con recall=100% en cohortes OAS1.  
    - En OAS2, las m√©tricas fueron m√°s bajas (AUC‚âà0.54) debido al reducido tama√±o de muestra, pero se mantuvo recall=100%.  
  - **Test:**  
    - AUC‚âà0.69 global.  
    - Recall‚âà78%, lo que representa una mejora respecto a modelos individuales.  
    - El blending aport√≥ mayor estabilidad en comparaci√≥n con usar un solo clasificador.  
- Conclusi√≥n: los ensembles **aumentan la sensibilidad del sistema y reducen el riesgo de overfitting**, consolid√°ndose como la mejor estrategia para explotar m√∫ltiples backbones en paralelo.

---
### üìÖ 07/09/2025 ‚Äì Pipeline p17

- **Objetivo:** Refinar los ensembles con calibraci√≥n de probabilidades.  
- **T√©cnicas aplicadas:**  
  - Stacking de outputs base (LR + HGB).  
  - Logistic Regression como meta-modelo.  
  - Platt scaling para calibraci√≥n probabil√≠stica.  
  - Optimizaci√≥n del umbral con F1 en validaci√≥n.  
- **Resultados globales:**  
  - [VAL] AUC‚âà0.78 | Recall=0.94 | F1=0.76 | Brier=0.176.  
  - [TEST] AUC‚âà0.70 | Recall=0.78 | F1=0.66 | Brier=0.227.  
- **An√°lisis por cohortes:**  
  - OAS1 se mantiene estable (val/test ‚âà0.84/0.77).  
  - OAS2 contin√∫a siendo inestable, con AUC ‚âà0.5 en test.  
- **Conclusi√≥n:**  
  - El ensemble calibrado aporta **confianza probabil√≠stica mejorada**.  
  - Se prioriza recall alto, sacrificando algo de precisi√≥n.  
  - El reto sigue siendo el tama√±o reducido de OAS2.  

 --- 

### üìÖ 07/09/2025 ‚Äì Pipeline p18
- Implementado **stacking multicapa** con cinco clasificadores base (LR, HGB, GB, RF, ET) y un meta-modelo log√≠stico.  
- Generaci√≥n de predicciones **OOF con 5 folds** para evitar fuga de informaci√≥n.  
- Ajuste de blending Œ±=0.02.  
- Evaluaci√≥n detallada por cohortes (OAS1, OAS2) y global.  
- **Resultados:**  
  - VAL AUC‚âà0.92 | Recall‚âà0.90 | F1‚âà0.83.  
  - TEST AUC‚âà0.67 | Recall‚âà0.78 | F1‚âà0.67.  
- Insight: GB y RF fueron los m√°s influyentes como modelos base, pero la generalizaci√≥n en OAS2 sigue limitada (AUC‚âà0.5).  

---

### üìÖ 07/09/2025 ‚Äì Pipeline p19

**Fase 8: Ensembles y calibraci√≥n (P18‚ÄìP19)**  

- **Qu√© hice:** ejecut√© P19 con stack de base learners (LR, HGB, GB, RF, LGBM, XGB) y meta-XGB. Constru√≠ OOF sin fuga con KFold, arm√© meta-features y evalu√© en VAL/TEST.  
- **Datos y features:** 56 columnas v√°lidas tras filtrar NaN>40%; representaci√≥n por paciente (mean/trimmed/top-k/p2).  
- **Resultados:**  
  - VAL: AUC=0.964; PRAUC=0.966; Acc=0.913; F1=0.897; Brier=0.071.  
  - TEST: AUC=0.729; PRAUC=0.688; Acc=0.714; F1=0.630; Brier=0.226.  
- **Aprendizajes:** meta fuerte en VAL pero recall bajo en TEST; hay shift (OAS1 vs OAS2) y el umbral global no es √≥ptimo. LightGBM sin splits √∫tiles sugiere simplificar meta y seleccionar features.  
- **Siguiente paso (p20):** calibrar meta, umbrales por cohorte, meta m√°s simple y Repeated KFold para robustez.

---

### üìÖ 07/09/2025 ‚Äì Fase 9: Meta-calibraci√≥n (P20)

**Qu√© hice:**  
Ejecut√© P20 sobre el meta-ensemble de p19, aplicando calibraci√≥n de probabilidades con Platt e isot√≥nica, tanto global como por cohorte (OAS1/OAS2).  

**Datos y setup:**  
36 columnas finales tras descartar NaN>40%. Modelos calibrados: HGB y LR. Guard√© predicciones calibradas en VAL/TEST y JSON de resumen.  

**Resultados clave:**  
- HGB-Isotonic-PerC: VAL AUC=0.840 | F1=0.753 | Brier=0.156  
- LR-Platt-Global: TEST AUC=0.686 | F1=0.658 | Brier=0.221  
- En TEST, recall‚âà0.78 con precisi√≥n moderada (‚âà0.54‚Äì0.57).  

**Aprendizajes:**  
La calibraci√≥n reduce el error de probabilidad (Brier), sobre todo en validaci√≥n.  
El umbral global no captura bien las diferencias entre cohortes; per-cohort mejora ligeramente.  
El modelo calibrado mantiene recall alto ‚Üí √∫til en escenario cl√≠nico de cribado.  

**Siguiente paso:**  
Integrar calibraciones en el ensemble completo, probar Elastic-Net como meta y explorar selecci√≥n de umbrales orientada a coste cl√≠nico.

---

### üìÖ 07/09/2025 ‚Äì Fase 8 ¬∑ P21 (Meta-refine)

**Qu√© hice.** Ejecut√© p21 con un stacking compacto (LR, HGB, LGBM, XGB) y meta a partir de 4 OOFs; filtr√© NaN>40% (36 columnas finales) y apliqu√© umbral F1-m√°x=0.45.

**Datos.** VAL=69, TEST=70; features por paciente procedentes de m√∫ltiples backbones (mean/trimmed/top-k/p2), con columna de cohorte (OAS1/OAS2).

**Resultados.**
- VAL: AUC 0.955, PRAUC 0.931, Acc 0.870, F1 0.862, Brier 0.082.
- TEST: AUC 0.653, PRAUC 0.587, Acc 0.643, F1 0.627, Brier 0.285.

**Observaciones.**
- LGBM sin splits con ganancia positiva ‚Üí complejidad excesiva frente a muestra disponible.
- Buen VAL pero ca√≠da en TEST (shift OAS1/OAS2 + umbral global).

**Siguiente.**
- p22: calibraci√≥n/umbrales por cohorte y por coste; meta m√°s regularizado; Repeated KFold para robustez.

---

### üìÖ 07/09/2025 ‚Äì Pipeline P22 (Meta-Ablation con calibraci√≥n avanzada)

- **Acci√≥n:** ejecut√© P22 aplicando calibraci√≥n Platt e Isot√≥nica a los modelos LR y HGB.  
- **Datos:** 69 pacientes en validaci√≥n y 70 en test, con 36 features seleccionadas (descartadas 20 por NaN>40%).  
- **Resultados clave:**  
  - LR-Platt: VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
  - LR-Isotonic: VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
  - HGB-Platt: VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
  - HGB-Isotonic: VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
  - Blend isot√≥nico: VAL AUC‚âà0.90, F1‚âà0.79 | TEST AUC‚âà0.68, F1‚âà0.62  
- **Aprendizaje:** la calibraci√≥n isot√≥nica mejora la fiabilidad de las probabilidades en validaci√≥n, pero en test muestra menor robustez (shift OAS1/OAS2). Platt mantiene recall m√°s alto.  
- **Conclusi√≥n:** P22 funcion√≥ como **estudio de ablaci√≥n** previo a la integraci√≥n final de calibraciones en meta-ensembles (p23).

---

### üìÖ 07/09/2025 ‚Äì Pipeline P23 (Meta-calibraci√≥n coste-cohorte)

- **Acci√≥n:** ejecut√© P23 aplicando calibraci√≥n Platt e Isot√≥nica con umbrales coste-√≥ptimos por cohorte (OAS1/OAS2).  
- **Criterio:** coste cl√≠nico FN=5, FP=1 ‚Üí penaliza falsos negativos.  
- **Artefactos guardados:**  
  - `p23_val_preds_calibrated.csv`  
  - `p23_test_preds_calibrated.csv`  
  - `p23_thresholds.json`  
  - `p23_calibrators.pkl`  
  - `p23_summary.json`  

**Resultados:**  
- **OAS1 (TEST):**  
  - Isotonic ‚Üí AUC=0.743 | PR-AUC=0.657 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
  - Platt ‚Üí AUC=0.724 | PR-AUC=0.649 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
- **OAS2 (TEST):**  
  - Ambos calibradores ‚Üí AUC=0.50 | PR-AUC‚âà0.52 | Recall=1.0 | Precision‚âà0.52 | Cost=11.0.  

**Conclusi√≥n:**  
- En OAS1, la calibraci√≥n isot√≥nica logra mejor AUC, pero Platt es competitivo.  
- En OAS2, el modelo no discrimina (AUC=0.5) pero alcanza recall=1.0, lo que elimina FN (clave cl√≠nicamente).  
- Se confirma la necesidad de **umbrales diferenciados por cohorte**.  
- P23 sienta la base para un meta-final m√°s simple y robusto (Elastic-Net + Repeated KFold).

---

### 2025-09-07 ‚Äî P24 ejecutado (LR elastic-net + KFold repetido + Platt)

- Features paciente fusionadas (p11+p14).  
- CV(5√ó5): AUC=0.880¬±0.090; mejores params: {'clf__C': 0.1, 'clf__l1_ratio': 0.7}.  
- TEST Global: AUC=0.727, PR-AUC=0.717, Brier=0.220.  
- TEST OAS1: AUC=0.754, PR-AUC=0.736, Brier=0.211.  
- TEST OAS2: AUC=0.750, PR-AUC=0.805, Brier=0.238.  
- Umbrales coste per-cohorte: OAS1 thr=0.435 ‚Üí Coste=39.0 (R=0.70, P=0.61, Acc=0.68) | OAS2 thr=0.332 ‚Üí Coste=12.0 (R=0.92, P=0.61, Acc=0.65)

_Artefactos_: `p24_meta_simple/` (preds, coeficientes, modelo, calibrador, summary, thresholds, report).

---

### 2025-09-07 ‚Äî P25 (construcci√≥n del informe final)

- Consolid√© P19/P22/P23/P24 en `p25_master_table.csv`.
- Gener√© bloques finales para README/Informe/Bit√°cora.
- Figuras: ROC/PR/Calibraci√≥n, curvas de coste, sensibilidad de coste, ICs bootstrap; coeficientes top.
- Predicciones demo: `p25_predictions_labeled.csv` / `p25_predictions_unlabeled.csv`.
- Release reproducible: `p25_release/` (MANIFEST.json, ENVIRONMENT.json, MODEL_CARD.md).

**Modelo final sugerido:** P24 (LR elastic-net + Platt) con umbrales por cohorte (FN:FP=5:1).  
**TEST @ umbral:** OAS1‚Üí R=0.70, P=0.61 (Coste=39) ¬∑ OAS2‚Üí R=0.917, P=0.611 (Coste=12).

---

### 2025-09-07 ‚Äî P26 intermodal (imagen + cl√≠nico)

- Consolidado cl√≠nico OASIS-1/2 (anti-fuga), OHE y medianas; 56 features de imagen (p11+p14/p13) alineadas.  
- Se√±al **p1** (OAS2) con cobertura ‚âà32% ‚Üí imputaci√≥n por cohorte (media VAL OAS2) + flag `p1_has`.  
- **Late vs Mid**:  
  - Late (p_img, p_clin, p1_fill, p1_has) ‚Äî **VAL AUC=0.916**, TEST **AUC=0.713**.  
  - Mid (IMG56+cl√≠nico+p1) ‚Äî VAL AUC=0.797, TEST 0.697.  
  - Selecci√≥n: **Late**.  
- **Coste 5:1 (umbral de VAL aplicado en TEST):**  
  - OAS1 @ 0.307 ‚Üí R=0.700, P=0.609, Acc=0.681, Coste=39.  
  - OAS2 @ 0.195 ‚Üí R=0.667, P=0.667, Acc=0.652, Coste=24.  
- **Calibraci√≥n (TEST, 10 bins):** ALL ECE=0.178; OAS1 0.150; **OAS2 0.313**.

### 2025-09-07 ‚Äî P26b (Platt por cohorte)

- Calibraci√≥n Platt por cohorte entrenada en VAL, aplicada en TEST; re-umbrales 5:1 por cohorte.  
- **OAS1:** Brier 0.208 ‚Üí **0.199** (AUC‚âà0.754); **thr_VAL=0.340**; confusi√≥n/coste id√©nticos a P26.  
- **OAS2:** Brier 0.288 ‚Üí **0.241** (AUC‚âà0.652); **thr_VAL=0.374**; confusi√≥n/coste id√©nticos a P26.  
- Decisi√≥n de producto:  
  - **√önico:** P26b (OAS1=0.340, OAS2=0.374).  
  - **Mixto (cribado):** OAS1‚ÜíP26b@0.340 ¬∑ OAS2‚ÜíP24@0.332 (‚Üë recall).

_Artefactos:_ `p26_intermodal/` (preds, ece/mce, umbrales, report, summary, calibrados, bloques).

---

### 2025-09-08 ‚Äî P27 (release + pol√≠tica S2)

**Hecho**
- Gener√© `p26_release.zip` con modelos, config, QA y documentaci√≥n.  
- Actualic√© **MODEL_CARD.md** y **HOW_TO_DEPLOY.md** con la **pol√≠tica S2** activa.  
- Regener√© `MANIFEST.json` y `ENVIRONMENT.txt` (trazabilidad completa).

**Pol√≠tica S2 (marcada)**
- Umbrales activos: `OAS1=0.42`, `OAS2=0.4928655287824083`.  
- Criterio: 5:1 (FN:FP) + ajuste OAS2 para **Recall ‚â• 0.90**.  
- Motivo: minimizar FN en dominio OAS2 (m√°s variable/descalibrado), manteniendo el balance 5:1 en OAS1.

**Smoke (TEST @S2)**
- OAS1 ‚Üí TP=14, FP=9, TN=18, FN=6 ‚áí R=0.70, P=0.61, Acc=0.681, Coste=39.  
- OAS2 ‚Üí TP=11, FP=6, TN=5, FN=1 ‚áí R=0.917, P=0.647, Acc=0.696, Coste=11.  
- Archivo: `p26_release/QA/p26b_test_report_recall_target.csv`.

**Archivos clave**
- `p26_release.zip` (23 ficheros, con MANIFEST).  
- Scripts: `compute_pimg_from_features.py`, `predict_end_to_end.py`.  
- Config activa: `CONFIG/deployment_config.json` (backup autom√°tico).

**Notas**
- ECE P26: ALL‚âà0.178, OAS1‚âà0.150, OAS2‚âà0.313 ‚Üí seguir monitorizando.  
- Mantener evaluaci√≥n por cohorte al desplegar; recalibrar si deriva.

**Siguiente**
- (Opcional) Endpoint batch/CLI y plantilla REST.  
- Checklist de producci√≥n: logs de FN y ECE, re-calibraci√≥n por ventana m√≥vil.

---

## üß≠ Chuleta r√°pida ‚Äî Pol√≠tica S2 y umbrales

**Pol√≠tica activa (S2)**  
- **OAS1 ‚Üí 5:1 (FN:FP)** con umbral aprendido en VAL ‚Üí **thr = 0.42**  
- **OAS2 ‚Üí ‚Äúrecall objetivo‚Äù en VAL (target = 0.85)** ‚Üí **thr ‚âà 0.492866**

**Archivo de configuraci√≥n:**  
`p26_release/CONFIG/deployment_config.json`

**Claves relevantes dentro del JSON:**
- `policy: "single"`
- `cost_policy: "FN:FP=5:1 (OAS1) + recall_target (OAS2)"`
- `thresholds: { "OAS1": 0.42, "OAS2": 0.4928655287824083 }`
- `thresholds_5to1: { "OAS1": 0.42, "OAS2": 0.49 }`  ‚Üê *fallback 5:1 puro*
- `thresholds_recall_target: { "OAS2": { "target": 0.85, "thr_val": 0.4928655‚Ä¶, "found": true } }`

**C√≥mo cambiar temporalmente de pol√≠tica:**
- **A 5:1 puro:** editar `cost_policy` y copiar `thresholds_5to1` a `thresholds`.
- **Volver a S2:** restablecer `cost_policy` anterior y los `thresholds` de S2.

> Tras editar el JSON, se recomienda un **smoke test** y (opcional) regenerar el ZIP del release.

---

### P27 ‚Äî Intermodal (Late) + Pol√≠tica S2 (TEST)

| Pipeline | Cohorte | M√©todo |   AUC | PR-AUC | Brier |   Acc |  Prec |   Rec |    Thr | Coste |
|:--------:|:------:|:------:|------:|------:|------:|------:|------:|------:|------:|-----:|
| **P27** | **ALL** | LATE | **0.736** | **0.729** | **0.229** | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
| **P27** | **OAS1** | **S2 (5:1)** | ‚Äî | ‚Äî | ‚Äî | **0.681** | **0.609** | **0.700** | **0.420** | **39** |
| **P27** | **OAS2** | **S2 (recall‚â•0.85)** | ‚Äî | ‚Äî | ‚Äî | **0.696** | **0.647** | **0.917** | **0.492866** | **11** |

**Notas:**
- Fila **ALL/LATE**: m√©tricas de probabilidad (AUC/PR-AUC/Brier) del modelo intermodal (Late).  
- Filas **OAS1/OAS2 (S2)**: decisi√≥n cl√≠nica tras calibraci√≥n por cohorte + pol√≠tica S2 (umbrales por cohorte).

---

## üìä P27 ‚Äî Tablas globales finales

### 1) Probabilidades (TEST) ‚Äî Comparativa por pipeline y cohorte
> Fuente: `p25_informe_final/p25_master_table.csv` (incluye P19, P22, P23, P24, P26).

| Pipeline | Cohorte | M√©todo        |   AUC | PR-AUC | Brier |
|:--------:|:------:|:--------------|------:|------:|------:|
| P19      | ALL    | XGB           | 0.671 | 0.606 | 0.292 |
| P19      | OAS1   | XGB           | 0.663 | 0.588 | 0.310 |
| P19      | OAS2   | XGB           | 0.663 | 0.683 | 0.257 |
| P22      | ALL    | **HGB_platt** | **0.702** | 0.629 | 0.222 |
| P22      | OAS1   | HGB_platt     | 0.724 | 0.649 | 0.209 |
| P22      | OAS2   | LR_platt      | 0.504 | 0.524 | 0.252 |
| P23      | OAS1   | isotonic      | 0.743 | 0.657 | 0.223 |
| P23      | OAS2   | platt         | 0.500 | 0.522 | 0.250 |
| P24      | ALL    | Platt         | 0.727 | 0.717 | 0.220 |
| P24      | OAS1   | Platt         | 0.754 | 0.736 | 0.211 |
| P24      | OAS2   | Platt         | 0.750 | 0.805 | 0.238 |
| P26      | ALL    | LATE          | 0.713 | 0.712 | 0.234 |
| P26      | OAS1   | LATE          | 0.754 | 0.736 | 0.208 |
| P26      | OAS2   | LATE          | 0.652 | 0.728 | 0.288 |

> Nota: P26=LATE intermodal (p\_img + p\_clin). P22 muestra varias calibraciones; arriba se listan las m√°s representativas.

### 2) Decisi√≥n cl√≠nica (TEST) ‚Äî Pol√≠tica activa **S2**
> Fuentes: `p26_release/QA/p26b_test_report_recall_target.csv` (S2) + `CONFIG/deployment_config.json`.

| Pipeline | Cohorte | Pol√≠tica        |  Acc  |  Prec |  Rec  |    Thr   | Coste |
|:--------:|:------:|:----------------|------:|------:|------:|---------:|-----:|
| P27      | OAS1   | **S2 (5:1)**    | 0.681 | 0.609 | 0.700 | 0.420000 |  39  |
| P27      | OAS2   | **S2 (R‚â•0.85)** | 0.696 | 0.647 | 0.917 | 0.492866 |  11  |

**Chuleta de umbrales S2 (d√≥nde cambiar):** `p26_release/CONFIG/deployment_config.json`  
`thresholds = {"OAS1": 0.42, "OAS2": 0.4928655‚Ä¶}` ¬∑ `thresholds_5to1` como fallback

---

### 2025-09-08 ‚Äî P27 (tablas globales y gr√°ficos finales)

- Consolid√© tabla **global** de probabilidades (TEST) por *pipeline √ó cohorte*.  
- A√±ad√≠ tabla de **decisi√≥n cl√≠nica @S2** (TEST) con TP/FP/TN/FN, m√©tricas y umbrales por cohorte.  
- Gener√© **figuras** de AUC/PR-AUC/Brier por cohorte y dej√© referencia a ECE/MCE (P26 intermodal).  
- Actualic√© documentaci√≥n con **pol√≠tica S2** vigente (umbrales en `deployment_config.json`).

_Artefactos:_ `p25_informe_final/p25_master_table.csv`, `p26_release/QA/p26b_test_report_recall_target.csv`, `p26_intermodal/p26_test_calibration_ece.csv`, `p27_final/*.png`.

---

### 2025-09-08 ‚Äî P27 (figuras y tablas finales)

- Generadas figuras de barras **AUC / PR-AUC / Brier** por cohorte desde `p25_master_table.csv`.
- Exportada tabla de **decisi√≥n S2** (`p27_final/p27_decision_S2_table.csv`) a partir del QA del release.
- (Si disponible) Creada figura comparativa **S2 vs 5:1** en OAS2.
- Ruta de salida: `p27_final/`.

_Artefactos:_ `p27_final/*.png`, `p27_final/p27_decision_S2_table.csv`.

---

...
### üß™ Extractos de logs √∫tiles

* Logits extremos y z-score (cuando aplic√≥):
    ```
    VAL (pre) logits: min=-7.78e5 | max=5.45e5 | mean‚âà-1.52e4 | std‚âà9.0e4
    VAL (post-z) logits: min‚âà-8.49 | max‚âà6.23 | std‚âà1.00
    TEST (pre) logits: min=-6.43e5 | max=4.92e5 | mean‚âà-1.28e4 | std‚âà8.87e4
    TEST (post-z) logits: min‚âà-7.10 | max‚âà5.69 | std‚âà1.00
    ```
* `safe_sigmoid` aplicado siempre antes de calibraci√≥n/ensembles que consumen logits.

---

### ‚ö†Ô∏è Incidencias recurrentes y soluciones

* **Drive ya montado**:
    * Error: `‚ÄúMountpoint must not already contain files‚Äù`.
    * Soluci√≥n: si `drive.mount()` falla, NO forzar; reiniciar entorno o usar `force_remount=True` s√≥lo cuando sea estrictamente necesario.
* **`DATA_DIR`/`VAL_MAP`/`TEST_MAP` ‚Äúno existen‚Äù aun existiendo**:
    * Causa: estado inconsistente de sesi√≥n (muchas horas/d√≠as sin reiniciar).
    * Soluci√≥n: reinicio completo; volver a montar; re-evaluar `Path.exists()`.
* **Columnas heterog√©neas** (`y_score`, `sigmoid(logit)`, `pred`):
    * Soluci√≥n: diccionario de normalizaci√≥n y validaci√≥n de esquemas, forzando `y_score`.
* **Overflow en `exp` (sigmoid)**:
    * Soluci√≥n: `safe_sigmoid` con `clip[-50, 50]`.
* **Sobreajuste de ensembles complejos** (Dirichlet EXT, STACK\_LR all-features):
    * Causa: `n(VAL)`=10, muchas features correlacionadas.
    * Mitigaci√≥n: reducir features, validaci√≥n cruzada a paciente, o usar regularizaci√≥n/priors m√°s informativos.

---

# üìä Resumen num√©rico (hitos clave, test)
| Bloque | M√©todo / Configuraci√≥n | AUC | PR-AUC | Acc | Recall | Precision |
|--------|------------------------|-----|--------|-----|--------|-----------|
| P7     | EffNet-B3 finetune     | .876| .762   | .745| 1.00   | .625      |
| P9     | EffNet-B3 stable       | .740| .630   | .72 | .65    | .62       |
| P10    | EffB3 stable + calib   | .546‚Äì.583 | .50‚Äì.53 | .51‚Äì.55 | 1.00 | .47‚Äì.49 |
| P10-ext| Ensemble pooling       | .754| .748   | .66‚Äì.70 | .50‚Äì.70 | .58‚Äì.71 |
| P11    | ConvNeXt-Tiny (mean)   | .509| .479   | .489| 1.00   | .455      |
| P11    | DenseNet-121 (trimmed) | .343| .407   | .319| .75    | .36       |
| P11    | Swin-Tiny (top7)       | .641| .597   | .553| .95    | .95       |
| P11-ens| Dirichlet (3 means)    | .520| .523   | .468| 1.00   | .444      |
| P11-ens| Dirichlet EXT (12)     | .361| .405   | .447| .85    | .425      |
| P11-ens| Swin-Tiny + isotonic   | .566| .458   | .553| .95    | .487      |

**Lectura**: los mejores ensembles paciente-level siguen siendo los construidos sobre EffNet-B3 (P10-ext).
Entre backbones alternativos, Swin-Tiny (`top7`) es el mejor individual; con isotonic gana algo de robustez.

---

### üß≠ Estado actual

* Pipelines del 1 al 11 implementados y documentados.
* Backbones alternativos evaluados (Swin, ConvNeXt, Dense).
* Ensembles probados (AVG, Dirichlet, Stacking, Isotonic) con resultados concluyentes sobre limitaciones por tama√±o de VAL y correlaciones.

---

# üöÄ Pr√≥ximos pasos
- **Ensemble h√≠brido**: EffNet-B3 (pooling 4-feat) + Swin-Tiny (top7 isotonic).
- **Regularizaci√≥n**: stacking con priors y selecci√≥n de features no correlacionadas.
- **Multimodal**: cl√≠nico + MRI.
- **Aumento de datos**: ADNI, augmentations.

---

# üìé Ap√©ndice: utilidades clave
Incluye `safe_sigmoid`, `fit_temperature`, `normalize_score`, `agg_patient`.

---

### üìé Ap√©ndice: fragmentos y utilidades

#### `safe_sigmoid` y `temperature scaling`

```python
import numpy as np
from scipy.optimize import minimize

def safe_sigmoid(z):
    z = np.clip(z, -50, 50)
    return 1/(1+np.exp(-z))

def fit_temperature(logits, y_true, init_T=1.0, bounds=(0.05,10.0)):
    logits = np.asarray(logits,float); y_true = np.asarray(y_true,float)
    def nll(T):
        p = safe_sigmoid(logits/T); eps=1e-7
        return -np.mean(y_true*np.log(p+eps)+(1-y_true)*np.log(1-p+eps))
    return float(minimize(lambda t: nll(t[0]), x0=[init_T], bounds=[bounds], method="L-BFGS-B").x[0])
```

#### Normalizaci√≥n de columnas de score

```python
SCORE_ALIASES = ['y_score','sigmoid(logit)','sigmoid(logits)','pred']

def normalize_score(df):
    for c in SCORE_ALIASES:
        if c in df.columns:
            df = df.rename(columns={c:'y_score'})
            break
    assert 'y_score' in df.columns, "No encuentro columna de score."
    return df
```

#### Pooling a paciente (`mean`/`trimmed20`/`top7`/`pmean_2`)

```python
import pandas as pd
import numpy as np

def agg_patient(df):
    g = df.groupby('patient_id')['y_score']
    return pd.DataFrame({
        'mean': g.mean(),
        'trimmed20': g.apply(lambda s: s.sort_values().iloc[int(len(s)*.1):int(len(s)*.9)].mean() if len(s)>=10 else s.mean()),
        'top7': g.apply(lambda s: s.sort_values(ascending=False).head(7).mean()),
        'pmean_2': g.apply(lambda s: (np.mean(np.power(np.clip(s,0,1),2)))**0.5)
    }).reset_index()
```

Actualizado: 08/09/2025 22:45