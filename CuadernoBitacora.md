# ðŸ§­ Cuaderno de BitÃ¡cora del Proyecto Cognitiva-AI 
> Diario tÃ©cnico detallado (por dÃ­as) con decisiones, incidencias y resultados.  
> Objetivo: trazabilidad completa desde la preparaciÃ³n del entorno hasta backbones alternativos y ensembles.

---

## ðŸ“Œ Convenciones y notas rÃ¡pidas

- **Estructura de datos**:
  - `BASE_DIR = /content/drive/MyDrive/CognitivaAI`
  - `DATA_DIR = BASE_DIR/oas1_data`
  - `OUT_DIR` por pipeline (p.ej. `ft_effb3_stable_colab_plus`, `p11_alt_backbones`, etc.)
- **Mapas OASIS**: `oas1_val_colab_mapped.csv`, `oas1_test_colab_mapped.csv` (columnas claves: `png_path`, `target`, `patient_id`, â€¦).
- **Columnas de predicciÃ³n**:
  - Formatos detectados: `y_score`, `sigmoid(logit)`, `sigmoid(logits)`, `pred`.
  - Se unifica a **`y_score`** internamente durante la carga.
- **Pooling a nivel paciente**: `mean`, `trimmed20`, `top7`, `pmean_2` (power mean con p=2).
- **MÃ©tricas**: AUC, PR-AUC, Acc, Recall, Precision. Umbral por:
  - **F1-opt** (maximiza F1 en VAL),
  - **Youden** (maximiza sensibilidad+especificidad-1),
  - **REC90/REC100** (recall fijado).

---

# ðŸ—“ Semana â€œceroâ€: preparaciÃ³n antes del arranque formal

## ðŸ“… 24/06/2025 â€” PreparaciÃ³n de entorno y Ã¡rbol de carpetas
- Estructuramos las rutas de trabajo en **Google Drive** para garantizar persistencia.
- Creamos `CognitivaAI/` con subcarpetas para datos, salidas por pipeline y documentos (`README.md`, `InformeTecnico.md`, `CuadernoBitacora.md`).
- Decidimos usar **Google Colab** como entorno primario.

**Decisiones**  
- ConvenciÃ³n de nombres de salida (por pipeline) para poder concatenar y comparar.
- EstÃ¡ndar de CSV: separador `,`, encoding UTF-8, cabeceras.

---

## ðŸ“… 25/06/2025 â€” Ingesta y saneamiento de OASIS
- RevisiÃ³n de **mapas** `oas1_val_colab_mapped.csv` y `oas1_test_colab_mapped.csv`.
- VerificaciÃ³n de columnas mÃ­nimas: `png_path`, `target`, `patient_id`.
- ExploraciÃ³n de duplicidades por `patient_id` (coincide con el supuesto de mÃºltiples cortes por paciente).
- DefiniciÃ³n de **helpers** de lectura robusta (detecciÃ³n de nombre real de columna score).

**Incidencias**  
- Rutas con barras invertidas en `source_hdr` (propiedad informativa). Sin impacto en lectura principal.

---

## ðŸ“… 26/06/2025 â€” MÃ©tricas y umbrales
- Implementamos un bloque de evaluaciÃ³n unificado con AUC, PR-AUC, Acc, P, R, y bÃºsqueda del **umbral Ã³ptimo F1** y **Youden**.
- AÃ±adimos perfiles **REC90** y **REC100** (para escenarios de alta sensibilidad).

**DecisiÃ³n**  
- Registrar siempre `n` (tamaÃ±o conjunto paciente) en los resÃºmenes.

---

## ðŸ“… 27/06/2025 â€” DiseÃ±o de pipelines
- Esbozo de los **Pipelines** P1â€¦P11 (clÃ­nico â†’ MRI â†’ calibraciÃ³n â†’ ensembles â†’ backbones).
- Cada pipeline escribe sus CSV y un **resumen** en una tabla comparativa.

**LecciÃ³n**  
- Trazabilidad por pipeline evita mezclar resultados de runs viejos.

---

## ðŸ“… 28/06/2025 â€” Helpers de pooling a paciente
- Definimos pooling: `mean`, `trimmed20`, `top7`, y **`pmean_2`** (promedio potencia con p=2).
- Aseguramos **idempotencia**: si existen tablas, se reusan; si no, se crean.

---

## ðŸ“… 29/06/2025 â€” ValidaciÃ³n rÃ¡pida de lectura + guardado
- Mini-pipeline de lectura de mapas y generaciÃ³n de features bÃ¡sicos a paciente.
- Confirmamos conteos esperados (p. ej., 940 cortes VAL/TEST â†’ 47 pacientes).

---

# ðŸ Arranque formal

## ðŸ“… 01/07/2025 â€” P1: ClÃ­nico OASIS-2 (XGB)
- **Modelo**: XGBoost.
- **Resultado**: **AUC â‰ˆ 0.897**.
- **ConclusiÃ³n**: baseline tabular fuerte.

---

## ðŸ“… 03/07/2025 â€” P2: ClÃ­nico fusiÃ³n (XGB)
- IntegraciÃ³n de variables clÃ­nicas ampliadas.
- **Resultado**: **AUC â‰ˆ 0.991**, **Recall ~1.0**.
- **Riesgo**: posible **overfitting**.

---

## ðŸ“… 10/07/2025 â€” P3: MRI OASIS-2 (ResNet50)
- **Backbone**: ResNet-50 (ImageNet).
- **Resultado (test)**: **AUC â‰ˆ 0.938**.
- **ConclusiÃ³n**: MRI viable; base sÃ³lida para Colab.

---

## ðŸ“… 15/07/2025 â€” P5: MRI Colab (ResNet18 + Calib)
- **Resultado**: AUC â‰ˆ 0.724 | PR-AUC â‰ˆ 0.606 | Acc â‰ˆ 0.60 | R=0.80 | P=0.52.
- **ConclusiÃ³n**: salto a Colab con calibraciÃ³n aporta control, pero rendimiento moderado.

---

## ðŸ“… 20/07/2025 â€” P6: EffNet-B3 embeddings
- **Resultado**: AUC â‰ˆ 0.704 | PR-AUC â‰ˆ 0.623 | Acc â‰ˆ 0.70 | R=0.90 | P=0.60.
- **Aprendizaje**: recall alto, aÃºn inestable.

---

## ðŸ“… 23/07/2025 â€” P7: EffNet-B3 finetune
- **Resultado**: **AUC â‰ˆ 0.876** | PR-AUC â‰ˆ 0.762 | Acc â‰ˆ 0.745 | **R=1.0** | P=0.625.
- **ConclusiÃ³n**: **mejor punto** hasta la fecha.

---

## ðŸ“… 30/07/2025 â€” P9: EffNet-B3 stable
- **Resultado**: AUC â‰ˆ 0.740 | PR-AUC â‰ˆ 0.630 | Acc â‰ˆ 0.72 | R=0.65 | P=0.62.
- **Notas**: gana estabilidad, cede algo de recall.

---

## ðŸ“… 05/08/2025 â€” P10: EffNet-B3 stable + calibraciÃ³n
- **TÃ©cnicas**: temperature scaling, isotonic.
- **Caveat**: grandes magnitudes de **logits** â†’ overflow en `exp`.
- **Parche**:
  ```python
  def safe_sigmoid(z):
      z = np.clip(z, -50, 50)
      return 1/(1+np.exp(-z))

  def fit_temperature(logits, y_true, init_T=1.0, bounds=(0.05, 10.0)):
      logits = np.asarray(logits, float); y_true = np.asarray(y_true, float)
      def nll(T):
          p = safe_sigmoid(logits/T); eps = 1e-7
          return -np.mean(y_true*np.log(p+eps) + (1-y_true)*np.log(1-p+eps))
      return float(minimize(lambda t: nll(t[0]), x0=[init_T], bounds=[bounds], method="L-BFGS-B").x[0])
    ```
 - **Resultado(rango):** **AUC test 0.546â€“0.583**, PR-AUC ~0.50â€“0.53, Acc ~0.51â€“0.55, **Recall=1.0**, Precision ~0.47â€“0.49.
 - **ConclusiÃ³n:** calibraciÃ³n â†“ AUC pero â†‘ interpretabilidad. Necesario ensemble posterior.

 ---

## ðŸ“… 10/08/2025 â€” P10-ext: TRIMMED y seed-ensemble
- **Semillas 41/42/43** con agregaciones por paciente.
- **Logs:** â€œVAL slices por seed: [940,940,940] â€¦ Guardado slice-level seedENSâ€¦â€
- **Seed-ensemble (media/TRIMMED/TOP7)** (sin calibrar) dio AUC test â‰ˆ 0.50â€“0.51 en algunos runs (semillas no aportaron mejora directa).
- **Stacking / Random weights (mean+trimmed20+top7+p2):**
  - **RF** y **STACK(no-neg)** sobre 4 features de pooling:
    - **VAL:** AUC ~0.90â€“0.91, PR-AUC ~0.92, Acc ~0.85â€“0.87, R ~0.75â€“0.95.
    - **TEST:** **AUC ~0.75**, PR-AUC ~0.73â€“0.75, Acc ~0.64â€“0.70, R ~0.50â€“0.70, P ~0.58â€“0.71.
  - **Ej. RAND(500 samples)** (mean/trimmed20/top7/p2):
    - Pesos ejemplo: mean 0.325, trimmed20 0.315, top7 0.322, p2 0.038.
    - **VAL:** AUC=0.909, PR-AUC=0.920, Acc=0.872, R=0.95, P=0.792.
    - **TEST:** **AUC=0.754**, PR-AUC=0.748, Acc=0.660, R=0.70, P=0.583.
 - **STACK_LR(mean+trimmed20+top7+p2):**
    - * Coefs â‰ˆ [0.407, 0.409, 0.485, 0.416], **intercept âˆ’0.923**.
    - **VAL**: AUC=0.909, PR-AUC=0.920, Acc=0.872, R=0.95, P=0.792.
    - **TEST**: AUC=0.754, PR-AUC=0.748, Acc=0.660, R=0.70, P=0.583.
- **ConclusiÃ³n:**
    - **Consolidado**: a nivel paciente, **ensembles de pooling** (4 features) mejoran notablemente sobre seed-ensemble puro.

---

### ðŸ“… 12/08/2025 â€” DocumentaciÃ³n y limpieza

 * AÃ±adidos al `README` e Informe: decisiÃ³n de que â€œestrategia de semillasâ€ no aportÃ³ sola.
 * NormalizaciÃ³n de nombres de columnas en todos los CSV (de cara a p11).

 ---

 ## ðŸ“… 15/08/2025 â€” P11: Backbones alternativos (inicio)

* Notebook: `cognitiva_ai_backbones.ipynb`.
* **Incidencia 1 (Drive)**: `â€œMountpoint must not already contain filesâ€` â†’ soluciÃ³n: no remount si ya montado / reiniciar entorno tras semanas.
* **Incidencia 2 (rutas)**: `DATA_DIR` marcaba `exists=False` pese a existir â†’ soluciÃ³n: reinicio completo; verificaciÃ³n con `Path.exists()`.
* Carga correcta:
    ```
    Mounted at /content/drive
    ðŸ”Ž VAL_MAP â€¦/oas1_val_colab_mapped.csv
    ðŸ”Ž TEST_MAP â€¦/oas1_test_colab_mapped.csv
    âœ… Columnas OK: ['patient_id','png_path','target']
    ðŸ’¾ Config guardada: â€¦/p11_alt_backbones/p11_config.json
    ```

---

### ðŸ“… 16/08/2025 â€” ConvNeXt-Tiny (in12k\_ft\_in1k)

* Inferencia: guardÃ³ `convnext_tiny.in12k_ft_in1k_val_slices.csv` y `_test_slices.csv`.
* Resumen por pooling:
    * **ConvNeXtTiny-mean**: VAL `AUC` 0.5556 | `PR-AUC` 0.5436 | TEST `AUC` 0.5093 | `PR-AUC` 0.4790 | `Acc` 0.489 | `R`=1.0 | `P`=0.455.
    * **trimmed20**: TEST `AUC` 0.5000 | `PR-AUC` 0.4723.
    * **top7**: TEST `AUC` 0.5111 | `PR-AUC` 0.4643.
* Fila README: `| P11 | MRI Colab | ConvNeXt-Tiny (in12k_ft_in1k) + mean | 0.509 | 0.479 | 0.49 | 1.00 | 0.45 |`

---

### ðŸ“… 17/08/2025 â€” DenseNet-121

* Peso ImageNet (no `d121_best.pth`).
* Slice-level â†’ patient-level:
    * **Dense121-mean**: TEST `AUC` 0.3241 | `PR-AUC` 0.3942 | `Acc` 0.340 | `R`=0.75 | `P`=0.366.
    * **trimmed20**: TEST `AUC` 0.3426 | `PR-AUC` 0.4068.
    * **top7**: TEST `AUC` 0.3019 (mÃ¡s bajo).
* **Resumen**: DenseNet-121 decepciona en este dataset.

---
### ðŸ“… 18/08/2025 â€” Swin-Tiny

* Slice-level â†’ patient-level:
    * **SwinTiny-mean**: TEST `AUC` 0.5352, `PR-AUC` 0.5109, `Acc` 0.447, `R`=1.0, `P`=1.0 (umbral muy bajo).
    * **SwinTiny-top7**: TEST `AUC` 0.6407, `PR-AUC` 0.5971, `Acc` 0.553, `R`=0.95, `P`=0.95 (mejor variante Swin).
* **ConclusiÃ³n**: Swin-Tiny (`top7`) es el mejor de los alternativos probados.

---

### ðŸ“… 19/08/2025 â€” CatÃ¡logo multi-backbone + normalizaciÃ³n columnas

* Escaneo de `p11_alt_backbones` y carpetas previas:
    * Detectados `SwinTiny`, `ConvNeXt slices`, `DenseNet-121`, y ademÃ¡s `efb3` de pipelines anteriores (`ft_effb3_*`).
* UnificaciÃ³n de columnas: mapeo auto (`y_score`, `sigmoid(logit[s])`, `pred` â†’ `y_score`).
* ConstrucciÃ³n features por paciente (VAL/TEST (47, 6) por fuente), guardados:
    * `val_patient_features_backbones.csv`
    * `test_patient_features_backbones.csv`
* ValidaciÃ³n:
    * `SwinTiny` OK (940 filas â†’ 47 pacientes).
    * `ConvNeXt slices` OK (940 â†’ 47).
    * `DenseNet` OK (940 â†’ 47).
    * Preds a nivel paciente de pipelines previos (47 directos) incluidas como features extra.

---

### ðŸ“… 20/08/2025 â€” Ensemble de backbones (promedios y stacking base)

* **AVG** de 12 seÃ±ales `â€œ*_meanâ€` (Swin/ConvNeXt/DenseNet + seÃ±ales paciente/effect):
    * **VAL (F1-opt)**: `AUC` 0.476 | `PR-AUC` 0.389 | `Acc` 0.40 | `R`=1.0 | `P`=0.333 | `thr`=0.3525 | `n`=10.
    * **TEST (F1-opt)**: `AUC` 0.713, `PR-AUC` 0.724 | `Acc` 0.426 | `R`=1.0 | `P`=0.426 | `thr`=0.3525 | `n`=47.
* **ObservaciÃ³n**: `AUC` test alto vs val bajo â†’ val (`n`=10) muy pequeÃ±o; umbral podrÃ­a transferirse demasiado â€œoptimistaâ€.
* **STACK\_LR(all\_features)**:
    * **VAL**: `AUC` 0.810 | `PR-AUC` 0.700 | `Acc` 0.800 | `R`=1.0 | `P`=0.600.
    * **TEST**: `AUC` 0.298 | `PR-AUC` 0.397 | `Acc` 0.383 | `P` 0.304 | `R` 0.35.
* **Overfitting claro a VAL**.

---

### ðŸ“… 21/08/2025 â€” Dirichlet (3 backbones, means)

* **FEATURES**: `SwinTiny_mean`, `convnext_tiny..._mean`, `png_preds_d121_mean`.
* `N_SAMPLES`=800 (semilla 42).
* Mejor combinaciÃ³n (ejemplo):
    * Pesos â‰ˆ Swin 0.972, ConvNeXt 0.004, Dense 0.024.
    * **VAL (F1-opt)**: `Acc` 0.70 | `P` 0.50 | `R` 1.0 | `thr` 0.474 | `AUC` 0.714, `PR-AUC` 0.633 (`n`=10).
    * **TEST (F1-opt)**: `Acc` 0.468 | `P` 0.444 | `R` 1.0 | `thr` 0.435 | `AUC` 0.520, `PR-AUC` 0.523 (`n`=47).
* **Youden TEST**: `Acc` 0.617 | `P` 0.667 | `R` 0.20 (umbral 0.481).
* **ConclusiÃ³n**: mejora leve vs ConvNeXt-mean/DenseNet, pero por debajo de Swin-top7 y muy lejos de los ensembles de EffNet-B3 del P10-ext.

---

### ðŸ“… 22/08/2025 â€” Dirichlet EXT (12 features)

* **FEATURES**: `{Swin[mean/trimmed/top7], ConvNeXt_slices[mean/trimmed/top7], DenseNet[mean/trimmed/top7]}` + seÃ±ales agregadas (`patient_preds_plus_mean`, `slice_preds_plus_mean`, `slice_preds_seedENS_mean`).
* **Resultado**:
    * **VAL**: `AUC` 0.714, `PR-AUC` 0.681.
    * **TEST**: `AUC` 0.361, `PR-AUC` 0.405.
* **ConclusiÃ³n**: sobreajuste; demasiados grados de libertad para `n(VAL)` = 10.

---

### ðŸ“… 23/08/2025 â€” Stacking L1 fuerte (sparsidad forzada)

* **FEATURES candidatas (ej.)**: `SwinTiny_top7`, `convnext..._top7`, `png_preds_d121_trimmed20`, `patient_preds_plus_mean`, `slice_preds_plus_mean`, `slice_preds_seedENS_mean`.
* **Resultado**: todos `coef=0` (modelo trivial), `intercept=0`.
* **VAL/TEST**: `AUC=0.5`; F1 ligado a prior por umbral 0.
* **InterpretaciÃ³n**: el penalizador â€œfuerteâ€ anulÃ³ todas las seÃ±ales (`n(VAL)` pequeÃ±o + correlaciÃ³n alta).

---

### ðŸ“… 24/08/2025 â€” Isotonic sobre Swin-Tiny (top7)

* **Resultado**:
    * **VAL**: `AUC` 0.714 | `PR-AUC` 0.556 | `Acc` 0.400 | `R` 1.0 | `P` 0.333 | `thr` 0.0025.
    * **TEST**: `AUC` 0.566 | `PR-AUC` 0.458 | `Acc` 0.553 | `R` 0.95 | `P` 0.487 | `thr` 0.0025.
* **ConclusiÃ³n**: la calibraciÃ³n isotÃ³nica ayuda ligeramente en test y fija un recall alto con precisiÃ³n moderada.

---

### ðŸ“… 25/08/2025 â€” CatÃ¡logo ampliado y parsers robustos

* Se indexan tambiÃ©n directorios previos:
    * `oas1_resnet18_linearprobe/â€¦`
    * `ft_effb3_colab/â€¦`, `ft_effb3_stable_colab_plus/â€¦`, etc.
* ValidaciÃ³n automÃ¡tica de columnas y tamaÃ±os; cualquier CSV no conforme se re-mapea.

---

### ðŸ“… 27/08/2025 â€” RevisiÃ³n de README/Informe/Cuaderno

* Se vuelcan resultados preliminares al `README`, con filas por pipeline (P1â€“P11), incluyendo ConvNeXt-Tiny, Swin-Tiny y DenseNet-121.
* Se documenta que la estrategia de semillas en solitario no aportÃ³ (`AUC` â‰ˆ 0.5), mientras que ensembles de pooling (4 features) sÃ­ mejoraron hasta `AUC` test â‰ˆ 0.75.
* Se prepara archivo de Contexto para otros chats (evitar pÃ©rdida de hilo).

---

### ðŸ“… 29/08/2025 â€” Ajustes finales P11 y ensembles

* Normalizado definitivo de nombres en `comparison_backbones_eval.csv`.
* ConfirmaciÃ³n de Swin-Tiny (`top7`) como mejor alternativo aislado.
* Resumen de ensembles P11:
    * **Dirichlet (3 means)**: TEST `AUC` â‰ˆ 0.52.
    * **Dirichlet EXT (12)**: TEST `AUC` â‰ˆ 0.36.
    * **STACK\_LR(all)**: TEST `AUC` â‰ˆ 0.30 (overfit).
    * **Swin-Tiny isotonic**: TEST `AUC` â‰ˆ 0.566; `Acc` â‰ˆ 0.553; `R` 0.95; `P` 0.487.

---

...
### ðŸ§ª Extractos de logs Ãºtiles

* Logits extremos y z-score (cuando aplicÃ³):
    ```
    VAL (pre) logits: min=-7.78e5 | max=5.45e5 | meanâ‰ˆ-1.52e4 | stdâ‰ˆ9.0e4
    VAL (post-z) logits: minâ‰ˆ-8.49 | maxâ‰ˆ6.23 | stdâ‰ˆ1.00
    TEST (pre) logits: min=-6.43e5 | max=4.92e5 | meanâ‰ˆ-1.28e4 | stdâ‰ˆ8.87e4
    TEST (post-z) logits: minâ‰ˆ-7.10 | maxâ‰ˆ5.69 | stdâ‰ˆ1.00
    ```
* `safe_sigmoid` aplicado siempre antes de calibraciÃ³n/ensembles que consumen logits.

---

### âš ï¸ Incidencias recurrentes y soluciones

* **Drive ya montado**:
    * Error: `â€œMountpoint must not already contain filesâ€`.
    * SoluciÃ³n: si `drive.mount()` falla, NO forzar; reiniciar entorno o usar `force_remount=True` sÃ³lo cuando sea estrictamente necesario.
* **`DATA_DIR`/`VAL_MAP`/`TEST_MAP` â€œno existenâ€ aun existiendo**:
    * Causa: estado inconsistente de sesiÃ³n (muchas horas/dÃ­as sin reiniciar).
    * SoluciÃ³n: reinicio completo; volver a montar; re-evaluar `Path.exists()`.
* **Columnas heterogÃ©neas** (`y_score`, `sigmoid(logit)`, `pred`):
    * SoluciÃ³n: diccionario de normalizaciÃ³n y validaciÃ³n de esquemas, forzando `y_score`.
* **Overflow en `exp` (sigmoid)**:
    * SoluciÃ³n: `safe_sigmoid` con `clip[-50, 50]`.
* **Sobreajuste de ensembles complejos** (Dirichlet EXT, STACK\_LR all-features):
    * Causa: `n(VAL)`=10, muchas features correlacionadas.
    * MitigaciÃ³n: reducir features, validaciÃ³n cruzada a paciente, o usar regularizaciÃ³n/priors mÃ¡s informativos.

---

# ðŸ“Š Resumen numÃ©rico (hitos clave, test)
| Bloque | MÃ©todo / ConfiguraciÃ³n | AUC | PR-AUC | Acc | Recall | Precision |
|--------|------------------------|-----|--------|-----|--------|-----------|
| P7     | EffNet-B3 finetune     | .876| .762   | .745| 1.00   | .625      |
| P9     | EffNet-B3 stable       | .740| .630   | .72 | .65    | .62       |
| P10    | EffB3 stable + calib   | .546â€“.583 | .50â€“.53 | .51â€“.55 | 1.00 | .47â€“.49 |
| P10-ext| Ensemble pooling       | .754| .748   | .66â€“.70 | .50â€“.70 | .58â€“.71 |
| P11    | ConvNeXt-Tiny (mean)   | .509| .479   | .489| 1.00   | .455      |
| P11    | DenseNet-121 (trimmed) | .343| .407   | .319| .75    | .36       |
| P11    | Swin-Tiny (top7)       | .641| .597   | .553| .95    | .95       |
| P11-ens| Dirichlet (3 means)    | .520| .523   | .468| 1.00   | .444      |
| P11-ens| Dirichlet EXT (12)     | .361| .405   | .447| .85    | .425      |
| P11-ens| Swin-Tiny + isotonic   | .566| .458   | .553| .95    | .487      |

**Lectura**: los mejores ensembles paciente-level siguen siendo los construidos sobre EffNet-B3 (P10-ext).
Entre backbones alternativos, Swin-Tiny (`top7`) es el mejor individual; con isotonic gana algo de robustez.

---

### ðŸ§­ Estado actual

* Pipelines del 1 al 11 implementados y documentados.
* Backbones alternativos evaluados (Swin, ConvNeXt, Dense).
* Ensembles probados (AVG, Dirichlet, Stacking, Isotonic) con resultados concluyentes sobre limitaciones por tamaÃ±o de VAL y correlaciones.

---

# ðŸš€ PrÃ³ximos pasos
- **Ensemble hÃ­brido**: EffNet-B3 (pooling 4-feat) + Swin-Tiny (top7 isotonic).
- **RegularizaciÃ³n**: stacking con priors y selecciÃ³n de features no correlacionadas.
- **Multimodal**: clÃ­nico + MRI.
- **Aumento de datos**: ADNI, augmentations.

---

# ðŸ“Ž ApÃ©ndice: utilidades clave
Incluye `safe_sigmoid`, `fit_temperature`, `normalize_score`, `agg_patient`.

---

### ðŸ“Ž ApÃ©ndice: fragmentos y utilidades

#### `safe_sigmoid` y `temperature scaling`

```python
import numpy as np
from scipy.optimize import minimize

def safe_sigmoid(z):
    z = np.clip(z, -50, 50)
    return 1/(1+np.exp(-z))

def fit_temperature(logits, y_true, init_T=1.0, bounds=(0.05,10.0)):
    logits = np.asarray(logits,float); y_true = np.asarray(y_true,float)
    def nll(T):
        p = safe_sigmoid(logits/T); eps=1e-7
        return -np.mean(y_true*np.log(p+eps)+(1-y_true)*np.log(1-p+eps))
    return float(minimize(lambda t: nll(t[0]), x0=[init_T], bounds=[bounds], method="L-BFGS-B").x[0])
```

#### NormalizaciÃ³n de columnas de score

```python
SCORE_ALIASES = ['y_score','sigmoid(logit)','sigmoid(logits)','pred']

def normalize_score(df):
    for c in SCORE_ALIASES:
        if c in df.columns:
            df = df.rename(columns={c:'y_score'})
            break
    assert 'y_score' in df.columns, "No encuentro columna de score."
    return df
```

#### Pooling a paciente (`mean`/`trimmed20`/`top7`/`pmean_2`)

```python
import pandas as pd
import numpy as np

def agg_patient(df):
    g = df.groupby('patient_id')['y_score']
    return pd.DataFrame({
        'mean': g.mean(),
        'trimmed20': g.apply(lambda s: s.sort_values().iloc[int(len(s)*.1):int(len(s)*.9)].mean() if len(s)>=10 else s.mean()),
        'top7': g.apply(lambda s: s.sort_values(ascending=False).head(7).mean()),
        'pmean_2': g.apply(lambda s: (np.mean(np.power(np.clip(s,0,1),2)))**0.5)
    }).reset_index()
```
