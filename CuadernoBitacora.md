# ðŸ§­ Cuaderno de BitÃ¡cora del Proyecto Cognitiva-AI 
> Diario tÃ©cnico detallado (por dÃ­as) con decisiones, incidencias y resultados.  
> Objetivo: trazabilidad completa desde la preparaciÃ³n del entorno hasta backbones alternativos y ensembles.

---

## ðŸ“Œ Convenciones y notas rÃ¡pidas

- **Estructura de datos**:
  - `BASE_DIR = /content/drive/MyDrive/CognitivaAI`
  - `DATA_DIR = BASE_DIR/oas1_data`
  - `OUT_DIR` por pipeline (p.ej. `ft_effb3_stable_colab_plus`, `p11_alt_backbones`, etc.)
- **Mapas OASIS**: `oas1_val_colab_mapped.csv`, `oas1_test_colab_mapped.csv` (columnas claves: `png_path`, `target`, `patient_id`, â€¦).
- **Columnas de predicciÃ³n**:
  - Formatos detectados: `y_score`, `sigmoid(logit)`, `sigmoid(logits)`, `pred`.
  - Se unifica a **`y_score`** internamente durante la carga.
- **Pooling a nivel paciente**: `mean`, `trimmed20`, `top7`, `pmean_2` (power mean con p=2).
- **MÃ©tricas**: AUC, PR-AUC, Acc, Recall, Precision. Umbral por:
  - **F1-opt** (maximiza F1 en VAL),
  - **Youden** (maximiza sensibilidad+especificidad-1),
  - **REC90/REC100** (recall fijado).

---

## Fase 7 â€“ OASIS-2 (p13, p14 y p15)

**Contexto:**  
ExploraciÃ³n y explotaciÃ³n del dataset OASIS-2 con EfficientNet-B3.  
Se implementaron tres pipelines consecutivos:

- **p13:** entrenamiento base con criterio de una sola visita por paciente.  
- **p14:** entrenamiento balanceado en Colab GPU, copiando imÃ¡genes a SSD para mejorar la E/S.  
- **p15:** consolidaciÃ³n de resultados de OASIS-2 (p13 y p14) junto a OASIS-1 (p11), integrando todos los backbones en un catÃ¡logo comÃºn y generando features de ensamble.

**Detalles tÃ©cnicos:**
- 20 slices por volumen, equiespaciados y normalizados (z-score + CLAHE).  
- Labels obtenidos del Excel clÃ­nico, convertidos a binario (Control=0, Dementia/Converted=1).  
- Split fijo: 105 train, 22 val, 23 test (1 sesiÃ³n por paciente).  
- P14: entrenamiento con **class weights** y datos en **SSD local de Colab**.  
- P15: consolidaciÃ³n en catÃ¡logo, eliminaciÃ³n de features con NaNâ‰¥40%, uso de Logistic Regression (con imputaciÃ³n) y HistGradientBoosting (manejo nativo de NaN).

**Resultados:**
- **p13:** recall alto, dataset limitado (150 pacientes).  
- **p14:** VAL AUCâ‰ˆ0.88, TEST AUCâ‰ˆ0.71 con recall=100%.  
- **p15:** consolidaciÃ³n con ensamble â†’ VAL AUCâ‰ˆ0.94, TEST AUCâ‰ˆ0.71; recall alto sostenido.  
- IntegraciÃ³n completa en el catÃ¡logo de backbones (`oas2_effb3`, `oas2_effb3_p14`) y en las features consolidadas con OASIS-1.

---

# Fase 8 â€“ OASIS-2 (p15 y p16)

**Contexto general:**  
Tras los avances logrados con p13 y p14, donde exploramos el dataset OASIS-2 y conseguimos un modelo base sÃ³lido con EfficientNet-B3, surgiÃ³ la necesidad de dar un paso mÃ¡s:  
1. **Consolidar la preparaciÃ³n de datos (p15)** para asegurar coherencia y cobertura completa del dataset.  
2. **Refinar la estrategia de ensembles (p16)**, combinando backbones heterogÃ©neos en un esquema patient-level con mÃ©tricas robustas.

---

## Fase 9 â€“ Ensemble Calibration (p17)

**Contexto:**  
Tras p16, el siguiente paso fue calibrar las probabilidades del ensemble para aumentar la interpretabilidad y la utilidad clÃ­nica.

**Detalles tÃ©cnicos:**  
- ConstrucciÃ³n de un meta-ensemble con Logistic Regression sobre outputs base.  
- AplicaciÃ³n de Platt scaling y optimizaciÃ³n de umbral (F1).  
- EvaluaciÃ³n con Brier Score para medir calibraciÃ³n.  

**Resultados:**  
- ValidaciÃ³n: AUCâ‰ˆ0.78, Recall=0.94, F1=0.76, Brier=0.176.  
- Test: AUCâ‰ˆ0.70, Recall=0.78, F1=0.66, Brier=0.227.  
- Cohortes: OAS1 consistente; OAS2 limitado.  

**ConclusiÃ³n:**  
La calibraciÃ³n refina el ensemble, mantiene sensibilidad alta y mejora la calidad de las probabilidades, aunque la robustez en OAS2 aÃºn requiere trabajo.

---

# Fase 9 â€“ Comparativa p16 vs p17

**p16 â€“ Blending clÃ¡sico:**  
- LR + HGB combinados con un peso Ã³ptimo (Î±=0.02).  
- ValidaciÃ³n espectacular (AUCâ‰ˆ0.95, Recall=1.0), pero riesgo de sobreajuste.  
- En test, buen recall (0.78) pero sin calibraciÃ³n de probabilidades.  

**p17 â€“ Ensemble calibrado:**  
- Stacking con Logistic Regression y Platt scaling.  
- AUC mÃ¡s modesto en validaciÃ³n (0.78) y test (0.70).  
- Mantiene recallâ‰ˆ0.78 y ademÃ¡s optimiza la calibraciÃ³n (Brier=0.227 en test).  
- Probabilidades mÃ¡s interpretables, mejor preparadas para escenarios clÃ­nicos.  

**ConclusiÃ³n de la fase:**  
- p16 = **mejor raw performance** (mÃ¡ximo AUC).  
- p17 = **mejor calibraciÃ³n y estabilidad clÃ­nica** (probabilidades confiables).  
- Ambos complementan la estrategia de ensembles: uno explota rendimiento, otro asegura interpretabilidad.

---

## Fase 9 â€“ Stacking avanzado (p18)

**Contexto:**  
Tras calibrar ensembles en p17, se diseÃ±Ã³ un stacking multicapa para explorar la combinaciÃ³n de mÃºltiples clasificadores heterogÃ©neos.  

**Detalles tÃ©cnicos:**  
- **Base learners:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.  
- **Meta learner:** regresiÃ³n logÃ­stica con blending Î±=0.02.  
- **Estrategia:**  
  - GeneraciÃ³n de predicciones OOF con 5-fold cross-validation.  
  - ValidaciÃ³n de umbral Ã³ptimo en F1.  
  - EvaluaciÃ³n separada para OAS1 y OAS2.  
- **MÃ©tricas adicionales:** Brier Score para calibraciÃ³n, coeficientes de meta-LR y permutaciÃ³n de importancias para interpretar contribuciones.

**Resultados:**  
- [VAL] AUC=0.92, Recallâ‰ˆ0.90, F1â‰ˆ0.83, Precisionâ‰ˆ0.78.  
- [TEST] AUC=0.67, Recallâ‰ˆ0.78, F1â‰ˆ0.67, Precisionâ‰ˆ0.59.  
- Cohorte OAS1 aportÃ³ la mayor estabilidad, mientras que OAS2 mantuvo recall alto pero sin seÃ±al discriminativa clara (AUCâ‰ˆ0.5).

**Conclusiones:**  
El stacking multicapa permitiÃ³ validar la viabilidad de **meta-modelos complejos** en un dataset MRI limitado.  
Gradient Boosting y Random Forest emergieron como pilares, aunque la brecha entre validaciÃ³n y test evidencia el reto de generalizaciÃ³n en cohortes pequeÃ±as.

---

## Fase 9 â€“ Meta-Ablation y calibraciÃ³n avanzada (P22)

**Contexto:**  
Tras consolidar los ensembles y aplicar calibraciones bÃ¡sicas en fases previas (p20â€“p21), se diseÃ±Ã³ P22 como un *ablation study* para comparar mÃ©todos de calibraciÃ³n y medir su efecto en la estabilidad de las probabilidades y en la sensibilidad de los modelos.

**DiseÃ±o y ejecuciÃ³n:**  
- Features: 56 columnas iniciales; tras filtrar NaN>40% se mantuvieron 36.  
- Cohortes: 69 pacientes en validaciÃ³n, 70 en test.  
- Modelos calibrados:  
  - Logistic Regression (LR) con imputaciÃ³n y escalado.  
  - HistGradientBoosting (HGB), tolerante a NaNs.  
- MÃ©todos de calibraciÃ³n aplicados:  
  - **Platt scaling (sigmoid).**  
  - **Isotonic regression.**  
- ValidaciÃ³n con OOF por StratifiedKFold (sin fugas).  
- SelecciÃ³n de umbral F1-mÃ¡x en validaciÃ³n (â‰ˆ0.30â€“0.35).  

**Resultados principales:**  
- LR-Platt: VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
- LR-Isotonic: VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
- HGB-Platt: VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
- HGB-Isotonic: VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
- Blend (Isotonic): VAL AUCâ‰ˆ0.90, F1â‰ˆ0.79 | TEST AUCâ‰ˆ0.68, F1â‰ˆ0.62  

**InterpretaciÃ³n:**  
- La calibraciÃ³n isotÃ³nica aporta mejor ajuste en validaciÃ³n (Brier bajo), pero pierde robustez en test.  
- Platt mantiene recall alto, lo que lo hace mÃ¡s apto para escenarios de cribado clÃ­nico.  
- El blend confirma robustez en validaciÃ³n, pero sigue presente el gap entre cohortes OAS1 y OAS2.  

**ConclusiÃ³n:**  
P22 aportÃ³ claridad sobre quÃ© tÃ©cnicas de calibraciÃ³n son mÃ¡s fiables en entornos clÃ­nicos pequeÃ±os y heterogÃ©neos. Constituye la base para P23, donde se buscarÃ¡ integrar estas calibraciones dentro de meta-ensembles finales y analizar umbrales de decisiÃ³n especÃ­ficos por cohorte.

---

### ðŸ“… Entrada â€“ Estrategia OASIS-1 y OASIS-2 en ensembles (p16â€“p22)

Durante los pipelines de ensembles avanzados (p16â€“p22) se trabajÃ³ con datos de
**OASIS-1 y OASIS-2** simultÃ¡neamente. 

**DecisiÃ³n clave:**
- No fusionar ambos datasets en uno Ãºnico.
- Mantener la cohorte identificada (`cohort = OAS1 / OAS2`) en todos los
  DataFrames.
- Entrenar meta-modelos (LR, HGB, XGB, blends, calibraciones) sobre los datos
  combinados, pero **siempre evaluando por cohorte y global**.

**Beneficios:**
- Evita leakage entre cohortes.
- Permite comparar rendimiento en escenarios distintos:
  - OAS1: cross-sectional, mayor homogeneidad.
  - OAS2: longitudinal, mÃ¡s ruido y variabilidad.
- Informa sobre la robustez del ensemble frente a shift de dominio.

**Resultado observado:**
- En validaciÃ³n (VAL), OAS1 logra mÃ©tricas mÃ¡s altas (AUC, Acc).
- En test (TEST), OAS2 muestra recall elevado pero menor calibraciÃ³n y precisiÃ³n.
- Globalmente (ALL), se obtiene una media ponderada que refleja mejor la
  dificultad del problema.

**ConclusiÃ³n:**
El tratamiento separado de OASIS-1 y OASIS-2 dentro de los ensembles es esencial
para interpretar los resultados clÃ­nicos y diseÃ±ar calibraciones especÃ­ficas
para cada cohorte en los pipelines posteriores (p20â€“p22).

---

## Ficha de modelo â€” P26 / P26b (intermodal)

**Entrada:**  
- Imagen (prob. P24 por paciente) + 56 features de imagen (p11+p14/p13).  
- ClÃ­nico consolidado (Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay).  
- SeÃ±al p1 (OAS2) con imputaciÃ³n por cohorte + flag.

**Arquitectura:**  
- **P26 (Late):** meta-LR sobre `{p_img, p_clin, p1_fill, p1_has}`.  
- **P26b:** P26 + **calibraciÃ³n Platt por cohorte** en VAL y re-umbrales 5:1.

**MÃ©tricas (TEST):**  
- P26 â€” ALL AUC=0.713 Â· PR-AUC=0.712 Â· Brier=0.234; OAS1 AUC=0.754 Â· OAS2 AUC=0.652.  
- P26b â€” mejora Brier (OAS1 0.199, OAS2 0.241) sin cambiar confusiÃ³n a coste 5:1.

**Umbrales recomendados:**  
- **P26:** OAS1=0.307 Â· OAS2=0.195 (coste mÃ­nimo).  
- **P26b (Ãºnico):** OAS1=0.340 Â· OAS2=0.374.  
- **Mixto (recall OAS2):** OAS1â†’P26b@0.340 Â· OAS2â†’P24@0.332.

**Riesgos:** descalibraciÃ³n en OAS2; tamaÃ±o muestral.  
**Mitigaciones:** monitorizar **ECE/MCE**, recalibrar con ventana mÃ³vil; reportar intervalos; mantener umbrales por cohorte.

**Artefactos clave:** ver `p26_intermodal/` (predicciones, calibraciones, umbrales, tablas ejecutivas, bloques).

---

# ðŸ—“ Semana â€œceroâ€: preparaciÃ³n antes del arranque formal

## ðŸ“… 24/06/2025 â€” PreparaciÃ³n de entorno y Ã¡rbol de carpetas
- Estructuramos las rutas de trabajo en **Google Drive** para garantizar persistencia.
- Creamos `CognitivaAI/` con subcarpetas para datos, salidas por pipeline y documentos (`README.md`, `InformeTecnico.md`, `CuadernoBitacora.md`).
- Decidimos usar **Google Colab** como entorno primario.

**Decisiones**  
- ConvenciÃ³n de nombres de salida (por pipeline) para poder concatenar y comparar.
- EstÃ¡ndar de CSV: separador `,`, encoding UTF-8, cabeceras.

---

## ðŸ“… 25/06/2025 â€” Ingesta y saneamiento de OASIS
- RevisiÃ³n de **mapas** `oas1_val_colab_mapped.csv` y `oas1_test_colab_mapped.csv`.
- VerificaciÃ³n de columnas mÃ­nimas: `png_path`, `target`, `patient_id`.
- ExploraciÃ³n de duplicidades por `patient_id` (coincide con el supuesto de mÃºltiples cortes por paciente).
- DefiniciÃ³n de **helpers** de lectura robusta (detecciÃ³n de nombre real de columna score).

**Incidencias**  
- Rutas con barras invertidas en `source_hdr` (propiedad informativa). Sin impacto en lectura principal.

---

## ðŸ“… 26/06/2025 â€” MÃ©tricas y umbrales
- Implementamos un bloque de evaluaciÃ³n unificado con AUC, PR-AUC, Acc, P, R, y bÃºsqueda del **umbral Ã³ptimo F1** y **Youden**.
- AÃ±adimos perfiles **REC90** y **REC100** (para escenarios de alta sensibilidad).

**DecisiÃ³n**  
- Registrar siempre `n` (tamaÃ±o conjunto paciente) en los resÃºmenes.

---

## ðŸ“… 27/06/2025 â€” DiseÃ±o de pipelines
- Esbozo de los **Pipelines** P1â€¦P11 (clÃ­nico â†’ MRI â†’ calibraciÃ³n â†’ ensembles â†’ backbones).
- Cada pipeline escribe sus CSV y un **resumen** en una tabla comparativa.

**LecciÃ³n**  
- Trazabilidad por pipeline evita mezclar resultados de runs viejos.

---

## ðŸ“… 28/06/2025 â€” Helpers de pooling a paciente
- Definimos pooling: `mean`, `trimmed20`, `top7`, y **`pmean_2`** (promedio potencia con p=2).
- Aseguramos **idempotencia**: si existen tablas, se reusan; si no, se crean.

---

## ðŸ“… 29/06/2025 â€” ValidaciÃ³n rÃ¡pida de lectura + guardado
- Mini-pipeline de lectura de mapas y generaciÃ³n de features bÃ¡sicos a paciente.
- Confirmamos conteos esperados (p. ej., 940 cortes VAL/TEST â†’ 47 pacientes).

---

# ðŸ Arranque formal

## ðŸ“… 01/07/2025 â€” P1: ClÃ­nico OASIS-2 (XGB)
- **Modelo**: XGBoost.
- **Resultado**: **AUC â‰ˆ 0.897**.
- **ConclusiÃ³n**: baseline tabular fuerte.

---

## ðŸ“… 03/07/2025 â€” P2: ClÃ­nico fusiÃ³n (XGB)
- IntegraciÃ³n de variables clÃ­nicas ampliadas.
- **Resultado**: **AUC â‰ˆ 0.991**, **Recall ~1.0**.
- **Riesgo**: posible **overfitting**.

---

## ðŸ“… 10/07/2025 â€” P3: MRI OASIS-2 (ResNet50)
- **Backbone**: ResNet-50 (ImageNet).
- **Resultado (test)**: **AUC â‰ˆ 0.938**.
- **ConclusiÃ³n**: MRI viable; base sÃ³lida para Colab.

---

## ðŸ“… 15/07/2025 â€” P5: MRI Colab (ResNet18 + Calib)
- **Resultado**: AUC â‰ˆ 0.724 | PR-AUC â‰ˆ 0.606 | Acc â‰ˆ 0.60 | R=0.80 | P=0.52.
- **ConclusiÃ³n**: salto a Colab con calibraciÃ³n aporta control, pero rendimiento moderado.

---

## ðŸ“… 20/07/2025 â€” P6: EffNet-B3 embeddings
- **Resultado**: AUC â‰ˆ 0.704 | PR-AUC â‰ˆ 0.623 | Acc â‰ˆ 0.70 | R=0.90 | P=0.60.
- **Aprendizaje**: recall alto, aÃºn inestable.

---

## ðŸ“… 23/07/2025 â€” P7: EffNet-B3 finetune
- **Resultado**: **AUC â‰ˆ 0.876** | PR-AUC â‰ˆ 0.762 | Acc â‰ˆ 0.745 | **R=1.0** | P=0.625.
- **ConclusiÃ³n**: **mejor punto** hasta la fecha.

---

## ðŸ“… 30/07/2025 â€” P9: EffNet-B3 stable
- **Resultado**: AUC â‰ˆ 0.740 | PR-AUC â‰ˆ 0.630 | Acc â‰ˆ 0.72 | R=0.65 | P=0.62.
- **Notas**: gana estabilidad, cede algo de recall.

---

## ðŸ“… 05/08/2025 â€” P10: EffNet-B3 stable + calibraciÃ³n
- **TÃ©cnicas**: temperature scaling, isotonic.
- **Caveat**: grandes magnitudes de **logits** â†’ overflow en `exp`.
- **Parche**:
  ```python
  def safe_sigmoid(z):
      z = np.clip(z, -50, 50)
      return 1/(1+np.exp(-z))

  def fit_temperature(logits, y_true, init_T=1.0, bounds=(0.05, 10.0)):
      logits = np.asarray(logits, float); y_true = np.asarray(y_true, float)
      def nll(T):
          p = safe_sigmoid(logits/T); eps = 1e-7
          return -np.mean(y_true*np.log(p+eps) + (1-y_true)*np.log(1-p+eps))
      return float(minimize(lambda t: nll(t[0]), x0=[init_T], bounds=[bounds], method="L-BFGS-B").x[0])
    ```
 - **Resultado(rango):** **AUC test 0.546â€“0.583**, PR-AUC ~0.50â€“0.53, Acc ~0.51â€“0.55, **Recall=1.0**, Precision ~0.47â€“0.49.
 - **ConclusiÃ³n:** calibraciÃ³n â†“ AUC pero â†‘ interpretabilidad. Necesario ensemble posterior.

 ---

## ðŸ“… 10/08/2025 â€” P10-ext: TRIMMED y seed-ensemble
- **Semillas 41/42/43** con agregaciones por paciente.
- **Logs:** â€œVAL slices por seed: [940,940,940] â€¦ Guardado slice-level seedENSâ€¦â€
- **Seed-ensemble (media/TRIMMED/TOP7)** (sin calibrar) dio AUC test â‰ˆ 0.50â€“0.51 en algunos runs (semillas no aportaron mejora directa).
- **Stacking / Random weights (mean+trimmed20+top7+p2):**
  - **RF** y **STACK(no-neg)** sobre 4 features de pooling:
    - **VAL:** AUC ~0.90â€“0.91, PR-AUC ~0.92, Acc ~0.85â€“0.87, R ~0.75â€“0.95.
    - **TEST:** **AUC ~0.75**, PR-AUC ~0.73â€“0.75, Acc ~0.64â€“0.70, R ~0.50â€“0.70, P ~0.58â€“0.71.
  - **Ej. RAND(500 samples)** (mean/trimmed20/top7/p2):
    - Pesos ejemplo: mean 0.325, trimmed20 0.315, top7 0.322, p2 0.038.
    - **VAL:** AUC=0.909, PR-AUC=0.920, Acc=0.872, R=0.95, P=0.792.
    - **TEST:** **AUC=0.754**, PR-AUC=0.748, Acc=0.660, R=0.70, P=0.583.
 - **STACK_LR(mean+trimmed20+top7+p2):**
    - * Coefs â‰ˆ [0.407, 0.409, 0.485, 0.416], **intercept âˆ’0.923**.
    - **VAL**: AUC=0.909, PR-AUC=0.920, Acc=0.872, R=0.95, P=0.792.
    - **TEST**: AUC=0.754, PR-AUC=0.748, Acc=0.660, R=0.70, P=0.583.
- **ConclusiÃ³n:**
    - **Consolidado**: a nivel paciente, **ensembles de pooling** (4 features) mejoran notablemente sobre seed-ensemble puro.

---

### ðŸ“… 12/08/2025 â€” DocumentaciÃ³n y limpieza

 * AÃ±adidos al `README` e Informe: decisiÃ³n de que â€œestrategia de semillasâ€ no aportÃ³ sola.
 * NormalizaciÃ³n de nombres de columnas en todos los CSV (de cara a p11).

 ---

 ## ðŸ“… 15/08/2025 â€” P11: Backbones alternativos (inicio)

* Notebook: `cognitiva_ai_backbones.ipynb`.
* **Incidencia 1 (Drive)**: `â€œMountpoint must not already contain filesâ€` â†’ soluciÃ³n: no remount si ya montado / reiniciar entorno tras semanas.
* **Incidencia 2 (rutas)**: `DATA_DIR` marcaba `exists=False` pese a existir â†’ soluciÃ³n: reinicio completo; verificaciÃ³n con `Path.exists()`.
* Carga correcta:
    ```
    Mounted at /content/drive
    ðŸ”Ž VAL_MAP â€¦/oas1_val_colab_mapped.csv
    ðŸ”Ž TEST_MAP â€¦/oas1_test_colab_mapped.csv
    âœ… Columnas OK: ['patient_id','png_path','target']
    ðŸ’¾ Config guardada: â€¦/p11_alt_backbones/p11_config.json
    ```

---

### ðŸ“… 16/08/2025 â€” ConvNeXt-Tiny (in12k\_ft\_in1k)

* Inferencia: guardÃ³ `convnext_tiny.in12k_ft_in1k_val_slices.csv` y `_test_slices.csv`.
* Resumen por pooling:
    * **ConvNeXtTiny-mean**: VAL `AUC` 0.5556 | `PR-AUC` 0.5436 | TEST `AUC` 0.5093 | `PR-AUC` 0.4790 | `Acc` 0.489 | `R`=1.0 | `P`=0.455.
    * **trimmed20**: TEST `AUC` 0.5000 | `PR-AUC` 0.4723.
    * **top7**: TEST `AUC` 0.5111 | `PR-AUC` 0.4643.
* Fila README: `| P11 | MRI Colab | ConvNeXt-Tiny (in12k_ft_in1k) + mean | 0.509 | 0.479 | 0.49 | 1.00 | 0.45 |`

---

### ðŸ“… 17/08/2025 â€” DenseNet-121

* Peso ImageNet (no `d121_best.pth`).
* Slice-level â†’ patient-level:
    * **Dense121-mean**: TEST `AUC` 0.3241 | `PR-AUC` 0.3942 | `Acc` 0.340 | `R`=0.75 | `P`=0.366.
    * **trimmed20**: TEST `AUC` 0.3426 | `PR-AUC` 0.4068.
    * **top7**: TEST `AUC` 0.3019 (mÃ¡s bajo).
* **Resumen**: DenseNet-121 decepciona en este dataset.

---
### ðŸ“… 18/08/2025 â€” Swin-Tiny

* Slice-level â†’ patient-level:
    * **SwinTiny-mean**: TEST `AUC` 0.5352, `PR-AUC` 0.5109, `Acc` 0.447, `R`=1.0, `P`=1.0 (umbral muy bajo).
    * **SwinTiny-top7**: TEST `AUC` 0.6407, `PR-AUC` 0.5971, `Acc` 0.553, `R`=0.95, `P`=0.95 (mejor variante Swin).
* **ConclusiÃ³n**: Swin-Tiny (`top7`) es el mejor de los alternativos probados.

---

### ðŸ“… 19/08/2025 â€” CatÃ¡logo multi-backbone + normalizaciÃ³n columnas

* Escaneo de `p11_alt_backbones` y carpetas previas:
    * Detectados `SwinTiny`, `ConvNeXt slices`, `DenseNet-121`, y ademÃ¡s `efb3` de pipelines anteriores (`ft_effb3_*`).
* UnificaciÃ³n de columnas: mapeo auto (`y_score`, `sigmoid(logit[s])`, `pred` â†’ `y_score`).
* ConstrucciÃ³n features por paciente (VAL/TEST (47, 6) por fuente), guardados:
    * `val_patient_features_backbones.csv`
    * `test_patient_features_backbones.csv`
* ValidaciÃ³n:
    * `SwinTiny` OK (940 filas â†’ 47 pacientes).
    * `ConvNeXt slices` OK (940 â†’ 47).
    * `DenseNet` OK (940 â†’ 47).
    * Preds a nivel paciente de pipelines previos (47 directos) incluidas como features extra.

---

### ðŸ“… 20/08/2025 â€” Ensemble de backbones (promedios y stacking base)

* **AVG** de 12 seÃ±ales `â€œ*_meanâ€` (Swin/ConvNeXt/DenseNet + seÃ±ales paciente/effect):
    * **VAL (F1-opt)**: `AUC` 0.476 | `PR-AUC` 0.389 | `Acc` 0.40 | `R`=1.0 | `P`=0.333 | `thr`=0.3525 | `n`=10.
    * **TEST (F1-opt)**: `AUC` 0.713, `PR-AUC` 0.724 | `Acc` 0.426 | `R`=1.0 | `P`=0.426 | `thr`=0.3525 | `n`=47.
* **ObservaciÃ³n**: `AUC` test alto vs val bajo â†’ val (`n`=10) muy pequeÃ±o; umbral podrÃ­a transferirse demasiado â€œoptimistaâ€.
* **STACK\_LR(all\_features)**:
    * **VAL**: `AUC` 0.810 | `PR-AUC` 0.700 | `Acc` 0.800 | `R`=1.0 | `P`=0.600.
    * **TEST**: `AUC` 0.298 | `PR-AUC` 0.397 | `Acc` 0.383 | `P` 0.304 | `R` 0.35.
* **Overfitting claro a VAL**.

---

### ðŸ“… 21/08/2025 â€” Dirichlet (3 backbones, means)

* **FEATURES**: `SwinTiny_mean`, `convnext_tiny..._mean`, `png_preds_d121_mean`.
* `N_SAMPLES`=800 (semilla 42).
* Mejor combinaciÃ³n (ejemplo):
    * Pesos â‰ˆ Swin 0.972, ConvNeXt 0.004, Dense 0.024.
    * **VAL (F1-opt)**: `Acc` 0.70 | `P` 0.50 | `R` 1.0 | `thr` 0.474 | `AUC` 0.714, `PR-AUC` 0.633 (`n`=10).
    * **TEST (F1-opt)**: `Acc` 0.468 | `P` 0.444 | `R` 1.0 | `thr` 0.435 | `AUC` 0.520, `PR-AUC` 0.523 (`n`=47).
* **Youden TEST**: `Acc` 0.617 | `P` 0.667 | `R` 0.20 (umbral 0.481).
* **ConclusiÃ³n**: mejora leve vs ConvNeXt-mean/DenseNet, pero por debajo de Swin-top7 y muy lejos de los ensembles de EffNet-B3 del P10-ext.

---

### ðŸ“… 22/08/2025 â€” Dirichlet EXT (12 features)

* **FEATURES**: `{Swin[mean/trimmed/top7], ConvNeXt_slices[mean/trimmed/top7], DenseNet[mean/trimmed/top7]}` + seÃ±ales agregadas (`patient_preds_plus_mean`, `slice_preds_plus_mean`, `slice_preds_seedENS_mean`).
* **Resultado**:
    * **VAL**: `AUC` 0.714, `PR-AUC` 0.681.
    * **TEST**: `AUC` 0.361, `PR-AUC` 0.405.
* **ConclusiÃ³n**: sobreajuste; demasiados grados de libertad para `n(VAL)` = 10.

---

### ðŸ“… 23/08/2025 â€” Stacking L1 fuerte (sparsidad forzada)

* **FEATURES candidatas (ej.)**: `SwinTiny_top7`, `convnext..._top7`, `png_preds_d121_trimmed20`, `patient_preds_plus_mean`, `slice_preds_plus_mean`, `slice_preds_seedENS_mean`.
* **Resultado**: todos `coef=0` (modelo trivial), `intercept=0`.
* **VAL/TEST**: `AUC=0.5`; F1 ligado a prior por umbral 0.
* **InterpretaciÃ³n**: el penalizador â€œfuerteâ€ anulÃ³ todas las seÃ±ales (`n(VAL)` pequeÃ±o + correlaciÃ³n alta).

---

### ðŸ“… 24/08/2025 â€” Isotonic sobre Swin-Tiny (top7)

* **Resultado**:
    * **VAL**: `AUC` 0.714 | `PR-AUC` 0.556 | `Acc` 0.400 | `R` 1.0 | `P` 0.333 | `thr` 0.0025.
    * **TEST**: `AUC` 0.566 | `PR-AUC` 0.458 | `Acc` 0.553 | `R` 0.95 | `P` 0.487 | `thr` 0.0025.
* **ConclusiÃ³n**: la calibraciÃ³n isotÃ³nica ayuda ligeramente en test y fija un recall alto con precisiÃ³n moderada.

---

### ðŸ“… 25/08/2025 â€” CatÃ¡logo ampliado y parsers robustos

* Se indexan tambiÃ©n directorios previos:
    * `oas1_resnet18_linearprobe/â€¦`
    * `ft_effb3_colab/â€¦`, `ft_effb3_stable_colab_plus/â€¦`, etc.
* ValidaciÃ³n automÃ¡tica de columnas y tamaÃ±os; cualquier CSV no conforme se re-mapea.

---

### ðŸ“… 27/08/2025 â€” RevisiÃ³n de README/Informe/Cuaderno

* Se vuelcan resultados preliminares al `README`, con filas por pipeline (P1â€“P11), incluyendo ConvNeXt-Tiny, Swin-Tiny y DenseNet-121.
* Se documenta que la estrategia de semillas en solitario no aportÃ³ (`AUC` â‰ˆ 0.5), mientras que ensembles de pooling (4 features) sÃ­ mejoraron hasta `AUC` test â‰ˆ 0.75.
* Se prepara archivo de Contexto para otros chats (evitar pÃ©rdida de hilo).

---

### ðŸ“… 29/08/2025 â€” Ajustes finales P11 y ensembles

* Normalizado definitivo de nombres en `comparison_backbones_eval.csv`.
* ConfirmaciÃ³n de Swin-Tiny (`top7`) como mejor alternativo aislado.
* Resumen de ensembles P11:
    * **Dirichlet (3 means)**: TEST `AUC` â‰ˆ 0.52.
    * **Dirichlet EXT (12)**: TEST `AUC` â‰ˆ 0.36.
    * **STACK\_LR(all)**: TEST `AUC` â‰ˆ 0.30 (overfit).
    * **Swin-Tiny isotonic**: TEST `AUC` â‰ˆ 0.566; `Acc` â‰ˆ 0.553; `R` 0.95; `P` 0.487.

---

### ðŸ“… 04/09/2025 â€“ Pipeline p13
- Procesamiento OASIS-2 â†’ 20 slices equiespaciados por scan.  
- SelecciÃ³n de 1 visita/paciente.  
- Entrenamiento base en EfficientNet-B3 (105/22/23).  

### ðŸ“… 05/09/2025 â€“ Pipeline p14
- Copia de 7340 slices a SSD local en Colab.  
- Entrenamiento balanceado con class weights.  
- AUCâ‰ˆ0.88 en val, recall=100% en test.  

### ðŸ“… 06/09/2025 â€“ Pipeline p15 (ConsolidaciÃ³n)
- IntegraciÃ³n de resultados p13 y p14 en el catÃ¡logo global de backbones.  
- GeneraciÃ³n de features combinadas con OASIS-1 (p11).  
- Dificultades: manejo de NaN en features y necesidad de descartar/ imputar columnas.  
- Modelos finales: Logistic Regression con imputaciÃ³n y HistGradientBoosting (NaN nativo).  
- Resultado: VAL AUCâ‰ˆ0.94, TEST AUCâ‰ˆ0.71 con recall alto.

---

### ðŸ“… 06/09/2025 â€“ Pipeline p15 (ConsolidaciÃ³n de dataset OASIS-2)
- Se revisaron de nuevo todos los **367 scans** procesados de OASIS-2.  
- Confirmamos que solo **150 scans** contaban con etiquetas clÃ­nicas vÃ¡lidas (Control/Dementia/Converted).  
- Se reafirmÃ³ el criterio de **una Ãºnica sesiÃ³n por paciente** para evitar *data leakage* entre splits.  
- Se generaron **20 slices axiales equiespaciados** por volumen, eliminando los extremos (8%) y aplicando **normalizaciÃ³n z-score + CLAHE opcional**.  
- Resultado: **150 pacientes Ã— 20 slices = 3.000 imÃ¡genes etiquetadas**.  
- Dificultad importante: el acceso a imÃ¡genes desde Google Drive seguÃ­a penalizando el entrenamiento por la latencia de E/S.  
  - **SoluciÃ³n:** replicar todo el dataset en el **SSD local de Colab** antes de cada entrenamiento, lo que redujo drÃ¡sticamente los tiempos.  
- Con esta consolidaciÃ³n, el dataset quedÃ³ consistente, balanceado y preparado para ser integrado en ensembles.

---

### ðŸ“… 06/09/2025 â€“ Pipeline p16 (Refinamiento de ensembles)
- Se construyeron features **patient-level** a partir de mÃºltiples backbones:  
  - `oas2_effb3`, `oas2_effb3_p14`, `SwinTiny`, `ConvNeXt_tiny`, `DenseNet121`, entre otros.  
- Durante la integraciÃ³n, se detectÃ³ un alto nÃºmero de columnas con valores faltantes (**NaNs**).  
  - Se aplicÃ³ un criterio estricto: **descartar columnas con >40% NaN**.  
  - Para las restantes:  
    - **Logistic Regression (LR):** imputaciÃ³n + columnas-flag de missingness.  
    - **HistGradientBoosting (HGB):** manejo nativo de NaNs, sin necesidad de imputar.  
- Se explorÃ³ un esquema de **blending** LR+HGB, optimizado en validaciÃ³n con Î±=0.02 (casi todo el peso en HGB).  
- **Resultados clave:**  
  - **ValidaciÃ³n:**  
    - AUCâ‰ˆ0.95 global, con recall=100% en cohortes OAS1.  
    - En OAS2, las mÃ©tricas fueron mÃ¡s bajas (AUCâ‰ˆ0.54) debido al reducido tamaÃ±o de muestra, pero se mantuvo recall=100%.  
  - **Test:**  
    - AUCâ‰ˆ0.69 global.  
    - Recallâ‰ˆ78%, lo que representa una mejora respecto a modelos individuales.  
    - El blending aportÃ³ mayor estabilidad en comparaciÃ³n con usar un solo clasificador.  
- ConclusiÃ³n: los ensembles **aumentan la sensibilidad del sistema y reducen el riesgo de overfitting**, consolidÃ¡ndose como la mejor estrategia para explotar mÃºltiples backbones en paralelo.

---
### ðŸ“… 07/09/2025 â€“ Pipeline p17

- **Objetivo:** Refinar los ensembles con calibraciÃ³n de probabilidades.  
- **TÃ©cnicas aplicadas:**  
  - Stacking de outputs base (LR + HGB).  
  - Logistic Regression como meta-modelo.  
  - Platt scaling para calibraciÃ³n probabilÃ­stica.  
  - OptimizaciÃ³n del umbral con F1 en validaciÃ³n.  
- **Resultados globales:**  
  - [VAL] AUCâ‰ˆ0.78 | Recall=0.94 | F1=0.76 | Brier=0.176.  
  - [TEST] AUCâ‰ˆ0.70 | Recall=0.78 | F1=0.66 | Brier=0.227.  
- **AnÃ¡lisis por cohortes:**  
  - OAS1 se mantiene estable (val/test â‰ˆ0.84/0.77).  
  - OAS2 continÃºa siendo inestable, con AUC â‰ˆ0.5 en test.  
- **ConclusiÃ³n:**  
  - El ensemble calibrado aporta **confianza probabilÃ­stica mejorada**.  
  - Se prioriza recall alto, sacrificando algo de precisiÃ³n.  
  - El reto sigue siendo el tamaÃ±o reducido de OAS2.  

 --- 

### ðŸ“… 07/09/2025 â€“ Pipeline p18
- Implementado **stacking multicapa** con cinco clasificadores base (LR, HGB, GB, RF, ET) y un meta-modelo logÃ­stico.  
- GeneraciÃ³n de predicciones **OOF con 5 folds** para evitar fuga de informaciÃ³n.  
- Ajuste de blending Î±=0.02.  
- EvaluaciÃ³n detallada por cohortes (OAS1, OAS2) y global.  
- **Resultados:**  
  - VAL AUCâ‰ˆ0.92 | Recallâ‰ˆ0.90 | F1â‰ˆ0.83.  
  - TEST AUCâ‰ˆ0.67 | Recallâ‰ˆ0.78 | F1â‰ˆ0.67.  
- Insight: GB y RF fueron los mÃ¡s influyentes como modelos base, pero la generalizaciÃ³n en OAS2 sigue limitada (AUCâ‰ˆ0.5).  

---

### ðŸ“… 07/09/2025 â€“ Pipeline p19

**Fase 8: Ensembles y calibraciÃ³n (P18â€“P19)**  

- **QuÃ© hice:** ejecutÃ© P19 con stack de base learners (LR, HGB, GB, RF, LGBM, XGB) y meta-XGB. ConstruÃ­ OOF sin fuga con KFold, armÃ© meta-features y evaluÃ© en VAL/TEST.  
- **Datos y features:** 56 columnas vÃ¡lidas tras filtrar NaN>40%; representaciÃ³n por paciente (mean/trimmed/top-k/p2).  
- **Resultados:**  
  - VAL: AUC=0.964; PRAUC=0.966; Acc=0.913; F1=0.897; Brier=0.071.  
  - TEST: AUC=0.729; PRAUC=0.688; Acc=0.714; F1=0.630; Brier=0.226.  
- **Aprendizajes:** meta fuerte en VAL pero recall bajo en TEST; hay shift (OAS1 vs OAS2) y el umbral global no es Ã³ptimo. LightGBM sin splits Ãºtiles sugiere simplificar meta y seleccionar features.  
- **Siguiente paso (p20):** calibrar meta, umbrales por cohorte, meta mÃ¡s simple y Repeated KFold para robustez.

---

### ðŸ“… 07/09/2025 â€“ Fase 9: Meta-calibraciÃ³n (P20)

**QuÃ© hice:**  
EjecutÃ© P20 sobre el meta-ensemble de p19, aplicando calibraciÃ³n de probabilidades con Platt e isotÃ³nica, tanto global como por cohorte (OAS1/OAS2).  

**Datos y setup:**  
36 columnas finales tras descartar NaN>40%. Modelos calibrados: HGB y LR. GuardÃ© predicciones calibradas en VAL/TEST y JSON de resumen.  

**Resultados clave:**  
- HGB-Isotonic-PerC: VAL AUC=0.840 | F1=0.753 | Brier=0.156  
- LR-Platt-Global: TEST AUC=0.686 | F1=0.658 | Brier=0.221  
- En TEST, recallâ‰ˆ0.78 con precisiÃ³n moderada (â‰ˆ0.54â€“0.57).  

**Aprendizajes:**  
La calibraciÃ³n reduce el error de probabilidad (Brier), sobre todo en validaciÃ³n.  
El umbral global no captura bien las diferencias entre cohortes; per-cohort mejora ligeramente.  
El modelo calibrado mantiene recall alto â†’ Ãºtil en escenario clÃ­nico de cribado.  

**Siguiente paso:**  
Integrar calibraciones en el ensemble completo, probar Elastic-Net como meta y explorar selecciÃ³n de umbrales orientada a coste clÃ­nico.

---

### ðŸ“… 07/09/2025 â€“ Fase 8 Â· P21 (Meta-refine)

**QuÃ© hice.** EjecutÃ© p21 con un stacking compacto (LR, HGB, LGBM, XGB) y meta a partir de 4 OOFs; filtrÃ© NaN>40% (36 columnas finales) y apliquÃ© umbral F1-mÃ¡x=0.45.

**Datos.** VAL=69, TEST=70; features por paciente procedentes de mÃºltiples backbones (mean/trimmed/top-k/p2), con columna de cohorte (OAS1/OAS2).

**Resultados.**
- VAL: AUC 0.955, PRAUC 0.931, Acc 0.870, F1 0.862, Brier 0.082.
- TEST: AUC 0.653, PRAUC 0.587, Acc 0.643, F1 0.627, Brier 0.285.

**Observaciones.**
- LGBM sin splits con ganancia positiva â†’ complejidad excesiva frente a muestra disponible.
- Buen VAL pero caÃ­da en TEST (shift OAS1/OAS2 + umbral global).

**Siguiente.**
- p22: calibraciÃ³n/umbrales por cohorte y por coste; meta mÃ¡s regularizado; Repeated KFold para robustez.

---

### ðŸ“… 07/09/2025 â€“ Pipeline P22 (Meta-Ablation con calibraciÃ³n avanzada)

- **AcciÃ³n:** ejecutÃ© P22 aplicando calibraciÃ³n Platt e IsotÃ³nica a los modelos LR y HGB.  
- **Datos:** 69 pacientes en validaciÃ³n y 70 en test, con 36 features seleccionadas (descartadas 20 por NaN>40%).  
- **Resultados clave:**  
  - LR-Platt: VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
  - LR-Isotonic: VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
  - HGB-Platt: VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
  - HGB-Isotonic: VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
  - Blend isotÃ³nico: VAL AUCâ‰ˆ0.90, F1â‰ˆ0.79 | TEST AUCâ‰ˆ0.68, F1â‰ˆ0.62  
- **Aprendizaje:** la calibraciÃ³n isotÃ³nica mejora la fiabilidad de las probabilidades en validaciÃ³n, pero en test muestra menor robustez (shift OAS1/OAS2). Platt mantiene recall mÃ¡s alto.  
- **ConclusiÃ³n:** P22 funcionÃ³ como **estudio de ablaciÃ³n** previo a la integraciÃ³n final de calibraciones en meta-ensembles (p23).

---

### ðŸ“… 07/09/2025 â€“ Pipeline P23 (Meta-calibraciÃ³n coste-cohorte)

- **AcciÃ³n:** ejecutÃ© P23 aplicando calibraciÃ³n Platt e IsotÃ³nica con umbrales coste-Ã³ptimos por cohorte (OAS1/OAS2).  
- **Criterio:** coste clÃ­nico FN=5, FP=1 â†’ penaliza falsos negativos.  
- **Artefactos guardados:**  
  - `p23_val_preds_calibrated.csv`  
  - `p23_test_preds_calibrated.csv`  
  - `p23_thresholds.json`  
  - `p23_calibrators.pkl`  
  - `p23_summary.json`  

**Resultados:**  
- **OAS1 (TEST):**  
  - Isotonic â†’ AUC=0.743 | PR-AUC=0.657 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
  - Platt â†’ AUC=0.724 | PR-AUC=0.649 | Recall=0.95 | Precision=0.50 | Cost=24.0.  
- **OAS2 (TEST):**  
  - Ambos calibradores â†’ AUC=0.50 | PR-AUCâ‰ˆ0.52 | Recall=1.0 | Precisionâ‰ˆ0.52 | Cost=11.0.  

**ConclusiÃ³n:**  
- En OAS1, la calibraciÃ³n isotÃ³nica logra mejor AUC, pero Platt es competitivo.  
- En OAS2, el modelo no discrimina (AUC=0.5) pero alcanza recall=1.0, lo que elimina FN (clave clÃ­nicamente).  
- Se confirma la necesidad de **umbrales diferenciados por cohorte**.  
- P23 sienta la base para un meta-final mÃ¡s simple y robusto (Elastic-Net + Repeated KFold).

---

### 2025-09-07 â€” P24 ejecutado (LR elastic-net + KFold repetido + Platt)

- Features paciente fusionadas (p11+p14).  
- CV(5Ã—5): AUC=0.880Â±0.090; mejores params: {'clf__C': 0.1, 'clf__l1_ratio': 0.7}.  
- TEST Global: AUC=0.727, PR-AUC=0.717, Brier=0.220.  
- TEST OAS1: AUC=0.754, PR-AUC=0.736, Brier=0.211.  
- TEST OAS2: AUC=0.750, PR-AUC=0.805, Brier=0.238.  
- Umbrales coste per-cohorte: OAS1 thr=0.435 â†’ Coste=39.0 (R=0.70, P=0.61, Acc=0.68) | OAS2 thr=0.332 â†’ Coste=12.0 (R=0.92, P=0.61, Acc=0.65)

_Artefactos_: `p24_meta_simple/` (preds, coeficientes, modelo, calibrador, summary, thresholds, report).

---

### 2025-09-07 â€” P25 (construcciÃ³n del informe final)

- ConsolidÃ© P19/P22/P23/P24 en `p25_master_table.csv`.
- GenerÃ© bloques finales para README/Informe/BitÃ¡cora.
- Figuras: ROC/PR/CalibraciÃ³n, curvas de coste, sensibilidad de coste, ICs bootstrap; coeficientes top.
- Predicciones demo: `p25_predictions_labeled.csv` / `p25_predictions_unlabeled.csv`.
- Release reproducible: `p25_release/` (MANIFEST.json, ENVIRONMENT.json, MODEL_CARD.md).

**Modelo final sugerido:** P24 (LR elastic-net + Platt) con umbrales por cohorte (FN:FP=5:1).  
**TEST @ umbral:** OAS1â†’ R=0.70, P=0.61 (Coste=39) Â· OAS2â†’ R=0.917, P=0.611 (Coste=12).

---

### 2025-09-07 â€” P26 intermodal (imagen + clÃ­nico)

- Consolidado clÃ­nico OASIS-1/2 (anti-fuga), OHE y medianas; 56 features de imagen (p11+p14/p13) alineadas.  
- SeÃ±al **p1** (OAS2) con cobertura â‰ˆ32% â†’ imputaciÃ³n por cohorte (media VAL OAS2) + flag `p1_has`.  
- **Late vs Mid**:  
  - Late (p_img, p_clin, p1_fill, p1_has) â€” **VAL AUC=0.916**, TEST **AUC=0.713**.  
  - Mid (IMG56+clÃ­nico+p1) â€” VAL AUC=0.797, TEST 0.697.  
  - SelecciÃ³n: **Late**.  
- **Coste 5:1 (umbral de VAL aplicado en TEST):**  
  - OAS1 @ 0.307 â†’ R=0.700, P=0.609, Acc=0.681, Coste=39.  
  - OAS2 @ 0.195 â†’ R=0.667, P=0.667, Acc=0.652, Coste=24.  
- **CalibraciÃ³n (TEST, 10 bins):** ALL ECE=0.178; OAS1 0.150; **OAS2 0.313**.

### 2025-09-07 â€” P26b (Platt por cohorte)

- CalibraciÃ³n Platt por cohorte entrenada en VAL, aplicada en TEST; re-umbrales 5:1 por cohorte.  
- **OAS1:** Brier 0.208 â†’ **0.199** (AUCâ‰ˆ0.754); **thr_VAL=0.340**; confusiÃ³n/coste idÃ©nticos a P26.  
- **OAS2:** Brier 0.288 â†’ **0.241** (AUCâ‰ˆ0.652); **thr_VAL=0.374**; confusiÃ³n/coste idÃ©nticos a P26.  
- DecisiÃ³n de producto:  
  - **Ãšnico:** P26b (OAS1=0.340, OAS2=0.374).  
  - **Mixto (cribado):** OAS1â†’P26b@0.340 Â· OAS2â†’P24@0.332 (â†‘ recall).

_Artefactos:_ `p26_intermodal/` (preds, ece/mce, umbrales, report, summary, calibrados, bloques).

---

### 2025-09-08 â€” P27 (release + polÃ­tica S2)

**Hecho**
- GenerÃ© `p26_release.zip` con modelos, config, QA y documentaciÃ³n.  
- ActualicÃ© **MODEL_CARD.md** y **HOW_TO_DEPLOY.md** con la **polÃ­tica S2** activa.  
- RegenerÃ© `MANIFEST.json` y `ENVIRONMENT.txt` (trazabilidad completa).

**PolÃ­tica S2 (marcada)**
- Umbrales activos: `OAS1=0.42`, `OAS2=0.4928655287824083`.  
- Criterio: 5:1 (FN:FP) + ajuste OAS2 para **Recall â‰¥ 0.90**.  
- Motivo: minimizar FN en dominio OAS2 (mÃ¡s variable/descalibrado), manteniendo el balance 5:1 en OAS1.

**Smoke (TEST @S2)**
- OAS1 â†’ TP=14, FP=9, TN=18, FN=6 â‡’ R=0.70, P=0.61, Acc=0.681, Coste=39.  
- OAS2 â†’ TP=11, FP=6, TN=5, FN=1 â‡’ R=0.917, P=0.647, Acc=0.696, Coste=11.  
- Archivo: `p26_release/QA/p26b_test_report_recall_target.csv`.

**Archivos clave**
- `p26_release.zip` (23 ficheros, con MANIFEST).  
- Scripts: `compute_pimg_from_features.py`, `predict_end_to_end.py`.  
- Config activa: `CONFIG/deployment_config.json` (backup automÃ¡tico).

**Notas**
- ECE P26: ALLâ‰ˆ0.178, OAS1â‰ˆ0.150, OAS2â‰ˆ0.313 â†’ seguir monitorizando.  
- Mantener evaluaciÃ³n por cohorte al desplegar; recalibrar si deriva.

**Siguiente**
- (Opcional) Endpoint batch/CLI y plantilla REST.  
- Checklist de producciÃ³n: logs de FN y ECE, re-calibraciÃ³n por ventana mÃ³vil.

---

## ðŸ§­ Chuleta rÃ¡pida â€” PolÃ­tica S2 y umbrales

**PolÃ­tica activa (S2)**  
- **OAS1 â†’ 5:1 (FN:FP)** con umbral aprendido en VAL â†’ **thr = 0.42**  
- **OAS2 â†’ â€œrecall objetivoâ€ en VAL (target = 0.85)** â†’ **thr â‰ˆ 0.492866**

**Archivo de configuraciÃ³n:**  
`p26_release/CONFIG/deployment_config.json`

**Claves relevantes dentro del JSON:**
- `policy: "single"`
- `cost_policy: "FN:FP=5:1 (OAS1) + recall_target (OAS2)"`
- `thresholds: { "OAS1": 0.42, "OAS2": 0.4928655287824083 }`
- `thresholds_5to1: { "OAS1": 0.42, "OAS2": 0.49 }`  â† *fallback 5:1 puro*
- `thresholds_recall_target: { "OAS2": { "target": 0.85, "thr_val": 0.4928655â€¦, "found": true } }`

**CÃ³mo cambiar temporalmente de polÃ­tica:**
- **A 5:1 puro:** editar `cost_policy` y copiar `thresholds_5to1` a `thresholds`.
- **Volver a S2:** restablecer `cost_policy` anterior y los `thresholds` de S2.

> Tras editar el JSON, se recomienda un **smoke test** y (opcional) regenerar el ZIP del release.

---

### P27 â€” Intermodal (Late) + PolÃ­tica S2 (TEST)

| Pipeline | Cohorte | MÃ©todo |   AUC | PR-AUC | Brier |   Acc |  Prec |   Rec |    Thr | Coste |
|:--------:|:------:|:------:|------:|------:|------:|------:|------:|------:|------:|-----:|
| **P27** | **ALL** | LATE | **0.736** | **0.729** | **0.229** | â€” | â€” | â€” | â€” | â€” |
| **P27** | **OAS1** | **S2 (5:1)** | â€” | â€” | â€” | **0.681** | **0.609** | **0.700** | **0.420** | **39** |
| **P27** | **OAS2** | **S2 (recallâ‰¥0.85)** | â€” | â€” | â€” | **0.696** | **0.647** | **0.917** | **0.492866** | **11** |

**Notas:**
- Fila **ALL/LATE**: mÃ©tricas de probabilidad (AUC/PR-AUC/Brier) del modelo intermodal (Late).  
- Filas **OAS1/OAS2 (S2)**: decisiÃ³n clÃ­nica tras calibraciÃ³n por cohorte + polÃ­tica S2 (umbrales por cohorte).

---

## ðŸ“Š P27 â€” Tablas globales finales

### 1) Probabilidades (TEST) â€” Comparativa por pipeline y cohorte
> Fuente: `p25_informe_final/p25_master_table.csv` (incluye P19, P22, P23, P24, P26).

| Pipeline | Cohorte | MÃ©todo        |   AUC | PR-AUC | Brier |
|:--------:|:------:|:--------------|------:|------:|------:|
| P19      | ALL    | XGB           | 0.671 | 0.606 | 0.292 |
| P19      | OAS1   | XGB           | 0.663 | 0.588 | 0.310 |
| P19      | OAS2   | XGB           | 0.663 | 0.683 | 0.257 |
| P22      | ALL    | **HGB_platt** | **0.702** | 0.629 | 0.222 |
| P22      | OAS1   | HGB_platt     | 0.724 | 0.649 | 0.209 |
| P22      | OAS2   | LR_platt      | 0.504 | 0.524 | 0.252 |
| P23      | OAS1   | isotonic      | 0.743 | 0.657 | 0.223 |
| P23      | OAS2   | platt         | 0.500 | 0.522 | 0.250 |
| P24      | ALL    | Platt         | 0.727 | 0.717 | 0.220 |
| P24      | OAS1   | Platt         | 0.754 | 0.736 | 0.211 |
| P24      | OAS2   | Platt         | 0.750 | 0.805 | 0.238 |
| P26      | ALL    | LATE          | 0.713 | 0.712 | 0.234 |
| P26      | OAS1   | LATE          | 0.754 | 0.736 | 0.208 |
| P26      | OAS2   | LATE          | 0.652 | 0.728 | 0.288 |

> Nota: P26=LATE intermodal (p\_img + p\_clin). P22 muestra varias calibraciones; arriba se listan las mÃ¡s representativas.

### 2) DecisiÃ³n clÃ­nica (TEST) â€” PolÃ­tica activa **S2**
> Fuentes: `p26_release/QA/p26b_test_report_recall_target.csv` (S2) + `CONFIG/deployment_config.json`.

| Pipeline | Cohorte | PolÃ­tica        |  Acc  |  Prec |  Rec  |    Thr   | Coste |
|:--------:|:------:|:----------------|------:|------:|------:|---------:|-----:|
| P27      | OAS1   | **S2 (5:1)**    | 0.681 | 0.609 | 0.700 | 0.420000 |  39  |
| P27      | OAS2   | **S2 (Râ‰¥0.85)** | 0.696 | 0.647 | 0.917 | 0.492866 |  11  |

**Chuleta de umbrales S2 (dÃ³nde cambiar):** `p26_release/CONFIG/deployment_config.json`  
`thresholds = {"OAS1": 0.42, "OAS2": 0.4928655â€¦}` Â· `thresholds_5to1` como fallback

---

### 2025-09-08 â€” P27 (tablas globales y grÃ¡ficos finales)

- ConsolidÃ© tabla **global** de probabilidades (TEST) por *pipeline Ã— cohorte*.  
- AÃ±adÃ­ tabla de **decisiÃ³n clÃ­nica @S2** (TEST) con TP/FP/TN/FN, mÃ©tricas y umbrales por cohorte.  
- GenerÃ© **figuras** de AUC/PR-AUC/Brier por cohorte y dejÃ© referencia a ECE/MCE (P26 intermodal).  
- ActualicÃ© documentaciÃ³n con **polÃ­tica S2** vigente (umbrales en `deployment_config.json`).

_Artefactos:_ `p25_informe_final/p25_master_table.csv`, `p26_release/QA/p26b_test_report_recall_target.csv`, `p26_intermodal/p26_test_calibration_ece.csv`, `p27_final/*.png`.

---

### 2025-09-08 â€” P27 (figuras y tablas finales)

- Generadas figuras de barras **AUC / PR-AUC / Brier** por cohorte desde `p25_master_table.csv`.
- Exportada tabla de **decisiÃ³n S2** (`p27_final/p27_decision_S2_table.csv`) a partir del QA del release.
- (Si disponible) Creada figura comparativa **S2 vs 5:1** en OAS2.
- Ruta de salida: `p27_final/`.

_Artefactos:_ `p27_final/*.png`, `p27_final/p27_decision_S2_table.csv`.

---

...
### ðŸ§ª Extractos de logs Ãºtiles

* Logits extremos y z-score (cuando aplicÃ³):
    ```
    VAL (pre) logits: min=-7.78e5 | max=5.45e5 | meanâ‰ˆ-1.52e4 | stdâ‰ˆ9.0e4
    VAL (post-z) logits: minâ‰ˆ-8.49 | maxâ‰ˆ6.23 | stdâ‰ˆ1.00
    TEST (pre) logits: min=-6.43e5 | max=4.92e5 | meanâ‰ˆ-1.28e4 | stdâ‰ˆ8.87e4
    TEST (post-z) logits: minâ‰ˆ-7.10 | maxâ‰ˆ5.69 | stdâ‰ˆ1.00
    ```
* `safe_sigmoid` aplicado siempre antes de calibraciÃ³n/ensembles que consumen logits.

---

### âš ï¸ Incidencias recurrentes y soluciones

* **Drive ya montado**:
    * Error: `â€œMountpoint must not already contain filesâ€`.
    * SoluciÃ³n: si `drive.mount()` falla, NO forzar; reiniciar entorno o usar `force_remount=True` sÃ³lo cuando sea estrictamente necesario.
* **`DATA_DIR`/`VAL_MAP`/`TEST_MAP` â€œno existenâ€ aun existiendo**:
    * Causa: estado inconsistente de sesiÃ³n (muchas horas/dÃ­as sin reiniciar).
    * SoluciÃ³n: reinicio completo; volver a montar; re-evaluar `Path.exists()`.
* **Columnas heterogÃ©neas** (`y_score`, `sigmoid(logit)`, `pred`):
    * SoluciÃ³n: diccionario de normalizaciÃ³n y validaciÃ³n de esquemas, forzando `y_score`.
* **Overflow en `exp` (sigmoid)**:
    * SoluciÃ³n: `safe_sigmoid` con `clip[-50, 50]`.
* **Sobreajuste de ensembles complejos** (Dirichlet EXT, STACK\_LR all-features):
    * Causa: `n(VAL)`=10, muchas features correlacionadas.
    * MitigaciÃ³n: reducir features, validaciÃ³n cruzada a paciente, o usar regularizaciÃ³n/priors mÃ¡s informativos.

---

# ðŸ“Š Resumen numÃ©rico (hitos clave, test)
| Bloque | MÃ©todo / ConfiguraciÃ³n | AUC | PR-AUC | Acc | Recall | Precision |
|--------|------------------------|-----|--------|-----|--------|-----------|
| P7     | EffNet-B3 finetune     | .876| .762   | .745| 1.00   | .625      |
| P9     | EffNet-B3 stable       | .740| .630   | .72 | .65    | .62       |
| P10    | EffB3 stable + calib   | .546â€“.583 | .50â€“.53 | .51â€“.55 | 1.00 | .47â€“.49 |
| P10-ext| Ensemble pooling       | .754| .748   | .66â€“.70 | .50â€“.70 | .58â€“.71 |
| P11    | ConvNeXt-Tiny (mean)   | .509| .479   | .489| 1.00   | .455      |
| P11    | DenseNet-121 (trimmed) | .343| .407   | .319| .75    | .36       |
| P11    | Swin-Tiny (top7)       | .641| .597   | .553| .95    | .95       |
| P11-ens| Dirichlet (3 means)    | .520| .523   | .468| 1.00   | .444      |
| P11-ens| Dirichlet EXT (12)     | .361| .405   | .447| .85    | .425      |
| P11-ens| Swin-Tiny + isotonic   | .566| .458   | .553| .95    | .487      |

**Lectura**: los mejores ensembles paciente-level siguen siendo los construidos sobre EffNet-B3 (P10-ext).
Entre backbones alternativos, Swin-Tiny (`top7`) es el mejor individual; con isotonic gana algo de robustez.

---

### ðŸ§­ Estado actual

* Pipelines del 1 al 11 implementados y documentados.
* Backbones alternativos evaluados (Swin, ConvNeXt, Dense).
* Ensembles probados (AVG, Dirichlet, Stacking, Isotonic) con resultados concluyentes sobre limitaciones por tamaÃ±o de VAL y correlaciones.

---

# ðŸš€ PrÃ³ximos pasos
- **Ensemble hÃ­brido**: EffNet-B3 (pooling 4-feat) + Swin-Tiny (top7 isotonic).
- **RegularizaciÃ³n**: stacking con priors y selecciÃ³n de features no correlacionadas.
- **Multimodal**: clÃ­nico + MRI.
- **Aumento de datos**: ADNI, augmentations.

---

# ðŸ“Ž ApÃ©ndice: utilidades clave
Incluye `safe_sigmoid`, `fit_temperature`, `normalize_score`, `agg_patient`.

---

### ðŸ“Ž ApÃ©ndice: fragmentos y utilidades

#### `safe_sigmoid` y `temperature scaling`

```python
import numpy as np
from scipy.optimize import minimize

def safe_sigmoid(z):
    z = np.clip(z, -50, 50)
    return 1/(1+np.exp(-z))

def fit_temperature(logits, y_true, init_T=1.0, bounds=(0.05,10.0)):
    logits = np.asarray(logits,float); y_true = np.asarray(y_true,float)
    def nll(T):
        p = safe_sigmoid(logits/T); eps=1e-7
        return -np.mean(y_true*np.log(p+eps)+(1-y_true)*np.log(1-p+eps))
    return float(minimize(lambda t: nll(t[0]), x0=[init_T], bounds=[bounds], method="L-BFGS-B").x[0])
```

#### NormalizaciÃ³n de columnas de score

```python
SCORE_ALIASES = ['y_score','sigmoid(logit)','sigmoid(logits)','pred']

def normalize_score(df):
    for c in SCORE_ALIASES:
        if c in df.columns:
            df = df.rename(columns={c:'y_score'})
            break
    assert 'y_score' in df.columns, "No encuentro columna de score."
    return df
```

#### Pooling a paciente (`mean`/`trimmed20`/`top7`/`pmean_2`)

```python
import pandas as pd
import numpy as np

def agg_patient(df):
    g = df.groupby('patient_id')['y_score']
    return pd.DataFrame({
        'mean': g.mean(),
        'trimmed20': g.apply(lambda s: s.sort_values().iloc[int(len(s)*.1):int(len(s)*.9)].mean() if len(s)>=10 else s.mean()),
        'top7': g.apply(lambda s: s.sort_values(ascending=False).head(7).mean()),
        'pmean_2': g.apply(lambda s: (np.mean(np.power(np.clip(s,0,1),2)))**0.5)
    }).reset_index()
```

Actualizado: 08/09/2025 22:45