# üß† Proyecto de Detecci√≥n Temprana de Alzheimer (COGNITIVA-AI)

Este proyecto explora la **detecci√≥n temprana de la enfermedad de Alzheimer** combinando **datos cl√≠nicos tabulares** y **resonancias magn√©ticas estructurales (MRI)** de los conjuntos **OASIS-1 y OASIS-2**.  

El enfoque se dise√±√≥ con una idea central: **replicar el razonamiento cl√≠nico** usando tanto la informaci√≥n disponible en la historia del paciente (tests neuropsicol√≥gicos, edad, educaci√≥n, volumen cerebral) como en las **im√°genes estructurales cerebrales**.  

Se construyeron **diez pipelines** para analizar y comparar modalidades:  

1. **COGNITIVA-AI-CLINIC** ‚Üí ML cl√°sico con datos cl√≠nicos (solo OASIS-2).  
2. **COGNITIVA-AI-CLINIC-IMPROVED** ‚Üí ML cl√°sico con datos cl√≠nicos fusionados OASIS-1 + OASIS-2.  
3. **COGNITIVA-AI-IMAGES** ‚Üí Deep Learning con MRI (solo OASIS-2, ResNet50).  
4. **COGNITIVA-AI-IMAGES-IMPROVED** ‚Üí fusi√≥n de OASIS-1+2 en im√°genes.  
5. **COGNITIVA-AI-IMAGES-IMPROVED-GPU (ResNet18)** ‚Üí embeddings ResNet18 entrenados en **Google Colab (GPU)**.  
6. **COGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATED (EffNet-B3)** ‚Üí embeddings EfficientNet-B3 + ensemble LR+XGB a nivel paciente.  
7. **COGNITIVA-AI-FINETUNING** ‚Üí Fine-tuning directo de EfficientNet-B3 en **Google Colab (GPU)** con *temperature scaling* y agregaci√≥n a **nivel paciente**.  
8. **COGNITIVA-AI-FINETUNING-IMPROVED**  ‚Üí Mejoras de fine-tuning (calibraci√≥n de probabilidades).
9. **COGNITIVA-AI-FINETUNING-STABLE** ‚Üí Retraining estable de EfficientNet-B3 en **Google Colab (GPU)** con cach√© SSD, *temperature scaling* y selecci√≥n de umbral cl√≠nico (recall‚â•0.95).
10. **COGNITIVA-AI-FINETUNING-STABLE-PLUS** ‚Üí checkpoint limpio + calibraci√≥n final

---

## üì¶ Datos y Variables Cl√≠nicas

Los datos provienen de los proyectos **OASIS-1** y **OASIS-2**:

- **OASIS-1 (transversal):** 416 sujetos, una sola visita por paciente.  
  - No tiene variable `Group`, la severidad se deduce a partir de **CDR** (`0=No demencia`, `>0=Demencia`).  

- **OASIS-2 (longitudinal):** 150 sujetos, m√∫ltiples visitas.  
  - Incluye `Group` (`Nondemented`, `Demented`, `Converted`).  

**Variables cl√≠nicas empleadas:**

- **Age** ‚Üí Edad del paciente en la visita inicial. Factor de riesgo primario en Alzheimer.  
- **Sex** ‚Üí Sexo biol√≥gico. El Alzheimer presenta prevalencias distintas en mujeres.  
- **Educ** ‚Üí A√±os de educaci√≥n formal. Factor protector (mayor reserva cognitiva).  
- **SES** (Socioeconomic Status) ‚Üí Escala 1‚Äì5 (mayor valor = mayor estatus). Se ha relacionado con acceso a recursos cognitivos.  
- **MMSE** (Mini-Mental State Examination) ‚Üí Test neuropsicol√≥gico de 0‚Äì30. Valores bajos indican deterioro cognitivo.  
- **CDR** (Clinical Dementia Rating) ‚Üí Escala cl√≠nica (0=normal, 0.5=mild, 1=moderate, 2‚Äì3=severe). Considerado est√°ndar de oro para diagn√≥stico.  
- **eTIV** (Estimated Total Intracranial Volume) ‚Üí Volumen craneal estimado, usado para normalizar medidas volum√©tricas.  
- **nWBV** (Normalized Whole Brain Volume) ‚Üí Proporci√≥n de volumen cerebral respecto al intracraneal. Refleja atrofia cerebral.  
- **ASF** (Atlas Scaling Factor) ‚Üí Factor de escalado anat√≥mico aplicado en el registro.  

Estas variables combinan **informaci√≥n cl√≠nica y volum√©trica**, proporcionando una visi√≥n integral de factores de riesgo y biomarcadores estructurales.

---

# 1Ô∏è‚É£ COGNITIVA-AI-CLINIC (solo OASIS-2)

- **Preprocesamiento**: imputaci√≥n SES/Educaci√≥n por mediana, escalado est√°ndar, codificaci√≥n one-hot.  
- **Modelos**: Logistic Regression, Random Forest, XGBoost.  

### üìä Resultados
- Regresi√≥n Log√≠stica ‚Üí **0.912 ¬± 0.050 (CV)**  
- Random Forest ‚Üí **0.925 ¬± 0.032 (CV)**  
- XGBoost ‚Üí **0.907 ¬± 0.032 (CV)**  
- Mejor en test: **XGBoost = 0.897 AUC**  

‚û°Ô∏è Primer baseline, estable pero dataset reducido (150 sujetos).  
---

# 2Ô∏è‚É£ COGNITIVA-AI-CLINIC-IMPROVED (fusi√≥n OASIS-1 + OASIS-2)

- **Unificaci√≥n de columnas** (`snake_case`).  
- **Selecci√≥n baseline** en OASIS-2.  
- **Target unificado**: `Group` (OASIS-2) o `CDR` (OASIS-1).  
- **Etiquetas de cohortes** para trazabilidad.  

### üìä Resultados
- **Hold-out inicial (80/20):** LogReg=1.000 | RF=0.986 | XGB=0.991  
- **Validaci√≥n cruzada (5-fold):**  
  - LogReg ‚Üí **0.979 ¬± 0.012**  
  - RF ‚Üí **0.974 ¬± 0.018**  
  - XGB ‚Üí **0.975 ¬± 0.021**  

‚û°Ô∏è Modelos muy estables con excelente generalizaci√≥n.  

**Umbral cl√≠nico (XGB):** recall‚âà100% con 15 falsos positivos.
**Interpretaci√≥n:** mejor tolerar falsos positivos que falsos negativos.

---

# 3Ô∏è‚É£ COGNITIVA-AI-IMAGES (MRI OASIS-2)

- **Pipeline**: conversi√≥n `.hdr/.img` a slices, normalizaci√≥n, augmentations ligeros.  
- **Modelo**: ResNet50 fine-tuning.  

### üìä Resultados
- 5 slices ‚Üí **AUC=0.938 (test)**  
- 20 slices + z-score ‚Üí AUC=0.858 (mayor recall, menor precisi√≥n).  

‚û°Ô∏è Buen baseline, costoso en CPU.  

---

# 4Ô∏è‚É£ COGNITIVA-AI-IMAGES-IMPROVED (MRI OASIS-1)

- **Split paciente/scan** estricto.  
- **M√°s slices** por paciente.  

### üìä Resultados
- Pipeline m√°s robusto, pero alto coste computacional en CPU.  

---

# 5Ô∏è‚É£ COGNITIVA-AI-IMAGES-IMPROVED-GPU (ResNet18 + Calibraci√≥n)

- **Embeddings ResNet18 (512D)**.  
- Clasificaci√≥n con **Logistic Regression**.  
- **Calibraci√≥n isot√≥nica**.  

### üìä Resultados
- **Slice-nivel:** AUC‚âà0.66 | Brier‚âà0.23.  
- **Paciente-nivel (thr‚âà0.20, recall‚â•0.90):**  
  - [VAL] Recall=0.90 | Precision=0.60 | AUC=0.722  
  - [TEST] Recall=0.80 | Precision=0.52 | AUC=0.724  

‚û°Ô∏è Probabilidades m√°s confiables tras calibraci√≥n.  

---

# 6Ô∏è‚É£ COGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATED (EffNet-B3)

- **Embeddings EfficientNet-B3 (1536D)**.  
- Modelos: LR, XGB, MLP a nivel paciente.  
- **Ensemble LR+XGB** ponderado por PR-AUC.  

### üìä Resultados
- [VAL] AUC=0.815 | PR-AUC=0.705 | Recall=0.95 | Acc=0.70  
- [TEST] AUC=0.704 | PR-AUC=0.623 | Recall=0.90 | Acc=0.70  

‚û°Ô∏è Mejor pipeline MRI hasta la fecha, con sensibilidad alta.  

---

# 7Ô∏è‚É£ COGNITIVA-AI-FINETUNING (EfficientNet-B3 Fine-Tuning parcial)

- **Notebook:** `cognitiva_ai_finetuning.ipynb` (Colab GPU)  
- **Modelo:** EfficientNet-B3 pre-entrenado (Imagenet) con √∫ltima(s) capas descongeladas y reentrenadas sobre MRI OASIS-2.
- **Entrenamiento:** Google Colab GPU (T4), early stopping guiado por PR-AUC en validaci√≥n.
- **Pooling por paciente:** pruebas con promedio vs. atenci√≥n (pesos por importancia de slice).  
- **Calibraci√≥n:** *temperature scaling* con **T=2.673**  
- **Umbral cl√≠nico:** **0.3651**  
- **Artefactos generados:**  
  - `ft_effb3_colab/best_ft_effb3.pth`  
  - `ft_effb3_colab/train_history.json`  
  - `ft_effb3_colab/ft_effb3_patient_eval.json`  
  - `ft_effb3_colab/graphs_from_metrics/‚Ä¶`

### üìä Resultados finales (nivel paciente, n=47)
- **VAL** ‚Üí AUC=**0.748** | PR-AUC=**0.665** | Acc=**0.702** | Precision=**0.588** | Recall=**1.0**  
- **TEST** ‚Üí AUC=**0.876** | PR-AUC=**0.762** | Acc=**0.745** | Precision=**0.625** | Recall=**1.0**  

**Matriz de confusi√≥n TEST (reconstruida, thr=0.3651):**  
**TP=8, FP=5, TN=34, FN=0**

- **Desempe√±o bruto (thr=0.5):** VAL AUC‚âà0.75 | PR-AUC‚âà0.66; TEST AUC‚âà0.87 | PR-AUC‚âà0.76
- **Recall por defecto (thr=0.5):** bajo en VAL (~0.40) y TEST (~0.55) con precisi√≥n alta (~0.85 test), indicando muchos casos positivos omitidos.

‚û°Ô∏è El fine-tuning mejora sustancialmente la discriminaci√≥n (AUC) respecto a pipelines previos (AUC_test ~0.87 vs ~0.70 en pipeline 6), pero con umbral est√°ndar a√∫n no alcanza sensibilidad adecuada (recall 55% en test).

### üñºÔ∏è Gr√°ficas (generadas desde m√©tricas)
- `graphs_from_metrics/ft_b3_patient_confusion_from_metrics.png`  
- `graphs_from_metrics/ft_b3_pr_point.png`  
- `graphs_from_metrics/ft_b3_bars_auc.png`  
- `graphs_from_metrics/ft_b3_bars_prauc.png`  

---

# 8Ô∏è‚É£ COGNITIVA-AI-IMAGES-FT-IMPROVED (Calibraci√≥n y ajustes Fine-tune)

- **Calibraci√≥n de probabilidades:**  se aplic√≥ `Temperature Scaling` en validaci√≥n para corregir el sesgo de confianza del modelo (evitando t√©cnicas prefit con riesgo de fuga de datos).
- **Pooling √≥ptimo:** la agregaci√≥n por *atenci√≥n* super√≥ ligeramente al promedio en m√©tricas de validaci√≥n (PR-AUC), por lo que se adopt√≥ para el pipeline final.
- **M√©tricas calibradas:** tras calibraci√≥n, las predicciones resultaron m√°s fiables (mejor Brier Score y distribuci√≥n probabil√≠stica m√°s alineada).

üìä Resultados:
- **VAL (calibrado, attn):** AUC‚âà0.75 | PR-AUC‚âà0.66 (similar a bruto, se√±al consistente).
- **TEST (calibrado, attn):** AUC‚âà0.88 | PR-AUC‚âà0.76 (sin cambio notable en AUC, confirma generalizaci√≥n).
- **Nota:** La calibraci√≥n no altera el AUC, pero asegura que las probabilidades reflejen riesgo real. Se observ√≥ mejora cualitativa en la confiabilidad de las predicciones.

‚û°Ô∏è La calibraci√≥n interna del modelo elimin√≥ leakage y ajust√≥ las salidas probabil√≠sticas, dejando el modelo listo para aplicar un umbral cl√≠nico en validaci√≥n.
 
---

### 9Ô∏è‚É£ COGNITIVA-AI-FINETUNING-STABLE (Fine Tunning + Umbral Cl√≠nico)
- **Notebook:** `cognitiva_ai_finetuning_stable.ipynb`  
- **Pooling paciente:** mean  
- **Calibraci√≥n:** temperature scaling (T=2.048)  
- **Umbral cl√≠nico:** 0.3400 (selecci√≥n en VAL con recall‚â•0.95)
- **Selecci√≥n de umbral cl√≠nico:** a partir de la curva Precision-Recall en validaci√≥n se eligi√≥ el menor umbral con recall ‚â•90% y m√°xima precisi√≥n. Obtuvo thr‚âà0.36 en probabilidades de paciente.

**Resultados (nivel paciente):**  
- VAL ‚Üí AUC=1.000 | PR-AUC=1.000 | Acc=1.000 | P=1.000 | R=1.000 | thr=0.3400 | n=10  
- TEST ‚Üí AUC=0.663 | PR-AUC=0.680 | Acc=0.574 | P=0.500 | R=0.650 | thr=0.3400 | n=47

üìä Resultados (Paciente-nivel (thr‚âà0.36, recall=1.00)):
- [VAL] Recall=1.00 | Precision=0.59 | AUC=0.748
- [TEST] Recall=1.00 | Precision=0.62 | AUC=0.876

**Comparativa r√°pida vs Pipeline 7 (FT previo):** TEST AUC: 0.585 ‚Üí 0.663, TEST PR‚ÄëAUC: 0.582 ‚Üí 0.680

**Gr√°ficas:** `ft_effb3_stable_colab/graphs_from_metrics/`  
- `effb3_stable_val_bars.png` / `effb3_stable_test_bars.png`  
- `effb3_stable_pr_val.png` / `effb3_stable_pr_test.png`  
- `effb3_stable_conf_val.png` / `effb3_stable_conf_test.png`  
- `comparison_p7_p9_test.png` / `comparison_p7_p9_val.png`

‚û°Ô∏è Mejor pipeline MRI logrado: se detectan el 100% de los casos positivos en test (sin falsos negativos) al costo de algunos falsos positivos (precision ~62%). El modelo fine-tune calibrado ofrece as√≠ alta sensibilidad adecuada para cribado cl√≠nico, acercando el rendimiento MRI al nivel de los datos cl√≠nicos puros.
---

# üîü COGNITIVA-AI-FINETUNING-STABLE-PLUS (checkpoint limpio + calibraci√≥n final)

- **Notebook:** `cognitiva_ai_finetuning_stable_plus.ipynb`  
- **Motivaci√≥n:** El pipeline 9 (Stable) aportaba estabilidad, pero arrastraba problemas de correspondencia entre checkpoints y arquitectura, adem√°s de no incluir calibraci√≥n expl√≠cita. Pipeline 10 surge para **normalizar completamente el checkpoint, asegurar compatibilidad de pesos (99.7% cargados) y aplicar calibraci√≥n final** (*temperature scaling*).  
- **Configuraci√≥n t√©cnica:**  
  - Arquitectura: EfficientNet-B3 con salida binaria.  
  - Normalizaci√≥n robusta de pesos: conversi√≥n de checkpoint entrenado a formato limpio.  
  - Calibraci√≥n: *temperature scaling* sobre logits para ajustar probabilidades.  
  - Pooling a nivel paciente: media (mean), median y variantes top-k.  
- **Resultados clave (paciente-nivel):**  
  - VAL: AUC=0.63 | PR-AUC=0.67 | Acc‚âà0.53 | P‚âà0.47 | R‚âà0.85  
  - TEST: AUC=0.55 | PR-AUC=0.53 | Acc‚âà0.51 | P‚âà0.47 | R=1.0  
- **Conclusi√≥n:** el pipeline 10 logra **recall=1.0 en test**, lo que lo convierte en la opci√≥n m√°s sensible para cribado cl√≠nico temprano, aunque con sacrificio en AUC y precisi√≥n. Cierra la etapa de *solo MRI* antes de avanzar a la fusi√≥n multimodal.

---

# üìä Comparativa Global (pipelines 1‚Äì10)

| Pipeline | Modalidad        | Modelo            | AUC (Test) | PR-AUC | Acc | Recall | Precision |
|----------|-----------------|-------------------|------------|--------|-----|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB               | 0.897      | ‚Äî      | ‚Äî   | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB               | 0.991      | ‚Äî      | ‚Äî   | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50          | 0.938      | ‚Äî      | ‚Äî   | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib  | 0.724      | 0.606  | 0.60| 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed   | 0.704      | 0.623  | 0.70| 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune| 0.876      | 0.762  | 0.745| 1.0   | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable  | 0.74       | 0.63   | 0.72| 0.65   | 0.62      |
| P10      | Fine-Tuning B3 Stable Plus | EffNet-B3 calibrado | 0.63 | 0.55 | 1.00 | 0.47 |


<p align="center">
  <img src="./graficos/global_auc_comparison_updated.png" alt="Comparativa Global ‚Äî ROC-AUC por Pipeline" width="880"/>
</p>

La comparaci√≥n global de ROC-AUC ilustra la mejora progresiva de cada pipeline, destacando el salto de rendimiento con fine-tuning (pipeline 9).
---

# üìà Visualizaciones MRI EffNet-B3 (patient-features)

<p align="center">
  <img src="./graficos/mri_effb3_pf_auc.png" alt="MRI EffB3 patient-features ‚Äî ROC-AUC (TEST)" width="720"/>
</p>

<p align="center">
  <img src="./graficos/mri_effb3_pf_prauc.png" alt="MRI EffB3 patient-features ‚Äî PR-AUC (TEST)" width="720"/>
</p>

<p align="center">
  <img src="./graficos/mri_effb3_pf_recall.png" alt="MRI EffB3 patient-features ‚Äî Recall (TEST)" width="720"/>
</p>

<p align="center">
  <img src="./graficos/mri_effb3_pf_precision.png" alt="MRI EffB3 patient-features ‚Äî Precisi√≥n (TEST)" width="720"/>
</p>

<p align="center">
  <img src="./graficos/mri_effb3_pf_accuracy.png" alt="MRI EffB3 patient-features ‚Äî Accuracy (TEST)" width="720"/>
</p>

---

**Autor√≠a:** Fran Ram√≠rez  
**√öltima actualizaci√≥n:** 26/08/2025 ‚Äì 00:09
