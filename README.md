# üß† COGNITIVA-AI ‚Äì Experimentos de Clasificaci√≥n Multimodal

Este repositorio documenta **toda la evoluci√≥n experimental** en el marco del proyecto **Cognitiva-AI**, cuyo objetivo ha sido **explorar modelos de machine learning para diagn√≥stico de Alzheimer** combinando datos cl√≠nicos y de imagen (MRI OASIS-2).  

El documento sigue un enfoque **cuaderno de bit√°cora extendido**, en el que cada pipeline corresponde a un conjunto de experimentos con motivaciones, configuraciones t√©cnicas, m√©tricas obtenidas y reflexiones.  
El tono es intencionadamente **verboso y detallado**: se incluyen incidencias de ejecuci√≥n, errores y aprendizajes pr√°cticos que acompa√±aron cada etapa.  

---

## üìö √çndice

1. [Introducci√≥n](#introducci√≥n)
2. [Pipelines experimentales](#pipelines-experimentales)
   - [P1: Datos cl√≠nicos con XGBoost](#p1-datos-cl√≠nicos-con-xgboost)
   - [P2: Datos cl√≠nicos fusionados](#p2-datos-cl√≠nicos-fusionados)
   - [P3: MRI OASIS-2 ‚Äì ResNet50](#p3-mri-oasis-2--resnet50)
   - [P5: MRI Colab ‚Äì ResNet18 calibrado](#p5-mri-colab--resnet18-calibrado)
   - [P6: MRI Colab ‚Äì EfficientNet-B3 embeddings](#p6-mri-colab--efficientnet-b3-embeddings)
   - [P7: MRI Colab ‚Äì EfficientNet-B3 fine-tuning](#p7-mri-colab--efficientnet-b3-fine-tuning)
   - [P9: MRI Colab ‚Äì EfficientNet-B3 stable](#p9-mri-colab--efficientnet-b3-stable)
   - [P10: MRI Colab ‚Äì EfficientNet-B3 stable + calibraci√≥n](#p10-mri-colab--efficientnet-b3-stable--calibraci√≥n)
   - [P10-ext: Extensiones y ensembles](#p10-ext-extensiones-y-ensembles)
   - [P11: Backbones alternativos](#p11-backbones-alternativos)
3. [Comparativa global de resultados](#comparativa-global-de-resultados)
4. [Desaf√≠os principales](#desaf√≠os-principales)
5. [Lecciones aprendidas](#lecciones-aprendidas)
6. [Pr√≥ximos pasos](#pr√≥ximos-pasos)

---

## Introducci√≥n

El proyecto **Cognitiva-AI** parte de la necesidad de evaluar modelos predictivos que integren datos cl√≠nicos y de imagen (MRI) en cohortes reducidas como OASIS-2.  

Desde el inicio se asumi√≥ que:
- Los **datos cl√≠nicos** podr√≠an servir como baseline fuerte (edad, MMSE, CDR, etc.).  
- Las **im√°genes cerebrales** aportar√≠an riqueza multimodal pero con mayor complejidad.  
- Ser√≠a necesario experimentar con **diferentes backbones** de visi√≥n profunda y con **estrategias de calibraci√≥n, ensembles y stacking** para compensar el peque√±o tama√±o muestral.  

El proceso se organiz√≥ en **pipelines numerados**. Cada uno corresponde a un conjunto de experimentos exploratorios.  

---

## Pipelines experimentales

### P1: Datos cl√≠nicos con XGBoost

- **Motivaci√≥n:** establecer un baseline s√≥lido con datos tabulares cl√≠nicos.  
- **Modelo:** XGBoost con optimizaci√≥n b√°sica de hiperpar√°metros.  
- **Resultados:**  
  - AUC (Test): 0.897  
  - Buen baseline, aunque limitado a informaci√≥n tabular.  

**Reflexi√≥n:**  
Los datos cl√≠nicos solos ya ofrecen un baseline sorprendentemente competitivo. Esto oblig√≥ a replantear si los modelos de imagen podr√≠an aportar ganancia marginal real.  

---

### P2: Datos cl√≠nicos fusionados

- **Motivaci√≥n:** combinar datos cl√≠nicos enriquecidos o fusionados con informaci√≥n adicional.  
- **Modelo:** XGBoost extendido.  
- **Resultados:**  
  - AUC (Test): 0.991  
  - Recall cercano a 1.0  

**Reflexi√≥n:**  
La fusi√≥n cl√≠nica alcanza casi techo de rendimiento en esta cohorte. Refuerza la hip√≥tesis de que la MRI aporta, sobre todo, complementariedad m√°s que superioridad aislada.  

---

### P3: MRI OASIS-2 ‚Äì ResNet50

- **Motivaci√≥n:** baseline en im√°genes MRI con un backbone cl√°sico.  
- **Modelo:** ResNet50 preentrenado en ImageNet, fine-tuning en OASIS-2.  
- **Resultados:**  
  - AUC (Test): 0.938  

**Reflexi√≥n:**  
Primer resultado fuerte en imagen pura. Abre la puerta a comparar cl√≠nico vs imagen.  

---

### P5: MRI Colab ‚Äì ResNet18 calibrado

- **Motivaci√≥n:** probar backbone m√°s ligero en entorno Colab.  
- **Modelo:** ResNet18 con calibraci√≥n posterior.  
- **Resultados:**  
  - AUC (Test): 0.724  
  - PR-AUC: 0.606  
  - Acc: 0.60 | Recall: 0.80 | Precisi√≥n: 0.52  

**Reflexi√≥n:**  
La calibraci√≥n ayud√≥ a controlar la sobreconfianza, pero los resultados son inferiores a ResNet50.  

---

### P6: MRI Colab ‚Äì EfficientNet-B3 embeddings

- **Motivaci√≥n:** usar EfficientNet-B3 solo como extractor de embeddings, sin fine-tuning completo.  
- **Resultados:**  
  - AUC (Test): 0.704  
  - PR-AUC: 0.623  
  - Recall: 0.90  

**Reflexi√≥n:**  
Como extractor simple ya supera ResNet18 calibrado, confirmando potencia de EfficientNet.  

---

### P7: MRI Colab ‚Äì EfficientNet-B3 fine-tuning

- **Motivaci√≥n:** pasar a fine-tuning completo de EfficientNet-B3.  
- **Resultados:**  
  - AUC (Test): 0.876  
  - PR-AUC: 0.762  
  - Acc: 0.745 | Recall: 1.0 | Precisi√≥n: 0.625  

**Reflexi√≥n:**  
Uno de los mejores backbones en imagen pura. Supone el nuevo baseline de referencia.  

---

### P9: MRI Colab ‚Äì EfficientNet-B3 stable

- **Motivaci√≥n:** estabilizar entrenamientos previos de EfficientNet-B3.  
- **Resultados:**  
  - AUC (Test): 0.740  
  - PR-AUC: 0.630  
  - Recall m√°s bajo que en P7.  

**Incidencias:**  
- Saturaci√≥n de logits detectada.  
- Variabilidad alta entre seeds.  

**Reflexi√≥n:**  
Confirma que la estabilidad no siempre se traduce en mejor rendimiento.  

---

### P10: MRI Colab ‚Äì EfficientNet-B3 stable + calibraci√≥n

- **Motivaci√≥n:** aplicar calibraci√≥n expl√≠cita para corregir sobreconfianza.  
- **M√©todo:** Platt scaling, isotonic regression y temperature scaling.  
- **Resultados:**  
  - AUC (Test): 0.546‚Äì0.583  
  - PR-AUC: 0.50‚Äì0.53  
  - Recall: 1.0 pero precisi√≥n baja (~0.47‚Äì0.49)  

**Reflexi√≥n:**  
La calibraci√≥n ayud√≥ a controlar la sobreconfianza pero sacrific√≥ precisi√≥n.  

---

### P10-ext: Extensiones y ensembles

- **Motivaci√≥n:** explotar estrategias de **ensembles y stacking** con EfficientNet-B3.  
- **Estrategias:**  
  - Seed ensembles (mean, trimmed, top7)  
  - Random forest sobre features derivadas  
  - Stacking log√≠stico  
- **Resultados destacados:**  
  - Ensemble (mean+trimmed20+top7+p2): Test AUC ~0.75  
  - Stacking LR sobre seeds: Test AUC ~0.75  

**Reflexi√≥n:**  
El ensemble aporta mejoras modestas pero consistentes. Se consolida como estrategia √∫til.  

---

### P11: Backbones alternativos

- **Motivaci√≥n:** comprobar si otros backbones de visi√≥n pod√≠an superar a EfficientNet-B3.  
- **Modelos probados:**  
  - ResNet-50  
  - DenseNet-121  
  - ConvNeXt-Tiny  
  - Swin-Tiny  
- **Resultados preliminares:**  
  - ResNet-50: Test AUC ~0.74  
  - DenseNet-121: Test AUC ~0.34 (muy bajo)  
  - ConvNeXt-Tiny: Test AUC ~0.50  
  - Swin-Tiny: Test AUC ~0.64 (con top7 pooling)  

**Incidencias:**  
- Varios problemas de montaje de Google Drive tras semanas sin reiniciar Colab.  
- Ficheros dispersos en directorios distintos (ej. slice vs patient).  
- Necesidad de armonizar columnas (`y_score` vs `sigmoid(logit)`).  

**Reflexi√≥n:**  
Ning√∫n backbone supera claramente a EfficientNet-B3.  
La v√≠a l√≥gica pasa a ser **ensembles de backbones**.  

---

### P13: **COGNITIVA-AI-OASIS2-P13 (EffNet-B3 base en OASIS-2)**  
- Procesamiento de **367 scans OASIS-2** ‚Üí 150 pacientes con labels cl√≠nicos.  
- **Slices:** 20 cortes axiales equiespaciados, evitando extremos, normalizados (z-score + CLAHE opcional).  
- **M√°scara cerebral:** segmentaci√≥n FSL o fallback con Otsu.  
- **Una visita por paciente** ‚Üí 150 pacientes (105 train, 22 val, 23 test).  

**Resultados:** recall alto en cohortes peque√±as, pero dataset limitado ‚Üí riesgo de sobreajuste.  

---

### P14: **COGNITIVA-AI-OASIS2-P14 (EffNet-B3 balanceado, Colab SSD)**  
- Copia de las 7340 slices a **SSD local de Colab** para reducir la latencia de E/S.  
- Entrenamiento con **class weights** para balancear clases.  
- Integraci√≥n en cat√°logo de backbones (p11).  

**Resultados:**  
- [VAL] AUC‚âà0.88 | Acc‚âà0.86 | Recall‚âà0.82  
- [TEST] AUC‚âà0.71 | Acc‚âà0.70 | Recall=1.0  

---

### P15: **COGNITIVA-AI-OASIS2-P15 (Consolidaci√≥n y comparaci√≥n)**  
- Fase de consolidaci√≥n: integraci√≥n de resultados de OASIS-2 (p13 y p14) en el **cat√°logo global de backbones**.  
- Generaci√≥n de features combinadas con OASIS-1 (p11).  
- Se descartaron features con NaN > 40% y se aplicaron modelos de ensamblado (Logistic Regression, HistGradientBoosting).  

**Resultados comparativos (VAL/TEST):**

| Pipeline | VAL AUC | VAL Acc | VAL Recall | TEST AUC | TEST Acc | TEST Recall |
|----------|---------|---------|------------|----------|----------|-------------|
| **p13**  | ~0.90   | 0.86    | 0.82       | ~0.77    | 0.78     | 0.83        |
| **p14**  | 0.88    | 0.86    | 0.82       | 0.71     | 0.70     | 1.00        |
| **p15** (ensemble) | 0.94 | 0.84 | ~1.0 | 0.71 | 0.63‚Äì0.71 | 0.78‚Äì1.0 |

‚û°Ô∏è p15 marca la transici√≥n de entrenamientos aislados a **ensambles integrados OASIS-1 + OASIS-2**.

---

### P15: **COGNITIVA-AI-OASIS2-P15 (Consolidaci√≥n)**
- Integraci√≥n de resultados de **p13 y p14** en un marco com√∫n.  
- Se verific√≥ la cobertura de labels (150 scans con target sobre 367 totales) y la estrategia de **una sesi√≥n por paciente**.  
- Dificultades: latencia de E/S en Google Drive ‚Üí necesidad de copiar slices a SSD de Colab.  
- Conclusi√≥n: P15 sirvi√≥ como **validaci√≥n de consistencia** antes de refinar ensembles.

### P16: **COGNITIVA-AI-OASIS2-P16 (Refinamiento de Ensembles)**
- Se construyeron **features patient-level** a partir del cat√°logo de backbones (`oas2_effb3`, `oas2_effb3_p14`, SwinTiny, ConvNeXt, etc.).  
- Manejo expl√≠cito de **NaNs** (descartar features con >40% de missing, imputaci√≥n/flags en LR, NaN nativos en HistGB).  
- Ensayos con **Logistic Regression, HistGradientBoosting y blending**.  
- Resultados:  
  - VAL: AUC‚âà0.95 (blend), recall‚âà1.0 en OAS1, estable en OAS2.  
  - TEST: AUC‚âà0.69, recall‚âà0.78 (blend), mejor que cada backbone aislado.  
- Conclusi√≥n: ensembles permiten mejorar estabilidad y recall, confirmando el valor de la integraci√≥n multimodelo.

---

## Comparativa global de resultados

| Pipeline | Modalidad        | Modelo                       | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|------------------------------|------------|--------|-------|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB                          | 0.897      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB                          | 0.991      | ‚Äî      | ‚Äî     | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50                     | 0.938      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib             | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed              | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune           | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable             | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib       | 0.546‚Äì0.583| 0.50‚Äì0.53 | 0.51‚Äì0.55 | 1.0 | 0.47‚Äì0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble         | 0.754      | 0.737  | 0.68  | 0.70   | 0.61      |
| P11      | MRI Colab       | ResNet-50 alt backbone       | 0.740      | 0.730  | 0.64  | 0.70   | 0.56      |
| P11      | MRI Colab       | ConvNeXt-Tiny (mean pooling) | 0.509      | 0.479  | 0.49  | 1.00   | 0.45      |
| P11      | MRI Colab       | DenseNet-121 (trimmed20)     | 0.343      | 0.407  | 0.32  | 0.75   | 0.36      |
| P11      | MRI Colab       | Swin-Tiny (top7 pooling)     | 0.641      | 0.597  | 0.55  | 0.95   | 0.95      |

---

## Desaf√≠os principales

1. **Peque√±o tama√±o de dataset**:  
   - Solo ~47 pacientes en test.  
   - Variabilidad extrema en m√©tricas seg√∫n fold.  
   - Riesgo de overfitting alt√≠simo.  

2. **Saturaci√≥n de logits**:  
   - En P9 y P10, los logits alcanzaban valores >500k, obligando a normalizaci√≥n y calibraci√≥n.  

3. **Problemas de montaje de Google Drive en Colab**:  
   - Errores de ‚ÄúMountpoint must not already contain files‚Äù tras semanas sin reinicio.  
   - Necesidad de reiniciar entorno completo.  

4. **Dispersi√≥n de ficheros de predicci√≥n**:  
   - Algunos outputs generados como `*_png_preds`, otros como `*_slice_preds`.  
   - Diferencias en columnas (`y_score`, `sigmoid(logit)`, `pred`).  

5. **Gesti√≥n de ensembles**:  
   - Decidir entre averaging, stacking, random search de pesos.  
   - Validaci√≥n compleja con tan pocos pacientes.  

---

## Lecciones aprendidas

- **Los datos cl√≠nicos son extremadamente informativos** en OASIS-2.  
- **EfficientNet-B3** sigue siendo el backbone m√°s consistente en MRI.  
- **La calibraci√≥n es necesaria** pero puede sacrificar precisi√≥n.  
- **Los ensembles ayudan modestamente**, pero su efecto depende de la diversidad real de los modelos.  
- **La organizaci√≥n de outputs es cr√≠tica**: nombres consistentes ahorran horas de debugging.  
- **El reinicio peri√≥dico de Colab** evita errores de montaje y rutas fantasmas.  

---

## Pr√≥ximos pasos

1. **Consolidar ensembles de backbones**:  
   - Probar combinaciones m√°s ricas (ResNet+EffNet+Swin).  
   - Usar stacking con regularizaci√≥n fuerte.  

2. **Explorar multimodal**:  
   - Fusionar cl√≠nico + MRI.  
   - Comparar si mejora sobre cl√≠nico solo.  

3. **Validaci√≥n externa**:  
   - Usar datasets adicionales (ADNI, etc.) para comprobar generalizaci√≥n.  

4. **Optimizaci√≥n final**:  
   - Revisar hiperpar√°metros con Bayesian Optimization.  
   - Estudiar interpretabilidad (Grad-CAM, SHAP).  

---
Actualizado: 06/09/2025 22:42