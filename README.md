> *Branch creada para analizar el c√≥digo y hacer comentarios.*

# üß† COGNITIVA-AI ‚Äì Experimentos de Clasificaci√≥n Multimodal

Este repositorio documenta **toda la evoluci√≥n experimental** en el marco del proyecto **Cognitiva-AI**, cuyo objetivo ha sido **explorar modelos de machine learning para diagn√≥stico de Alzheimer** combinando datos cl√≠nicos y de imagen (MRI OASIS-2).  

El documento sigue un enfoque **cuaderno de bit√°cora extendido**, en el que cada pipeline corresponde a un conjunto de experimentos con motivaciones, configuraciones t√©cnicas, m√©tricas obtenidas y reflexiones.  
El tono es intencionadamente **verboso y detallado**: se incluyen incidencias de ejecuci√≥n, errores y aprendizajes pr√°cticos que acompa√±aron cada etapa.  

---

## üìö √çndice

1. [Introducci√≥n](#introducci√≥n)
2. [Pipelines experimentales](#pipelines-experimentales)
   - [P1: Datos cl√≠nicos con XGBoost](#p1-datos-cl√≠nicos-con-xgboost)
   - [P2: Datos cl√≠nicos fusionados](#p2-datos-cl√≠nicos-fusionados)
   - [P3: MRI OASIS-2 ‚Äì ResNet50](#p3-mri-oasis-2--resnet50)
   - [P5: MRI Colab ‚Äì ResNet18 calibrado](#p5-mri-colab--resnet18-calibrado)
   - [P6: MRI Colab ‚Äì EfficientNet-B3 embeddings](#p6-mri-colab--efficientnet-b3-embeddings)
   - [P7: MRI Colab ‚Äì EfficientNet-B3 fine-tuning](#p7-mri-colab--efficientnet-b3-fine-tuning)
   - [P9: MRI Colab ‚Äì EfficientNet-B3 stable](#p9-mri-colab--efficientnet-b3-stable)
   - [P10: MRI Colab ‚Äì EfficientNet-B3 stable + calibraci√≥n](#p10-mri-colab--efficientnet-b3-stable--calibraci√≥n)
   - [P10-ext: Extensiones y ensembles](#p10-ext-extensiones-y-ensembles)
   - [P11: Backbones alternativos](#p11-backbones-alternativos)
3. [Comparativa global de resultados](#comparativa-global-de-resultados)
4. [Desaf√≠os principales](#desaf√≠os-principales)
5. [Lecciones aprendidas](#lecciones-aprendidas)
6. [Pr√≥ximos pasos](#pr√≥ximos-pasos)

---

## Introducci√≥n

El proyecto **Cognitiva-AI** parte de la necesidad de evaluar modelos predictivos que integren datos cl√≠nicos y de imagen (MRI) en cohortes reducidas como OASIS-2.  

Desde el inicio se asumi√≥ que:
- Los **datos cl√≠nicos** podr√≠an servir como baseline fuerte (edad, MMSE, CDR, etc.).  
- Las **im√°genes cerebrales** aportar√≠an riqueza multimodal pero con mayor complejidad.  
- Ser√≠a necesario experimentar con **diferentes backbones** de visi√≥n profunda y con **estrategias de calibraci√≥n, ensembles y stacking** para compensar el peque√±o tama√±o muestral.  

El proceso se organiz√≥ en **pipelines numerados**. Cada uno corresponde a un conjunto de experimentos exploratorios.  

---

## Pipelines experimentales

### P1: Datos cl√≠nicos con XGBoost

- **Motivaci√≥n:** establecer un baseline s√≥lido con datos tabulares cl√≠nicos.  
- **Modelo:** XGBoost con optimizaci√≥n b√°sica de hiperpar√°metros.  
- **Resultados:**  
  - AUC (Test): 0.897  
  - Buen baseline, aunque limitado a informaci√≥n tabular.  

**Reflexi√≥n:**  
Los datos cl√≠nicos solos ya ofrecen un baseline sorprendentemente competitivo. Esto oblig√≥ a replantear si los modelos de imagen podr√≠an aportar ganancia marginal real.  

---

### P2: Datos cl√≠nicos fusionados

- **Motivaci√≥n:** combinar datos cl√≠nicos enriquecidos o fusionados con informaci√≥n adicional.  
- **Modelo:** XGBoost extendido.  
- **Resultados:**  
  - AUC (Test): 0.991  
  - Recall cercano a 1.0  

**Reflexi√≥n:**  
La fusi√≥n cl√≠nica alcanza casi techo de rendimiento en esta cohorte. Refuerza la hip√≥tesis de que la MRI aporta, sobre todo, complementariedad m√°s que superioridad aislada.  

---

### P3: MRI OASIS-2 ‚Äì ResNet50

- **Motivaci√≥n:** baseline en im√°genes MRI con un backbone cl√°sico.  
- **Modelo:** ResNet50 preentrenado en ImageNet, fine-tuning en OASIS-2.  
- **Resultados:**  
  - AUC (Test): 0.938  

**Reflexi√≥n:**  
Primer resultado fuerte en imagen pura. Abre la puerta a comparar cl√≠nico vs imagen.  

---

### P5: MRI Colab ‚Äì ResNet18 calibrado

- **Motivaci√≥n:** probar backbone m√°s ligero en entorno Colab.  
- **Modelo:** ResNet18 con calibraci√≥n posterior.  
- **Resultados:**  
  - AUC (Test): 0.724  
  - PR-AUC: 0.606  
  - Acc: 0.60 | Recall: 0.80 | Precisi√≥n: 0.52  

**Reflexi√≥n:**  
La calibraci√≥n ayud√≥ a controlar la sobreconfianza, pero los resultados son inferiores a ResNet50.  

---

### P6: MRI Colab ‚Äì EfficientNet-B3 embeddings

- **Motivaci√≥n:** usar EfficientNet-B3 solo como extractor de embeddings, sin fine-tuning completo.  
- **Resultados:**  
  - AUC (Test): 0.704  
  - PR-AUC: 0.623  
  - Recall: 0.90  

**Reflexi√≥n:**  
Como extractor simple ya supera ResNet18 calibrado, confirmando potencia de EfficientNet.  

---

### P7: MRI Colab ‚Äì EfficientNet-B3 fine-tuning

- **Motivaci√≥n:** pasar a fine-tuning completo de EfficientNet-B3.  
- **Resultados:**  
  - AUC (Test): 0.876  
  - PR-AUC: 0.762  
  - Acc: 0.745 | Recall: 1.0 | Precisi√≥n: 0.625  

**Reflexi√≥n:**  
Uno de los mejores backbones en imagen pura. Supone el nuevo baseline de referencia.  

---

### P9: MRI Colab ‚Äì EfficientNet-B3 stable

- **Motivaci√≥n:** estabilizar entrenamientos previos de EfficientNet-B3.  
- **Resultados:**  
  - AUC (Test): 0.740  
  - PR-AUC: 0.630  
  - Recall m√°s bajo que en P7.  

**Incidencias:**  
- Saturaci√≥n de logits detectada.  
- Variabilidad alta entre seeds.  

**Reflexi√≥n:**  
Confirma que la estabilidad no siempre se traduce en mejor rendimiento.  

---

### P10: MRI Colab ‚Äì EfficientNet-B3 stable + calibraci√≥n

- **Motivaci√≥n:** aplicar calibraci√≥n expl√≠cita para corregir sobreconfianza.  
- **M√©todo:** Platt scaling, isotonic regression y temperature scaling.  
- **Resultados:**  
  - AUC (Test): 0.546‚Äì0.583  
  - PR-AUC: 0.50‚Äì0.53  
  - Recall: 1.0 pero precisi√≥n baja (~0.47‚Äì0.49)  

**Reflexi√≥n:**  
La calibraci√≥n ayud√≥ a controlar la sobreconfianza pero sacrific√≥ precisi√≥n.  

---

### P10-ext: Extensiones y ensembles

- **Motivaci√≥n:** explotar estrategias de **ensembles y stacking** con EfficientNet-B3.  
- **Estrategias:**  
  - Seed ensembles (mean, trimmed, top7)  
  - Random forest sobre features derivadas  
  - Stacking log√≠stico  
- **Resultados destacados:**  
  - Ensemble (mean+trimmed20+top7+p2): Test AUC ~0.75  
  - Stacking LR sobre seeds: Test AUC ~0.75  

**Reflexi√≥n:**  
El ensemble aporta mejoras modestas pero consistentes. Se consolida como estrategia √∫til.  

---

### P11: Backbones alternativos

- **Motivaci√≥n:** comprobar si otros backbones de visi√≥n pod√≠an superar a EfficientNet-B3.  
- **Modelos probados:**  
  - ResNet-50  
  - DenseNet-121  
  - ConvNeXt-Tiny  
  - Swin-Tiny  
- **Resultados preliminares:**  
  - ResNet-50: Test AUC ~0.74  
  - DenseNet-121: Test AUC ~0.34 (muy bajo)  
  - ConvNeXt-Tiny: Test AUC ~0.50  
  - Swin-Tiny: Test AUC ~0.64 (con top7 pooling)  

**Incidencias:**  
- Varios problemas de montaje de Google Drive tras semanas sin reiniciar Colab.  
- Ficheros dispersos en directorios distintos (ej. slice vs patient).  
- Necesidad de armonizar columnas (`y_score` vs `sigmoid(logit)`).  

**Reflexi√≥n:**  
Ning√∫n backbone supera claramente a EfficientNet-B3.  
La v√≠a l√≥gica pasa a ser **ensembles de backbones**.  

---

### P13: **COGNITIVA-AI-OASIS2-P13 (EffNet-B3 base en OASIS-2)**  
- Procesamiento de **367 scans OASIS-2** ‚Üí 150 pacientes con labels cl√≠nicos.  
- **Slices:** 20 cortes axiales equiespaciados, evitando extremos, normalizados (z-score + CLAHE opcional).  
- **M√°scara cerebral:** segmentaci√≥n FSL o fallback con Otsu.  
- **Una visita por paciente** ‚Üí 150 pacientes (105 train, 22 val, 23 test).  

**Resultados:** recall alto en cohortes peque√±as, pero dataset limitado ‚Üí riesgo de sobreajuste.  

---

### P14: **COGNITIVA-AI-OASIS2-P14 (EffNet-B3 balanceado, Colab SSD)**  
- Copia de las 7340 slices a **SSD local de Colab** para reducir la latencia de E/S.  
- Entrenamiento con **class weights** para balancear clases.  
- Integraci√≥n en cat√°logo de backbones (p11).  

**Resultados:**  
- [VAL] AUC‚âà0.88 | Acc‚âà0.86 | Recall‚âà0.82  
- [TEST] AUC‚âà0.71 | Acc‚âà0.70 | Recall=1.0  

---

### P15: **COGNITIVA-AI-OASIS2-P15 (Consolidaci√≥n y comparaci√≥n)**  
- Fase de consolidaci√≥n: integraci√≥n de resultados de OASIS-2 (p13 y p14) en el **cat√°logo global de backbones**.  
- Generaci√≥n de features combinadas con OASIS-1 (p11).  
- Se descartaron features con NaN > 40% y se aplicaron modelos de ensamblado (Logistic Regression, HistGradientBoosting).  

**Resultados comparativos (VAL/TEST):**

| Pipeline | VAL AUC | VAL Acc | VAL Recall | TEST AUC | TEST Acc | TEST Recall |
|----------|---------|---------|------------|----------|----------|-------------|
| **p13**  | ~0.90   | 0.86    | 0.82       | ~0.77    | 0.78     | 0.83        |
| **p14**  | 0.88    | 0.86    | 0.82       | 0.71     | 0.70     | 1.00        |
| **p15** (ensemble) | 0.94 | 0.84 | ~1.0 | 0.71 | 0.63‚Äì0.71 | 0.78‚Äì1.0 |

‚û°Ô∏è p15 marca la transici√≥n de entrenamientos aislados a **ensambles integrados OASIS-1 + OASIS-2**.

---

### P15: **COGNITIVA-AI-OASIS2-P15 (Consolidaci√≥n)**
- Integraci√≥n de resultados de **p13 y p14** en un marco com√∫n.  
- Se verific√≥ la cobertura de labels (150 scans con target sobre 367 totales) y la estrategia de **una sesi√≥n por paciente**.  
- Dificultades: latencia de E/S en Google Drive ‚Üí necesidad de copiar slices a SSD de Colab.  
- Conclusi√≥n: P15 sirvi√≥ como **validaci√≥n de consistencia** antes de refinar ensembles.

### P16: **COGNITIVA-AI-OASIS2-P16 (Refinamiento de Ensembles)**
- Se construyeron **features patient-level** a partir del cat√°logo de backbones (`oas2_effb3`, `oas2_effb3_p14`, SwinTiny, ConvNeXt, etc.).  
- Manejo expl√≠cito de **NaNs** (descartar features con >40% de missing, imputaci√≥n/flags en LR, NaN nativos en HistGB).  
- Ensayos con **Logistic Regression, HistGradientBoosting y blending**.  
- Resultados:  
  - VAL: AUC‚âà0.95 (blend), recall‚âà1.0 en OAS1, estable en OAS2.  
  - TEST: AUC‚âà0.69, recall‚âà0.78 (blend), mejor que cada backbone aislado.  
- Conclusi√≥n: ensembles permiten mejorar estabilidad y recall, confirmando el valor de la integraci√≥n multimodelo.

---

### P17: **COGNITIVA-AI-Ensemble Calibration (Stacking + Platt Scaling)**  
- Refinamiento de ensembles con **stacking (LR sobre outputs base)** y calibraci√≥n de probabilidades mediante **Platt scaling**.  
- Umbral optimizado en validaci√≥n para F1 (0.35), aplicado despu√©s en test.  
- M√©tricas adicionales: **Brier Score** para evaluar calibraci√≥n.  

**Resultados (VAL/TEST):**  
- [VAL] AUC‚âà0.78 | Acc‚âà0.74 | Recall‚âà0.94 | F1‚âà0.76 | Brier=0.176  
- [TEST] AUC‚âà0.70 | Acc‚âà0.63 | Recall‚âà0.78 | F1‚âà0.66 | Brier=0.227  

‚û°Ô∏è El ensemble calibrado mantiene un **recall alto y probabilidades mejor calibradas**, aunque OAS2 sigue limitado por tama√±o muestral.

---

### Comparativa p16 vs p17

| Pipeline | M√©todo principal                | VAL AUC | VAL Acc | VAL Recall | VAL F1 | TEST AUC | TEST Acc | TEST Recall | TEST F1 | Brier (Test) |
|----------|---------------------------------|---------|---------|------------|--------|----------|----------|-------------|---------|--------------|
| **p16**  | Blending (LR + HGB, Œ±=0.02)     | 0.95    | 0.84    | 1.00       | 0.84   | 0.69     | 0.64     | 0.78        | 0.64    | ‚Äì            |
| **p17**  | Stacking + Platt scaling (LR)   | 0.78    | 0.74    | 0.94       | 0.76   | 0.70     | 0.63     | 0.78        | 0.66    | 0.227        |

‚û°Ô∏è **p16** maximiz√≥ el AUC en validaci√≥n, pero con cierto riesgo de sobreajuste.  
‚û°Ô∏è **p17** ajust√≥ las probabilidades (Brier=0.227 en test) y mantuvo recall alto, ofreciendo **mejor calibraci√≥n** y utilidad cl√≠nica.

---

7Ô∏è‚É£ COGNITIVA-AI-ENSEMBLE-ADVANCED (p18, stacking multicapa)

- **Objetivo:** explorar t√©cnicas de stacking avanzadas con m√∫ltiples clasificadores de nivel base y un meta-modelo log√≠stico.
- **Modelos base:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.
- **Estrategia:** 
  - Generaci√≥n de predicciones OOF (out-of-fold) para evitar fugas.
  - Meta-modelo: regresi√≥n log√≠stica + blending con ajuste fino de pesos (Œ±‚âà0.02).
  - Validaci√≥n y test separados por cohortes OAS1 y OAS2.
- **Resultados:**
  - [VAL] AUC‚âà0.92 | F1‚âà0.83 | Recall‚âà0.90 | Precision‚âà0.77.
  - [TEST] AUC‚âà0.67 | F1‚âà0.67 | Recall‚âà0.78 | Precision‚âà0.59.
- **Insights:** 
  - El meta-modelo favoreci√≥ especialmente a Gradient Boosting y Random Forest.
  - El stacking alcanz√≥ recall alto pero con menor generalizaci√≥n en OAS2 (AUC‚âà0.5 en test).

---

### P19: **COGNITIVA-AI-OASIS2-P19 (Meta-Ensemble apilado)**  

**Objetivo:** consolidar las se√±ales de m√∫ltiples backbones (p11/p14/p16/p18) con un stacking de segundo nivel.  

- **Base learners:** LR, HistGB, GB, RF, LGBM, XGB entrenados con OOF sin fuga, usando features por-paciente derivados (mean / trimmed / top-k / p2).  
- **Meta-learner:** XGBoost entrenado sobre los OOF; inferencia en TEST con predicciones de base learners.  
- **Manejo de NaN:** exclusi√≥n de columnas con NaN>40% + imputaci√≥n simple donde procede para modelos que lo requieren.  

**M√©tricas:**  
- VAL: AUC‚âà0.964, PRAUC‚âà0.966, Acc‚âà0.913, F1‚âà0.897, Brier‚âà0.071.  
- TEST: AUC‚âà0.729, PRAUC‚âà0.688, Acc‚âà0.714, Prec‚âà0.773, Recall‚âà0.531, F1‚âà0.630, Brier‚âà0.226.  

‚û°Ô∏è **Conclusi√≥n:** el meta-ensemble eleva la performance en validaci√≥n, pero el recall en TEST sugiere ajustar calibraci√≥n/umbrales y atender shift OAS1/OAS2. Se programar√° p20 para calibraci√≥n fina y umbrales por cohorte.

---

### P20: **COGNITIVA-AI-OASIS2-P20 (Meta-calibraci√≥n y umbrales por cohorte)**

- **Objetivo:** refinar el meta-ensemble (de p19) con **calibraci√≥n de probabilidades** y **umbrales espec√≠ficos**.  
- **M√©todos de calibraci√≥n:** Platt scaling (sigmoide) e isot√≥nica.  
- **Escenarios:** calibraci√≥n **global** y calibraci√≥n **per-cohort** (OAS1/OAS2).  
- **Modelos meta evaluados:** HistGradientBoosting (HGB) y Logistic Regression (LR).  

**Resultados:**
- [VAL|HGB-Isotonic-PerC] AUC‚âà0.840 | Acc‚âà0.725 | F1‚âà0.753 | Brier‚âà0.156  
- [TEST|HGB-Isotonic-PerC] AUC‚âà0.679 | Acc‚âà0.600 | F1‚âà0.641 | Brier‚âà0.253  
- [VAL|LR-Platt-Global] AUC‚âà0.743 | Acc‚âà0.638 | F1‚âà0.691 | Brier‚âà0.209  
- [TEST|LR-Platt-Global] AUC‚âà0.686 | Acc‚âà0.629 | F1‚âà0.658 | Brier‚âà0.221  

‚û°Ô∏è **Conclusi√≥n:** la calibraci√≥n mejor√≥ la fiabilidad de las probabilidades (Brier menor en VAL). En TEST el recall sigue alto (‚âà0.78) con sacrificio de precisi√≥n, confirmando la necesidad de ajustar umbrales por cohorte.

---

### P21: **COGNITIVA-AI-OASIS2-P21 (Meta-refine)**
**Objetivo.** Refinar el meta-ensemble con menos base learners y un meta-modelo m√°s simple, controlando NaNs y validaci√≥n OOF sin fuga.

**Setup.**
- Datos: 56 features por paciente (tras filtrado NaN>40% se mantienen 36).
- Cohortes: VAL=69, TEST=70 (con etiqueta de cohorte OAS1/OAS2).
- Base learners: LR (L2), HGB, LightGBM, XGBoost (OOF estratificado a nivel paciente).
- Meta-learner: blending/stacking con 4 se√±ales OOF (shape meta VAL=69√ó4, TEST=70√ó4).
- Umbral: F1-m√°x en VAL ‚Üí **0.45**.

**Resultados.**
- **VAL:** AUC‚âà0.955, PRAUC‚âà0.931, Acc‚âà0.870, F1‚âà0.862, Brier‚âà0.082.
- **TEST:** AUC‚âà0.653, PRAUC‚âà0.587, Acc‚âà0.643, F1‚âà0.627, Brier‚âà0.285.

**Notas.**
- LightGBM advirti√≥ *‚ÄúNo further splits with positive gain‚Äù* (dataset peque√±o + features ya destiladas).
- El umbral global favorece recall razonable pero con ca√≠da de AUC en TEST (shift OAS1/OAS2).
- Este paso consolida el flujo de meta-se√±ales reducido y sienta base para calibraci√≥n por cohorte/coste.

---

### P22: **COGNITIVA-AI-OASIS2-P22 (Meta-Ablation con calibraci√≥n avanzada)**

- **Objetivo:** explorar variantes de calibraci√≥n (Platt vs Isot√≥nica) aplicadas a meta-modelos (LR y HGB), evaluando su impacto en la estabilidad y confiabilidad de las probabilidades.  
- **Datos:** 69 pacientes en validaci√≥n, 70 en test, con 36 features seleccionadas tras descartar columnas con NaN>40%.  
- **Modelos:** Logistic Regression (LR) y HistGradientBoosting (HGB), calibrados con Platt (*sigmoid*) e Isotonic.  
- **Umbral:** ajustado en validaci√≥n para F1-m√°x (0.30‚Äì0.35 seg√∫n modelo).  

**Resultados (paciente-nivel):**  

- **LR-Platt:** VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
- **LR-Isotonic:** VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
- **HGB-Platt:** VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
- **HGB-Isotonic:** VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
- **Blend (Isotonic):** VAL AUC‚âà0.90, F1‚âà0.79 | TEST AUC‚âà0.68, F1‚âà0.62  

‚û°Ô∏è **Conclusi√≥n:**  
La calibraci√≥n isot√≥nica tiende a mejorar el ajuste de las probabilidades (Brier Score bajo en VAL), mientras que Platt produce recall m√°s alto en test. El blend confirma robustez en validaci√≥n, aunque en test persiste el gap OAS1/OAS2. P22 se consolida como paso de *ablation study* antes de ensambles finales.

---

## Comparativa global de resultados

| Pipeline | Modalidad        | Modelo                       | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|------------------------------|------------|--------|-------|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB                          | 0.897      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB                          | 0.991      | ‚Äî      | ‚Äî     | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50                     | 0.938      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib             | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed              | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune           | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable             | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib       | 0.546‚Äì0.583| 0.50‚Äì0.53 | 0.51‚Äì0.55 | 1.0 | 0.47‚Äì0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble         | 0.754      | 0.737  | 0.68  | 0.70   | 0.61      |
| P11      | MRI Colab       | ResNet-50 alt backbone       | 0.740      | 0.730  | 0.64  | 0.70   | 0.56      |
| P11      | MRI Colab       | ConvNeXt-Tiny (mean pooling) | 0.509      | 0.479  | 0.49  | 1.00   | 0.45      |
| P11      | MRI Colab       | DenseNet-121 (trimmed20)     | 0.343      | 0.407  | 0.32  | 0.75   | 0.36      |
| P11      | MRI Colab       | Swin-Tiny (top7 pooling)     | 0.641      | 0.597  | 0.55  | 0.95   | 0.95      |

---

## Desaf√≠os principales

1. **Peque√±o tama√±o de dataset**:  
   - Solo ~47 pacientes en test.  
   - Variabilidad extrema en m√©tricas seg√∫n fold.  
   - Riesgo de overfitting alt√≠simo.  

2. **Saturaci√≥n de logits**:  
   - En P9 y P10, los logits alcanzaban valores >500k, obligando a normalizaci√≥n y calibraci√≥n.  

3. **Problemas de montaje de Google Drive en Colab**:  
   - Errores de ‚ÄúMountpoint must not already contain files‚Äù tras semanas sin reinicio.  
   - Necesidad de reiniciar entorno completo.  

4. **Dispersi√≥n de ficheros de predicci√≥n**:  
   - Algunos outputs generados como `*_png_preds`, otros como `*_slice_preds`.  
   - Diferencias en columnas (`y_score`, `sigmoid(logit)`, `pred`).  

5. **Gesti√≥n de ensembles**:  
   - Decidir entre averaging, stacking, random search de pesos.  
   - Validaci√≥n compleja con tan pocos pacientes.  

---

## Lecciones aprendidas

- **Los datos cl√≠nicos son extremadamente informativos** en OASIS-2.  
- **EfficientNet-B3** sigue siendo el backbone m√°s consistente en MRI.  
- **La calibraci√≥n es necesaria** pero puede sacrificar precisi√≥n.  
- **Los ensembles ayudan modestamente**, pero su efecto depende de la diversidad real de los modelos.  
- **La organizaci√≥n de outputs es cr√≠tica**: nombres consistentes ahorran horas de debugging.  
- **El reinicio peri√≥dico de Colab** evita errores de montaje y rutas fantasmas.  

---

## Pr√≥ximos pasos

1. **Consolidar ensembles de backbones**:  
   - Probar combinaciones m√°s ricas (ResNet+EffNet+Swin).  
   - Usar stacking con regularizaci√≥n fuerte.  

2. **Explorar multimodal**:  
   - Fusionar cl√≠nico + MRI.  
   - Comparar si mejora sobre cl√≠nico solo.  

3. **Validaci√≥n externa**:  
   - Usar datasets adicionales (ADNI, etc.) para comprobar generalizaci√≥n.  

4. **Optimizaci√≥n final**:  
   - Revisar hiperpar√°metros con Bayesian Optimization.  
   - Estudiar interpretabilidad (Grad-CAM, SHAP).  

---
Actualizado: 07/09/2025 15:43