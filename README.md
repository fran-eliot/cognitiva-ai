# üß† Proyecto de Detecci√≥n Temprana de Alzheimer (COGNITIVA-AI) ‚Äì Experimentos de Clasificaci√≥n Multimodal

Este repositorio documenta **toda la evoluci√≥n experimental** en el marco del proyecto **Cognitiva-AI**, cuyo objetivo ha sido **explorar modelos de machine learning para la predicci√≥n binaria de deterioro cognitivo (Alzheimer)** combinando  **datos cl√≠nicos tabulares** y **resonancias magn√©ticas estructurales (MRI)** de los conjuntos **OASIS-1 y OASIS-2**.   

El enfoque se dise√±√≥ con una idea central: **replicar el razonamiento cl√≠nico** usando tanto la informaci√≥n disponible en la historia del paciente (tests neuropsicol√≥gicos, edad, educaci√≥n, volumen cerebral) como en las **im√°genes estructurales cerebrales**.  

> **Idea fuerza**: un flujo **reproducible, interpretable y cl√≠nicamente orientado** que prioriza **recall** (minimizar FN) y mantiene la **calibraci√≥n** de probabilidades con umbrales **por cohorte** (OAS1/OAS2).

El documento sigue un enfoque **cuaderno de bit√°cora extendido**, en el que cada pipeline corresponde a un conjunto de experimentos con motivaciones, configuraciones t√©cnicas, m√©tricas obtenidas y reflexiones.  
El tono es intencionadamente **verboso y detallado**: se incluyen incidencias de ejecuci√≥n, errores y aprendizajes pr√°cticos que acompa√±aron cada etapa.  

Se construyeron **diez pipelines** para analizar y comparar modalidades:  

1. **COGNITIVA-AI-CLINIC** ‚Üí ML cl√°sico con datos cl√≠nicos (solo OASIS-2).  
2. **COGNITIVA-AI-CLINIC-IMPROVED** ‚Üí ML cl√°sico con datos cl√≠nicos fusionados OASIS-1 + OASIS-2.  
3. **COGNITIVA-AI-IMAGES** ‚Üí Deep Learning con MRI (solo OASIS-2, ResNet50).  
4. **COGNITIVA-AI-IMAGES-IMPROVED** ‚Üí fusi√≥n de OASIS-1+2 en im√°genes.  
5. **COGNITIVA-AI-IMAGES-IMPROVED-GPU (ResNet18)** ‚Üí embeddings ResNet18 entrenados en **Google Colab (GPU)**.  
6. **COGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATED (EffNet-B3)** ‚Üí embeddings EfficientNet-B3 + ensemble LR+XGB a nivel paciente.  
7. **COGNITIVA-AI-FINETUNING** ‚Üí Fine-tuning directo de EfficientNet-B3 en **Google Colab (GPU)** con *temperature scaling* y agregaci√≥n a **nivel paciente**.  
8. **COGNITIVA-AI-FINETUNING-IMPROVED**  ‚Üí Mejoras de fine-tuning (calibraci√≥n de probabilidades). Ajustes univariados (normalizaci√≥n, dropout, etc.).  
9. **COGNITIVA-AI-FINETUNING-STABLE** ‚Üí Retraining estable de EfficientNet-B3 en **Google Colab (GPU)** con cach√© SSD, *temperature scaling* y selecci√≥n de umbral cl√≠nico (recall‚â•0.95). Entrenamiento estable con configuraci√≥n refinada y early stopping.  
10. **COGNITIVA-AI-FINETUNING-STABLE-PLUS** ‚Üí Versi√≥n extendida con calibraci√≥n adicional y pooling alternativo (mean, median, top-k).  

---

## üìö √çndice

1. [Introducci√≥n](#introducci√≥n)
2. [Pipelines experimentales](#pipelines-experimentales)
   - [P1: Datos cl√≠nicos con XGBoost](#p1-datos-cl√≠nicos-con-xgboost)
   - [P2: Datos cl√≠nicos fusionados](#p2-datos-cl√≠nicos-fusionados)
   - [P3: MRI OASIS-2 ‚Äì ResNet50](#p3-mri-oasis-2--resnet50)
   - [P5: MRI Colab ‚Äì ResNet18 calibrado](#p5-mri-colab--resnet18-calibrado)
   - [P6: MRI Colab ‚Äì EfficientNet-B3 embeddings](#p6-mri-colab--efficientnet-b3-embeddings)
   - [P7: MRI Colab ‚Äì EfficientNet-B3 fine-tuning](#p7-mri-colab--efficientnet-b3-fine-tuning)
   - [P9: MRI Colab ‚Äì EfficientNet-B3 stable](#p9-mri-colab--efficientnet-b3-stable)
   - [P10: MRI Colab ‚Äì EfficientNet-B3 stable + calibraci√≥n](#p10-mri-colab--efficientnet-b3-stable--calibraci√≥n)
   - [P10-ext: Extensiones y ensembles](#p10-ext-extensiones-y-ensembles)
   - [P11: Backbones alternativos](#p11-backbones-alternativos)
3. [Comparativa global de resultados](#comparativa-global-de-resultados)
4. [Desaf√≠os principales](#desaf√≠os-principales)
5. [Lecciones aprendidas](#lecciones-aprendidas)
6. [Pr√≥ximos pasos](#pr√≥ximos-pasos)

---

## üì¶ Datos y Variables Cl√≠nicas

Los datos provienen de los proyectos **OASIS-1** y **OASIS-2**:

- **OASIS-1 (transversal):** 416 sujetos, una sola visita por paciente.  
  - No tiene variable `Group`, la severidad se deduce a partir de **CDR** (`0=No demencia`, `>0=Demencia`).  

- **OASIS-2 (longitudinal):** 150 sujetos, m√∫ltiples visitas.  
  - Incluye `Group` (`Nondemented`, `Demented`, `Converted`).  

**Variables cl√≠nicas empleadas:**

- **Age** ‚Üí Edad del paciente en la visita inicial. Factor de riesgo primario en Alzheimer.  
- **Sex** ‚Üí Sexo biol√≥gico. El Alzheimer presenta prevalencias distintas en mujeres.  
- **Educ** ‚Üí A√±os de educaci√≥n formal. Factor protector (mayor reserva cognitiva).  
- **SES** (Socioeconomic Status) ‚Üí Escala 1‚Äì5 (mayor valor = mayor estatus). Se ha relacionado con acceso a recursos cognitivos.  
- **MMSE** (Mini-Mental State Examination) ‚Üí Test neuropsicol√≥gico de 0‚Äì30. Valores bajos indican deterioro cognitivo.  
- **CDR** (Clinical Dementia Rating) ‚Üí Escala cl√≠nica (0=normal, 0.5=mild, 1=moderate, 2‚Äì3=severe). Considerado est√°ndar de oro para diagn√≥stico.  
- **eTIV** (Estimated Total Intracranial Volume) ‚Üí Volumen craneal estimado, usado para normalizar medidas volum√©tricas.  
- **nWBV** (Normalized Whole Brain Volume) ‚Üí Proporci√≥n de volumen cerebral respecto al intracraneal. Refleja atrofia cerebral.  
- **ASF** (Atlas Scaling Factor) ‚Üí Factor de escalado anat√≥mico aplicado en el registro.  

Estas variables combinan **informaci√≥n cl√≠nica y volum√©trica**, proporcionando una visi√≥n integral de factores de riesgo y biomarcadores estructurales.

---

## Estructura y datasets

**Datasets**  
- **OASIS‚Äë1** (cross‚Äësectional). Etiqueta derivada de **CDR** (CDR=0‚Üí0, CDR>0‚Üí1).  
- **OASIS‚Äë2** (longitudinal). Etiqueta a partir de **Group** (*Nondemented=0; Demented/Converted=1*).  
- Criterio **1 visita/paciente** en OASIS‚Äë2 para evitar *leakage* inter‚Äësesi√≥n.  
- MRI: **20 slices axiales** equiespaciadas, normalizaci√≥n *z‚Äëscore* + **CLAHE** opcional.  
- Splits **estratificados a nivel paciente** (sin fuga).

**Estructura de carpetas (clave)**
```
/p11_alt_backbones/          # Cat√°logo y matrices patient-level OASIS-1 (base para ensembles)
/p13_oasis2_images/, /p14_oasis2_images/  # EffNet-B3 OASIS-2 (pesos, preds y features)
/p19_meta_ensemble, /p20_meta_calibration, /p21_meta_refine, /p22_meta_ablation
/p24_meta_simple, /p25_informe_final
/p26_intermodal/             # Fusi√≥n Late/Mid + P26b (calibraci√≥n por cohorte)
/p26_release/                # Release reproducible (modelos, config, QA, docs)
/p27_final/                  # Figuras y tablas finales consolidadas
```
**Documentaci√≥n viva**: `README.md` (este), `InformeTecnico.md`, `CuadernoBitacora.md`.

---

## Introducci√≥n

El proyecto **Cognitiva-AI** parte de la necesidad de evaluar modelos predictivos que integren datos cl√≠nicos y de imagen (MRI) en cohortes reducidas como OASIS-1/2.  

Desde el inicio se asumi√≥ que:
- Los **datos cl√≠nicos** podr√≠an servir como baseline fuerte (edad, MMSE, CDR, etc.).  
- Las **im√°genes cerebrales** aportar√≠an riqueza multimodal pero con mayor complejidad.  
- Ser√≠a necesario experimentar con **diferentes backbones** de visi√≥n profunda y con **estrategias de calibraci√≥n, ensembles y stacking** para compensar el peque√±o tama√±o muestral.  

El proceso se organiz√≥ en **pipelines numerados**. Cada uno corresponde a un conjunto de experimentos exploratorios.  

---

## Pipelines experimentales

### Resumen ejecutivo

- **Mejor modelo unimodal (imagen)**: **P24** (LR elastic‚Äënet sobre features por paciente + **Platt**).  
  - **TEST**: **AUC=0.727** (ALL) ¬∑ **0.754** (OAS1) ¬∑ **0.750** (OAS2).  
  - Umbrales **5:1** (FN:FP): OAS1 **0.435** (Coste=39, R=0.70, P=0.61), OAS2 **0.332** (Coste=12, R=0.92, P=0.61).

- **Modelo intermodal (imagen+cl√≠nico)**: **P26 (Late)** y **P26b (Late + Platt por cohorte)**.  
  - **TEST** P26 Late: **AUC=0.713**, PR‚ÄëAUC=0.712, Brier=0.234.  
  - **TEST** P26b (Platt por cohorte): **OAS1 AUC‚âà0.754 (Brier‚âà0.199)** ¬∑ **OAS2 AUC‚âà0.652 (Brier‚âà0.241)**.

- **Pol√≠tica activa (P27): S2**  
  - Base **5:1** (FN:FP) + **ajuste OAS2** para **Recall objetivo ‚â•0.90** (cribado).  
  - **Umbrales S2**: **OAS1=0.42**, **OAS2‚âà0.4928655288** ‚Üí en TEST:  
    - OAS1: TP=14, FP=9, TN=18, FN=6 ‚Üí **R=0.70**, **P=0.609**, Coste=39.  
    - OAS2: TP=11, FP=6, TN=5, FN=1 ‚Üí **R=0.917**, **P=0.647**, Coste=11.

---

### L√≠nea temporal (P1‚ÜíP27)

- **P1‚ÄìP4 (local)**: *slicing*, normalizaci√≥n y primeros baselines tabulares e imagen.  
- **P5‚ÄìP12 (Colab, OASIS‚Äë1)**: consolidaci√≥n de **EffNet‚ÄëB3**, agregaci√≥n por paciente, **cat√°logo p11** y **ensembles**.  
- **P13‚ÄìP14 (OASIS‚Äë2)**: entrenamiento **EffNet‚ÄëB3** espec√≠fico (1 visita/paciente); copia a **SSD Colab** y **class_weight**.  
- **P16‚ÄìP18**: ensembles avanzados (OOF sin fuga, stacking/blending, calibraci√≥n).  
- **P19**: **Meta‚Äëensemble (XGB)** con **LR/HGB/GB/RF/LGBM/XGB** como *base learners*.  
- **P20‚ÄìP22**: **calibraci√≥n** (Platt/Isot√≥nica), **umbrales por cohorte** y *ablation*.  
- **P23**: **calibraci√≥n por cohorte con coste** (5:1 FN:FP).  
- **P24**: **meta simple interpretable** (LR‚ÄëEN + Platt) ‚Üí mejor equilibrio generalizaci√≥n/calibraci√≥n.  
- **P25**: **consolidaci√≥n** y tabla maestra (P19/P22/P23/P24).  
- **P26/P26b**: **intermodal** (Late vs Mid) + **calibraci√≥n por cohorte**; elecci√≥n **Late**.  
- **P27**: **release reproducible** + **pol√≠tica S2** y figuras finales.

---

### P1: COGNITIVA-AI-CLINIC (solo OASIS-2) 

- **Motivaci√≥n:** establecer un baseline s√≥lido con datos tabulares cl√≠nicos. 
- **Preprocesamiento**: imputaci√≥n SES/Educaci√≥n por mediana, escalado est√°ndar, codificaci√≥n one-hot.  
- **Modelos**: Logistic Regression, Random Forest, XGBoost.  

### üìä Resultados
- Regresi√≥n Log√≠stica ‚Üí **0.912 ¬± 0.050 (CV)**  
- Random Forest ‚Üí **0.925 ¬± 0.032 (CV)**  
- XGBoost ‚Üí **0.907 ¬± 0.032 (CV)**  
- Mejor en test: **XGBoost = 0.897 AUC**  

‚û°Ô∏è Primer baseline, estable pero dataset reducido (150 sujetos) y limitado a datos cl√≠nicos.    

**Reflexi√≥n:**  
Los datos cl√≠nicos solos ya ofrecen un baseline sorprendentemente competitivo. Esto oblig√≥ a replantear si los modelos de imagen podr√≠an aportar ganancia marginal real.  

---

### P2: COGNITIVA-AI-CLINIC-IMPROVED (datos cl√≠nicos fusionados OASIS-1 + OASIS-2)

- **Motivaci√≥n:** combinar datos cl√≠nicos fusionados de ambas cohortes.
- **Unificaci√≥n de columnas** (`snake_case`).  
- **Selecci√≥n baseline** en OASIS-2.  
- **Target unificado**: `Group` (OASIS-2) o `CDR` (OASIS-1).  
- **Etiquetas de cohortes** para trazabilidad. 

### üìä Resultados
- **Hold-out inicial (80/20):** LogReg=1.000 | RF=0.986 | XGB=0.991  
- **Validaci√≥n cruzada (5-fold):**  
  - LogReg ‚Üí **0.979 ¬± 0.012**  
  - RF ‚Üí **0.974 ¬± 0.018**  
  - XGB ‚Üí **0.975 ¬± 0.021**  

‚û°Ô∏è Modelos muy estables con excelente generalizaci√≥n.  

**Umbral cl√≠nico (XGB):** recall‚âà100% con 15 falsos positivos.
**Interpretaci√≥n:** mejor tolerar falsos positivos que falsos negativos.


- **Modelo:** XGBoost extendido.  
- **Resultados:**  
  - AUC (Test): 0.991  
  - Recall cercano a 1.0  

**Reflexi√≥n:**  
La fusi√≥n cl√≠nica alcanza casi techo de rendimiento en esta cohorte. Refuerza la hip√≥tesis de que la MRI aporta, sobre todo, complementariedad m√°s que superioridad aislada.  

---

### P3: COGNITIVA-AI-IMAGES (MRI OASIS-2) ‚Äì ResNet50

- **Motivaci√≥n:** baseline en im√°genes MRI con un backbone cl√°sico.  
- **Pipeline**: conversi√≥n `.hdr/.img` a slices, normalizaci√≥n, augmentations ligeros.
- **Modelo:** ResNet50 preentrenado en ImageNet, fine-tuning en OASIS-2.  
- **Resultados:**  
  - 5 slices ‚Üí **AUC=0.938 (test)**  
  - 20 slices + z-score ‚Üí AUC=0.858 (mayor recall, menor precisi√≥n). 

**Reflexi√≥n:**  
Primer resultado fuerte en imagen pura. Abre la puerta a comparar cl√≠nico vs imagen.  Muy costoso en CPU

---

### P4: COGNITIVA-AI-IMAGES-IMPROVED (MRI OASIS-1/2)

- **Split paciente/scan** estricto.  
- **M√°s slices** por paciente.  

### üìä Resultados
- Pipeline m√°s robusto, pero alto coste computacional en CPU.  

---

### P5: COGNITIVA-AI-IMAGES-IMPROVED-GPU ‚Äì ResNet18 calibrado

- **Motivaci√≥n:** probar backbone m√°s ligero en entorno Colab.  
- **Modelo:** ResNet18 (512D) con calibraci√≥n posterior.
- Clasificaci√≥n con **Logistic Regression**.  
- **Calibraci√≥n isot√≥nica**.    
- **Resultados:**  
 - **Slice-nivel:** AUC‚âà0.66 | Brier‚âà0.23.  
 - **Paciente-nivel (thr‚âà0.20, recall‚â•0.90):**  
  - [VAL] Recall=0.90 | Precision=0.60 | AUC=0.722  
  - [TEST] Recall=0.80 | Precision=0.52 | AUC=0.724 

**Reflexi√≥n:**  
La calibraci√≥n ayud√≥ a controlar la sobreconfianza, pero los resultados son inferiores a ResNet50.  

---

### P6: MCOGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATE ‚Äì EfficientNet-B3 embeddings

- **Motivaci√≥n:** usar EfficientNet-B3 solo como extractor de embeddings, sin fine-tuning completo.  
- **Embeddings EfficientNet-B3 (1536D)**.  
- Modelos: LR, XGB, MLP a nivel paciente.  
- **Ensemble LR+XGB** ponderado por PR-AUC. 
- **Resultados:**  
  - [VAL] AUC=0.815 | PR-AUC=0.705 | Recall=0.95 | Acc=0.70  
  - [TEST] AUC=0.704 | PR-AUC=0.623 | Recall=0.90 | Acc=0.70  

**Reflexi√≥n:**  
Como extractor simple ya supera ResNet18 calibrado, confirmando potencia de EfficientNet.  Mejor pipeline MRI hasta la fecha, con sensibilidad alta.

---

### P7: COGNITIVA-AI-FINETUNING (EfficientNet-B3 Fine-Tuning parcial)

- **Motivaci√≥n:** pasar a fine-tuning completo de EfficientNet-B3.  
- **Modelo:** EfficientNet-B3 pre-entrenado (Imagenet) con √∫ltima(s) capas descongeladas y reentrenadas sobre MRI OASIS-2.
- **Entrenamiento:** Google Colab GPU (T4), early stopping guiado por PR-AUC en validaci√≥n.
- **Pooling por paciente:** pruebas con promedio vs. atenci√≥n (pesos por importancia de slice).  
- **Calibraci√≥n:** *temperature scaling* con **T=2.673**  
- **Umbral cl√≠nico:** **0.3651**  
- **Artefactos generados:**  
  - `ft_effb3_colab/best_ft_effb3.pth`  
  - `ft_effb3_colab/train_history.json`  
  - `ft_effb3_colab/ft_effb3_patient_eval.json`  
  - `ft_effb3_colab/graphs_from_metrics/‚Ä¶`
- **Resultados (nivel paciente, n=47):**  
  - **VAL** ‚Üí AUC=**0.748** | PR-AUC=**0.665** | Acc=**0.702** | Precision=**0.588** | Recall=**1.0**  
  - **TEST** ‚Üí AUC=**0.876** | PR-AUC=**0.762** | Acc=**0.745** | Precision=**0.625** | Recall=**1.0**  

**Matriz de confusi√≥n TEST (reconstruida, thr=0.3651):**  
**TP=8, FP=5, TN=34, FN=0**

- **Desempe√±o bruto (thr=0.5):** VAL AUC‚âà0.75 | PR-AUC‚âà0.66; TEST AUC‚âà0.87 | PR-AUC‚âà0.76
- **Recall por defecto (thr=0.5):** bajo en VAL (~0.40) y TEST (~0.55) con precisi√≥n alta (~0.85 test), indicando muchos casos positivos omitidos. 

‚û°Ô∏è El fine-tuning mejora sustancialmente la discriminaci√≥n (AUC) respecto a pipelines previos (AUC_test ~0.87 vs ~0.70 en pipeline 6), pero con umbral est√°ndar a√∫n no alcanza sensibilidad adecuada (recall 55% en test).

**Reflexi√≥n:**  
Uno de los mejores backbones en imagen pura. Supone el nuevo baseline de referencia.  

---

### P8: COGNITIVA-AI-IMAGES-FT-IMPROVED (Calibraci√≥n y ajustes Fine-tune)

- **Calibraci√≥n de probabilidades:**  se aplic√≥ `Temperature Scaling` en validaci√≥n para corregir el sesgo de confianza del modelo (evitando t√©cnicas prefit con riesgo de fuga de datos).
- **Pooling √≥ptimo:** la agregaci√≥n por *atenci√≥n* super√≥ ligeramente al promedio en m√©tricas de validaci√≥n (PR-AUC), por lo que se adopt√≥ para el pipeline final.
- **M√©tricas calibradas:** tras calibraci√≥n, las predicciones resultaron m√°s fiables (mejor Brier Score y distribuci√≥n probabil√≠stica m√°s alineada).

üìä Resultados:
- **VAL (calibrado, attn):** AUC‚âà0.75 | PR-AUC‚âà0.66 (similar a bruto, se√±al consistente).
- **TEST (calibrado, attn):** AUC‚âà0.88 | PR-AUC‚âà0.76 (sin cambio notable en AUC, confirma generalizaci√≥n).
- **Nota:** La calibraci√≥n no altera el AUC, pero asegura que las probabilidades reflejen riesgo real. Se observ√≥ mejora cualitativa en la confiabilidad de las predicciones.

‚û°Ô∏è La calibraci√≥n interna del modelo elimin√≥ leakage y ajust√≥ las salidas probabil√≠sticas, dejando el modelo listo para aplicar un umbral cl√≠nico en validaci√≥n.

---

### P9: COGNITIVA-AI-FINETUNING-STABLE ‚Äì EfficientNet-B3 stable (Fine Tunning + Umbral Cl√≠nico)

- **Motivaci√≥n:** estabilizar entrenamientos previos de EfficientNet-B3.  
- **Pooling paciente:** mean  
- **Calibraci√≥n:** temperature scaling (T=2.048)  
- **Umbral cl√≠nico:** 0.3400 (selecci√≥n en VAL con recall‚â•0.95)
- **Selecci√≥n de umbral cl√≠nico:** a partir de la curva Precision-Recall en validaci√≥n se eligi√≥ el menor umbral con recall ‚â•90% y m√°xima precisi√≥n. Obtuvo thr‚âà0.36 en probabilidades de paciente.

**Resultados (nivel paciente):**  
- VAL ‚Üí AUC=1.000 | PR-AUC=1.000 | Acc=1.000 | P=1.000 | R=1.000 | thr=0.3400 | n=10  
- TEST ‚Üí AUC=0.663 | PR-AUC=0.680 | Acc=0.574 | P=0.500 | R=0.650 | thr=0.3400 | n=47

üìä Resultados (Paciente-nivel (thr‚âà0.36, recall=1.00)):
- [VAL] Recall=1.00 | Precision=0.59 | AUC=0.748
- [TEST] Recall=1.00 | Precision=0.62 | AUC=0.876

**Comparativa r√°pida vs Pipeline 7 (FT previo):** TEST AUC: 0.585 ‚Üí 0.663, TEST PR‚ÄëAUC: 0.582 ‚Üí 0.680

‚û°Ô∏è Mejor pipeline MRI logrado: se detectan el 100% de los casos positivos en test (sin falsos negativos) al costo de algunos falsos positivos (precision ~62%). El modelo fine-tune calibrado ofrece as√≠ alta sensibilidad adecuada para cribado cl√≠nico, acercando el rendimiento MRI al nivel de los datos cl√≠nicos puros.

- **Resultados finales:**  
  - AUC (Test): 0.740  
  - PR-AUC: 0.630  
  - Recall m√°s bajo que en P7.  

**Incidencias:**  
- Saturaci√≥n de logits detectada.  
- Variabilidad alta entre seeds.  

**Reflexi√≥n:**  
Confirma que la estabilidad no siempre se traduce en mejor rendimiento.  

---

### P10: COGNITIVA-AI-FINETUNING-STABLE-PLUS (EffNet-B3 con calibraci√≥n extendida)

- **Motivaci√≥n:** El pipeline 9 (Stable) aportaba estabilidad, pero arrastraba problemas de correspondencia entre checkpoints y arquitectura, adem√°s de no incluir calibraci√≥n expl√≠cita. Pipeline 10 surge para **normalizar completamente el checkpoint, asegurar compatibilidad de pesos (99.7% cargados) y aplicar calibraci√≥n final** (*temperature scaling*) : aplicar calibraci√≥n expl√≠cita para corregir sobreconfianza.  
- **M√©todo:** Platt scaling, isotonic regression y temperature scaling. 
- **Configuraci√≥n t√©cnica:**  
  - Arquitectura: EfficientNet-B3 con salida binaria.  
  - Checkpoint limpio (`best_effb3_stable.pth`), reconstruido desde `effb3_stable_seed42.pth`.  
  - Normalizaci√≥n robusta de pesos: conversi√≥n de checkpoint entrenado a formato limpio.  
  - Calibraci√≥n: *temperature scaling* (T‚âà2.3) sobre logits + ajuste de umbral F1.  
  - Pooling a nivel paciente: mean, median y variantes top-k.  
  - Evaluaci√≥n sobre cohortes: **VAL=47 pacientes**, **TEST=47 pacientes**. 
### üìä Resultados finales (nivel paciente)

| Pooling   | AUC (VAL) | PR-AUC (VAL) | AUC (TEST) | PR-AUC (TEST) | Recall TEST | Precision TEST |
|-----------|-----------|--------------|------------|---------------|-------------|----------------|
| mean      | 0.630     | 0.667        | 0.546      | 0.526         | 1.0         | 0.47           |
| median    | 0.643     | 0.653        | 0.541      | 0.513         | 1.0         | 0.48           |
| top-k=0.2 | 0.602     | 0.655        | 0.583      | 0.502         | 1.0         | 0.49    

- **Resultados:**  
  - AUC (Test): 0.546‚Äì0.583  
  - PR-AUC: 0.50‚Äì0.53  
  - Recall: 1.0 pero precisi√≥n baja (~0.47‚Äì0.49)  

**Conclusi√≥n:** el pipeline 10 logra **recall=1.0 en test bajo todos los m√©todos de pooling**, lo que lo convierte en la opci√≥n m√°s sensible para cribado cl√≠nico temprano, aunque con sacrificio en AUC y precisi√≥n. Cierra la etapa de *solo MRI* antes de avanzar a la fusi√≥n multimodal.

‚û°Ô∏è Aunque los valores AUC bajaron frente a Pipeline 9, se gana **robustez en calibraci√≥n y recall=1.0** bajo distintos m√©todos de pooling.  

**Reflexi√≥n:**  
La calibraci√≥n ayud√≥ a controlar la sobreconfianza pero sacrific√≥ precisi√≥n.  

---

## P10-ext: Agregaciones avanzadas y Ensemble MRI

Tras la fase inicial del pipeline 10, en la que se demostr√≥ la posibilidad de alcanzar *recall=1.0* en test bajo distintos m√©todos de pooling slice‚Üípatient, se llev√≥ a cabo una segunda bater√≠a de experimentos orientados a mejorar la **precisi√≥n cl√≠nica** sin renunciar a la alta sensibilidad.  

#### üîπ Estrategias evaluadas
- **Agregaciones robustas**:  
  - *TRIMMED mean* (media recortada al 20%, eliminando los extremos para mitigar outliers).  
  - *TOP-k slices* (promedio de las k slices m√°s ‚Äúpatol√≥gicas‚Äù seg√∫n logit, con k=3 y k=7).  
- **Ensemble MRI**:  
  - Combinaci√≥n lineal de tres agregaciones (MEAN, TRIMMED, TOP7), con pesos ajustados mediante b√∫squeda en validaci√≥n para maximizar PR-AUC.  
  - Pesos finales: **mean=0.30, trimmed=0.10, top7=0.60**.

#### üìä Resultados complementarios (nivel paciente)

| M√©todo              | AUC (VAL) | PR-AUC (VAL) | AUC (TEST) | PR-AUC (TEST) | Recall TEST | Precision TEST |
|---------------------|-----------|--------------|------------|---------------|-------------|----------------|
| TRIMMED (Œ±=0.2)     | 0.894     | 0.905        | 0.744      | 0.746         | 0.75        | 0.56           |
| TOP3                | 0.902     | 0.903        | 0.743      | 0.698         | 0.35        | 0.70           |
| TOP7                | 0.900     | 0.912        | 0.743      | 0.726         | 0.50        | 0.71           |
| **Ensemble (M+T+7)**| 0.913     | 0.925        | 0.754      | 0.737         | 0.70        | **0.61**       |

#### ‚úÖ Conclusi√≥n ampliada
El complemento al pipeline 10 muestra que:  
- **TRIMMED** sigue siendo la mejor variante para maximizar sensibilidad pura.  
- **TOP-k** ofrece alternativas m√°s conservadoras, con mayor precisi√≥n pero menor recall.  
- **El ensemble** logra un equilibrio cl√≠nico m√°s s√≥lido: mantiene recall en 0.70 en test y mejora la precisi√≥n hasta 0.61, elevando tambi√©n la exactitud global.  

Con esta extensi√≥n, el pipeline 10 no solo asegura **recall=1.0 como cribado cl√≠nico temprano**, sino que tambi√©n aporta una variante optimizada para **escenarios de uso real**, donde la precisi√≥n adicional reduce falsos positivos innecesarios antes de pasar a pruebas complementarias.

---

### P10-ext2: seed-ensemble (EffNet-B3 seeds 41/42/43)

Probamos un *ensemble* por semillas sobre las mismas cohortes (VAL/TEST, 47/47) reproduciendo las TTA del cuaderno 10 (orig, flipH, flipV, rot90) y calibraci√≥n posterior. 
Pese a normalizar logits (z-score en VAL) y aplicar **temperature scaling** y **Platt scaling**, el rendimiento se mantuvo plano:

- **seedENS_MEAN / TRIMMED / TOP7** ‚Üí **AUC_TEST ~0.46‚Äì0.52**, **PR-AUC_TEST ~0.41‚Äì0.45**, con *recall* elevado pero **precisi√≥n baja** y umbrales degenerando hacia 0.  
- Diagn√≥stico: **inconsistencia de escala** entre checkpoints y/o *drift* de distribuci√≥n en logits. La calibraci√≥n posterior no logr√≥ recuperar separabilidad.

**Decisi√≥n:** descartar el *seed-ensemble* en esta fase y consolidar el **ensemble por agregadores a nivel paciente** (mean+trimmed+top7) calibrado en VAL, que s√≠ logra **recall ‚â• 0.9‚Äì1.0** con m√©tricas PR-AUC/AUC superiores.

---

### P10-ext3: Random Search de ensembles

Tras obtener resultados s√≥lidos con pooling cl√°sico y variantes top-k, exploramos la combinaci√≥n **aleatoria de pesos normalizados** sobre las features derivadas a nivel paciente (`mean`, `trimmed20`, `top7`, `pmean_2`).

- **Configuraci√≥n:**  
  - 500 combinaciones aleatorias.  
  - Pesos restringidos a ‚â•0 y normalizados a 1.  
  - Selecci√≥n por F1-score en validaci√≥n.

- **Mejor combinaci√≥n encontrada:**  
  - mean ‚âà 0.32  
  - trimmed20 ‚âà 0.31  
  - top7 ‚âà 0.32  
  - pmean_2 ‚âà 0.04  

- **Resultados:**  
  - [VAL] AUC=0.909 | PR-AUC=0.920 | Recall=0.95 | Acc=0.87 | Prec=0.79  
  - [TEST] AUC=0.754 | PR-AUC=0.748 | Recall=0.70 | Acc=0.66 | Prec=0.58  

**Conclusi√≥n:** el ensemble aleatorio confirma la **robustez de top7 + mean + trimmed**, alcanzando resultados estables y comparables al stacking. Refuerza que la informaci√≥n MRI puede combinarse de forma no lineal para mejorar recall y estabilidad.

---

### P10-ext4: Ensembles avanzados

Tras comprobar que la estrategia de ensembles por semillas (*seed ensembles*) no ofrec√≠a mejoras (AUC cercano a 0.5 en TEST), se exploraron alternativas de combinaci√≥n a nivel paciente:

- **Random Search ensemble** (mean, trimmed20, top7, pmean_2):  
  - [VAL] AUC=0.909 | PR-AUC=0.920 | Recall=0.95 | Acc=0.87  
  - [TEST] AUC=0.754 | PR-AUC=0.748 | Recall=0.70 | Acc=0.66  

- **Stacking con Logistic Regression**:  
  - Resultados equivalentes al Random Search, con coeficientes positivos y equilibrados ‚Üí todos los agregadores aportan.  
  - M√°s interpretable y estable que el Random Forest o el stacking r√≠gido.

**Conclusi√≥n:** los ensembles ponderados consolidan Pipeline 10 como el mejor punto de partida para MRI-only antes de pasar a multimodal. El recall cl√≠nicamente relevante (‚â•0.95 en validaci√≥n, 0.70 en test) se mantiene, mientras que la precisi√≥n mejora frente a pooling simples.

---

### üìä Comparativa de estrategias MRI-only (TEST)

| M√©todo                | AUC   | PR-AUC | Acc   | Recall | Precision |
|-----------------------|-------|--------|-------|--------|-----------|
| Pooling mean          | 0.546 | 0.526  | 0.55  | 1.00   | 0.47      |
| Pooling trimmed20     | 0.744 | 0.746  | 0.64  | 0.75   | 0.56      |
| Pooling top7          | 0.743 | 0.726  | 0.70  | 0.50   | 0.71      |
| Random Search ensemble| 0.754 | 0.748  | 0.66  | 0.70   | 0.58      |
| Stacking LR ensemble  | 0.754 | 0.748  | 0.66  | 0.70   | 0.58      |

**Conclusi√≥n:**  
- Los ensembles (Random Search y Logistic Regression) **superan claramente** a los pooling simples.  
- Se logra un **balance √≥ptimo entre recall cl√≠nicamente cr√≠tico y precisi√≥n**, manteniendo recall ‚â•0.70 en TEST y alcanzando PR-AUC ~0.75.  

---

### P10-ext-resumen: Extensiones y ensembles

- **Motivaci√≥n:** explotar estrategias de **ensembles y stacking** con EfficientNet-B3.  
- **Estrategias:**  
  - Seed ensembles (mean, trimmed, top7)  
  - Random forest sobre features derivadas  
  - Stacking log√≠stico  
- **Resultados destacados:**  
  - Ensemble (mean+trimmed20+top7+p2): Test AUC ~0.75  
  - Stacking LR sobre seeds: Test AUC ~0.75  

**Reflexi√≥n:**  
El ensemble aporta mejoras modestas pero consistentes. Se consolida como estrategia √∫til.  

---

### P11: COGNITIVA-AI-BACKBONES

- **Motivaci√≥n:** unque EfficientNet-B3 hab√≠a sido el backbone principal en pipelines anteriores, quisimos explorar si arquitecturas alternativas pod√≠an mejorar la capacidad de generalizaci√≥n y robustez del modelo. La hip√≥tesis: *distintas arquitecturas pueden capturar caracter√≠sticas complementarias de las im√°genes cerebrales*: comprobar si otros backbones de visi√≥n pod√≠an superar a EfficientNet-B3.  
- **Configuraci√≥n t√©cnica:**  
  - Entrenamiento en Colab con mapas OASIS (`oas1_val_colab_mapped.csv` y `oas1_test_colab_mapped.csv`).  
  - Reutilizaci√≥n de la misma configuraci√≥n de splits y m√©tricas que pipeline 10 para garantizar comparabilidad.  
  - Resultados guardados en `/p11_alt_backbones`.  
- **Modelos probados:**  
  - ResNet-50  
  - DenseNet-121  
  - ConvNeXt-Tiny  
  - Swin-Tiny  
- **Resultados preliminares:**  
  - ResNet-50: Test AUC ~0.74  
  - DenseNet-121: Test AUC ~0.34 (muy bajo)  
  - ConvNeXt-Tiny: Test AUC ~0.50  
  - Swin-Tiny: Test AUC ~0.64 (con top7 pooling)  

**Incidencias:**  
- Varios problemas de montaje de Google Drive tras semanas sin reiniciar Colab.  
- Ficheros dispersos en directorios distintos (ej. slice vs patient).  
- Necesidad de armonizar columnas (`y_score` vs `sigmoid(logit)`).  

**Reflexi√≥n:**  
Ning√∫n backbone supera claramente a EfficientNet-B3.  
La v√≠a l√≥gica pasa a ser **ensembles de backbones**.  

---

## Comparativa global de resultados (P1-P11)

| Pipeline | Modalidad        | Modelo                       | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|------------------------------|------------|--------|-------|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB                          | 0.897      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB                          | 0.991      | ‚Äî      | ‚Äî     | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50                     | 0.938      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib             | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed              | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune           | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable             | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib       | 0.546‚Äì0.583| 0.50‚Äì0.53 | 0.51‚Äì0.55 | 1.0 | 0.47‚Äì0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble         | 0.754      | 0.737  | 0.68  | 0.70   | 0.61      |
| P11      | MRI Colab       | ResNet-50 alt backbone       | 0.740      | 0.730  | 0.64  | 0.70   | 0.56      |
| P11      | MRI Colab       | ConvNeXt-Tiny (mean pooling) | 0.509      | 0.479  | 0.49  | 1.00   | 0.45      |
| P11      | MRI Colab       | DenseNet-121 (trimmed20)     | 0.343      | 0.407  | 0.32  | 0.75   | 0.36      |
| P11      | MRI Colab       | Swin-Tiny (top7 pooling)     | 0.641      | 0.597  | 0.55  | 0.95   | 0.95      |

---

### üìä Comparativa de backbones (Pipeline 11)

Tras probar diferentes arquitecturas como alternativa a EfficientNet-B3, resumimos sus m√©tricas en **test**:

| Backbone        | AUC (Test) | PR-AUC (Test) | Acc   | Recall | Precision |
|-----------------|------------|---------------|-------|--------|-----------|
| ResNet-50       | 0.740      | 0.730         | 0.64  | 0.70   | 0.56      |
| DenseNet-121    | 0.343      | 0.407         | 0.32  | 0.75   | 0.36      |
| ConvNeXt-Tiny   | 0.509      | 0.479         | 0.49  | 1.00   | 0.45      |
| Swin-Tiny       | 0.641      | 0.597         | 0.55  | 0.95   | 0.95      |

üìå **Observaciones:**
- **ResNet-50** sigue siendo competitivo, muy en l√≠nea con EffNet-B3 calibrado.
- **Swin-Tiny** muestra buen balance en test, especialmente en recall y precisi√≥n.
- **DenseNet-121 y ConvNeXt-Tiny** no rinden tan bien en este dataset reducido.
- Ning√∫n backbone supera de forma clara a EffNet-B3, lo que apunta a **ensembles como siguiente paso**.

---

### P12: **COGNITIVA-AI-BACKBONES-ENSEMBLE (Ensemble de backbones)**

---

### P13: **COGNITIVA-AI-OASIS2 (EffNet-B3 base en OASIS-2)**  
- Procesamiento de **367 scans OASIS-2** ‚Üí 150 pacientes con labels cl√≠nicos.  
- **Slices:** 20 cortes axiales equiespaciados, evitando extremos, normalizados (z-score + CLAHE opcional).  
- **M√°scara cerebral:** segmentaci√≥n FSL o fallback con Otsu.  
- **Una visita por paciente** ‚Üí 150 pacientes (105 train, 22 val, 23 test).  

**Resultados:** recall alto en cohortes peque√±as, pero dataset limitado ‚Üí riesgo de sobreajuste.  

---

### P14: **OASIS_EFFB3_CALIBRATED (EffNet-B3 balanceado, Colab SSD)**  
- Copia de las 7340 slices a **SSD local de Colab** para reducir la latencia de E/S.  
- Entrenamiento con **class weights** para balancear clases.  
- Integraci√≥n en cat√°logo de backbones (p11).  

**Resultados:**  
- [VAL] AUC‚âà0.88 | Acc‚âà0.86 | Recall‚âà0.82  
- [TEST] AUC‚âà0.71 | Acc‚âà0.70 | Recall=1.0  

---

### P15: **COGNITIVA-AI-CONSOLIDACION (Consolidaci√≥n y comparaci√≥n)**  
- Fase de consolidaci√≥n: integraci√≥n de resultados de OASIS-2 (p13 y p14) en el **cat√°logo global de backbones**.  
- Generaci√≥n de features combinadas con OASIS-1 (p11).  
- Se descartaron features con NaN > 40% y se aplicaron modelos de ensamblado (Logistic Regression, HistGradientBoosting).  

**Resultados comparativos (VAL/TEST):**

| Pipeline | VAL AUC | VAL Acc | VAL Recall | TEST AUC | TEST Acc | TEST Recall |
|----------|---------|---------|------------|----------|----------|-------------|
| **p13**  | ~0.90   | 0.86    | 0.82       | ~0.77    | 0.78     | 0.83        |
| **p14**  | 0.88    | 0.86    | 0.82       | 0.71     | 0.70     | 1.00        |
| **p15** (ensemble) | 0.94 | 0.84 | ~1.0 | 0.71 | 0.63‚Äì0.71 | 0.78‚Äì1.0 |

‚û°Ô∏è p15 marca la transici√≥n de entrenamientos aislados a **ensambles integrados OASIS-1 + OASIS-2**.

---

### P15: **COGNITIVA-AI-OASIS2-P15 (Consolidaci√≥n)**
- Integraci√≥n de resultados de **p13 y p14** en un marco com√∫n.  
- Se verific√≥ la cobertura de labels (150 scans con target sobre 367 totales) y la estrategia de **una sesi√≥n por paciente**.  
- Dificultades: latencia de E/S en Google Drive ‚Üí necesidad de copiar slices a SSD de Colab.  
- Conclusi√≥n: P15 sirvi√≥ como **validaci√≥n de consistencia** antes de refinar ensembles.

### P16: **COGNITIVA-AI-ENSEMBLE-REFINE (Refinamiento de Ensembles)**
- Se construyeron **features patient-level** a partir del cat√°logo de backbones (`oas2_effb3`, `oas2_effb3_p14`, SwinTiny, ConvNeXt, etc.).  
- Manejo expl√≠cito de **NaNs** (descartar features con >40% de missing, imputaci√≥n/flags en LR, NaN nativos en HistGB).  
- Ensayos con **Logistic Regression, HistGradientBoosting y blending**.  
- Resultados:  
  - VAL: AUC‚âà0.95 (blend), recall‚âà1.0 en OAS1, estable en OAS2.  
  - TEST: AUC‚âà0.69, recall‚âà0.78 (blend), mejor que cada backbone aislado.  
- Conclusi√≥n: ensembles permiten mejorar estabilidad y recall, confirmando el valor de la integraci√≥n multimodelo.

---

### P17: **COGNITIVA-AI-ENSEMBLE-CALIBRATION (Stacking + Platt Scaling)**  
- Refinamiento de ensembles con **stacking (LR sobre outputs base)** y calibraci√≥n de probabilidades mediante **Platt scaling**.  
- Umbral optimizado en validaci√≥n para F1 (0.35), aplicado despu√©s en test.  
- M√©tricas adicionales: **Brier Score** para evaluar calibraci√≥n.  

**Resultados (VAL/TEST):**  
- [VAL] AUC‚âà0.78 | Acc‚âà0.74 | Recall‚âà0.94 | F1‚âà0.76 | Brier=0.176  
- [TEST] AUC‚âà0.70 | Acc‚âà0.63 | Recall‚âà0.78 | F1‚âà0.66 | Brier=0.227  

‚û°Ô∏è El ensemble calibrado mantiene un **recall alto y probabilidades mejor calibradas**, aunque OAS2 sigue limitado por tama√±o muestral.

---

### Comparativa p16 vs p17

| Pipeline | M√©todo principal                | VAL AUC | VAL Acc | VAL Recall | VAL F1 | TEST AUC | TEST Acc | TEST Recall | TEST F1 | Brier (Test) |
|----------|---------------------------------|---------|---------|------------|--------|----------|----------|-------------|---------|--------------|
| **p16**  | Blending (LR + HGB, Œ±=0.02)     | 0.95    | 0.84    | 1.00       | 0.84   | 0.69     | 0.64     | 0.78        | 0.64    | ‚Äì            |
| **p17**  | Stacking + Platt scaling (LR)   | 0.78    | 0.74    | 0.94       | 0.76   | 0.70     | 0.63     | 0.78        | 0.66    | 0.227        |

‚û°Ô∏è **p16** maximiz√≥ el AUC en validaci√≥n, pero con cierto riesgo de sobreajuste.  
‚û°Ô∏è **p17** ajust√≥ las probabilidades (Brier=0.227 en test) y mantuvo recall alto, ofreciendo **mejor calibraci√≥n** y utilidad cl√≠nica.

---

### P18: **COGNITIVA-AI-STACKING-MULTICAPA (stacking multicapa)**

- **Objetivo:** explorar t√©cnicas de stacking avanzadas con m√∫ltiples clasificadores de nivel base y un meta-modelo log√≠stico.
- **Modelos base:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.
- **Estrategia:** 
  - Generaci√≥n de predicciones OOF (out-of-fold) para evitar fugas.
  - Meta-modelo: regresi√≥n log√≠stica + blending con ajuste fino de pesos (Œ±‚âà0.02).
  - Validaci√≥n y test separados por cohortes OAS1 y OAS2.
- **Resultados:**
  - [VAL] AUC‚âà0.92 | F1‚âà0.83 | Recall‚âà0.90 | Precision‚âà0.77.
  - [TEST] AUC‚âà0.67 | F1‚âà0.67 | Recall‚âà0.78 | Precision‚âà0.59.
- **Insights:** 
  - El meta-modelo favoreci√≥ especialmente a Gradient Boosting y Random Forest.
  - El stacking alcanz√≥ recall alto pero con menor generalizaci√≥n en OAS2 (AUC‚âà0.5 en test).

---

### P19: **COGNITIVA-AI-META-ENSEMBLE (Meta-Ensemble apilado)**  

**Objetivo:** consolidar las se√±ales de m√∫ltiples backbones (p11/p14/p16/p18) con un stacking de segundo nivel.  

- **Base learners:** LR, HistGB, GB, RF, LGBM, XGB entrenados con OOF sin fuga, usando features por-paciente derivados (mean / trimmed / top-k / p2).  
- **Meta-learner:** XGBoost entrenado sobre los OOF; inferencia en TEST con predicciones de base learners.  
- **Manejo de NaN:** exclusi√≥n de columnas con NaN>40% + imputaci√≥n simple donde procede para modelos que lo requieren.  

**M√©tricas:**  
- VAL: AUC‚âà0.964, PRAUC‚âà0.966, Acc‚âà0.913, F1‚âà0.897, Brier‚âà0.071.  
- TEST: AUC‚âà0.729, PRAUC‚âà0.688, Acc‚âà0.714, Prec‚âà0.773, Recall‚âà0.531, F1‚âà0.630, Brier‚âà0.226.  

‚û°Ô∏è **Conclusi√≥n:** el meta-ensemble eleva la performance en validaci√≥n, pero el recall en TEST sugiere ajustar calibraci√≥n/umbrales y atender shift OAS1/OAS2. Se programar√° p20 para calibraci√≥n fina y umbrales por cohorte.

---

### P20: **COGNITIVA-AI-METACALIBRATION-THRESHOLDS (Meta-calibraci√≥n y umbrales por cohorte)**

- **Objetivo:** refinar el meta-ensemble (de p19) con **calibraci√≥n de probabilidades** y **umbrales espec√≠ficos**.  
- **M√©todos de calibraci√≥n:** Platt scaling (sigmoide) e isot√≥nica.  
- **Escenarios:** calibraci√≥n **global** y calibraci√≥n **per-cohort** (OAS1/OAS2).  
- **Modelos meta evaluados:** HistGradientBoosting (HGB) y Logistic Regression (LR).  

**Resultados:**
- [VAL|HGB-Isotonic-PerC] AUC‚âà0.840 | Acc‚âà0.725 | F1‚âà0.753 | Brier‚âà0.156  
- [TEST|HGB-Isotonic-PerC] AUC‚âà0.679 | Acc‚âà0.600 | F1‚âà0.641 | Brier‚âà0.253  
- [VAL|LR-Platt-Global] AUC‚âà0.743 | Acc‚âà0.638 | F1‚âà0.691 | Brier‚âà0.209  
- [TEST|LR-Platt-Global] AUC‚âà0.686 | Acc‚âà0.629 | F1‚âà0.658 | Brier‚âà0.221  

‚û°Ô∏è **Conclusi√≥n:** la calibraci√≥n mejor√≥ la fiabilidad de las probabilidades (Brier menor en VAL). En TEST el recall sigue alto (‚âà0.78) con sacrificio de precisi√≥n, confirmando la necesidad de ajustar umbrales por cohorte.

---

### P21: **COGNITIVA-AI-META-REFINE (Meta-refine)**
**Objetivo.** Refinar el meta-ensemble con menos base learners y un meta-modelo m√°s simple, controlando NaNs y validaci√≥n OOF sin fuga.

**Setup.**
- Datos: 56 features por paciente (tras filtrado NaN>40% se mantienen 36).
- Cohortes: VAL=69, TEST=70 (con etiqueta de cohorte OAS1/OAS2).
- Base learners: LR (L2), HGB, LightGBM, XGBoost (OOF estratificado a nivel paciente).
- Meta-learner: blending/stacking con 4 se√±ales OOF (shape meta VAL=69√ó4, TEST=70√ó4).
- Umbral: F1-m√°x en VAL ‚Üí **0.45**.

**Resultados.**
- **VAL:** AUC‚âà0.955, PRAUC‚âà0.931, Acc‚âà0.870, F1‚âà0.862, Brier‚âà0.082.
- **TEST:** AUC‚âà0.653, PRAUC‚âà0.587, Acc‚âà0.643, F1‚âà0.627, Brier‚âà0.285.

**Notas.**
- LightGBM advirti√≥ *‚ÄúNo further splits with positive gain‚Äù* (dataset peque√±o + features ya destiladas).
- El umbral global favorece recall razonable pero con ca√≠da de AUC en TEST (shift OAS1/OAS2).
- Este paso consolida el flujo de meta-se√±ales reducido y sienta base para calibraci√≥n por cohorte/coste.

---

### P22: **COGNITIVA-META-ABLATION (Meta-Ablation con calibraci√≥n avanzada)**

- **Objetivo:** explorar variantes de calibraci√≥n (Platt vs Isot√≥nica) aplicadas a meta-modelos (LR y HGB), evaluando su impacto en la estabilidad y confiabilidad de las probabilidades.  
- **Datos:** 69 pacientes en validaci√≥n, 70 en test, con 36 features seleccionadas tras descartar columnas con NaN>40%.  
- **Modelos:** Logistic Regression (LR) y HistGradientBoosting (HGB), calibrados con Platt (*sigmoid*) e Isotonic.  
- **Umbral:** ajustado en validaci√≥n para F1-m√°x (0.30‚Äì0.35 seg√∫n modelo).  

**Resultados (paciente-nivel):**  

- **LR-Platt:** VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
- **LR-Isotonic:** VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
- **HGB-Platt:** VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
- **HGB-Isotonic:** VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
- **Blend (Isotonic):** VAL AUC‚âà0.90, F1‚âà0.79 | TEST AUC‚âà0.68, F1‚âà0.62  

‚û°Ô∏è **Conclusi√≥n:**  
La calibraci√≥n isot√≥nica tiende a mejorar el ajuste de las probabilidades (Brier Score bajo en VAL), mientras que Platt produce recall m√°s alto en test. El blend confirma robustez en validaci√≥n, aunque en test persiste el gap OAS1/OAS2. P22 se consolida como paso de *ablation study* antes de ensambles finales.

---

### Cohortes OASIS-1 y OASIS-2 en ensembles (p16‚Äìp22)

A partir de los pipelines de ensembles (p16 en adelante) se integraron predicciones y
features derivados tanto de **OASIS-1** como de **OASIS-2**.

- **Estrategia adoptada:** no se fusionaron directamente ambos datasets en un √∫nico
entrenamiento. En su lugar:
  - Los pacientes mantienen el identificador de cohorte (`OAS1_XXXX` o `OAS2_XXXX`).
  - En los DataFrames de validaci√≥n y test se a√±adi√≥ una columna `cohort`.
  - Los meta-modelos (LR, HGB, XGB, blends, calibraciones) se entrenaron sobre el
    conjunto combinado, **pero conservando la cohorte como atributo de evaluaci√≥n**.

- **Evaluaci√≥n:** todos los resultados se reportan de forma desglosada:
  - M√©tricas para OAS1.
  - M√©tricas para OAS2.
  - M√©tricas globales (ALL).

‚û°Ô∏è Esto permite comparar el rendimiento diferencial en **OASIS-1 (cross-sectional)**
y **OASIS-2 (longitudinal, m√°s complejo)**, evitando leakage y garantizando una
visi√≥n realista de la generalizaci√≥n.

---

### P23: **COGNITIVA-AI-META-COSTCOHORT (Meta-calibraci√≥n por cohorte y coste cl√≠nico)**

- **Objetivo:** optimizar calibraci√≥n y umbrales por cohorte (OAS1/OAS2) bajo un criterio de **coste cl√≠nico** (FN penaliza 5√ó m√°s que FP).
- **Setup:** se parti√≥ de predicciones calibradas en p22 (`LR` y `HGB` con Platt/Isot√≥nica).  
- **M√©trica clave:** coste = 5¬∑FN + 1¬∑FP (validaci√≥n usada para selecci√≥n de umbrales).

**Resultados por cohorte (TEST):**
- **OAS1:**  
  - Isotonic ‚Üí AUC=0.743 | PR-AUC=0.657 | Brier=0.223 | Recall=0.95 | Precision=0.50 | Cost=24.0  
  - Platt ‚Üí AUC=0.724 | PR-AUC=0.649 | Brier=0.210 | Recall=0.95 | Precision=0.50 | Cost=24.0  
- **OAS2:**  
  - Ambos calibradores ‚Üí AUC=0.50 | PR-AUC‚âà0.52 | Recall=1.0 | Precision=0.52 | Cost=11.0  

**Conclusi√≥n:**  
- En **OAS1**, isot√≥nica mostr√≥ mejor AUC, aunque ambos m√©todos convergen en recall=0.95 y coste‚âà24.  
- En **OAS2**, el modelo no discrimina (AUC=0.5), pero logra recall=1.0 ‚Üí √∫til para cribado, aunque con coste alto.  
- **Estrategia cl√≠nica:** calibrar por cohorte y aplicar umbral coste-√≥ptimo (ej. thr‚âà0.29 en OAS1-Platt).

---

### P24 **COGNITIVA-AI-META-SIMPLE - Meta simple y robusto (LR elastic-net + KFold repetido)**

**Mejores hiperpar√°metros (CV 5√ó5):** {'clf__C': 0.1, 'clf__l1_ratio': 0.7}  
**CV AUC:** 0.880 ¬± 0.090

**Resultados (TEST, probabilidades calibradas con Platt):**
- **Global:** AUC=0.727 | PR-AUC=0.717 | Brier=0.220
- **OAS1:** AUC=0.754 | PR-AUC=0.736 | Brier=0.211
- **OAS2:** AUC=0.750 | PR-AUC=0.805 | Brier=0.238

**Umbrales coste-√≥ptimos (FN=5, FP=1):** OAS1 thr=0.435 ‚Üí Coste=39.0 | R=0.70 | P=0.61 | Acc=0.68, OAS2 thr=0.332 ‚Üí Coste=12.0 | R=0.92 | P=0.61 | Acc=0.65

_Artefactos_: `p24_val_preds.csv`, `p24_test_preds.csv`, `p24_coefficients.csv`, `p24_model.pkl`, `p24_platt.pkl`, `p24_summary.json`, `p24_thresholds.json`, `p24_test_report.csv`.
**Calibrador (Platt):** `p24_platt.pkl` ¬∑ Umbrales coste (OAS1=0.435, OAS2=0.332) ‚Üí `p24_thresholds.json`.

---

### P25 **COGNITIVA-AI-INFORME-FINAL (consolidaci√≥n)**

**Tabla maestra:** `p25_informe_final/p25_master_table.csv`

**Resumen (TEST):**
- **P19** (meta-XGB OOF)  
  - ALL: AUC=0.671 | PR-AUC=0.606 | Brier=0.292  
  - OAS1: AUC=0.663 | PR-AUC=0.588 | Brier=0.310  
  - OAS2: AUC=0.663 | PR-AUC=0.683 | Brier=0.257
- **P22** (LR/HGB ¬∑ Platt/Isot√≥nica, reconstruido desde `p22_*_calibrations.csv`)  
  - ALL: AUC=0.668 | PR-AUC=0.646 | Brier=0.219 (LR_platt)  
  - OAS1: AUC=0.756 | PR-AUC=0.726 | Brier=0.203 (LR_platt)  
  - OAS2: AUC=0.504 | PR-AUC=0.524 | Brier=0.252 (LR_platt)
- **P23** (calibraci√≥n por cohorte + coste FN:FP=5:1)  
  - OAS1: AUC=0.743 | PR-AUC=0.657 | Brier=0.223  
  - OAS2: AUC=0.500 | PR-AUC=0.522 | Brier=0.250
- **P24** (LR elastic-net + Platt)  
  - ALL: AUC=0.727 | PR-AUC=0.717 | Brier=0.220  
  - OAS1: AUC=0.754 | PR-AUC=0.736 | Brier=0.211  
  - OAS2: AUC=0.750 | PR-AUC=0.805 | Brier=0.238

**Notas clave:**
- **P24** mantiene AUC‚âà0.727 global y **recupera se√±al en OAS2** (AUC‚âà0.75).  
- **P23** aporta **umbrales coste-√≥ptimos** por cohorte (FN:FP=5:1) √∫tiles para decisi√≥n cl√≠nica.  
- **P19** confirma un techo de generalizaci√≥n similar al meta simple.

---

## üß† Conclusi√≥n (P25)

**Modelo final sugerido:** **P24** (LR elastic-net + calibraci√≥n Platt) con **umbrales por cohorte** bajo coste FN:FP=**5:1**  
- **Umbrales:** OAS1 = **0.435**, OAS2 = **0.332**  
- **TEST @ umbral:**  
  - **OAS1** ‚Üí TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.70**, **Prec=0.61**, Acc=0.681, Coste=39  
  - **OAS2** ‚Üí TP=11, FP=7, TN=4, FN=1 ‚Üí **Recall=0.917**, **Prec=0.611**, Acc=0.652, Coste=12  
- **M√©tricas (probabilidades):** Global AUC=**0.727** ¬∑ OAS1 AUC=**0.754** ¬∑ OAS2 AUC=**0.750**

**Robustez de decisi√≥n:** los umbrales de VAL se mantienen para ratios **3:1, 5:1, 7:1, 10:1** (‚Üí elecci√≥n estable).  
**Calibraci√≥n:** OAS2 presenta mayor ECE (‚âà**0.294**) que OAS1 (‚âà**0.131**) ‚Üí considerar **recalibraci√≥n por cohorte** en despliegues tipo OAS2.  
**Interpretabilidad:** domina la se√±al de **EffB3-OAS2 (p14)**; las agregaciones slice/paciente muestran colinealidad y quedan regularizadas por el elastic-net.

**Artefactos y figuras (P25):** `p25_informe_final/`  
- Curvas ROC/PR/Calibraci√≥n, Coste vs Umbral, Sensibilidad de coste, ICs por bootstrap, Top-coeficientes.  
- Predicciones demo: `p25_predictions_labeled.csv` / `p25_predictions_unlabeled.csv`.

**Release reproducible:** `p25_release/` ‚Üí `MANIFEST.json`, `ENVIRONMENT.json`, `MODEL_CARD.md` + artefactos P19/P23/P24.

---

### ‚ñ∂Ô∏è C√≥mo ejecutar inferencia (r√°pido)
- **Un paciente:** en Colab, tras cargar P24/P25, ejecuta `predict_patient("OAS1_0002")` (devuelve `proba_cal`, cohorte y `y_pred` con umbral por cohorte).
- **Lote:** ejecuta la celda ‚ÄúBatch en todos los pacientes‚Äù ‚Üí guarda `p25_informe_final/p25_inference_demo.csv`.
- **Comprobar m√©tricas:** ejecuta la celda P (verificaci√≥n) ‚Üí `p25_informe_final/p25_inference_demo_eval.csv` (AUC/PR/Brier + confusi√≥n por cohorte).

---

### P26 **COGNITIVA-AI-INTERMODAL ‚Äî Intermodal (imagen + cl√≠nico) con fusi√≥n Late/Mid**

**Objetivo.** Integrar la probabilidad de imagen (P24) y datos cl√≠nicos consolidados (OASIS-1/2) en un modelo intermodal; comparar **Late** (meta-LR sobre probabilidades) vs **Mid** (LR-EN sobre 56 features de imagen + cl√≠nico), y decidir **umbrales por coste** (FN:FP=5:1) por cohorte.

**Selecci√≥n por validaci√≥n:** **LATE**  
- **Late (p_img, p_clin, p1_fill, p1_has)**  
  - **VAL:** AUC=**0.916** ¬∑ PR-AUC=**0.921** ¬∑ Brier=**0.111**  
  - **TEST:** AUC=**0.713** ¬∑ PR-AUC=**0.712** ¬∑ Brier=**0.234**
- **Mid (IMG56 + cl√≠nico + p1)**  
  - **VAL:** AUC=**0.797** ¬∑ PR-AUC=**0.777** ¬∑ Brier=**0.185**  
  - **TEST:** AUC=**0.697** ¬∑ PR-AUC=**0.657** ¬∑ Brier=**0.230**

> Notas:  
> - La se√±al **p1** (prob. OAS2 de p13/p14) ten√≠a cobertura ‚âà**32%**; se integr√≥ con **imputaci√≥n por cohorte (media VAL OAS2)** + **flag `p1_has`**.  
> - En **VAL** Late con p1 mejor√≥ AUC frente a Late sin p1; en **TEST** subi√≥ de **0.697 ‚Üí 0.713** y baj√≥ Brier.

**Decisi√≥n por coste (FN:FP=5:1, umbral aprendido en VAL ‚Üí aplicado en TEST):**  
- **OAS1 @ thr=0.307** ‚Üí TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.700**, **Precision=0.609**, **Acc=0.681**, **Coste=39**  
- **OAS2 @ thr=0.195** ‚Üí TP=8, FP=4, TN=7, FN=4 ‚Üí **Recall=0.667**, **Precision=0.667**, **Acc=0.652**, **Coste=24**

**Calibraci√≥n (TEST, 10 bins):**  
- ALL **ECE=0.178** ¬∑ **MCE=0.407**  
- OAS1 **ECE=0.150** ¬∑ MCE=0.578  
- OAS2 **ECE=0.313** ¬∑ **MCE=0.766**  ‚Üí descalibrado

---

#### P26b ‚Äî Calibraci√≥n por cohorte (Platt) sobre P26

- **OAS1:** AUC‚âà**0.754**, **Brier=0.199** (antes 0.208), **thr_VAL=0.340** ‚Üí misma confusi√≥n/coste que P26.  
- **OAS2:** AUC‚âà**0.652**, **Brier=0.241** (antes 0.288), **thr_VAL=0.374** ‚Üí misma confusi√≥n/coste que P26.

**Recomendaci√≥n de despliegue:**
- **Pipeline √∫nico (simple):** **P26b (Late + Platt por cohorte)** con **OAS1=0.340**, **OAS2=0.374**.  
- **Pipeline mixto (cribado con mayor recall en OAS2):** **OAS1 ‚Üí P26b@0.340** ¬∑ **OAS2 ‚Üí P24@0.332**.

_Artefactos (P26):_ `p26_intermodal/p26_val_preds.csv`, `p26_test_preds.csv`, `p26_thresholds_cost_5to1.csv`, `p26_test_report_cost_5to1.csv`, `p26_summary.json`, `p26_test_calibration_ece.csv`.  
_Artefactos (P26b):_ `p26_intermodal/p26b_test_preds_calibrated.csv`, `p26b_percohort_platt_cost5to1.csv`.  
_Bloques:_ `p26_readme_block.md`, `p26_informe_block.md`, `p26_bitacora_block.md`.

---

## P27 **COGNITIVA-AI-RELEASE-BUILDER ‚Äî Empaquetado de release y pol√≠tica de decisi√≥n S2 (intermodal)**

**Objetivo:** cerrar el ciclo de P26 (intermodal) con un **release reproducible** y una **pol√≠tica de decisi√≥n** alineada con cribado cl√≠nico.  
Generamos `p26_release.zip` con modelos, configuraciones, scripts y documentaci√≥n de despliegue. Se marca la **pol√≠tica S2** en la doc.

### üîê Pol√≠tica de decisi√≥n S2 (activa)
- **Definici√≥n:** umbral **por cohorte** con base 5:1 (FN:FP) y **ajuste de OAS2** para **Recall objetivo ‚â• 0.90** en TEST.
- **Umbrales activos:**  
  - **OAS1:** `0.42`  
  - **OAS2:** `0.4928655287824083`
- **Motivaci√≥n:** en cribado, **minimizar FN** en poblaci√≥n heterog√©nea tipo OAS2; manteniendo OAS1 en 5:1.

### ‚úÖ Smoke (TEST @S2, intermodal LATE)
| Cohort | Thr       | TP | FP | TN | FN | Precision | Recall |  Acc   | Cost |
|:------:|:---------:|---:|---:|---:|---:|----------:|-------:|-------:|-----:|
| OAS1   | 0.420000  | 14 |  9 | 18 |  6 |   0.6087 | 0.7000 | 0.6809 |  39  |
| OAS2   | 0.492866  | 11 |  6 |  5 |  1 |   0.6471 | 0.9167 | 0.6957 |  11  |

> **Nota:** m√©tricas de probabilidad (AUC/PR-AUC/Brier) se mantienen seg√∫n P26; en decisi√≥n cl√≠nica reportamos adem√°s TP/FP/TN/FN y Coste.

### üì¶ Contenido clave del release
- **Modelos:** `p24_model.pkl`, `p24_platt.pkl` (probabilidades imagen); `p26_clinical_model.pkl` (tabular).  
- **Config:** `CONFIG/deployment_config.json` (umbrales S2 activos), respaldos `.backup.json`.  
- **QA:** `p26b_test_report_recall_target.csv`, curvas/calibraci√≥n P26 (ECE/MCE).  
- **Scripts:**  
  - `compute_pimg_from_features.py` (probabilidad imagen desde features paciente)  
  - `predict_end_to_end.py` (pipeline integrado imagen+cl√≠nico con pol√≠tica S2)  
- **Docs:** `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`, `README_RELEASE.md`  
- **Trazabilidad:** `MANIFEST.json`, `ENVIRONMENT.txt`

---

## üß© Resumen ejecutivo (P26‚ÄìP27)

- **Mejor unimodal (imagen, P24 LR elastic-net  + Platt):**  
  - TEST (**ALL**): AUC=**0.727**, PR-AUC=0.717, Brier=0.220  
  - TEST **OAS1**: AUC=**0.754**, PR-AUC=0.736, Brier=0.211  
  - TEST **OAS2**: AUC=**0.750**, PR-AUC=0.805, Brier=0.238
  Umbrales **5:1 (FN:FP)** por cohorte: **OAS1=0.435**, **OAS2=0.332**.

- **Intermodal (imagen+clinico: P26 Late / P26b Late+Platt por cohorte):**  
  - P26 **ALL**: AUC=**0.713**, PR-AUC=0.712, Brier=0.234  
  - P26b **OAS1**: AUC‚âà**0.754**, PR-AUC‚âà0.736, **Brier‚âà0.199**  
  - P26b **OAS2**: AUC‚âà**0.652**, PR-AUC‚âà0.728, **Brier‚âà0.241**

---

## Pol√≠tica de decisi√≥n S2 (activa en P27)

**Definici√≥n.** Pol√≠tica cl√≠nica basada en **coste 5:1 (FN:FP)** con **ajuste espec√≠fico para OAS2** a fin de garantizar **Recall ‚â• 0.90** en TEST (cribado).

- **Umbrales activos** (en `p26_release/CONFIG/deployment_config.json`):  
  - **OAS1:** `0.42` (5:1 puro)  
  - **OAS2:** `‚âà0.4928655288` (ajuste por recall objetivo)

**Smoke (TEST @S2, P26 Late):**  
| Cohort | Thr       | TP | FP | TN | FN | Precision | Recall |  Acc   | Cost |
|:------:|:---------:|---:|---:|---:|---:|----------:|-------:|-------:|-----:|
| OAS1   | 0.420000  | 14 |  9 | 18 |  6 |   0.6087 | 0.7000 | 0.6809 |  39  |
| OAS2   | 0.492866  | 11 |  6 |  5 |  1 |   0.6471 | 0.9167 | 0.6957 |  11  |

> **Por qu√© S2?** En entornos tipo OAS2 el **riesgo cl√≠nico** por FN es alto; S2 prioriza **detectar** (alta sensibilidad) y **documenta expl√≠citamente** el coste.

---

## üìä Resultados comparativos (TEST)

### Probabilidades (P19, P22, **P24**, P26/P26b)
| Pipeline | Cohorte | Modelo/Calib           |   AUC  | PR-AUC | Brier |
|---------:|:-------:|-------------------------|:------:|:------:|:-----:|
| P19      |  ALL    | Meta-XGB                | 0.671  | 0.606  | 0.292 |
| P19      |  OAS1   | Meta-XGB                | 0.663  | 0.588  | 0.310 |
| P19      |  OAS2   | Meta-XGB                | 0.663  | 0.683  | 0.257 |
| P22      |  ALL    | HGB-Platt               | 0.702  | 0.629  | 0.222 |
| P22      |  ALL    | LR-Platt                | 0.668  | 0.646  | 0.219 |
| P22      |  OAS1   | LR-Platt                | 0.756  | 0.726  | 0.203 |
| P22      |  OAS2   | LR-Platt                | 0.504  | 0.524  | 0.252 |
| **P24**  |  ALL    | **LR-EN + Platt**       | **0.727** | **0.717** | **0.220** |
| **P24**  |  OAS1   | **LR-EN + Platt**       | **0.754** | **0.736** | **0.211** |
| **P24**  |  OAS2   | **LR-EN + Platt**       | **0.750** | **0.805** | **0.238** |
| P26      |  ALL    | Late (raw)              | 0.713  | 0.712  | 0.234 |
| P26b     |  OAS1   | Late + Platt (coh)      | 0.754  | 0.736  | 0.199 |
| P26b     |  OAS2   | Late + Platt (coh)      | 0.652  | 0.728  | 0.241 |

### Decisi√≥n por coste (FN:FP=5:1) ‚Äî P24 vs P26
| Pipeline | Cohorte | Thr   |  TP |  FP |  TN |  FN | Precision | Recall |  Acc  | Cost |
|---------:|:------:|:-----:|----:|----:|----:|----:|----------:|-------:|------:|-----:|
| **P24**  | OAS1   | 0.435 | 14  |  9  | 18  |  6  |  0.609    | 0.700  | 0.681 |  39  |
| **P24**  | OAS2   | 0.332 | 11  |  7  |  4  |  1  |  0.611    | 0.917  | 0.652 |  12  |
| **P26**  | OAS1   | 0.307 | 14  |  9  | 18  |  6  |  0.609    | 0.700  | 0.681 |  39  |
| **P26**  | OAS2   | 0.195 |  8  |  4  |  7  |  4  |  0.667    | 0.667  | 0.652 |  24  |

> **Lectura**: P24 mantiene la mejor **discriminaci√≥n global** y robustez en OAS2 (conserva mejor AUC global); P26 Late apoya la **complementariedad** con cl√≠nico, reduce Brier en OAS1 con P26b, pero penaliza OAS2‚Äîde ah√≠ el **ajuste S2** para elevar *recall* en OAS2.

---

## üß≠ Pol√≠tica S2 ‚Äî detalle y razones

- **Motivaci√≥n cl√≠nica**: priorizar **sensibilidad** (minimizar FN) manteniendo precisi√≥n aceptable (penalizar **FN** (casos no detectados) sobre **FP**).  
- **Base**: umbral coste-√≥ptimo **5:1** por cohorte aprendido en VAL.  
- **Ajuste OAS2**: incremento de umbral hasta alcanzar **Recall ‚â•0.90** en TEST.  
- **Umbrales activos** (`p26_release/CONFIG/deployment_config.json`):  
  ```json
  {
    "OAS1": 0.42,
    "OAS2": 0.4928655287824083
  }
  ```
**Evidnecia: Smoke TEST @S2 (P26 Late):**  
- **OAS1**: TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.70**, Precision=0.609, Coste=39  
- **OAS2**: TP=11, FP=6, TN=5, FN=1 ‚Üí **Recall=0.917**, Precision=0.647, Coste=11

> **Cu√°ndo S2?** Contextos de **cribado** o **triaje**. Si el contexto penaliza mucho FP, considerar **5:1 puro** o **policy Manual** con sliders (App Streamlit).

---

## Figuras y tablas finales

- **Comparativas P24/P26** (AUC/PR-AUC/Brier por cohorte): `p27_final/p27_comparativas_*.png`  
- **Curvas ROC/PR** por cohorte (P24, P26): `p27_final/*roc*.png`, `p27_final/*pr*.png`  
- **Calibraci√≥n (ECE/MCE)** por cohorte (P24, P26): `p27_final/*cal*.png`  
- **Coste vs Umbral** por cohorte (P24, P26): `p27_final/*cost_curve*.png`  
- **Tablas ejecutivas**:  
  - `p25_informe_final/p25_executive_table.md`  
  - `p26_intermodal/p26_test_report_cost_5to1.csv`  
  - `p26_intermodal/p26b_percohort_platt_cost5to1.csv`  
  - `p26_release/QA/p26b_test_report_recall_target.csv`

---

## Reproducibilidad & Release

- **Release reproducible**: `p26_release.zip`  
  - **Modelos**: `p24_model.pkl`, `p24_platt.pkl` (imagen), `p26_clinical_model.pkl` (tabular).  
  - **CONFIG**: `deployment_config.json` (umbrales S2), *backups*.  
  - **QA**: `p26b_test_report_recall_target.csv`, ECE/MCE de P26, curvas, etc.  
  - **DOCS**: `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`, `README_RELEASE.md`.  
  - **Trazabilidad**: `MANIFEST.json`, `ENVIRONMENT.txt`.
- **Scripts operativos**:  
  - `compute_pimg_from_features.py` ‚Üí genera `p_img` calibrado (P24+Platt) desde **features** por paciente.  
  - `predict_end_to_end.py` ‚Üí fusi√≥n **Late** (p_img + p_clin) + **pol√≠tica S2**; guarda CSV con `proba_cal` + `decision`.

**Checklist reproducible**
- Fijar *seeds* y versiones (ver `ENVIRONMENT.txt`).  
- Usar exactamente las columnas de features **P24** y las **cl√≠nicas m√≠nimas** (`Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay, patient_id`).  
- Respetar IDs `OAS1_XXXX`/`OAS2_XXXX` y evitar cualquier *leakage*.

---

## Gu√≠a de uso ‚Äî scripts, app y API

### Scripts (CLI)

### 1) **Probabilidad de imagen (P24 + Platt)**: `compute_pimg_from_features.py`
Genera **Probabilidad de imagen (p_img)** (P24 + Platt) desde matrices de features por paciente:
```bash
python compute_pimg_from_features.py   --features path/patient_features.csv   --models_dir p26_release/models   --out p_img.csv
```

### 2) **Inferencia Intermodal + pol√≠tica (LATE + S2)**:  `predict_end_to_end.py`
Fusi√≥n **Late** (p_img + p_clin) + **S2** (umbrales por cohorte):
```bash
python predict_end_to_end.py \
  --pimg p_img.csv \
  --clinic clinical.csv \
  --models_dir p26_release/models \
  --config p26_release/CONFIG/deployment_config.json \
  --out predictions.csv
```

### App gr√°fica (Streamlit)
```bash
pip install streamlit pandas numpy scikit-learn==1.7.1 joblib requests
streamlit run app.py
```
- **Datos**: subir CSV de *features* y CSV *cl√≠nico* (o usar **Modo Demo**).  
- **Resultados**: muestra `p_img`, `p_clin`, `proba_cal`, decisi√≥n y descarga CSV.  
- **M√©tricas** (si hay `y_true`): AUC/PR-AUC/Brier, **confusi√≥n** (TP/FP/TN/FN), **coste** y **calibraci√≥n** (ECE/MCE).  
- **Ajustes**: **S2** (por JSON) o **Manual** (sliders) y guardado de umbrales.

### API (FastAPI)

- Endpoint `POST /predict` que acepta `clinical + features` **o** `clinical + p_img`.  
- Respuesta con `p_img`, `p_clin`, `proba_cal`, `thr` y `decision`.  
- Ver `docs/FASTAPI_GUIDE.md`.

---

## Reproducibilidad y release

- **Release**: `p26_release.zip`  
  - **models**: `p24_model.pkl`, `p24_platt.pkl`, `p26_clinical_model.pkl`  
  - **CONFIG**: `deployment_config.json` (**S2 activa**) + backups  
  - **QA**: `p26b_test_report_recall_target.csv`, ECE/MCE, curvas  
  - **DOCS**: `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`  
  - **Trazabilidad**: `MANIFEST.json`, `ENVIRONMENT.txt`
- **Versiones**: usar **scikit-learn 1.7.1** (coherente con pickles) y alinear columnas con `feature_names_in_`.

---

## üñºÔ∏è Figuras finales

- `p27_final/*.png`: comparativas AUC/PR-AUC/Brier, costes S2, calibraci√≥n.  
- `p26_intermodal/*`: reportes P26/P26b y curvas de coste por cohorte.  
- `p25_informe_final/*`: ROC/PR/Cal + CIs bootstrap P24.

## ‚úÖ Checklist operativo

- Validar **versiones** (scikit-learn 1.7.1) y **columnas** esperadas por cada *pickle*.  
- Aplicar **S2** s√≥lo si contexto cl√≠nico prioriza **recall** (cribado).  
- Monitorizar **ECE/MCE** y **recalibrar** por cohorte si ECE > 0.2.  
- Registrar **TP/FP/TN/FN**, coste y *drift* de cohortes (mezcla OAS1/OAS2).

---

## Changelog P26/P26b/P27

- **P26**: Fusi√≥n **Late** y **Mid**; elecci√≥n **Late** por mejor equilibrio; umbrales 5:1 en VAL aplicados a TEST.  
- **P26b**: **Platt por cohorte** para Late; **OAS1 Brier‚Üì**; consolidaci√≥n de **tablas** y **ECE/MCE**.  
- **P27**: **Pol√≠tica S2** (ajuste OAS2‚Üírecall), **smoke TEST**, **release** (zip), **scripts**, **app** y **figuras finales**.

---

## Desaf√≠os principales

1. **Peque√±o tama√±o de dataset**:  
   - Solo ~47 pacientes en test.  
   - Variabilidad extrema en m√©tricas seg√∫n fold.  
   - Riesgo de overfitting alt√≠simo.  

2. **Saturaci√≥n de logits**:  
   - En P9 y P10, los logits alcanzaban valores >500k, obligando a normalizaci√≥n y calibraci√≥n.  

3. **Problemas de montaje de Google Drive en Colab**:  
   - Errores de ‚ÄúMountpoint must not already contain files‚Äù tras semanas sin reinicio.  
   - Necesidad de reiniciar entorno completo.  

4. **Dispersi√≥n de ficheros de predicci√≥n**:  
   - Algunos outputs generados como `*_png_preds`, otros como `*_slice_preds`.  
   - Diferencias en columnas (`y_score`, `sigmoid(logit)`, `pred`).  

5. **Gesti√≥n de ensembles**:  
   - Decidir entre averaging, stacking, random search de pesos.  
   - Validaci√≥n compleja con tan pocos pacientes.  

---

## Lecciones aprendidas

- **Los datos cl√≠nicos son extremadamente informativos** en OASIS; **imagen** aporta **complementariedad** que se capitaliza mejor con **fusi√≥n Late** + **calibraci√≥n**.  
- **EfficientNet-B3** sigue siendo el backbone m√°s consistente en MRI.  
- **La calibraci√≥n es necesaria** pero puede sacrificar precisi√≥n.  
- **Los ensembles ayudan modestamente**, pero su efecto depende de la diversidad real de los modelos.  
- **La organizaci√≥n de outputs es cr√≠tica**: nombres consistentes ahorran horas de debugging.  
- **El reinicio peri√≥dico de Colab** evita errores de montaje y rutas fantasmas.  
- **Peque√±o N** exige OOF sin fuga, control de NaNs y *reporting* honesto (incl. coste).

---

## Limitaciones y Pr√≥ximos pasos

1. **Consolidar ensembles de backbones**:  
   - Probar combinaciones m√°s ricas (ResNet+EffNet+Swin).  
   - Usar stacking con regularizaci√≥n fuerte.  

2. **Explorar multimodal**:  
   - Fusionar cl√≠nico + MRI.  
   - Comparar si mejora sobre cl√≠nico solo.  

3. **Descalibraci√≥n en OAS2**: monitorizar **ECE/MCE** y **recalibrar** peri√≥dicamente. 

4. **Validaci√≥n externa**:  
   -  **N reducido** (OAS2) ‚Üí CIs amplios; ideal **validaci√≥n externa** (p.ej., ADNI).  
   - Usar datasets adicionales (ADNI, etc.) para comprobar generalizaci√≥n.  

5. **Optimizaci√≥n final**:  
   - Revisar hiperpar√°metros con Bayesian Optimization.  
   - Estudiar interpretabilidad (Grad-CAM, SHAP).  

---





