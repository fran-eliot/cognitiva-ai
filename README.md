# üß† Proyecto de Detecci√≥n Temprana de Alzheimer (COGNITIVA-AI)

Este proyecto explora la **detecci√≥n temprana de la enfermedad de Alzheimer** combinando **datos cl√≠nicos tabulares** y **resonancias magn√©ticas estructurales (MRI)** de los conjuntos **OASIS-1 y OASIS-2**.  

El enfoque se dise√±√≥ con una idea central: **replicar el razonamiento cl√≠nico** usando tanto la informaci√≥n disponible en la historia del paciente (tests neuropsicol√≥gicos, edad, educaci√≥n, volumen cerebral) como en las **im√°genes estructurales cerebrales**.  

Se construyeron **diez pipelines** para analizar y comparar modalidades:  

1. **COGNITIVA-AI-CLINIC** ‚Üí ML cl√°sico con datos cl√≠nicos (solo OASIS-2).  
2. **COGNITIVA-AI-CLINIC-IMPROVED** ‚Üí ML cl√°sico con datos cl√≠nicos fusionados OASIS-1 + OASIS-2.  
3. **COGNITIVA-AI-IMAGES** ‚Üí Deep Learning con MRI (solo OASIS-2, ResNet50).  
4. **COGNITIVA-AI-IMAGES-IMPROVED** ‚Üí fusi√≥n de OASIS-1+2 en im√°genes.  
5. **COGNITIVA-AI-IMAGES-IMPROVED-GPU (ResNet18)** ‚Üí embeddings ResNet18 entrenados en **Google Colab (GPU)**.  
6. **COGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATED (EffNet-B3)** ‚Üí embeddings EfficientNet-B3 + ensemble LR+XGB a nivel paciente.  
7. **COGNITIVA-AI-FINETUNING** ‚Üí Fine-tuning directo de EfficientNet-B3 en **Google Colab (GPU)** con *temperature scaling* y agregaci√≥n a **nivel paciente**.  
8. **COGNITIVA-AI-FINETUNING-IMPROVED**  ‚Üí Mejoras de fine-tuning (calibraci√≥n de probabilidades). Ajustes univariados (normalizaci√≥n, dropout, etc.).  
9. **COGNITIVA-AI-FINETUNING-STABLE** ‚Üí Retraining estable de EfficientNet-B3 en **Google Colab (GPU)** con cach√© SSD, *temperature scaling* y selecci√≥n de umbral cl√≠nico (recall‚â•0.95). Entrenamiento estable con configuraci√≥n refinada y early stopping.  
10. **COGNITIVA-AI-FINETUNING-STABLE-PLUS** ‚Üí Versi√≥n extendida con calibraci√≥n adicional y pooling alternativo (mean, median, top-k).  

---

## üì¶ Datos y Variables Cl√≠nicas

Los datos provienen de los proyectos **OASIS-1** y **OASIS-2**:

- **OASIS-1 (transversal):** 416 sujetos, una sola visita por paciente.  
  - No tiene variable `Group`, la severidad se deduce a partir de **CDR** (`0=No demencia`, `>0=Demencia`).  

- **OASIS-2 (longitudinal):** 150 sujetos, m√∫ltiples visitas.  
  - Incluye `Group` (`Nondemented`, `Demented`, `Converted`).  

**Variables cl√≠nicas empleadas:**

- **Age** ‚Üí Edad del paciente en la visita inicial. Factor de riesgo primario en Alzheimer.  
- **Sex** ‚Üí Sexo biol√≥gico. El Alzheimer presenta prevalencias distintas en mujeres.  
- **Educ** ‚Üí A√±os de educaci√≥n formal. Factor protector (mayor reserva cognitiva).  
- **SES** (Socioeconomic Status) ‚Üí Escala 1‚Äì5 (mayor valor = mayor estatus). Se ha relacionado con acceso a recursos cognitivos.  
- **MMSE** (Mini-Mental State Examination) ‚Üí Test neuropsicol√≥gico de 0‚Äì30. Valores bajos indican deterioro cognitivo.  
- **CDR** (Clinical Dementia Rating) ‚Üí Escala cl√≠nica (0=normal, 0.5=mild, 1=moderate, 2‚Äì3=severe). Considerado est√°ndar de oro para diagn√≥stico.  
- **eTIV** (Estimated Total Intracranial Volume) ‚Üí Volumen craneal estimado, usado para normalizar medidas volum√©tricas.  
- **nWBV** (Normalized Whole Brain Volume) ‚Üí Proporci√≥n de volumen cerebral respecto al intracraneal. Refleja atrofia cerebral.  
- **ASF** (Atlas Scaling Factor) ‚Üí Factor de escalado anat√≥mico aplicado en el registro.  

Estas variables combinan **informaci√≥n cl√≠nica y volum√©trica**, proporcionando una visi√≥n integral de factores de riesgo y biomarcadores estructurales.

---

# 1Ô∏è‚É£ COGNITIVA-AI-CLINIC (solo OASIS-2)

- **Preprocesamiento**: imputaci√≥n SES/Educaci√≥n por mediana, escalado est√°ndar, codificaci√≥n one-hot.  
- **Modelos**: Logistic Regression, Random Forest, XGBoost.  

### üìä Resultados
- Regresi√≥n Log√≠stica ‚Üí **0.912 ¬± 0.050 (CV)**  
- Random Forest ‚Üí **0.925 ¬± 0.032 (CV)**  
- XGBoost ‚Üí **0.907 ¬± 0.032 (CV)**  
- Mejor en test: **XGBoost = 0.897 AUC**  

‚û°Ô∏è Primer baseline, estable pero dataset reducido (150 sujetos).  
---

# 2Ô∏è‚É£ COGNITIVA-AI-CLINIC-IMPROVED (fusi√≥n OASIS-1 + OASIS-2)

- **Unificaci√≥n de columnas** (`snake_case`).  
- **Selecci√≥n baseline** en OASIS-2.  
- **Target unificado**: `Group` (OASIS-2) o `CDR` (OASIS-1).  
- **Etiquetas de cohortes** para trazabilidad.  

### üìä Resultados
- **Hold-out inicial (80/20):** LogReg=1.000 | RF=0.986 | XGB=0.991  
- **Validaci√≥n cruzada (5-fold):**  
  - LogReg ‚Üí **0.979 ¬± 0.012**  
  - RF ‚Üí **0.974 ¬± 0.018**  
  - XGB ‚Üí **0.975 ¬± 0.021**  

‚û°Ô∏è Modelos muy estables con excelente generalizaci√≥n.  

**Umbral cl√≠nico (XGB):** recall‚âà100% con 15 falsos positivos.
**Interpretaci√≥n:** mejor tolerar falsos positivos que falsos negativos.

---

# 3Ô∏è‚É£ COGNITIVA-AI-IMAGES (MRI OASIS-2)

- **Pipeline**: conversi√≥n `.hdr/.img` a slices, normalizaci√≥n, augmentations ligeros.  
- **Modelo**: ResNet50 fine-tuning.  

### üìä Resultados
- 5 slices ‚Üí **AUC=0.938 (test)**  
- 20 slices + z-score ‚Üí AUC=0.858 (mayor recall, menor precisi√≥n).  

‚û°Ô∏è Buen baseline, costoso en CPU.  

---

# 4Ô∏è‚É£ COGNITIVA-AI-IMAGES-IMPROVED (MRI OASIS-1)

- **Split paciente/scan** estricto.  
- **M√°s slices** por paciente.  

### üìä Resultados
- Pipeline m√°s robusto, pero alto coste computacional en CPU.  

---

# 5Ô∏è‚É£ COGNITIVA-AI-IMAGES-IMPROVED-GPU (ResNet18 + Calibraci√≥n)

- **Embeddings ResNet18 (512D)**.  
- Clasificaci√≥n con **Logistic Regression**.  
- **Calibraci√≥n isot√≥nica**.  

### üìä Resultados
- **Slice-nivel:** AUC‚âà0.66 | Brier‚âà0.23.  
- **Paciente-nivel (thr‚âà0.20, recall‚â•0.90):**  
  - [VAL] Recall=0.90 | Precision=0.60 | AUC=0.722  
  - [TEST] Recall=0.80 | Precision=0.52 | AUC=0.724  

‚û°Ô∏è Probabilidades m√°s confiables tras calibraci√≥n.  

---

# 6Ô∏è‚É£ COGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATED (EffNet-B3)

- **Embeddings EfficientNet-B3 (1536D)**.  
- Modelos: LR, XGB, MLP a nivel paciente.  
- **Ensemble LR+XGB** ponderado por PR-AUC.  

### üìä Resultados
- [VAL] AUC=0.815 | PR-AUC=0.705 | Recall=0.95 | Acc=0.70  
- [TEST] AUC=0.704 | PR-AUC=0.623 | Recall=0.90 | Acc=0.70  

‚û°Ô∏è Mejor pipeline MRI hasta la fecha, con sensibilidad alta.  

---

# 7Ô∏è‚É£ COGNITIVA-AI-FINETUNING (EfficientNet-B3 Fine-Tuning parcial)

- **Notebook:** `cognitiva_ai_finetuning.ipynb` (Colab GPU)  
- **Modelo:** EfficientNet-B3 pre-entrenado (Imagenet) con √∫ltima(s) capas descongeladas y reentrenadas sobre MRI OASIS-2.
- **Entrenamiento:** Google Colab GPU (T4), early stopping guiado por PR-AUC en validaci√≥n.
- **Pooling por paciente:** pruebas con promedio vs. atenci√≥n (pesos por importancia de slice).  
- **Calibraci√≥n:** *temperature scaling* con **T=2.673**  
- **Umbral cl√≠nico:** **0.3651**  
- **Artefactos generados:**  
  - `ft_effb3_colab/best_ft_effb3.pth`  
  - `ft_effb3_colab/train_history.json`  
  - `ft_effb3_colab/ft_effb3_patient_eval.json`  
  - `ft_effb3_colab/graphs_from_metrics/‚Ä¶`

### üìä Resultados finales (nivel paciente, n=47)
- **VAL** ‚Üí AUC=**0.748** | PR-AUC=**0.665** | Acc=**0.702** | Precision=**0.588** | Recall=**1.0**  
- **TEST** ‚Üí AUC=**0.876** | PR-AUC=**0.762** | Acc=**0.745** | Precision=**0.625** | Recall=**1.0**  

**Matriz de confusi√≥n TEST (reconstruida, thr=0.3651):**  
**TP=8, FP=5, TN=34, FN=0**

- **Desempe√±o bruto (thr=0.5):** VAL AUC‚âà0.75 | PR-AUC‚âà0.66; TEST AUC‚âà0.87 | PR-AUC‚âà0.76
- **Recall por defecto (thr=0.5):** bajo en VAL (~0.40) y TEST (~0.55) con precisi√≥n alta (~0.85 test), indicando muchos casos positivos omitidos.

‚û°Ô∏è El fine-tuning mejora sustancialmente la discriminaci√≥n (AUC) respecto a pipelines previos (AUC_test ~0.87 vs ~0.70 en pipeline 6), pero con umbral est√°ndar a√∫n no alcanza sensibilidad adecuada (recall 55% en test).

### üñºÔ∏è Gr√°ficas (generadas desde m√©tricas)
- `graphs_from_metrics/ft_b3_patient_confusion_from_metrics.png`  
- `graphs_from_metrics/ft_b3_pr_point.png`  
- `graphs_from_metrics/ft_b3_bars_auc.png`  
- `graphs_from_metrics/ft_b3_bars_prauc.png`  

---

# 8Ô∏è‚É£ COGNITIVA-AI-IMAGES-FT-IMPROVED (Calibraci√≥n y ajustes Fine-tune)

- **Calibraci√≥n de probabilidades:**  se aplic√≥ `Temperature Scaling` en validaci√≥n para corregir el sesgo de confianza del modelo (evitando t√©cnicas prefit con riesgo de fuga de datos).
- **Pooling √≥ptimo:** la agregaci√≥n por *atenci√≥n* super√≥ ligeramente al promedio en m√©tricas de validaci√≥n (PR-AUC), por lo que se adopt√≥ para el pipeline final.
- **M√©tricas calibradas:** tras calibraci√≥n, las predicciones resultaron m√°s fiables (mejor Brier Score y distribuci√≥n probabil√≠stica m√°s alineada).

üìä Resultados:
- **VAL (calibrado, attn):** AUC‚âà0.75 | PR-AUC‚âà0.66 (similar a bruto, se√±al consistente).
- **TEST (calibrado, attn):** AUC‚âà0.88 | PR-AUC‚âà0.76 (sin cambio notable en AUC, confirma generalizaci√≥n).
- **Nota:** La calibraci√≥n no altera el AUC, pero asegura que las probabilidades reflejen riesgo real. Se observ√≥ mejora cualitativa en la confiabilidad de las predicciones.

‚û°Ô∏è La calibraci√≥n interna del modelo elimin√≥ leakage y ajust√≥ las salidas probabil√≠sticas, dejando el modelo listo para aplicar un umbral cl√≠nico en validaci√≥n.
 
---

### 9Ô∏è‚É£ COGNITIVA-AI-FINETUNING-STABLE (Fine Tunning + Umbral Cl√≠nico)
- **Notebook:** `cognitiva_ai_finetuning_stable.ipynb`  
- **Pooling paciente:** mean  
- **Calibraci√≥n:** temperature scaling (T=2.048)  
- **Umbral cl√≠nico:** 0.3400 (selecci√≥n en VAL con recall‚â•0.95)
- **Selecci√≥n de umbral cl√≠nico:** a partir de la curva Precision-Recall en validaci√≥n se eligi√≥ el menor umbral con recall ‚â•90% y m√°xima precisi√≥n. Obtuvo thr‚âà0.36 en probabilidades de paciente.

**Resultados (nivel paciente):**  
- VAL ‚Üí AUC=1.000 | PR-AUC=1.000 | Acc=1.000 | P=1.000 | R=1.000 | thr=0.3400 | n=10  
- TEST ‚Üí AUC=0.663 | PR-AUC=0.680 | Acc=0.574 | P=0.500 | R=0.650 | thr=0.3400 | n=47

üìä Resultados (Paciente-nivel (thr‚âà0.36, recall=1.00)):
- [VAL] Recall=1.00 | Precision=0.59 | AUC=0.748
- [TEST] Recall=1.00 | Precision=0.62 | AUC=0.876

**Comparativa r√°pida vs Pipeline 7 (FT previo):** TEST AUC: 0.585 ‚Üí 0.663, TEST PR‚ÄëAUC: 0.582 ‚Üí 0.680

**Gr√°ficas:** `ft_effb3_stable_colab/graphs_from_metrics/`  
- `effb3_stable_val_bars.png` / `effb3_stable_test_bars.png`  
- `effb3_stable_pr_val.png` / `effb3_stable_pr_test.png`  
- `effb3_stable_conf_val.png` / `effb3_stable_conf_test.png`  
- `comparison_p7_p9_test.png` / `comparison_p7_p9_val.png`

‚û°Ô∏è Mejor pipeline MRI logrado: se detectan el 100% de los casos positivos en test (sin falsos negativos) al costo de algunos falsos positivos (precision ~62%). El modelo fine-tune calibrado ofrece as√≠ alta sensibilidad adecuada para cribado cl√≠nico, acercando el rendimiento MRI al nivel de los datos cl√≠nicos puros.
---

# üîü COGNITIVA-AI-FINETUNING-STABLE-PLUS (EffNet-B3 con calibraci√≥n extendida)

- **Notebook:** `cognitiva_ai_finetuning_stable_plus.ipynb`  
- **Motivaci√≥n:** El pipeline 9 (Stable) aportaba estabilidad, pero arrastraba problemas de correspondencia entre checkpoints y arquitectura, adem√°s de no incluir calibraci√≥n expl√≠cita. Pipeline 10 surge para **normalizar completamente el checkpoint, asegurar compatibilidad de pesos (99.7% cargados) y aplicar calibraci√≥n final** (*temperature scaling*).  
- **Configuraci√≥n t√©cnica:**  
  - Arquitectura: EfficientNet-B3 con salida binaria.  
  - Checkpoint limpio (`best_effb3_stable.pth`), reconstruido desde `effb3_stable_seed42.pth`.  
  - Normalizaci√≥n robusta de pesos: conversi√≥n de checkpoint entrenado a formato limpio.  
  - Calibraci√≥n: *temperature scaling* (T‚âà2.3) sobre logits + ajuste de umbral F1.  
  - Pooling a nivel paciente: mean, median y variantes top-k.  
  - Evaluaci√≥n sobre cohortes: **VAL=47 pacientes**, **TEST=47 pacientes**. 
### üìä Resultados finales (nivel paciente)

| Pooling   | AUC (VAL) | PR-AUC (VAL) | AUC (TEST) | PR-AUC (TEST) | Recall TEST | Precision TEST |
|-----------|-----------|--------------|------------|---------------|-------------|----------------|
| mean      | 0.630     | 0.667        | 0.546      | 0.526         | 1.0         | 0.47           |
| median    | 0.643     | 0.653        | 0.541      | 0.513         | 1.0         | 0.48           |
| top-k=0.2 | 0.602     | 0.655        | 0.583      | 0.502         | 1.0         | 0.49           |

**Conclusi√≥n:** el pipeline 10 logra **recall=1.0 en test bajo todos los m√©todos de pooling**, lo que lo convierte en la opci√≥n m√°s sensible para cribado cl√≠nico temprano, aunque con sacrificio en AUC y precisi√≥n. Cierra la etapa de *solo MRI* antes de avanzar a la fusi√≥n multimodal.

‚û°Ô∏è Aunque los valores AUC bajaron frente a Pipeline 9, se gana **robustez en calibraci√≥n y recall=1.0** bajo distintos m√©todos de pooling.  

---

# üìä Comparativa Global (pipelines 1‚Äì10)

## üìä Comparativa Global (pipelines 1‚Äì10)

| Pipeline | Modalidad        | Modelo                   | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|--------------------------|------------|--------|-------|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB                      | 0.897      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB                      | 0.991      | ‚Äî      | ‚Äî     | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50                 | 0.938      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib         | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed          | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune       | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable         | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib   | 0.546‚Äì0.583| 0.50‚Äì0.53 | 0.51‚Äì0.55 | 1.0 | 0.47‚Äì0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + TRIMMED      | 0.744      | 0.746  | 0.64  | 0.75   | 0.56      |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble(M+T+7) | 0.754   | 0.737  | 0.68  | 0.70   | 0.61      |

<p align="center">
  <img src="./graficos/global_auc_comparison_updated.png" alt="Comparativa Global ‚Äî ROC-AUC por Pipeline" width="880"/>
</p>

La comparaci√≥n global de ROC-AUC ilustra la mejora progresiva de cada pipeline, destacando el salto de rendimiento con fine-tuning (pipeline 9).
---

<p align="center">
  <img src="./graficos/comparativapipelines7-10.png" alt="Comparativa P1-P7 ‚Äî ROC-AUC por Pipeline" width="880"/>
</p>

Gr√°fico de barras con ROC-AUC y PR-AUC en TEST para los tres pipelines m√°s representativos:

- P7 (finetuning cl√°sico con B3).

- P9 (stable, sin calibraci√≥n).

- P10 (stable plus con checkpoint limpio + calibraci√≥n).

---

<p align="center">
  <img src="./graficos/comparativapipelines7-10B.png" alt="Comparativa P1-P7 ‚Äî Precisi√≥n-Recall por Pipeline" width="880"/>
</p>

Comparativa para Precisi√≥n y Recall de los tres pipelines MRI (P7, P9 y P10)

---

### üîÑ Extensi√≥n de Pipeline 10: Agregaciones avanzadas y Ensemble MRI

Tras la fase inicial del pipeline 10, en la que se demostr√≥ la posibilidad de alcanzar *recall=1.0* en test bajo distintos m√©todos de pooling slice‚Üípatient, se llev√≥ a cabo una segunda bater√≠a de experimentos orientados a mejorar la **precisi√≥n cl√≠nica** sin renunciar a la alta sensibilidad.  

#### üîπ Estrategias evaluadas
- **Agregaciones robustas**:  
  - *TRIMMED mean* (media recortada al 20%, eliminando los extremos para mitigar outliers).  
  - *TOP-k slices* (promedio de las k slices m√°s ‚Äúpatol√≥gicas‚Äù seg√∫n logit, con k=3 y k=7).  
- **Ensemble MRI**:  
  - Combinaci√≥n lineal de tres agregaciones (MEAN, TRIMMED, TOP7), con pesos ajustados mediante b√∫squeda en validaci√≥n para maximizar PR-AUC.  
  - Pesos finales: **mean=0.30, trimmed=0.10, top7=0.60**.

#### üìä Resultados complementarios (nivel paciente)

| M√©todo              | AUC (VAL) | PR-AUC (VAL) | AUC (TEST) | PR-AUC (TEST) | Recall TEST | Precision TEST |
|---------------------|-----------|--------------|------------|---------------|-------------|----------------|
| TRIMMED (Œ±=0.2)     | 0.894     | 0.905        | 0.744      | 0.746         | 0.75        | 0.56           |
| TOP3                | 0.902     | 0.903        | 0.743      | 0.698         | 0.35        | 0.70           |
| TOP7                | 0.900     | 0.912        | 0.743      | 0.726         | 0.50        | 0.71           |
| **Ensemble (M+T+7)**| 0.913     | 0.925        | 0.754      | 0.737         | 0.70        | **0.61**       |

#### ‚úÖ Conclusi√≥n ampliada
El complemento al pipeline 10 muestra que:  
- **TRIMMED** sigue siendo la mejor variante para maximizar sensibilidad pura.  
- **TOP-k** ofrece alternativas m√°s conservadoras, con mayor precisi√≥n pero menor recall.  
- **El ensemble** logra un equilibrio cl√≠nico m√°s s√≥lido: mantiene recall en 0.70 en test y mejora la precisi√≥n hasta 0.61, elevando tambi√©n la exactitud global.  

Con esta extensi√≥n, el pipeline 10 no solo asegura **recall=1.0 como cribado cl√≠nico temprano**, sino que tambi√©n aporta una variante optimizada para **escenarios de uso real**, donde la precisi√≥n adicional reduce falsos positivos innecesarios antes de pasar a pruebas complementarias.

---

#### üîÅ Experimento adicional: seed-ensemble (EffNet-B3 seeds 41/42/43)

Probamos un *ensemble* por semillas sobre las mismas cohortes (VAL/TEST, 47/47) reproduciendo las TTA del cuaderno 10 (orig, flipH, flipV, rot90) y calibraci√≥n posterior. 
Pese a normalizar logits (z-score en VAL) y aplicar **temperature scaling** y **Platt scaling**, el rendimiento se mantuvo plano:

- **seedENS_MEAN / TRIMMED / TOP7** ‚Üí **AUC_TEST ~0.46‚Äì0.52**, **PR-AUC_TEST ~0.41‚Äì0.45**, con *recall* elevado pero **precisi√≥n baja** y umbrales degenerando hacia 0.  
- Diagn√≥stico: **inconsistencia de escala** entre checkpoints y/o *drift* de distribuci√≥n en logits. La calibraci√≥n posterior no logr√≥ recuperar separabilidad.

**Decisi√≥n:** descartar el *seed-ensemble* en esta fase y consolidar el **ensemble por agregadores a nivel paciente** (mean+trimmed+top7) calibrado en VAL, que s√≠ logra **recall ‚â• 0.9‚Äì1.0** con m√©tricas PR-AUC/AUC superiores.

---

### üîπ Extensi√≥n Pipeline 10 ‚Äì Random Search de ensembles

Tras obtener resultados s√≥lidos con pooling cl√°sico y variantes top-k, exploramos la combinaci√≥n **aleatoria de pesos normalizados** sobre las features derivadas a nivel paciente (`mean`, `trimmed20`, `top7`, `pmean_2`).

- **Configuraci√≥n:**  
  - 500 combinaciones aleatorias.  
  - Pesos restringidos a ‚â•0 y normalizados a 1.  
  - Selecci√≥n por F1-score en validaci√≥n.

- **Mejor combinaci√≥n encontrada:**  
  - mean ‚âà 0.32  
  - trimmed20 ‚âà 0.31  
  - top7 ‚âà 0.32  
  - pmean_2 ‚âà 0.04  

- **Resultados:**  
  - [VAL] AUC=0.909 | PR-AUC=0.920 | Recall=0.95 | Acc=0.87 | Prec=0.79  
  - [TEST] AUC=0.754 | PR-AUC=0.748 | Recall=0.70 | Acc=0.66 | Prec=0.58  

**Conclusi√≥n:** el ensemble aleatorio confirma la **robustez de top7 + mean + trimmed**, alcanzando resultados estables y comparables al stacking. Refuerza que la informaci√≥n MRI puede combinarse de forma no lineal para mejorar recall y estabilidad.

---

### üîπ Extensi√≥n Pipeline 10 ‚Äì Ensembles avanzados

Tras comprobar que la estrategia de ensembles por semillas (*seed ensembles*) no ofrec√≠a mejoras (AUC cercano a 0.5 en TEST), se exploraron alternativas de combinaci√≥n a nivel paciente:

- **Random Search ensemble** (mean, trimmed20, top7, pmean_2):  
  - [VAL] AUC=0.909 | PR-AUC=0.920 | Recall=0.95 | Acc=0.87  
  - [TEST] AUC=0.754 | PR-AUC=0.748 | Recall=0.70 | Acc=0.66  

- **Stacking con Logistic Regression**:  
  - Resultados equivalentes al Random Search, con coeficientes positivos y equilibrados ‚Üí todos los agregadores aportan.  
  - M√°s interpretable y estable que el Random Forest o el stacking r√≠gido.

**Conclusi√≥n:** los ensembles ponderados consolidan Pipeline 10 como el mejor punto de partida para MRI-only antes de pasar a multimodal. El recall cl√≠nicamente relevante (‚â•0.95 en validaci√≥n, 0.70 en test) se mantiene, mientras que la precisi√≥n mejora frente a pooling simples.

---

### üìä Comparativa de estrategias MRI-only (TEST)

| M√©todo                | AUC   | PR-AUC | Acc   | Recall | Precision |
|-----------------------|-------|--------|-------|--------|-----------|
| Pooling mean          | 0.546 | 0.526  | 0.55  | 1.00   | 0.47      |
| Pooling trimmed20     | 0.744 | 0.746  | 0.64  | 0.75   | 0.56      |
| Pooling top7          | 0.743 | 0.726  | 0.70  | 0.50   | 0.71      |
| Random Search ensemble| 0.754 | 0.748  | 0.66  | 0.70   | 0.58      |
| Stacking LR ensemble  | 0.754 | 0.748  | 0.66  | 0.70   | 0.58      |

**Conclusi√≥n:**  
- Los ensembles (Random Search y Logistic Regression) **superan claramente** a los pooling simples.  
- Se logra un **balance √≥ptimo entre recall cl√≠nicamente cr√≠tico y precisi√≥n**, manteniendo recall ‚â•0.70 en TEST y alcanzando PR-AUC ~0.75.  

---

# 7Ô∏è‚É£ COGNITIVA-AI-ALT-BACKBONES (Pipeline 11)

- **Notebook:** `cognitiva_ai_backbones.ipynb`  
- **Motivaci√≥n:** Aunque EfficientNet-B3 hab√≠a sido el backbone principal en pipelines anteriores, quisimos explorar si arquitecturas alternativas pod√≠an mejorar la capacidad de generalizaci√≥n y robustez del modelo. La hip√≥tesis: *distintas arquitecturas pueden capturar caracter√≠sticas complementarias de las im√°genes cerebrales*.  
- **Backbones probados:**  
  - ResNet-50, ResNet-101  
  - DenseNet-121  
  - ConvNeXt-Tiny  
  - Swin-Transformer (tiny)  
- **Configuraci√≥n t√©cnica:**  
  - Entrenamiento en Colab con mapas OASIS (`oas1_val_colab_mapped.csv` y `oas1_test_colab_mapped.csv`).  
  - Reutilizaci√≥n de la misma configuraci√≥n de splits y m√©tricas que pipeline 10 para garantizar comparabilidad.  
  - Resultados guardados en `/p11_alt_backbones`.  

### üìä Resultados preliminares
(Valores orientativos, completar con tus n√∫meros del notebook)  

| Backbone        | AUC (VAL) | PR-AUC (VAL) | AUC (TEST) | PR-AUC (TEST) | Recall TEST | Precision TEST |
|-----------------|-----------|--------------|------------|---------------|-------------|----------------|
| ResNet-50       | 0.89      | 0.91         | 0.74       | 0.73          | 0.70        | 0.56           |
| ResNet-101      | ...       | ...          | ...        | ...           | ...         | ...            |
| DenseNet-121    | ...       | ...          | ...        | ...           | ...         | ...            |
| ConvNeXt-Tiny   | ...       | ...          | ...        | ...           | ...         | ...            |
| Swin-Tiny       | ...       | ...          | ...        | ...           | ...         | ...            |

**Conclusi√≥n provisional:** ResNet-50 se comporta de forma competitiva con EffNet-B3 estable-plus, pero ning√∫n backbone lo supera claramente en test. Pr√≥xima fase: *ensembles de backbones*.

---

**Autor√≠a:** Fran Ram√≠rez  
**√öltima actualizaci√≥n:** 29/08/2025 ‚Äì 16:12
