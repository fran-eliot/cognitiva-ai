# ðŸ§  Proyecto de DetecciÃ³n Temprana de Alzheimer con datos clÃ­nicos y de resonancia magnÃ©tica (COGNITIVA-AI) â€“ Experimentos de ClasificaciÃ³n Multimodal

Este repositorio documenta **toda la evoluciÃ³n experimental** en el marco del proyecto **Cognitiva-AI**, cuyo objetivo ha sido **explorar modelos de machine learning para la predicciÃ³n binaria de deterioro cognitivo (Alzheimer)** combinando  **datos clÃ­nicos tabulares** y **resonancias magnÃ©ticas estructurales (MRI)** de los conjuntos **OASIS-1 y OASIS-2**.   

El enfoque se diseÃ±Ã³ con una idea central: **replicar el razonamiento clÃ­nico** usando tanto la informaciÃ³n disponible en la historia del paciente (tests neuropsicolÃ³gicos, edad, educaciÃ³n, volumen cerebral) como en las **imÃ¡genes estructurales cerebrales**.  

La hipÃ³tesis central que guÃ­a todo el trabajo es que **distintas fuentes de informaciÃ³n y distintas arquitecturas de modelos pueden capturar facetas complementarias del proceso neurodegenerativo**.  

> **Idea fuerza**: un flujo **reproducible, interpretable y clÃ­nicamente orientado** que prioriza **recall** (minimizar FN) y mantiene la **calibraciÃ³n** de probabilidades con umbrales **por cohorte** (OAS1/OAS2).

El documento sigue un enfoque **cuaderno de bitÃ¡cora extendido**, en el que cada pipeline corresponde a un conjunto de experimentos con motivaciones, configuraciones tÃ©cnicas, mÃ©tricas obtenidas y reflexiones.  
El tono es intencionadamente **verboso y detallado**: se incluyen incidencias de ejecuciÃ³n, errores y aprendizajes prÃ¡cticos que acompaÃ±aron cada etapa.  

Se construyeron **diez pipelines** para analizar y comparar modalidades siguiendo una filosofÃ­a de **experimentaciÃ³n incremental**:  
- comenzar con modelos sencillos sobre datos clÃ­nicos,  
- avanzar hacia CNNs entrenadas sobre imÃ¡genes MRI,  
- introducir calibraciÃ³n, normalizaciÃ³n y estrategias de ensemble,  
- explorar arquitecturas modernas de visiÃ³n,  
- y finalmente preparar el terreno hacia un modelo multimodal.
  

1. **P1_COGNITIVA_AI_CLINIC** â†’ ML clÃ¡sico con datos clÃ­nicos (solo OASIS-2).  
2. **P2_COGNITIVA_AI_CLINIC_IMPROVED** â†’ ML clÃ¡sico con datos clÃ­nicos fusionados OASIS-1 + OASIS-2.  
3. **P3_COGNITIVA_AI_IMAGES** â†’ Deep Learning con MRI (solo OASIS-2, ResNet50).  
4. **P4_COGNITIVA_AI_IMAGES_IMPROVED** â†’ fusiÃ³n de OASIS-1+2 en imÃ¡genes.  
5. **COGNITIVA-AI-IMAGES-IMPROVED-GPU (ResNet18)** â†’ embeddings ResNet18 entrenados en **Google Colab (GPU)**.  
6. **COGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATED (EffNet-B3)** â†’ embeddings EfficientNet-B3 + ensemble LR+XGB a nivel paciente.  
7. **COGNITIVA-AI-FINETUNING** â†’ Fine-tuning directo de EfficientNet-B3 en **Google Colab (GPU)** con *temperature scaling* y agregaciÃ³n a **nivel paciente**.  
8. **COGNITIVA-AI-FINETUNING-IMPROVED**  â†’ Mejoras de fine-tuning (calibraciÃ³n de probabilidades). Ajustes univariados (normalizaciÃ³n, dropout, etc.).  
9. **COGNITIVA-AI-FINETUNING-STABLE** â†’ Retraining estable de EfficientNet-B3 en **Google Colab (GPU)** con cachÃ© SSD, *temperature scaling* y selecciÃ³n de umbral clÃ­nico (recallâ‰¥0.95). Entrenamiento estable con configuraciÃ³n refinada y early stopping.  
10. **COGNITIVA-AI-FINETUNING-STABLE-PLUS** â†’ VersiÃ³n extendida con calibraciÃ³n adicional y pooling alternativo (mean, median, top-k).  

---

## ðŸ“š Ãndice

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Pipelines experimentales](#pipelines-experimentales)
   - [P1: Datos clÃ­nicos con XGBoost](#p1-datos-clÃ­nicos-con-xgboost)
   - [P2: Datos clÃ­nicos fusionados](#p2-datos-clÃ­nicos-fusionados)
   - [P3: MRI OASIS-2 â€“ ResNet50](#p3-mri-oasis-2--resnet50)
   - [P5: MRI Colab â€“ ResNet18 calibrado](#p5-mri-colab--resnet18-calibrado)
   - [P6: MRI Colab â€“ EfficientNet-B3 embeddings](#p6-mri-colab--efficientnet-b3-embeddings)
   - [P7: MRI Colab â€“ EfficientNet-B3 fine-tuning](#p7-mri-colab--efficientnet-b3-fine-tuning)
   - [P9: MRI Colab â€“ EfficientNet-B3 stable](#p9-mri-colab--efficientnet-b3-stable)
   - [P10: MRI Colab â€“ EfficientNet-B3 stable + calibraciÃ³n](#p10-mri-colab--efficientnet-b3-stable--calibraciÃ³n)
   - [P10-ext: Extensiones y ensembles](#p10-ext-extensiones-y-ensembles)
   - [P11: Backbones alternativos](#p11-backbones-alternativos)
3. [Comparativa global de resultados](#comparativa-global-de-resultados)
4. [DesafÃ­os principales](#desafÃ­os-principales)
5. [Lecciones aprendidas](#lecciones-aprendidas)
6. [PrÃ³ximos pasos](#prÃ³ximos-pasos)

---

## ðŸ“¦ Datos y Variables ClÃ­nicas

El dataset de referencia ha sido **OASIS** (Open Access Series of Imaging Studies), en particular sus cohortes OASIS-2 y derivados:

- **OASIS-1 (transversal):** 416 sujetos, una sola visita por paciente.  
  - No tiene variable `Group`, la severidad se deduce a partir de **CDR** (`0=No demencia`, `>0=Demencia`).  

- **OASIS-2 (longitudinal):** 150 sujetos, mÃºltiples visitas.  
  - Incluye `Group` (`Nondemented`, `Demented`, `Converted`).  

**Variables clÃ­nicas empleadas:**

- **Age** â†’ Edad del paciente en la visita inicial. Factor de riesgo primario en Alzheimer.  
- **Sex** â†’ Sexo biolÃ³gico. El Alzheimer presenta prevalencias distintas en mujeres.  
- **Educ** â†’ AÃ±os de educaciÃ³n formal. Factor protector (mayor reserva cognitiva).  
- **SES** (Socioeconomic Status) â†’ Escala 1â€“5 (mayor valor = mayor estatus). Se ha relacionado con acceso a recursos cognitivos.  
- **MMSE** (Mini-Mental State Examination) â†’ Test neuropsicolÃ³gico de 0â€“30. Valores bajos indican deterioro cognitivo.  
- **CDR** (Clinical Dementia Rating) â†’ Escala clÃ­nica (0=normal, 0.5=mild, 1=moderate, 2â€“3=severe). Considerado estÃ¡ndar de oro para diagnÃ³stico.  
- **eTIV** (Estimated Total Intracranial Volume) â†’ Volumen craneal estimado, usado para normalizar medidas volumÃ©tricas.  
- **nWBV** (Normalized Whole Brain Volume) â†’ ProporciÃ³n de volumen cerebral respecto al intracraneal. Refleja atrofia cerebral.  
- **ASF** (Atlas Scaling Factor) â†’ Factor de escalado anatÃ³mico aplicado en el registro.  

Estas variables combinan **informaciÃ³n clÃ­nica y volumÃ©trica**, proporcionando una visiÃ³n integral de factores de riesgo y biomarcadores estructurales.

---

## Estructura y datasets

**Datasets**  
- **OASISâ€‘1** (crossâ€‘sectional). Etiqueta derivada de **CDR** (CDR=0â†’0, CDR>0â†’1).  
- **OASISâ€‘2** (longitudinal). Etiqueta a partir de **Group** (*Nondemented=0; Demented/Converted=1*).  
- Criterio **primera visita/paciente** (baseline) en OASISâ€‘2 para evitar *leakage* interâ€‘sesiÃ³n.  (En OASIS1 es ya 1 entrada por sujeto).
**Target unificado (binario):**  
- `0 = Nondemented`  
- `1 = Demented` o `Converted` 
- **NaN crÃ­ticos**: eliminamos filas sin `mmse`, `cdr` o `target`.
-  **ImputaciÃ³n**: `ses` y `education` con **mediana**. 
- **CodificaciÃ³n**: one-hot para `sex` (y `hand` si se usa).
-  **Escalado**: `StandardScaler` **ajustado solo en train**.
- **MRI:** archivos `.hdr/.img` por paciente, con segmentaciones asociadas (`FSL_SEG`).  
- MRI: **20 slices axiales** equiespaciadas, normalizaciÃ³n *zâ€‘score* + **CLAHE** opcional.  
- Splits **estratificados a nivel paciente** (sin fuga).

> âš ï¸ **Control estricto de fugas de informaciÃ³n (data leakage):**  
> - En clÃ­nico â†’ seleccionamos **solo una visita por sujeto (baseline)** de cada paciente para no mezclar repeticiones del mismo paciente entre train y test.  
> - Con imÃ¡genes (MRI): el **split es por paciente/scan_id**; todas las slices de un scan quedan en el mismo subset.  

**Estructura de carpetas (clave)**
```
/p11_alt_backbones/          # CatÃ¡logo y matrices patient-level OASIS-1 (base para ensembles)
/p13_oasis2_images/, /p14_oasis2_images/  # EffNet-B3 OASIS-2 (pesos, preds y features)
/p19_meta_ensemble, /p20_meta_calibration, /p21_meta_refine, /p22_meta_ablation
/p24_meta_simple, /p25_informe_final
/p26_intermodal/             # FusiÃ³n Late/Mid + P26b (calibraciÃ³n por cohorte)
/p26_release/                # Release reproducible (modelos, config, QA, docs)
/p27_final/                  # Figuras y tablas finales consolidadas
```
**DocumentaciÃ³n viva**: `README.md` (este), `InformeTecnico.md`, `CuadernoBitacora.md`.

---

## IntroducciÃ³n

El proyecto **Cognitiva-AI** parte de la necesidad de evaluar modelos predictivos que integren datos clÃ­nicos y de imagen (MRI) en cohortes reducidas como OASIS-1/2.  

Desde el inicio se asumiÃ³ que:
- Los **datos clÃ­nicos** podrÃ­an servir como baseline fuerte (edad, MMSE, CDR, etc.).  
- Las **imÃ¡genes cerebrales** aportarÃ­an riqueza multimodal pero con mayor complejidad.  
- SerÃ­a necesario experimentar con **diferentes backbones** de visiÃ³n profunda y con **estrategias de calibraciÃ³n, ensembles y stacking** para compensar el pequeÃ±o tamaÃ±o muestral.  

El proceso se organizÃ³ en **pipelines numerados**. Cada uno corresponde a un conjunto de experimentos exploratorios.  

---

## Pipelines experimentales

A continuaciÃ³n, se detallan los diferentes pipelines experimentales desarrollados en el proyecto. Cada uno introduce una idea nueva, una arquitectura diferente o una estrategia de evaluaciÃ³n alternativa.

### Resumen ejecutivo

- **Mejor modelo unimodal (imagen)**: **P24** (LR elasticâ€‘net sobre features por paciente + **Platt**).  
  - **TEST**: **AUC=0.727** (ALL) Â· **0.754** (OAS1) Â· **0.750** (OAS2).  
  - Umbrales **5:1** (FN:FP): OAS1 **0.435** (Coste=39, R=0.70, P=0.61), OAS2 **0.332** (Coste=12, R=0.92, P=0.61).

- **Modelo intermodal (imagen+clÃ­nico)**: **P26 (Late)** y **P26b (Late + Platt por cohorte)**.  
  - **TEST** P26 Late: **AUC=0.713**, PRâ€‘AUC=0.712, Brier=0.234.  
  - **TEST** P26b (Platt por cohorte): **OAS1 AUCâ‰ˆ0.754 (Brierâ‰ˆ0.199)** Â· **OAS2 AUCâ‰ˆ0.652 (Brierâ‰ˆ0.241)**.

- **PolÃ­tica activa (P27): S2**  
  - Base **5:1** (FN:FP) + **ajuste OAS2** para **Recall objetivo â‰¥0.90** (cribado).  
  - **Umbrales S2**: **OAS1=0.42**, **OAS2â‰ˆ0.4928655288** â†’ en TEST:  
    - OAS1: TP=14, FP=9, TN=18, FN=6 â†’ **R=0.70**, **P=0.609**, Coste=39.  
    - OAS2: TP=11, FP=6, TN=5, FN=1 â†’ **R=0.917**, **P=0.647**, Coste=11.

---

### LÃ­nea temporal (P1â†’P27)

- **P1â€“P4 (local)**: *slicing*, normalizaciÃ³n y primeros baselines tabulares e imagen.  
- **P5â€“P12 (Colab, OASISâ€‘1)**: consolidaciÃ³n de **EffNetâ€‘B3**, agregaciÃ³n por paciente, **catÃ¡logo p11** y **ensembles**.  
- **P13â€“P14 (OASISâ€‘2)**: entrenamiento **EffNetâ€‘B3** especÃ­fico (1 visita/paciente); copia a **SSD Colab** y **class_weight**.  
- **P16â€“P18**: ensembles avanzados (OOF sin fuga, stacking/blending, calibraciÃ³n).  
- **P19**: **Metaâ€‘ensemble (XGB)** con **LR/HGB/GB/RF/LGBM/XGB** como *base learners*.  
- **P20â€“P22**: **calibraciÃ³n** (Platt/IsotÃ³nica), **umbrales por cohorte** y *ablation*.  
- **P23**: **calibraciÃ³n por cohorte con coste** (5:1 FN:FP).  
- **P24**: **meta simple interpretable** (LRâ€‘EN + Platt) â†’ mejor equilibrio generalizaciÃ³n/calibraciÃ³n.  
- **P25**: **consolidaciÃ³n** y tabla maestra (P19/P22/P23/P24).  
- **P26/P26b**: **intermodal** (Late vs Mid) + **calibraciÃ³n por cohorte**; elecciÃ³n **Late**.  
- **P27**: **release reproducible** + **polÃ­tica S2** y figuras finales.

---

### P1: COGNITIVA-AI-CLINIC (datos clÃ­nicos solo OASIS-2) 

- **MotivaciÃ³n:** establecer un baseline sÃ³lido con datos tabulares clÃ­nicos. 
### ðŸ§¹ Preprocesamiento
- **Renombrado a `snake_case`** para legibilidad (`Subject ID â†’ subject_id`, etc.).  
- **SelecciÃ³n de una visita por sujeto**: baseline (mÃ­nimo `mr_delay`) para tener un Ãºnico registro representativo por paciente.  
- ConversiÃ³n de tipos numÃ©ricos y **imputaciÃ³n** (mediana) para columnas con NaN (`ses`, `mmse`, `cdr`, â€¦).  
- CodificaciÃ³n:
  - `sex`: `M â†’ 0`, `F â†’ 1`.  
  - `hand`: one-hot (categorÃ­a desconocida a `Unknown`).

### âš™ï¸ Modelado
- **Modelos base:** Logistic Regression, Random Forest, XGBoost.  
- **ValidaciÃ³n:** `StratifiedKFold` y mÃ©trica **ROC-AUC**.  
- **OptimizaciÃ³n:**  
  - *GridSearchCV* para Random Forest.  
  - **Algoritmo GenÃ©tico (DEAP)** para RF/XGB: bÃºsqueda evolutiva de hiperparÃ¡metros (mÃ¡s eficiente en espacios grandes/no convexos).

> â„¹ï¸ **Por quÃ© ROC-AUC**: mide la capacidad de discriminaciÃ³n a todos los umbrales, robusta ante desbalance moderado y facilita comparaciÃ³n entre modelos.  

### ðŸ“Š Resultados (clÃ­nico)

- **Cross-val (grid/genÃ©tico):**  
  - RF (grid) â†’ mejor ROC-AUC CV â‰ˆ **0.9224**  
  - RF (GA) â†’ mejor ROC-AUC CV â‰ˆ **0.9215**  
  - XGB (GA) â†’ mejor ROC-AUC CV â‰ˆ **0.9215**

- **Test hold-out (final):**
  | Modelo              | ROC-AUC (Test) |
  |---------------------|----------------|
  | Random Forest (opt) | 0.884          |
  | **XGBoost (opt)**   | **0.897**      |

### ðŸ“Š Resultados
- RegresiÃ³n LogÃ­stica â†’ **0.912 Â± 0.050 (CV)**  
- Random Forest â†’ **0.925 Â± 0.032 (CV)**  
- XGBoost â†’ **0.907 Â± 0.032 (CV)**  
- Mejor en test: **XGBoost = 0.897 AUC**  

âž¡ï¸ Primer baseline, estable pero dataset reducido (150 sujetos) y limitado a datos clÃ­nicos.    

**ReflexiÃ³n:**  
Los datos clÃ­nicos solos ya ofrecen un baseline sorprendentemente competitivo. Esto obligÃ³ a replantear si los modelos de imagen podrÃ­an aportar ganancia marginal real.  

---

### P2: COGNITIVA-AI-CLINIC-IMPROVED (datos clÃ­nicos fusionados OASIS-1 + OASIS-2)

- **MotivaciÃ³n:** combinar datos clÃ­nicos fusionados de ambas cohortes para **aumentar la robustez**.
- **UnificaciÃ³n de columnas** (`snake_case`).  
- **SelecciÃ³n baseline** primera visita en OASIS-2.  
- **Target unificado**: `Group` (OASIS-2) o `CDR` (OASIS-1).  
- **ImputaciÃ³n:** SES/EducaciÃ³n â†’ mediana.
- **Escalado y codificaciÃ³n**.
- **Etiquetas de cohortes** para trazabilidad (`OASIS1` vs `OASIS2`). 

### âš™ï¸ Modelado
- Modelos: Logistic Regression, Random Forest, XGBoost.  
- Cross-validation estratificado (5 folds).  Escalado dentro del fold para evitar leakage.
- MÃ©trica principal: **ROC-AUC**.
- **Reproducibilidad**: semillas fijadas y paralelismo limitado.

### ðŸ“Š Resultados  clÃ­nicos tras fusiÃ³n
- **Hold-out inicial (80/20):** LogReg=1.000 | RF=0.986 | XGB=0.991  
- **ValidaciÃ³n cruzada (5-fold):**  
  - LogReg â†’ **0.979 Â± 0.012**  
  - RF â†’ **0.974 Â± 0.018**  
  - XGB â†’ **0.975 Â± 0.021**  

âž¡ï¸ La fusiÃ³n de datasets clÃ­nicos genera modelos **muy estables y con excelente generalizaciÃ³n**.  

### âš–ï¸ Manejo del desbalance
- DistribuciÃ³n real â‰ˆ 54% vs 46% â†’ ligero desbalance.  
- Estrategias usadas: `class_weight=balanced` y ajuste de **umbral clÃ­nico** para priorizar **recall**.    

### ðŸ©º Umbral clÃ­nico (XGBoost)
- Ajustado para maximizar **recall (â‰ˆ100%)**.  
- Resultado: recall perfecto, con mÃ¡s falsos positivos (~15/77 test).  
- InterpretaciÃ³n clÃ­nica: **preferimos un falso positivo antes que un falso negativo**, ya que permite tratar antes. 

- ObservaciÃ³n: el aumento de datos clÃ­nicos mejora la capacidad predictiva.  

### ðŸ©º Interpretabilidad
- **Coeficientes LR:**  
  - CDR (coef â‰ˆ 4.15) â†’ predictor mÃ¡s fuerte.  
  - MMSE (negativo fuerte).  
  - VolumÃ©tricas (eTIV, nWBV, ASF) menos influyentes.  
- **AblaciÃ³n:**  
  - Sin CDR â†’ AUC = 0.86.  
  - Sin CDR+MMSE â†’ AUC = 0.76.  
  - Sin volumÃ©tricas â†’ AUC â‰ˆ 1.0.  

âž¡ï¸ **ConclusiÃ³n clÃ­nica:** los test **CDR + MMSE son crÃ­ticos**, las volumÃ©tricas aportan menos.  

### ðŸ”§ CalibraciÃ³n y Robustez
- Mejor calibrado: **LogReg + IsotÃ³nica (Brier=0.010)**.  
- Nested CV (10x5) â†’ ROC-AUC = **0.985 Â± 0.011**.  
- Ensemble (LR+RF+XGB) â†’ ROC-AUC â‰ˆ **0.995**.  

- **Modelo:** XGBoost extendido.  
- **Resultados:**  
  - AUC (Test): 0.991  
  - Recall cercano a 1.0  

**ReflexiÃ³n:**  
La fusiÃ³n clÃ­nica alcanza casi techo de rendimiento en esta cohorte. Refuerza la hipÃ³tesis de que la MRI aporta, sobre todo, complementariedad mÃ¡s que superioridad aislada.  

---

### P3: COGNITIVA-AI-IMAGES (MRI OASIS-2) â€“ ResNet50

- **MotivaciÃ³n:** baseline en imÃ¡genes MRI con un backbone clÃ¡sico.  
- **ðŸ› ï¸ Preprocesamiento de imÃ¡genes**
- ConversiÃ³n de `.hdr/.img` a **slices PNG** (cortes axiales centrales).  
- **NormalizaciÃ³n** 0â€“255, opciÃ³n de **CLAHE**, y **z-score por slice**.  
- **Data augmentation** (train): flips, rotaciones Â±10Â°, jitter ligero.  
- **EvaluaciÃ³n por paciente**: promediado de probabilidades por `scan_id`.
- **Pipeline**: conversiÃ³n `.hdr/.img` a cortes axiales (slices), normalizaciÃ³n [0â€“255], augmentations ligeros.

- **Modelo:** ResNet50 preentrenado en ImageNet, fine-tuning en OASIS-2.  
- **Resultados:**  
  - 5 slices â†’ **AUC=0.938 (test)**  
  - 20 slices + z-score â†’ AUC=0.858 (mayor recall, menor precisiÃ³n). 

  ## ðŸ“Š Resultados (MRI â€“ nivel paciente)

> **Split estratificado por paciente 60/20/20** (train/val/test)

| ConfiguraciÃ³n | Preprocesamiento | Train Acc | Val Acc | Test Acc | ROC-AUC | Comentarios |
|---|---|---:|---:|---:|---:|---|
| **5 slices** | **Sin CLAHE** | â†‘ (â‰ˆ0.94) | â‰ˆ0.73 | **0.89** | **0.938** | LÃ­nea base fuerte; generaliza bien en test. |
| 5 slices | CLAHE | â‰ˆ0.95 | â‰ˆ0.72 | 0.69 | 0.777 | Mejora visual, pero menor discriminaciÃ³n; probable realce de ruido. |
| 5 slices | CLAHE + z-score | â‰ˆ0.96 | â‰ˆ0.75 | 0.72 | 0.820 | Recupera estabilidad; mejor balance entre clases, sigue < baseline. |
| **20 slices** | CLAHE + z-score | **0.98** | â‰ˆ0.71 | **0.80** | **0.858** | MÃ¡s cobertura anatÃ³mica; mejora global respecto a CLAHE, aunque con algo de sobreajuste. |

**ConclusiÃ³n MRI:**  
- El **baseline sin CLAHE con 5 slices** fue el mÃ¡s alto en **ROC-AUC (0.94)** en nuestro test.  
- **Aumentar a 20 slices** mejora la robustez general y el *recall* de la clase positiva, pero aÃºn no supera al baseline en ROC-AUC.  
- **CLAHE** debe usarse con cautela (o de forma selectiva) y acompaÃ±ado de normalizaciÃ³n adecuada.

## ðŸ§  Decisiones de diseÃ±o (y por quÃ©)

- **Binarizar `Group`** (`Nondemented` vs `Demented/Converted`): simplifica el problema y mejora estabilidad en CV y test.  
- **Una visita por sujeto (clÃ­nico)**: evita duplicar pacientes y **fuga de informaciÃ³n**.  
- **Split por paciente (imÃ¡genes)**: todas las slices de un `scan_id` deben ir al mismo subset â†’ evaluaciÃ³n realista.  
- **EvaluaciÃ³n por paciente** (MRI): lo clÃ­nicamente relevante es la clasificaciÃ³n del **paciente**, no de cada corte aislado.  
- **Early stopping**: protege frente a sobreajuste visible (train â‰« val).  
- **MÃ©trica ROC-AUC**: adecuada con clases desbalanceadas/moderadas y para comparar modelos a distintos umbrales.

**ReflexiÃ³n:**  
Primer resultado fuerte en imagen pura. Abre la puerta a comparar clÃ­nico vs imagen.  
Dependiente del preprocesamiento y costoso en CPU.

---

### ðŸ”¹ ClÃ­nico â€“ OASIS-2 (tabular)

| Modelo / Variante                      | ValidaciÃ³n (CV 5-fold)         | Test hold-out | Notas |
|---------------------------------------|---------------------------------|---------------|-------|
| Logistic Regression (baseline)        | **0.912 Â± 0.050**               | 0.911 (AUC)   | Split inicial; buen baseline y muy estable |
| Random Forest (balanced)              | **0.925 Â± 0.032**               | â€”             | CV alto con `class_weight` |
| XGBoost (default)                     | **0.907 Â± 0.032**               | â€”             | Buen baseline |
| **RF (GridSearchCV, mejor)**          | **0.922**                       | â€”             | Ajuste clÃ¡sico |
| **RF (Alg. GenÃ©tico, mejor)**         | **0.922**                       | â€”             | DEAP; rendimiento parejo al grid |
| **XGBoost (Alg. GenÃ©tico, mejor)**    | **0.922**                       | â€”             | GA efectivo |
| **RF (optimizado, test)**             | â€”                               | **0.884**     | Test de referencia |
| **XGBoost (optimizado, test)**        | â€”                               | **0.897**     | **Mejor en test** |

> *MÃ©tricas clÃ­nicas: ROC-AUC. El test se hizo con un split estratificado y honesto por paciente.*

---

### ðŸ”¹ ImÃ¡genes â€“ OASIS-2 (ResNet50, nivel **paciente**)

| Slices | Preprocesamiento                 | Train Acc | Val Acc | **Test Acc** | **ROC-AUC** | Comentarios |
|-------:|----------------------------------|----------:|--------:|-------------:|------------:|-------------|
| **5**  | **Sin CLAHE**                    | ~0.94     | ~0.73   | **0.89**     | **0.938**   | **Mejor AUC**; baseline fuerte |
| 5      | CLAHE                            | ~0.95     | ~0.72   | 0.69         | 0.777       | Realce local perjudicÃ³ patrones sutiles |
| 5      | CLAHE + z-score (slice)          | ~0.96     | ~0.75   | 0.72         | 0.820       | Recupera parte del rendimiento |
| **20** | CLAHE + z-score (slice)          | **0.98**  | ~0.71   | **0.80**     | **0.858**   | MÃ¡s cobertura anatÃ³mica; mejor recall |

> **ConclusiÃ³n OASIS-2 (imÃ¡genes):** el **baseline 5 slices sin CLAHE** obtuvo el **mejor AUC (0.938)**; usar mÃ¡s slices (20) mejora robustez y recall pero no supera ese AUC en nuestro test.

---

### P4: COGNITIVA-AI-IMAGES-IMPROVED (MRI OASIS-1/2)

- Objetivo: fusionar OASIS-1 y OASIS-2 en imÃ¡genes.  
- Ventaja: aumentar el nÃºmero de pacientes y la robustez del modelo.  

### ðŸ”§ Decisiones de diseÃ±o
- GeneraciÃ³n de **embeddings ResNet18** (preentrenado en ImageNet) de dimensiÃ³n 512 por slice axial.  
- ClasificaciÃ³n con **Logistic Regression**.  
- **CalibraciÃ³n isotÃ³nica** mediante `CalibratedClassifierCV`.  
- EvaluaciÃ³n tanto a nivel **slice** como **paciente** (media de probabilidades).  
- **Split paciente/scan** estricto.  
- **MÃ¡s slices** por paciente. 

### ðŸ“Š Resultados
- **Sin calibrar (LR):**  
  - Val: AUC â‰ˆ 0.624 | Test: AUC â‰ˆ 0.661  
  - Brier â‰ˆ 0.33 (probabilidades poco confiables)  

- **Con calibrado (LR + isotÃ³nica):**  
  - Val: AUC â‰ˆ 0.639 | Test: AUC â‰ˆ 0.656  
  - Brier â‰ˆ 0.23 (**mejora sustancial en calidad probabilÃ­stica**)  

- **Nivel paciente (thr=0.5):**  
  - Val: AUC=0.730, PR-AUC=0.641, Recall=0.25  
  - Test: AUC=0.719, PR-AUC=0.610, Recall=0.40  

- **Umbral clÃ­nico ajustado (thrâ‰ˆ0.40, recallâ‰¥0.90 en Val):**  
  - Val: Recall=0.90 | Precision=0.64  
  - Test: Recall=0.70 | Precision=0.56  

### ðŸ©º ConclusiÃ³n
El calibrado isotÃ³nico no incrementa la discriminaciÃ³n (AUC estable â‰ˆ0.72), pero **reduce drÃ¡sticamente el error de probabilidad (Brier Score)**, haciendo que las salidas del modelo sean mÃ¡s confiables para escenarios clÃ­nicos. Se establece un **baseline robusto en GPU**, desde el que explorar mejoras adicionales (otros clasificadores, pooling mÃ¡s sofisticado, modelos 2.5D/3D).

Pipeline mÃ¡s robusto, pero alto coste computacional en CPU.  

---

### P5: COGNITIVA-AI-IMAGES-IMPROVED-GPU â€“ ResNet18 calibrado

- **MotivaciÃ³n:** probar backbone mÃ¡s ligero en entorno Colab (para usar GPUs).  
- **Modelo:** ResNet18 (512D) con calibraciÃ³n posterior.
- ValidaciÃ³n cruzada interna (cv=5), evitando el uso de `cv='prefit'` (deprecado en scikit-learn â‰¥1.6).
- ClasificaciÃ³n con **Logistic Regression**.  
- **CalibraciÃ³n isotÃ³nica**.    
- **Resultados:**  
- **Slice-nivel (thr=0.5)**  
  - [VAL] Acc=0.62 | AUC=0.627 | PR-AUC=0.538 | Brier=0.296 | P=0.57 | R=0.43  
  - [TEST] Acc=0.62 | AUC=0.661 | PR-AUC=0.535 | Brier=0.289 | P=0.57 | R=0.47  

 - **Paciente-nivel (thrâ‰ˆ0.20, recallâ‰¥0.90):**  
Se evaluaron tres estrategias de pooling (`mean`, `max`, `wmean`).  
  - Con **mean @0.5**: [VAL] AUC=0.722 | PR-AUC=0.634 | Acc=0.53 | P=0.42 | R=0.25  
  - Con **max @0.5**: [VAL] AUC=0.664 | PR-AUC=0.539 | Acc=0.49 | P=0.45 | R=0.95  

  Para un escenario clÃ­nico se fijÃ³ un **umbral bajo (thrâ‰ˆ0.204)** en validaciÃ³n, garantizando **recall â‰¥0.90**:  
  - [VAL] AUC=0.722 | PR-AUC=0.634 | Acc=0.70 | P=0.60 | R=0.90  
  - [TEST] AUC=0.724 | PR-AUC=0.606 | Acc=0.60 | P=0.52 | R=0.80  

ðŸ“Œ ConclusiÃ³n: la calibraciÃ³n isotÃ³nica estabiliza las probabilidades (mejor Brier score) y, con un umbral clÃ­nico bajo, se alcanzan **sensibilidades altas (Râ‰ˆ0.8 en test)**, lo cual es preferible en un escenario de cribado temprano de Alzheimer.

**ReflexiÃ³n:**  
La calibraciÃ³n ayudÃ³ a controlar la sobreconfianza, pero los resultados son inferiores a ResNet50.  

---

# ðŸ“Š Comparativa Parcial P1-P5

| Modalidad       | Dataset            | Modelo        | ROC-AUC | Notas |
|-----------------|--------------------|---------------|---------|-------|
| ClÃ­nico         | OASIS-2            | XGBoost       | 0.897   | Mejor tabular OASIS-2 |
| ClÃ­nico Fusion  | OASIS-1+2          | LogReg        | 0.979   | Simple, interpretable |
| ImÃ¡genes        | OASIS-2            | ResNet50 (5s) | 0.938   | Mejor en MRI |
| ClÃ­nico Fusion  | OASIS-1+2 Ensemble | LR+RF+XGB     | 0.995   | **Mejor global** |

---

### P6: MCOGNITIVA-AI-IMAGES-IMPROVED-GPU-CALIBRATE â€“ EfficientNet-B3 embeddings

- **MotivaciÃ³n:** usar EfficientNet-B3 solo como extractor de embeddings, sin fine-tuning completo.  
- **Embeddings EfficientNet-B3 (1536D)**.  
- Modelos: LR, XGB, MLP a nivel paciente.  
- **Ensemble LR+XGB** ponderado por PR-AUC. 
- **Resultados:**  
  - [VAL] AUC=0.815 | PR-AUC=0.705 | Recall=0.95 | Acc=0.70  
  - [TEST] AUC=0.704 | PR-AUC=0.623 | Recall=0.90 | Acc=0.70  

**ReflexiÃ³n:**  
Como extractor simple ya supera ResNet18 calibrado, confirmando potencia de EfficientNet.  Mejor pipeline MRI hasta la fecha, con sensibilidad alta.

---

### P7: COGNITIVA-AI-FINETUNING (EfficientNet-B3 Fine-Tuning parcial)

- **MotivaciÃ³n:** pasar a fine-tuning completo de EfficientNet-B3.  
- **Modelo:** EfficientNet-B3 pre-entrenado (Imagenet) con Ãºltima(s) capas descongeladas y reentrenadas sobre MRI OASIS-2.
- **Entrenamiento:** Google Colab GPU (T4), early stopping guiado por PR-AUC en validaciÃ³n.
- **Pooling por paciente:** pruebas con promedio vs. atenciÃ³n (pesos por importancia de slice).  
- **CalibraciÃ³n:** *temperature scaling* con **T=2.673**  
- **Umbral clÃ­nico:** **0.3651**  
- **Artefactos generados:**  
  - `ft_effb3_colab/best_ft_effb3.pth`  
  - `ft_effb3_colab/train_history.json`  
  - `ft_effb3_colab/ft_effb3_patient_eval.json`  
  - `ft_effb3_colab/graphs_from_metrics/â€¦`
- **Resultados (nivel paciente, n=47):**  
  - **VAL** â†’ AUC=**0.748** | PR-AUC=**0.665** | Acc=**0.702** | Precision=**0.588** | Recall=**1.0**  
  - **TEST** â†’ AUC=**0.876** | PR-AUC=**0.762** | Acc=**0.745** | Precision=**0.625** | Recall=**1.0**  

**Matriz de confusiÃ³n TEST (reconstruida, thr=0.3651):**  
**TP=8, FP=5, TN=34, FN=0**

- **DesempeÃ±o bruto (thr=0.5):** VAL AUCâ‰ˆ0.75 | PR-AUCâ‰ˆ0.66; TEST AUCâ‰ˆ0.87 | PR-AUCâ‰ˆ0.76
- **Recall por defecto (thr=0.5):** bajo en VAL (~0.40) y TEST (~0.55) con precisiÃ³n alta (~0.85 test), indicando muchos casos positivos omitidos. 

âž¡ï¸ El fine-tuning mejora sustancialmente la discriminaciÃ³n (AUC) respecto a pipelines previos (AUC_test ~0.87 vs ~0.70 en pipeline 6), pero con umbral estÃ¡ndar aÃºn no alcanza sensibilidad adecuada (recall 55% en test).

**ReflexiÃ³n:**  
Uno de los mejores backbones en imagen pura. Supone el nuevo baseline de referencia.  

---

### P8: COGNITIVA-AI-IMAGES-FT-IMPROVED (CalibraciÃ³n y ajustes Fine-tune)

- **CalibraciÃ³n de probabilidades:**  se aplicÃ³ `Temperature Scaling` en validaciÃ³n para corregir el sesgo de confianza del modelo (evitando tÃ©cnicas prefit con riesgo de fuga de datos).
- **Pooling Ã³ptimo:** la agregaciÃ³n por *atenciÃ³n* superÃ³ ligeramente al promedio en mÃ©tricas de validaciÃ³n (PR-AUC), por lo que se adoptÃ³ para el pipeline final.
- **MÃ©tricas calibradas:** tras calibraciÃ³n, las predicciones resultaron mÃ¡s fiables (mejor Brier Score y distribuciÃ³n probabilÃ­stica mÃ¡s alineada).

ðŸ“Š Resultados:
- **VAL (calibrado, attn):** AUCâ‰ˆ0.75 | PR-AUCâ‰ˆ0.66 (similar a bruto, seÃ±al consistente).
- **TEST (calibrado, attn):** AUCâ‰ˆ0.88 | PR-AUCâ‰ˆ0.76 (sin cambio notable en AUC, confirma generalizaciÃ³n).
- **Nota:** La calibraciÃ³n no altera el AUC, pero asegura que las probabilidades reflejen riesgo real. Se observÃ³ mejora cualitativa en la confiabilidad de las predicciones.

âž¡ï¸ La calibraciÃ³n interna del modelo eliminÃ³ leakage y ajustÃ³ las salidas probabilÃ­sticas, dejando el modelo listo para aplicar un umbral clÃ­nico en validaciÃ³n.

---

### P9: COGNITIVA-AI-FINETUNING-STABLE â€“ EfficientNet-B3 stable (Fine Tunning + Umbral ClÃ­nico)

- **MotivaciÃ³n:** estabilizar entrenamientos previos de EfficientNet-B3.  
- **Pooling paciente:** mean  
- **CalibraciÃ³n:** temperature scaling (T=2.048)  
- **Umbral clÃ­nico:** 0.3400 (selecciÃ³n en VAL con recallâ‰¥0.95)
- **SelecciÃ³n de umbral clÃ­nico:** a partir de la curva Precision-Recall en validaciÃ³n se eligiÃ³ el menor umbral con recall â‰¥90% y mÃ¡xima precisiÃ³n. Obtuvo thrâ‰ˆ0.36 en probabilidades de paciente.

**Resultados (nivel paciente):**  
- VAL â†’ AUC=1.000 | PR-AUC=1.000 | Acc=1.000 | P=1.000 | R=1.000 | thr=0.3400 | n=10  
- TEST â†’ AUC=0.663 | PR-AUC=0.680 | Acc=0.574 | P=0.500 | R=0.650 | thr=0.3400 | n=47

ðŸ“Š Resultados (Paciente-nivel (thrâ‰ˆ0.36, recall=1.00)):
- [VAL] Recall=1.00 | Precision=0.59 | AUC=0.748
- [TEST] Recall=1.00 | Precision=0.62 | AUC=0.876

**Comparativa rÃ¡pida vs Pipeline 7 (FT previo):** TEST AUC: 0.585 â†’ 0.663, TEST PRâ€‘AUC: 0.582 â†’ 0.680

âž¡ï¸ Mejor pipeline MRI logrado: se detectan el 100% de los casos positivos en test (sin falsos negativos) al costo de algunos falsos positivos (precision ~62%). El modelo fine-tune calibrado ofrece asÃ­ alta sensibilidad adecuada para cribado clÃ­nico, acercando el rendimiento MRI al nivel de los datos clÃ­nicos puros.

- **Resultados finales:**  
  - AUC (Test): 0.740  
  - PR-AUC: 0.630  
  - Recall mÃ¡s bajo que en P7.  

**Incidencias:**  
- SaturaciÃ³n de logits detectada.  
- Variabilidad alta entre seeds.  

**ReflexiÃ³n:**  
Confirma que la estabilidad no siempre se traduce en mejor rendimiento.  

---

### P10: COGNITIVA-AI-FINETUNING-STABLE-PLUS (EffNet-B3 con calibraciÃ³n extendida)

- **MotivaciÃ³n:** El pipeline 9 (Stable) aportaba estabilidad, pero arrastraba problemas de correspondencia entre checkpoints y arquitectura, ademÃ¡s de no incluir calibraciÃ³n explÃ­cita. Pipeline 10 surge para **normalizar completamente el checkpoint, asegurar compatibilidad de pesos (99.7% cargados) y aplicar calibraciÃ³n final** (*temperature scaling*) : aplicar calibraciÃ³n explÃ­cita (Platt scaling, temperature scaling) para corregir sobreconfianza.
- **MÃ©todo:** Platt scaling, isotonic regression y temperature scaling. 
- **ConfiguraciÃ³n tÃ©cnica:**  
  - Arquitectura: EfficientNet-B3 con salida binaria.  
  - Checkpoint limpio (`best_effb3_stable.pth`), reconstruido desde `effb3_stable_seed42.pth`.  
  - NormalizaciÃ³n robusta de pesos: conversiÃ³n de checkpoint entrenado a formato limpio.  
  - CalibraciÃ³n: *temperature scaling* (Tâ‰ˆ2.3) sobre logits + ajuste de umbral F1.  
  - Pooling a nivel paciente: mean, median y variantes top-k.  
  - EvaluaciÃ³n sobre cohortes: **VAL=47 pacientes**, **TEST=47 pacientes**. 
### ðŸ“Š Resultados finales (nivel paciente)

| Pooling   | AUC (VAL) | PR-AUC (VAL) | AUC (TEST) | PR-AUC (TEST) | Recall TEST | Precision TEST |
|-----------|-----------|--------------|------------|---------------|-------------|----------------|
| mean      | 0.630     | 0.667        | 0.546      | 0.526         | 1.0         | 0.47           |
| median    | 0.643     | 0.653        | 0.541      | 0.513         | 1.0         | 0.48           |
| top-k=0.2 | 0.602     | 0.655        | 0.583      | 0.502         | 1.0         | 0.49    

- **Resultados:**  
  - AUC (Test): 0.546â€“0.583  
  - PR-AUC: 0.50â€“0.53  
  - Recall: 1.0 pero precisiÃ³n baja (~0.47â€“0.49)  

**ConclusiÃ³n:** el pipeline 10 logra **recall=1.0 en test bajo todos los mÃ©todos de pooling**, lo que lo convierte en la opciÃ³n mÃ¡s sensible para cribado clÃ­nico temprano, aunque con sacrificio en AUC y precisiÃ³n. Cierra la etapa de *solo MRI* antes de avanzar a la fusiÃ³n multimodal.

âž¡ï¸ Aunque los valores AUC bajaron frente a Pipeline 9, se gana **robustez en calibraciÃ³n y recall=1.0** bajo distintos mÃ©todos de pooling: Recall alto pero precisiÃ³n baja

**ObservaciÃ³n:**  Se documentan dificultades de estabilidad y saturaciÃ³n de logits.

**ReflexiÃ³n:**  
La calibraciÃ³n ayudÃ³ a controlar la sobreconfianza pero sacrificÃ³ precisiÃ³n.  

---

## P10-ext: Agregaciones avanzadas y Ensemble MRI

Tras la fase inicial del pipeline 10, en la que se demostrÃ³ la posibilidad de alcanzar *recall=1.0* en test bajo distintos mÃ©todos de pooling sliceâ†’patient, se llevÃ³ a cabo una segunda baterÃ­a de experimentos orientados a mejorar la **precisiÃ³n clÃ­nica** sin renunciar a la alta sensibilidad.  

#### ðŸ”¹ Estrategias evaluadas
- **Agregaciones robustas**:  
  - *TRIMMED mean* (media recortada al 20%, eliminando los extremos para mitigar outliers).  
  - *TOP-k slices* (promedio de las k slices mÃ¡s â€œpatolÃ³gicasâ€ segÃºn logit, con k=3 y k=7).  
- **Ensemble MRI**:  
  - CombinaciÃ³n lineal de tres agregaciones (MEAN, TRIMMED, TOP7), con pesos ajustados mediante bÃºsqueda en validaciÃ³n para maximizar PR-AUC.  
  - Pesos finales: **mean=0.30, trimmed=0.10, top7=0.60**.

#### ðŸ“Š Resultados complementarios (nivel paciente)

| MÃ©todo              | AUC (VAL) | PR-AUC (VAL) | AUC (TEST) | PR-AUC (TEST) | Recall TEST | Precision TEST |
|---------------------|-----------|--------------|------------|---------------|-------------|----------------|
| TRIMMED (Î±=0.2)     | 0.894     | 0.905        | 0.744      | 0.746         | 0.75        | 0.56           |
| TOP3                | 0.902     | 0.903        | 0.743      | 0.698         | 0.35        | 0.70           |
| TOP7                | 0.900     | 0.912        | 0.743      | 0.726         | 0.50        | 0.71           |
| **Ensemble (M+T+7)**| 0.913     | 0.925        | 0.754      | 0.737         | 0.70        | **0.61**       |

#### âœ… ConclusiÃ³n ampliada
El complemento al pipeline 10 muestra que:  
- **TRIMMED** sigue siendo la mejor variante para maximizar sensibilidad pura.  
- **TOP-k** ofrece alternativas mÃ¡s conservadoras, con mayor precisiÃ³n pero menor recall.  
- **El ensemble** logra un equilibrio clÃ­nico mÃ¡s sÃ³lido: mantiene recall en 0.70 en test y mejora la precisiÃ³n hasta 0.61, elevando tambiÃ©n la exactitud global.  

Con esta extensiÃ³n, el pipeline 10 no solo asegura **recall=1.0 como cribado clÃ­nico temprano**, sino que tambiÃ©n aporta una variante optimizada para **escenarios de uso real**, donde la precisiÃ³n adicional reduce falsos positivos innecesarios antes de pasar a pruebas complementarias.

---

### P10-ext2: seed-ensemble (EffNet-B3 seeds 41/42/43)

Probamos un *ensemble* por semillas sobre las mismas cohortes (VAL/TEST, 47/47) reproduciendo las TTA del cuaderno 10 (orig, flipH, flipV, rot90) y calibraciÃ³n posterior. 
Pese a normalizar logits (z-score en VAL) y aplicar **temperature scaling** y **Platt scaling**, el rendimiento se mantuvo plano:

- **seedENS_MEAN / TRIMMED / TOP7** â†’ **AUC_TEST ~0.46â€“0.52**, **PR-AUC_TEST ~0.41â€“0.45**, con *recall* elevado pero **precisiÃ³n baja** y umbrales degenerando hacia 0.  
- DiagnÃ³stico: **inconsistencia de escala** entre checkpoints y/o *drift* de distribuciÃ³n en logits. La calibraciÃ³n posterior no logrÃ³ recuperar separabilidad.

**DecisiÃ³n:** descartar el *seed-ensemble* en esta fase y consolidar el **ensemble por agregadores a nivel paciente** (mean+trimmed+top7) calibrado en VAL, que sÃ­ logra **recall â‰¥ 0.9â€“1.0** con mÃ©tricas PR-AUC/AUC superiores.

---

### P10-ext3: Random Search de ensembles

Tras obtener resultados sÃ³lidos con pooling clÃ¡sico y variantes top-k, exploramos la combinaciÃ³n **aleatoria de pesos normalizados** sobre las features derivadas a nivel paciente (`mean`, `trimmed20`, `top7`, `pmean_2`).

- **ConfiguraciÃ³n:**  
  - 500 combinaciones aleatorias.  
  - Pesos restringidos a â‰¥0 y normalizados a 1.  
  - SelecciÃ³n por F1-score en validaciÃ³n.

- **Mejor combinaciÃ³n encontrada:**  
  - mean â‰ˆ 0.32  
  - trimmed20 â‰ˆ 0.31  
  - top7 â‰ˆ 0.32  
  - pmean_2 â‰ˆ 0.04  

- **Resultados:**  
  - [VAL] AUC=0.909 | PR-AUC=0.920 | Recall=0.95 | Acc=0.87 | Prec=0.79  
  - [TEST] AUC=0.754 | PR-AUC=0.748 | Recall=0.70 | Acc=0.66 | Prec=0.58  

**ConclusiÃ³n:** el ensemble aleatorio confirma la **robustez de top7 + mean + trimmed**, alcanzando resultados estables y comparables al stacking. Refuerza que la informaciÃ³n MRI puede combinarse de forma no lineal para mejorar recall y estabilidad.

---

### P10-ext4: Ensembles avanzados

Tras comprobar que la estrategia de ensembles por semillas (*seed ensembles*) no ofrecÃ­a mejoras (AUC cercano a 0.5 en TEST), se exploraron alternativas de combinaciÃ³n a nivel paciente:

- **Random Search ensemble** (mean, trimmed20, top7, pmean_2):  
  - [VAL] AUC=0.909 | PR-AUC=0.920 | Recall=0.95 | Acc=0.87  
  - [TEST] AUC=0.754 | PR-AUC=0.748 | Recall=0.70 | Acc=0.66  

- **Stacking con Logistic Regression**:  
  - Resultados equivalentes al Random Search, con coeficientes positivos y equilibrados â†’ todos los agregadores aportan.  
  - MÃ¡s interpretable y estable que el Random Forest o el stacking rÃ­gido.

**ConclusiÃ³n:** los ensembles ponderados consolidan Pipeline 10 como el mejor punto de partida para MRI-only antes de pasar a multimodal. El recall clÃ­nicamente relevante (â‰¥0.95 en validaciÃ³n, 0.70 en test) se mantiene, mientras que la precisiÃ³n mejora frente a pooling simples.

---

### ðŸ“Š Comparativa de estrategias MRI-only (TEST)

| MÃ©todo                | AUC   | PR-AUC | Acc   | Recall | Precision |
|-----------------------|-------|--------|-------|--------|-----------|
| Pooling mean          | 0.546 | 0.526  | 0.55  | 1.00   | 0.47      |
| Pooling trimmed20     | 0.744 | 0.746  | 0.64  | 0.75   | 0.56      |
| Pooling top7          | 0.743 | 0.726  | 0.70  | 0.50   | 0.71      |
| Random Search ensemble| 0.754 | 0.748  | 0.66  | 0.70   | 0.58      |
| Stacking LR ensemble  | 0.754 | 0.748  | 0.66  | 0.70   | 0.58      |

**ConclusiÃ³n:**  
- Los ensembles (Random Search y Logistic Regression) **superan claramente** a los pooling simples.  
- Se logra un **balance Ã³ptimo entre recall clÃ­nicamente crÃ­tico y precisiÃ³n**, manteniendo recall â‰¥0.70 en TEST y alcanzando PR-AUC ~0.75.  

---

### P10-ext-resumen: Extensiones y ensembles

- **MotivaciÃ³n:** explotar estrategias de **ensembles y stacking** con EfficientNet-B3.  
- **Estrategias:**  
  - Seed ensembles (mean, trimmed, top7)  
  - Random forest sobre features derivadas  
  - Stacking logÃ­stico  
- **Resultados destacados:**  
  - Ensemble (mean+trimmed20+top7+p2): Test AUC ~0.75  
  - Stacking LR sobre seeds: Test AUC ~0.75  

**ReflexiÃ³n:**  
El ensemble aporta mejoras modestas pero consistentes. Se consolida como estrategia Ãºtil. El ensembling estabiliza pero no revoluciona.

---

### P11: COGNITIVA-AI-BACKBONES

- **MotivaciÃ³n:** unque EfficientNet-B3 habÃ­a sido el backbone principal en pipelines anteriores, quisimos explorar si arquitecturas alternativas podÃ­an mejorar la capacidad de generalizaciÃ³n y robustez del modelo. La hipÃ³tesis: *distintas arquitecturas pueden capturar caracterÃ­sticas complementarias de las imÃ¡genes cerebrales*: comprobar si otros backbones de visiÃ³n podÃ­an superar a EfficientNet-B3.  
- **ConfiguraciÃ³n tÃ©cnica:**  
  - Entrenamiento en Colab con mapas OASIS (`oas1_val_colab_mapped.csv` y `oas1_test_colab_mapped.csv`).  
  - ReutilizaciÃ³n de la misma configuraciÃ³n de splits y mÃ©tricas que pipeline 10 para garantizar comparabilidad.  
  - Resultados guardados en `/p11_alt_backbones`.  
- **Modelos probados:**  
  - ResNet-50  
  - DenseNet-121  
  - ConvNeXt-Tiny  
  - Swin-Tiny  
- **Resultados preliminares:**  
  - ResNet-50: Test AUC ~0.74  
  - DenseNet-121: Test AUC ~0.34 (muy bajo)  
  - ConvNeXt-Tiny: Test AUC ~0.50  
  - Swin-Tiny: Test AUC ~0.64 (con top7 pooling)  

**Incidencias:**  
- Varios problemas de montaje de Google Drive tras semanas sin reiniciar Colab.  
- Ficheros dispersos en directorios distintos (ej. slice vs patient).  
- Necesidad de armonizar columnas (`y_score` vs `sigmoid(logit)`).  

**ReflexiÃ³n:**  
NingÃºn backbone supera claramente a EfficientNet-B3,  aunque ResNet50 y SwinTiny muestran competitividad parcial.
La vÃ­a lÃ³gica pasa a ser **ensembles de backbones**.  

---

## Comparativa global de resultados (P1-P11)

| Pipeline | Modalidad        | Modelo                       | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|------------------------------|------------|--------|-------|--------|-----------|
| P1       | ClÃ­nico OASIS-2 | XGB                          | 0.897      | â€”      | â€”     | â€”      | â€”         |
| P2       | ClÃ­nico fusion  | XGB                          | 0.991      | â€”      | â€”     | ~1.0   | â€”         |
| P3       | MRI OASIS-2     | ResNet50                     | 0.938      | â€”      | â€”     | â€”      | â€”         |
| P5       | MRI Colab       | ResNet18 + Calib             | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed              | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune           | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable             | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib       | 0.546â€“0.583| 0.50â€“0.53 | 0.51â€“0.55 | 1.0 | 0.47â€“0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble         | 0.754      | 0.737  | 0.68  | 0.70   | 0.61      |
| P11      | MRI Colab       | ResNet-50 alt backbone       | 0.740      | 0.730  | 0.64  | 0.70   | 0.56      |
| P11      | MRI Colab       | ConvNeXt-Tiny (mean pooling) | 0.509      | 0.479  | 0.49  | 1.00   | 0.45      |
| P11      | MRI Colab       | DenseNet-121 (trimmed20)     | 0.343      | 0.407  | 0.32  | 0.75   | 0.36      |
| P11      | MRI Colab       | Swin-Tiny (top7 pooling)     | 0.641      | 0.597  | 0.55  | 0.95   | 0.95      |

---

### ðŸ“Š Comparativa de backbones (Pipeline 11)

Tras probar diferentes arquitecturas como alternativa a EfficientNet-B3, resumimos sus mÃ©tricas en **test**:

| Backbone        | AUC (Test) | PR-AUC (Test) | Acc   | Recall | Precision |
|-----------------|------------|---------------|-------|--------|-----------|
| ResNet-50       | 0.740      | 0.730         | 0.64  | 0.70   | 0.56      |
| DenseNet-121    | 0.343      | 0.407         | 0.32  | 0.75   | 0.36      |
| ConvNeXt-Tiny   | 0.509      | 0.479         | 0.49  | 1.00   | 0.45      |
| Swin-Tiny       | 0.641      | 0.597         | 0.55  | 0.95   | 0.95      |

ðŸ“Œ **Observaciones:**
- **ResNet-50** sigue siendo competitivo, muy en lÃ­nea con EffNet-B3 calibrado.
- **Swin-Tiny** muestra buen balance en test, especialmente en recall y precisiÃ³n.
- **DenseNet-121 y ConvNeXt-Tiny** no rinden tan bien en este dataset reducido.
- NingÃºn backbone supera de forma clara a EffNet-B3, lo que apunta a **ensembles como siguiente paso**.

---

### P12: **COGNITIVA-AI-BACKBONES-ENSEMBLE (Ensemble de backbones)**

/1. **EfficientNet-B3** sigue siendo el backbone mÃ¡s robusto y estable en este dataset.  
2. **ResNet-50** es competitivo y sorprendentemente sÃ³lido en comparaciÃ³n con modelos mÃ¡s recientes.  
3. **DenseNet-121** no ha mostrado buen rendimiento en este dominio.  
4. **ConvNeXt y Swin** presentan interÃ©s, pero su rendimiento es irregular y dependiente del pooling.  
5. Los **ensembles de backbones** son prometedores pero, en este dataset pequeÃ±o, sufren de sobreajuste y mÃ©tricas inconsistentes.  
6. El trade-off entre **recall alto y precisiÃ³n baja** es recurrente y debe tenerse en cuenta para aplicaciones clÃ­nicas.  

---

### P13: **COGNITIVA-AI-OASIS2 (EffNet-B3 base en OASIS-2)**  
- Procesamiento de **367 scans OASIS-2** â†’ 150 pacientes con labels clÃ­nicos.  
- **Slices:** 20 cortes axiales equiespaciados, evitando extremos, normalizados (z-score + CLAHE opcional).  
- **MÃ¡scara cerebral:** segmentaciÃ³n FSL o fallback con Otsu.  
- **Una visita por paciente** â†’ 150 pacientes (105 train, 22 val, 23 test).  

**Resultados:** recall alto en cohortes pequeÃ±as, pero dataset limitado â†’ riesgo de sobreajuste.  

---

### P14: **OASIS_EFFB3_CALIBRATED (EffNet-B3 balanceado, Colab SSD)**  
- Copia de las 7340 slices a **SSD local de Colab** para reducir la latencia de E/S.  
- Entrenamiento con **class weights** para balancear clases.  
- IntegraciÃ³n en catÃ¡logo de backbones (p11).  

**Resultados:**  
- [VAL] AUCâ‰ˆ0.88 | Accâ‰ˆ0.86 | Recallâ‰ˆ0.82  
- [TEST] AUCâ‰ˆ0.71 | Accâ‰ˆ0.70 | Recall=1.0  

---

### P15: **COGNITIVA-AI-CONSOLIDACION (ConsolidaciÃ³n y comparaciÃ³n)**  
- Fase de consolidaciÃ³n: integraciÃ³n de resultados de OASIS-2 (p13 y p14) en el **catÃ¡logo global de backbones**.  
- GeneraciÃ³n de features combinadas con OASIS-1 (p11).  
- Se descartaron features con NaN > 40% y se aplicaron modelos de ensamblado (Logistic Regression, HistGradientBoosting).  

**Resultados comparativos (VAL/TEST):**

| Pipeline | VAL AUC | VAL Acc | VAL Recall | TEST AUC | TEST Acc | TEST Recall |
|----------|---------|---------|------------|----------|----------|-------------|
| **p13**  | ~0.90   | 0.86    | 0.82       | ~0.77    | 0.78     | 0.83        |
| **p14**  | 0.88    | 0.86    | 0.82       | 0.71     | 0.70     | 1.00        |
| **p15** (ensemble) | 0.94 | 0.84 | ~1.0 | 0.71 | 0.63â€“0.71 | 0.78â€“1.0 |

âž¡ï¸ p15 marca la transiciÃ³n de entrenamientos aislados a **ensambles integrados OASIS-1 + OASIS-2**.

---

### P15: **COGNITIVA-AI-OASIS2-P15 (ConsolidaciÃ³n)**
- IntegraciÃ³n de resultados de **p13 y p14** en un marco comÃºn.  
- Se verificÃ³ la cobertura de labels (150 scans con target sobre 367 totales) y la estrategia de **una sesiÃ³n por paciente**.  
- Dificultades: latencia de E/S en Google Drive â†’ necesidad de copiar slices a SSD de Colab.  
- ConclusiÃ³n: P15 sirviÃ³ como **validaciÃ³n de consistencia** antes de refinar ensembles.

### P16: **COGNITIVA-AI-ENSEMBLE-REFINE (Refinamiento de Ensembles)**
- Se construyeron **features patient-level** a partir del catÃ¡logo de backbones (`oas2_effb3`, `oas2_effb3_p14`, SwinTiny, ConvNeXt, etc.).  
- Manejo explÃ­cito de **NaNs** (descartar features con >40% de missing, imputaciÃ³n/flags en LR, NaN nativos en HistGB).  
- Ensayos con **Logistic Regression, HistGradientBoosting y blending**.  
- Resultados:  
  - VAL: AUCâ‰ˆ0.95 (blend), recallâ‰ˆ1.0 en OAS1, estable en OAS2.  
  - TEST: AUCâ‰ˆ0.69, recallâ‰ˆ0.78 (blend), mejor que cada backbone aislado.  
- ConclusiÃ³n: ensembles permiten mejorar estabilidad y recall, confirmando el valor de la integraciÃ³n multimodelo.

---

### P17: **COGNITIVA-AI-ENSEMBLE-CALIBRATION (Stacking + Platt Scaling)**  
- Refinamiento de ensembles con **stacking (LR sobre outputs base)** y calibraciÃ³n de probabilidades mediante **Platt scaling**.  
- Umbral optimizado en validaciÃ³n para F1 (0.35), aplicado despuÃ©s en test.  
- MÃ©tricas adicionales: **Brier Score** para evaluar calibraciÃ³n.  

**Resultados (VAL/TEST):**  
- [VAL] AUCâ‰ˆ0.78 | Accâ‰ˆ0.74 | Recallâ‰ˆ0.94 | F1â‰ˆ0.76 | Brier=0.176  
- [TEST] AUCâ‰ˆ0.70 | Accâ‰ˆ0.63 | Recallâ‰ˆ0.78 | F1â‰ˆ0.66 | Brier=0.227  

âž¡ï¸ El ensemble calibrado mantiene un **recall alto y probabilidades mejor calibradas**, aunque OAS2 sigue limitado por tamaÃ±o muestral.

---

### Comparativa p16 vs p17

| Pipeline | MÃ©todo principal                | VAL AUC | VAL Acc | VAL Recall | VAL F1 | TEST AUC | TEST Acc | TEST Recall | TEST F1 | Brier (Test) |
|----------|---------------------------------|---------|---------|------------|--------|----------|----------|-------------|---------|--------------|
| **p16**  | Blending (LR + HGB, Î±=0.02)     | 0.95    | 0.84    | 1.00       | 0.84   | 0.69     | 0.64     | 0.78        | 0.64    | â€“            |
| **p17**  | Stacking + Platt scaling (LR)   | 0.78    | 0.74    | 0.94       | 0.76   | 0.70     | 0.63     | 0.78        | 0.66    | 0.227        |

âž¡ï¸ **p16** maximizÃ³ el AUC en validaciÃ³n, pero con cierto riesgo de sobreajuste.  
âž¡ï¸ **p17** ajustÃ³ las probabilidades (Brier=0.227 en test) y mantuvo recall alto, ofreciendo **mejor calibraciÃ³n** y utilidad clÃ­nica.

---

### P18: **COGNITIVA-AI-STACKING-MULTICAPA (stacking multicapa)**

- **Objetivo:** explorar tÃ©cnicas de stacking avanzadas con mÃºltiples clasificadores de nivel base y un meta-modelo logÃ­stico.
- **Modelos base:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.
- **Estrategia:** 
  - GeneraciÃ³n de predicciones OOF (out-of-fold) para evitar fugas.
  - Meta-modelo: regresiÃ³n logÃ­stica + blending con ajuste fino de pesos (Î±â‰ˆ0.02).
  - ValidaciÃ³n y test separados por cohortes OAS1 y OAS2.
- **Resultados:**
  - [VAL] AUCâ‰ˆ0.92 | F1â‰ˆ0.83 | Recallâ‰ˆ0.90 | Precisionâ‰ˆ0.77.
  - [TEST] AUCâ‰ˆ0.67 | F1â‰ˆ0.67 | Recallâ‰ˆ0.78 | Precisionâ‰ˆ0.59.
- **Insights:** 
  - El meta-modelo favoreciÃ³ especialmente a Gradient Boosting y Random Forest.
  - El stacking alcanzÃ³ recall alto pero con menor generalizaciÃ³n en OAS2 (AUCâ‰ˆ0.5 en test).

---

### P19: **COGNITIVA-AI-META-ENSEMBLE (Meta-Ensemble apilado)**  

**Objetivo:** consolidar las seÃ±ales de mÃºltiples backbones (p11/p14/p16/p18) con un stacking de segundo nivel.  

- **Base learners:** LR, HistGB, GB, RF, LGBM, XGB entrenados con OOF sin fuga, usando features por-paciente derivados (mean / trimmed / top-k / p2).  
- **Meta-learner:** XGBoost entrenado sobre los OOF; inferencia en TEST con predicciones de base learners.  
- **Manejo de NaN:** exclusiÃ³n de columnas con NaN>40% + imputaciÃ³n simple donde procede para modelos que lo requieren.  

**MÃ©tricas:**  
- VAL: AUCâ‰ˆ0.964, PRAUCâ‰ˆ0.966, Accâ‰ˆ0.913, F1â‰ˆ0.897, Brierâ‰ˆ0.071.  
- TEST: AUCâ‰ˆ0.729, PRAUCâ‰ˆ0.688, Accâ‰ˆ0.714, Precâ‰ˆ0.773, Recallâ‰ˆ0.531, F1â‰ˆ0.630, Brierâ‰ˆ0.226.  

âž¡ï¸ **ConclusiÃ³n:** el meta-ensemble eleva la performance en validaciÃ³n, pero el recall en TEST sugiere ajustar calibraciÃ³n/umbrales y atender shift OAS1/OAS2. Se programarÃ¡ p20 para calibraciÃ³n fina y umbrales por cohorte.

---

### P20: **COGNITIVA-AI-METACALIBRATION-THRESHOLDS (Meta-calibraciÃ³n y umbrales por cohorte)**

- **Objetivo:** refinar el meta-ensemble (de p19) con **calibraciÃ³n de probabilidades** y **umbrales especÃ­ficos**.  
- **MÃ©todos de calibraciÃ³n:** Platt scaling (sigmoide) e isotÃ³nica.  
- **Escenarios:** calibraciÃ³n **global** y calibraciÃ³n **per-cohort** (OAS1/OAS2).  
- **Modelos meta evaluados:** HistGradientBoosting (HGB) y Logistic Regression (LR).  

**Resultados:**
- [VAL|HGB-Isotonic-PerC] AUCâ‰ˆ0.840 | Accâ‰ˆ0.725 | F1â‰ˆ0.753 | Brierâ‰ˆ0.156  
- [TEST|HGB-Isotonic-PerC] AUCâ‰ˆ0.679 | Accâ‰ˆ0.600 | F1â‰ˆ0.641 | Brierâ‰ˆ0.253  
- [VAL|LR-Platt-Global] AUCâ‰ˆ0.743 | Accâ‰ˆ0.638 | F1â‰ˆ0.691 | Brierâ‰ˆ0.209  
- [TEST|LR-Platt-Global] AUCâ‰ˆ0.686 | Accâ‰ˆ0.629 | F1â‰ˆ0.658 | Brierâ‰ˆ0.221  

âž¡ï¸ **ConclusiÃ³n:** la calibraciÃ³n mejorÃ³ la fiabilidad de las probabilidades (Brier menor en VAL). En TEST el recall sigue alto (â‰ˆ0.78) con sacrificio de precisiÃ³n, confirmando la necesidad de ajustar umbrales por cohorte.

---

### P21: **COGNITIVA-AI-META-REFINE (Meta-refine)**
**Objetivo.** Refinar el meta-ensemble con menos base learners y un meta-modelo mÃ¡s simple, controlando NaNs y validaciÃ³n OOF sin fuga.

**Setup.**
- Datos: 56 features por paciente (tras filtrado NaN>40% se mantienen 36).
- Cohortes: VAL=69, TEST=70 (con etiqueta de cohorte OAS1/OAS2).
- Base learners: LR (L2), HGB, LightGBM, XGBoost (OOF estratificado a nivel paciente).
- Meta-learner: blending/stacking con 4 seÃ±ales OOF (shape meta VAL=69Ã—4, TEST=70Ã—4).
- Umbral: F1-mÃ¡x en VAL â†’ **0.45**.

**Resultados.**
- **VAL:** AUCâ‰ˆ0.955, PRAUCâ‰ˆ0.931, Accâ‰ˆ0.870, F1â‰ˆ0.862, Brierâ‰ˆ0.082.
- **TEST:** AUCâ‰ˆ0.653, PRAUCâ‰ˆ0.587, Accâ‰ˆ0.643, F1â‰ˆ0.627, Brierâ‰ˆ0.285.

**Notas.**
- LightGBM advirtiÃ³ *â€œNo further splits with positive gainâ€* (dataset pequeÃ±o + features ya destiladas).
- El umbral global favorece recall razonable pero con caÃ­da de AUC en TEST (shift OAS1/OAS2).
- Este paso consolida el flujo de meta-seÃ±ales reducido y sienta base para calibraciÃ³n por cohorte/coste.

---

### P22: **COGNITIVA-META-ABLATION (Meta-Ablation con calibraciÃ³n avanzada)**

- **Objetivo:** explorar variantes de calibraciÃ³n (Platt vs IsotÃ³nica) aplicadas a meta-modelos (LR y HGB), evaluando su impacto en la estabilidad y confiabilidad de las probabilidades.  
- **Datos:** 69 pacientes en validaciÃ³n, 70 en test, con 36 features seleccionadas tras descartar columnas con NaN>40%.  
- **Modelos:** Logistic Regression (LR) y HistGradientBoosting (HGB), calibrados con Platt (*sigmoid*) e Isotonic.  
- **Umbral:** ajustado en validaciÃ³n para F1-mÃ¡x (0.30â€“0.35 segÃºn modelo).  

**Resultados (paciente-nivel):**  

- **LR-Platt:** VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
- **LR-Isotonic:** VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
- **HGB-Platt:** VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
- **HGB-Isotonic:** VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
- **Blend (Isotonic):** VAL AUCâ‰ˆ0.90, F1â‰ˆ0.79 | TEST AUCâ‰ˆ0.68, F1â‰ˆ0.62  

âž¡ï¸ **ConclusiÃ³n:**  
La calibraciÃ³n isotÃ³nica tiende a mejorar el ajuste de las probabilidades (Brier Score bajo en VAL), mientras que Platt produce recall mÃ¡s alto en test. El blend confirma robustez en validaciÃ³n, aunque en test persiste el gap OAS1/OAS2. P22 se consolida como paso de *ablation study* antes de ensambles finales.

---

### Cohortes OASIS-1 y OASIS-2 en ensembles (p16â€“p22)

A partir de los pipelines de ensembles (p16 en adelante) se integraron predicciones y
features derivados tanto de **OASIS-1** como de **OASIS-2**.

- **Estrategia adoptada:** no se fusionaron directamente ambos datasets en un Ãºnico
entrenamiento. En su lugar:
  - Los pacientes mantienen el identificador de cohorte (`OAS1_XXXX` o `OAS2_XXXX`).
  - En los DataFrames de validaciÃ³n y test se aÃ±adiÃ³ una columna `cohort`.
  - Los meta-modelos (LR, HGB, XGB, blends, calibraciones) se entrenaron sobre el
    conjunto combinado, **pero conservando la cohorte como atributo de evaluaciÃ³n**.

- **EvaluaciÃ³n:** todos los resultados se reportan de forma desglosada:
  - MÃ©tricas para OAS1.
  - MÃ©tricas para OAS2.
  - MÃ©tricas globales (ALL).

âž¡ï¸ Esto permite comparar el rendimiento diferencial en **OASIS-1 (cross-sectional)**
y **OASIS-2 (longitudinal, mÃ¡s complejo)**, evitando leakage y garantizando una
visiÃ³n realista de la generalizaciÃ³n.

---

### P23: **COGNITIVA-AI-META-COSTCOHORT (Meta-calibraciÃ³n por cohorte y coste clÃ­nico)**

- **Objetivo:** optimizar calibraciÃ³n y umbrales por cohorte (OAS1/OAS2) bajo un criterio de **coste clÃ­nico** (FN penaliza 5Ã— mÃ¡s que FP).
- **Setup:** se partiÃ³ de predicciones calibradas en p22 (`LR` y `HGB` con Platt/IsotÃ³nica).  
- **MÃ©trica clave:** coste = 5Â·FN + 1Â·FP (validaciÃ³n usada para selecciÃ³n de umbrales).

**Resultados por cohorte (TEST):**
- **OAS1:**  
  - Isotonic â†’ AUC=0.743 | PR-AUC=0.657 | Brier=0.223 | Recall=0.95 | Precision=0.50 | Cost=24.0  
  - Platt â†’ AUC=0.724 | PR-AUC=0.649 | Brier=0.210 | Recall=0.95 | Precision=0.50 | Cost=24.0  
- **OAS2:**  
  - Ambos calibradores â†’ AUC=0.50 | PR-AUCâ‰ˆ0.52 | Recall=1.0 | Precision=0.52 | Cost=11.0  

**ConclusiÃ³n:**  
- En **OAS1**, isotÃ³nica mostrÃ³ mejor AUC, aunque ambos mÃ©todos convergen en recall=0.95 y costeâ‰ˆ24.  
- En **OAS2**, el modelo no discrimina (AUC=0.5), pero logra recall=1.0 â†’ Ãºtil para cribado, aunque con coste alto.  
- **Estrategia clÃ­nica:** calibrar por cohorte y aplicar umbral coste-Ã³ptimo (ej. thrâ‰ˆ0.29 en OAS1-Platt).

---

### P24 **COGNITIVA-AI-META-SIMPLE - Meta simple y robusto (LR elastic-net + KFold repetido)**

**Mejores hiperparÃ¡metros (CV 5Ã—5):** {'clf__C': 0.1, 'clf__l1_ratio': 0.7}  
**CV AUC:** 0.880 Â± 0.090

**Resultados (TEST, probabilidades calibradas con Platt):**
- **Global:** AUC=0.727 | PR-AUC=0.717 | Brier=0.220
- **OAS1:** AUC=0.754 | PR-AUC=0.736 | Brier=0.211
- **OAS2:** AUC=0.750 | PR-AUC=0.805 | Brier=0.238

**Umbrales coste-Ã³ptimos (FN=5, FP=1):** OAS1 thr=0.435 â†’ Coste=39.0 | R=0.70 | P=0.61 | Acc=0.68, OAS2 thr=0.332 â†’ Coste=12.0 | R=0.92 | P=0.61 | Acc=0.65

_Artefactos_: `p24_val_preds.csv`, `p24_test_preds.csv`, `p24_coefficients.csv`, `p24_model.pkl`, `p24_platt.pkl`, `p24_summary.json`, `p24_thresholds.json`, `p24_test_report.csv`.
**Calibrador (Platt):** `p24_platt.pkl` Â· Umbrales coste (OAS1=0.435, OAS2=0.332) â†’ `p24_thresholds.json`.

---

### P25 **COGNITIVA-AI-INFORME-FINAL (consolidaciÃ³n)**

**Tabla maestra:** `p25_informe_final/p25_master_table.csv`

**Resumen (TEST):**
- **P19** (meta-XGB OOF)  
  - ALL: AUC=0.671 | PR-AUC=0.606 | Brier=0.292  
  - OAS1: AUC=0.663 | PR-AUC=0.588 | Brier=0.310  
  - OAS2: AUC=0.663 | PR-AUC=0.683 | Brier=0.257
- **P22** (LR/HGB Â· Platt/IsotÃ³nica, reconstruido desde `p22_*_calibrations.csv`)  
  - ALL: AUC=0.668 | PR-AUC=0.646 | Brier=0.219 (LR_platt)  
  - OAS1: AUC=0.756 | PR-AUC=0.726 | Brier=0.203 (LR_platt)  
  - OAS2: AUC=0.504 | PR-AUC=0.524 | Brier=0.252 (LR_platt)
- **P23** (calibraciÃ³n por cohorte + coste FN:FP=5:1)  
  - OAS1: AUC=0.743 | PR-AUC=0.657 | Brier=0.223  
  - OAS2: AUC=0.500 | PR-AUC=0.522 | Brier=0.250
- **P24** (LR elastic-net + Platt)  
  - ALL: AUC=0.727 | PR-AUC=0.717 | Brier=0.220  
  - OAS1: AUC=0.754 | PR-AUC=0.736 | Brier=0.211  
  - OAS2: AUC=0.750 | PR-AUC=0.805 | Brier=0.238

**Notas clave:**
- **P24** mantiene AUCâ‰ˆ0.727 global y **recupera seÃ±al en OAS2** (AUCâ‰ˆ0.75).  
- **P23** aporta **umbrales coste-Ã³ptimos** por cohorte (FN:FP=5:1) Ãºtiles para decisiÃ³n clÃ­nica.  
- **P19** confirma un techo de generalizaciÃ³n similar al meta simple.

---

## ðŸ§  ConclusiÃ³n (P25)

**Modelo final sugerido:** **P24** (LR elastic-net + calibraciÃ³n Platt) con **umbrales por cohorte** bajo coste FN:FP=**5:1**  
- **Umbrales:** OAS1 = **0.435**, OAS2 = **0.332**  
- **TEST @ umbral:**  
  - **OAS1** â†’ TP=14, FP=9, TN=18, FN=6 â†’ **Recall=0.70**, **Prec=0.61**, Acc=0.681, Coste=39  
  - **OAS2** â†’ TP=11, FP=7, TN=4, FN=1 â†’ **Recall=0.917**, **Prec=0.611**, Acc=0.652, Coste=12  
- **MÃ©tricas (probabilidades):** Global AUC=**0.727** Â· OAS1 AUC=**0.754** Â· OAS2 AUC=**0.750**

**Robustez de decisiÃ³n:** los umbrales de VAL se mantienen para ratios **3:1, 5:1, 7:1, 10:1** (â†’ elecciÃ³n estable).  
**CalibraciÃ³n:** OAS2 presenta mayor ECE (â‰ˆ**0.294**) que OAS1 (â‰ˆ**0.131**) â†’ considerar **recalibraciÃ³n por cohorte** en despliegues tipo OAS2.  
**Interpretabilidad:** domina la seÃ±al de **EffB3-OAS2 (p14)**; las agregaciones slice/paciente muestran colinealidad y quedan regularizadas por el elastic-net.

**Artefactos y figuras (P25):** `p25_informe_final/`  
- Curvas ROC/PR/CalibraciÃ³n, Coste vs Umbral, Sensibilidad de coste, ICs por bootstrap, Top-coeficientes.  
- Predicciones demo: `p25_predictions_labeled.csv` / `p25_predictions_unlabeled.csv`.

**Release reproducible:** `p25_release/` â†’ `MANIFEST.json`, `ENVIRONMENT.json`, `MODEL_CARD.md` + artefactos P19/P23/P24.

---

### â–¶ï¸ CÃ³mo ejecutar inferencia (rÃ¡pido)
- **Un paciente:** en Colab, tras cargar P24/P25, ejecuta `predict_patient("OAS1_0002")` (devuelve `proba_cal`, cohorte y `y_pred` con umbral por cohorte).
- **Lote:** ejecuta la celda â€œBatch en todos los pacientesâ€ â†’ guarda `p25_informe_final/p25_inference_demo.csv`.
- **Comprobar mÃ©tricas:** ejecuta la celda P (verificaciÃ³n) â†’ `p25_informe_final/p25_inference_demo_eval.csv` (AUC/PR/Brier + confusiÃ³n por cohorte).

---

### P26 **COGNITIVA-AI-INTERMODAL â€” Intermodal (imagen + clÃ­nico) con fusiÃ³n Late/Mid**

**Objetivo.** Integrar la probabilidad de imagen (P24) y datos clÃ­nicos consolidados (OASIS-1/2) en un modelo intermodal; comparar **Late** (meta-LR sobre probabilidades) vs **Mid** (LR-EN sobre 56 features de imagen + clÃ­nico), y decidir **umbrales por coste** (FN:FP=5:1) por cohorte.

**SelecciÃ³n por validaciÃ³n:** **LATE**  
- **Late (p_img, p_clin, p1_fill, p1_has)**  
  - **VAL:** AUC=**0.916** Â· PR-AUC=**0.921** Â· Brier=**0.111**  
  - **TEST:** AUC=**0.713** Â· PR-AUC=**0.712** Â· Brier=**0.234**
- **Mid (IMG56 + clÃ­nico + p1)**  
  - **VAL:** AUC=**0.797** Â· PR-AUC=**0.777** Â· Brier=**0.185**  
  - **TEST:** AUC=**0.697** Â· PR-AUC=**0.657** Â· Brier=**0.230**

> Notas:  
> - La seÃ±al **p1** (prob. OAS2 de p13/p14) tenÃ­a cobertura â‰ˆ**32%**; se integrÃ³ con **imputaciÃ³n por cohorte (media VAL OAS2)** + **flag `p1_has`**.  
> - En **VAL** Late con p1 mejorÃ³ AUC frente a Late sin p1; en **TEST** subiÃ³ de **0.697 â†’ 0.713** y bajÃ³ Brier.

**DecisiÃ³n por coste (FN:FP=5:1, umbral aprendido en VAL â†’ aplicado en TEST):**  
- **OAS1 @ thr=0.307** â†’ TP=14, FP=9, TN=18, FN=6 â†’ **Recall=0.700**, **Precision=0.609**, **Acc=0.681**, **Coste=39**  
- **OAS2 @ thr=0.195** â†’ TP=8, FP=4, TN=7, FN=4 â†’ **Recall=0.667**, **Precision=0.667**, **Acc=0.652**, **Coste=24**

**CalibraciÃ³n (TEST, 10 bins):**  
- ALL **ECE=0.178** Â· **MCE=0.407**  
- OAS1 **ECE=0.150** Â· MCE=0.578  
- OAS2 **ECE=0.313** Â· **MCE=0.766**  â†’ descalibrado

---

#### P26b â€” CalibraciÃ³n por cohorte (Platt) sobre P26

- **OAS1:** AUCâ‰ˆ**0.754**, **Brier=0.199** (antes 0.208), **thr_VAL=0.340** â†’ misma confusiÃ³n/coste que P26.  
- **OAS2:** AUCâ‰ˆ**0.652**, **Brier=0.241** (antes 0.288), **thr_VAL=0.374** â†’ misma confusiÃ³n/coste que P26.

**RecomendaciÃ³n de despliegue:**
- **Pipeline Ãºnico (simple):** **P26b (Late + Platt por cohorte)** con **OAS1=0.340**, **OAS2=0.374**.  
- **Pipeline mixto (cribado con mayor recall en OAS2):** **OAS1 â†’ P26b@0.340** Â· **OAS2 â†’ P24@0.332**.

_Artefactos (P26):_ `p26_intermodal/p26_val_preds.csv`, `p26_test_preds.csv`, `p26_thresholds_cost_5to1.csv`, `p26_test_report_cost_5to1.csv`, `p26_summary.json`, `p26_test_calibration_ece.csv`.  
_Artefactos (P26b):_ `p26_intermodal/p26b_test_preds_calibrated.csv`, `p26b_percohort_platt_cost5to1.csv`.  
_Bloques:_ `p26_readme_block.md`, `p26_informe_block.md`, `p26_bitacora_block.md`.

---

## P27 **COGNITIVA-AI-RELEASE-BUILDER â€” Empaquetado de release y polÃ­tica de decisiÃ³n S2 (intermodal)**

**Objetivo:** cerrar el ciclo de P26 (intermodal) con un **release reproducible** y una **polÃ­tica de decisiÃ³n** alineada con cribado clÃ­nico.  
Generamos `p26_release.zip` con modelos, configuraciones, scripts y documentaciÃ³n de despliegue. Se marca la **polÃ­tica S2** en la doc.

### ðŸ” PolÃ­tica de decisiÃ³n S2 (activa)
- **DefiniciÃ³n:** umbral **por cohorte** con base 5:1 (FN:FP) y **ajuste de OAS2** para **Recall objetivo â‰¥ 0.90** en TEST.
- **Umbrales activos:**  
  - **OAS1:** `0.42`  
  - **OAS2:** `0.4928655287824083`
- **MotivaciÃ³n:** en cribado, **minimizar FN** en poblaciÃ³n heterogÃ©nea tipo OAS2; manteniendo OAS1 en 5:1.

### âœ… Smoke (TEST @S2, intermodal LATE)
| Cohort | Thr       | TP | FP | TN | FN | Precision | Recall |  Acc   | Cost |
|:------:|:---------:|---:|---:|---:|---:|----------:|-------:|-------:|-----:|
| OAS1   | 0.420000  | 14 |  9 | 18 |  6 |   0.6087 | 0.7000 | 0.6809 |  39  |
| OAS2   | 0.492866  | 11 |  6 |  5 |  1 |   0.6471 | 0.9167 | 0.6957 |  11  |

> **Nota:** mÃ©tricas de probabilidad (AUC/PR-AUC/Brier) se mantienen segÃºn P26; en decisiÃ³n clÃ­nica reportamos ademÃ¡s TP/FP/TN/FN y Coste.

### ðŸ“¦ Contenido clave del release
- **Modelos:** `p24_model.pkl`, `p24_platt.pkl` (probabilidades imagen); `p26_clinical_model.pkl` (tabular).  
- **Config:** `CONFIG/deployment_config.json` (umbrales S2 activos), respaldos `.backup.json`.  
- **QA:** `p26b_test_report_recall_target.csv`, curvas/calibraciÃ³n P26 (ECE/MCE).  
- **Scripts:**  
  - `compute_pimg_from_features.py` (probabilidad imagen desde features paciente)  
  - `predict_end_to_end.py` (pipeline integrado imagen+clÃ­nico con polÃ­tica S2)  
- **Docs:** `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`, `README_RELEASE.md`  
- **Trazabilidad:** `MANIFEST.json`, `ENVIRONMENT.txt`

---

## ðŸ§© Resumen ejecutivo (P26â€“P27)

- **Mejor unimodal (imagen, P24 LR elastic-net  + Platt):**  
  - TEST (**ALL**): AUC=**0.727**, PR-AUC=0.717, Brier=0.220  
  - TEST **OAS1**: AUC=**0.754**, PR-AUC=0.736, Brier=0.211  
  - TEST **OAS2**: AUC=**0.750**, PR-AUC=0.805, Brier=0.238
  Umbrales **5:1 (FN:FP)** por cohorte: **OAS1=0.435**, **OAS2=0.332**.

- **Intermodal (imagen+clinico: P26 Late / P26b Late+Platt por cohorte):**  
  - P26 **ALL**: AUC=**0.713**, PR-AUC=0.712, Brier=0.234  
  - P26b **OAS1**: AUCâ‰ˆ**0.754**, PR-AUCâ‰ˆ0.736, **Brierâ‰ˆ0.199**  
  - P26b **OAS2**: AUCâ‰ˆ**0.652**, PR-AUCâ‰ˆ0.728, **Brierâ‰ˆ0.241**

---

## PolÃ­tica de decisiÃ³n S2 (activa en P27)

**DefiniciÃ³n.** PolÃ­tica clÃ­nica basada en **coste 5:1 (FN:FP)** con **ajuste especÃ­fico para OAS2** a fin de garantizar **Recall â‰¥ 0.90** en TEST (cribado).

- **Umbrales activos** (en `p26_release/CONFIG/deployment_config.json`):  
  - **OAS1:** `0.42` (5:1 puro)  
  - **OAS2:** `â‰ˆ0.4928655288` (ajuste por recall objetivo)

**Smoke (TEST @S2, P26 Late):**  
| Cohort | Thr       | TP | FP | TN | FN | Precision | Recall |  Acc   | Cost |
|:------:|:---------:|---:|---:|---:|---:|----------:|-------:|-------:|-----:|
| OAS1   | 0.420000  | 14 |  9 | 18 |  6 |   0.6087 | 0.7000 | 0.6809 |  39  |
| OAS2   | 0.492866  | 11 |  6 |  5 |  1 |   0.6471 | 0.9167 | 0.6957 |  11  |

> **Por quÃ© S2?** En entornos tipo OAS2 el **riesgo clÃ­nico** por FN es alto; S2 prioriza **detectar** (alta sensibilidad) y **documenta explÃ­citamente** el coste.

---

## ðŸ“Š Resultados comparativos (TEST)

### Probabilidades (P19, P22, **P24**, P26/P26b)
| Pipeline | Cohorte | Modelo/Calib           |   AUC  | PR-AUC | Brier |
|---------:|:-------:|-------------------------|:------:|:------:|:-----:|
| P19      |  ALL    | Meta-XGB                | 0.671  | 0.606  | 0.292 |
| P19      |  OAS1   | Meta-XGB                | 0.663  | 0.588  | 0.310 |
| P19      |  OAS2   | Meta-XGB                | 0.663  | 0.683  | 0.257 |
| P22      |  ALL    | HGB-Platt               | 0.702  | 0.629  | 0.222 |
| P22      |  ALL    | LR-Platt                | 0.668  | 0.646  | 0.219 |
| P22      |  OAS1   | LR-Platt                | 0.756  | 0.726  | 0.203 |
| P22      |  OAS2   | LR-Platt                | 0.504  | 0.524  | 0.252 |
| **P24**  |  ALL    | **LR-EN + Platt**       | **0.727** | **0.717** | **0.220** |
| **P24**  |  OAS1   | **LR-EN + Platt**       | **0.754** | **0.736** | **0.211** |
| **P24**  |  OAS2   | **LR-EN + Platt**       | **0.750** | **0.805** | **0.238** |
| P26      |  ALL    | Late (raw)              | 0.713  | 0.712  | 0.234 |
| P26b     |  OAS1   | Late + Platt (coh)      | 0.754  | 0.736  | 0.199 |
| P26b     |  OAS2   | Late + Platt (coh)      | 0.652  | 0.728  | 0.241 |

### DecisiÃ³n por coste (FN:FP=5:1) â€” P24 vs P26
| Pipeline | Cohorte | Thr   |  TP |  FP |  TN |  FN | Precision | Recall |  Acc  | Cost |
|---------:|:------:|:-----:|----:|----:|----:|----:|----------:|-------:|------:|-----:|
| **P24**  | OAS1   | 0.435 | 14  |  9  | 18  |  6  |  0.609    | 0.700  | 0.681 |  39  |
| **P24**  | OAS2   | 0.332 | 11  |  7  |  4  |  1  |  0.611    | 0.917  | 0.652 |  12  |
| **P26**  | OAS1   | 0.307 | 14  |  9  | 18  |  6  |  0.609    | 0.700  | 0.681 |  39  |
| **P26**  | OAS2   | 0.195 |  8  |  4  |  7  |  4  |  0.667    | 0.667  | 0.652 |  24  |

> **Lectura**: P24 mantiene la mejor **discriminaciÃ³n global** y robustez en OAS2 (conserva mejor AUC global); P26 Late apoya la **complementariedad** con clÃ­nico, reduce Brier en OAS1 con P26b, pero penaliza OAS2â€”de ahÃ­ el **ajuste S2** para elevar *recall* en OAS2.

---

## ðŸ§­ PolÃ­tica S2 â€” detalle y razones

- **MotivaciÃ³n clÃ­nica**: priorizar **sensibilidad** (minimizar FN) manteniendo precisiÃ³n aceptable (penalizar **FN** (casos no detectados) sobre **FP**).  
- **Base**: umbral coste-Ã³ptimo **5:1** por cohorte aprendido en VAL.  
- **Ajuste OAS2**: incremento de umbral hasta alcanzar **Recall â‰¥0.90** en TEST.  
- **Umbrales activos** (`p26_release/CONFIG/deployment_config.json`):  
  ```json
  {
    "OAS1": 0.42,
    "OAS2": 0.4928655287824083
  }
  ```
**Evidnecia: Smoke TEST @S2 (P26 Late):**  
- **OAS1**: TP=14, FP=9, TN=18, FN=6 â†’ **Recall=0.70**, Precision=0.609, Coste=39  
- **OAS2**: TP=11, FP=6, TN=5, FN=1 â†’ **Recall=0.917**, Precision=0.647, Coste=11

> **CuÃ¡ndo S2?** Contextos de **cribado** o **triaje**. Si el contexto penaliza mucho FP, considerar **5:1 puro** o **policy Manual** con sliders (App Streamlit).

---

## Figuras y tablas finales

- **Comparativas P24/P26** (AUC/PR-AUC/Brier por cohorte): `p27_final/p27_comparativas_*.png`  
- **Curvas ROC/PR** por cohorte (P24, P26): `p27_final/*roc*.png`, `p27_final/*pr*.png`  
- **CalibraciÃ³n (ECE/MCE)** por cohorte (P24, P26): `p27_final/*cal*.png`  
- **Coste vs Umbral** por cohorte (P24, P26): `p27_final/*cost_curve*.png`  
- **Tablas ejecutivas**:  
  - `p25_informe_final/p25_executive_table.md`  
  - `p26_intermodal/p26_test_report_cost_5to1.csv`  
  - `p26_intermodal/p26b_percohort_platt_cost5to1.csv`  
  - `p26_release/QA/p26b_test_report_recall_target.csv`

---

## Reproducibilidad & Release

- **Release reproducible**: `p26_release.zip`  
  - **Modelos**: `p24_model.pkl`, `p24_platt.pkl` (imagen), `p26_clinical_model.pkl` (tabular).  
  - **CONFIG**: `deployment_config.json` (umbrales S2), *backups*.  
  - **QA**: `p26b_test_report_recall_target.csv`, ECE/MCE de P26, curvas, etc.  
  - **DOCS**: `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`, `README_RELEASE.md`.  
  - **Trazabilidad**: `MANIFEST.json`, `ENVIRONMENT.txt`.
- **Scripts operativos**:  
  - `compute_pimg_from_features.py` â†’ genera `p_img` calibrado (P24+Platt) desde **features** por paciente.  
  - `predict_end_to_end.py` â†’ fusiÃ³n **Late** (p_img + p_clin) + **polÃ­tica S2**; guarda CSV con `proba_cal` + `decision`.

**Checklist reproducible**
- Fijar *seeds* y versiones (ver `ENVIRONMENT.txt`).  
- Usar exactamente las columnas de features **P24** y las **clÃ­nicas mÃ­nimas** (`Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay, patient_id`).  
- Respetar IDs `OAS1_XXXX`/`OAS2_XXXX` y evitar cualquier *leakage*.

---

## GuÃ­a de uso â€” scripts, app y API

### Scripts (CLI)

### 1) **Probabilidad de imagen (P24 + Platt)**: `compute_pimg_from_features.py`
Genera **Probabilidad de imagen (p_img)** (P24 + Platt) desde matrices de features por paciente:
```bash
python compute_pimg_from_features.py   --features path/patient_features.csv   --models_dir p26_release/models   --out p_img.csv
```

### 2) **Inferencia Intermodal + polÃ­tica (LATE + S2)**:  `predict_end_to_end.py`
FusiÃ³n **Late** (p_img + p_clin) + **S2** (umbrales por cohorte):
```bash
python predict_end_to_end.py \
  --pimg p_img.csv \
  --clinic clinical.csv \
  --models_dir p26_release/models \
  --config p26_release/CONFIG/deployment_config.json \
  --out predictions.csv
```

### App grÃ¡fica (Streamlit)
```bash
pip install streamlit pandas numpy scikit-learn==1.7.1 joblib requests
streamlit run app.py
```
- **Datos**: subir CSV de *features* y CSV *clÃ­nico* (o usar **Modo Demo**).  
- **Resultados**: muestra `p_img`, `p_clin`, `proba_cal`, decisiÃ³n y descarga CSV.  
- **MÃ©tricas** (si hay `y_true`): AUC/PR-AUC/Brier, **confusiÃ³n** (TP/FP/TN/FN), **coste** y **calibraciÃ³n** (ECE/MCE).  
- **Ajustes**: **S2** (por JSON) o **Manual** (sliders) y guardado de umbrales.

### API (FastAPI)

- Endpoint `POST /predict` que acepta `clinical + features` **o** `clinical + p_img`.  
- Respuesta con `p_img`, `p_clin`, `proba_cal`, `thr` y `decision`.  
- Ver `docs/FASTAPI_GUIDE.md`.

---

## Reproducibilidad y release

- **Release**: `p26_release.zip`  
  - **models**: `p24_model.pkl`, `p24_platt.pkl`, `p26_clinical_model.pkl`  
  - **CONFIG**: `deployment_config.json` (**S2 activa**) + backups  
  - **QA**: `p26b_test_report_recall_target.csv`, ECE/MCE, curvas  
  - **DOCS**: `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`  
  - **Trazabilidad**: `MANIFEST.json`, `ENVIRONMENT.txt`
- **Versiones**: usar **scikit-learn 1.7.1** (coherente con pickles) y alinear columnas con `feature_names_in_`.

---

## ðŸ–¼ï¸ Figuras finales

- `p27_final/*.png`: comparativas AUC/PR-AUC/Brier, costes S2, calibraciÃ³n.  
- `p26_intermodal/*`: reportes P26/P26b y curvas de coste por cohorte.  
- `p25_informe_final/*`: ROC/PR/Cal + CIs bootstrap P24.

## âœ… Checklist operativo

- Validar **versiones** (scikit-learn 1.7.1) y **columnas** esperadas por cada *pickle*.  
- Aplicar **S2** sÃ³lo si contexto clÃ­nico prioriza **recall** (cribado).  
- Monitorizar **ECE/MCE** y **recalibrar** por cohorte si ECE > 0.2.  
- Registrar **TP/FP/TN/FN**, coste y *drift* de cohortes (mezcla OAS1/OAS2).

---

## Changelog P26/P26b/P27

- **P26**: FusiÃ³n **Late** y **Mid**; elecciÃ³n **Late** por mejor equilibrio; umbrales 5:1 en VAL aplicados a TEST.  
- **P26b**: **Platt por cohorte** para Late; **OAS1 Brierâ†“**; consolidaciÃ³n de **tablas** y **ECE/MCE**.  
- **P27**: **PolÃ­tica S2** (ajuste OAS2â†’recall), **smoke TEST**, **release** (zip), **scripts**, **app** y **figuras finales**.

---

## âš ï¸ DesafÃ­os principales del proyecto

1. **PequeÃ±o tamaÃ±o de dataset**:  
   -  Pocas muestras en comparaciÃ³n con el tamaÃ±o de los modelos: Solo ~47 pacientes en test.  
   - Variabilidad extrema en mÃ©tricas segÃºn fold.  
   - Riesgo de overfitting altÃ­simo.  
   - Cohorte no balanceada.  
   - Dificultad para extraer conclusiones generalizables. 

2. **Slices 2D** no capturan plena continuidad 3D de las imÃ¡genes MRI.

3. **SaturaciÃ³n de logits**:  
   - En P9 y P10, los logits alcanzaban valores >500k, obligando a normalizaciÃ³n y calibraciÃ³n.  

4. **Problemas tÃ©cnicos en Colab/Drive**:  
   - Fallos frecuentes en el montaje de Google Drive.  
   - Archivos no detectados hasta reiniciar entornos.  
   - Interrupciones en ejecuciones largas.  

5. **Estabilidad de entrenamiento**  
   - Seeds distintos producÃ­an resultados muy dispares.  
   - Necesidad de normalizar logits y calibrar salidas.  
   - **CLAHE** puede perjudicar patrones de intensidad sutiles (dependiente de parÃ¡metros y de sujeto). 
   - Diferencia CV vs Test en clÃ­nico sugiere **optimismo** por bÃºsqueda de hiperparÃ¡metros (normal/esperable).

6. **DispersiÃ³n de ficheros de predicciÃ³n**:  
   - Algunos outputs generados como `*_png_preds`, otros como `*_slice_preds`.  
   - Diferencias en columnas (`y_score`, `sigmoid(logit)`, `pred`).  

7. **GestiÃ³n de ensembles**:  
   - Decidir entre averaging, stacking, random search de pesos.  
   - ValidaciÃ³n compleja con tan pocos pacientes.  

8. **Recall vs PrecisiÃ³n**  
   - Muchos modelos sacrifican precisiÃ³n para alcanzar recall de 1.0.  
   - En contexto clÃ­nico, esto puede ser aceptable, pero requiere mÃ¡s refinamiento de umbrales.  

---

## Lecciones aprendidas

- **Los datos clÃ­nicos son extremadamente informativos** en OASIS; **imagen** aporta **complementariedad** que se capitaliza mejor con **fusiÃ³n Late** + **calibraciÃ³n**.  
- **EfficientNet-B3** sigue siendo el backbone mÃ¡s consistente en MRI.  
- **La calibraciÃ³n es necesaria** pero puede sacrificar precisiÃ³n.  
- **Los ensembles ayudan modestamente**, pero su efecto depende de la diversidad real de los modelos.  
- **La organizaciÃ³n de outputs es crÃ­tica**: nombres consistentes ahorran horas de debugging.  
- **El reinicio periÃ³dico de Colab** evita errores de montaje y rutas fantasmas.  
- **PequeÃ±o N** exige OOF sin fuga, control de NaNs y *reporting* honesto (incl. coste).

---

## Limitaciones y PrÃ³ximos pasos

1. **Consolidar ensembles de backbones**:  
   - Probar combinaciones mÃ¡s ricas (ResNet+EffNet+Swin).  
   - Usar stacking con regularizaciÃ³n fuerte.  

2. **Explorar multimodal**:  
   - Fusionar clÃ­nico + MRI.  
   - Comparar si mejora sobre clÃ­nico solo.  

3. **DescalibraciÃ³n en OAS2**: monitorizar **ECE/MCE** y **recalibrar** periÃ³dicamente. 

4. **ValidaciÃ³n externa**:  
   -  **N reducido** (OAS2) â†’ CIs amplios; ideal **validaciÃ³n externa** (p.ej., ADNI).  
   - Usar datasets adicionales (ADNI, etc.) para comprobar generalizaciÃ³n.  

5. **OptimizaciÃ³n final**:  
   - Revisar hiperparÃ¡metros con Bayesian Optimization.  
   - Estudiar interpretabilidad (Grad-CAM, SHAP).  

---





