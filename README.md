# üß† COGNITIVA-AI ‚Äì Experimentos de Clasificaci√≥n Multimodal

Este repositorio documenta **toda la evoluci√≥n experimental** en el marco del proyecto **Cognitiva-AI**, cuyo objetivo ha sido **explorar modelos de machine learning para diagn√≥stico de Alzheimer** combinando datos cl√≠nicos y de imagen (MRI OASIS-2).  

El documento sigue un enfoque **cuaderno de bit√°cora extendido**, en el que cada pipeline corresponde a un conjunto de experimentos con motivaciones, configuraciones t√©cnicas, m√©tricas obtenidas y reflexiones.  
El tono es intencionadamente **verboso y detallado**: se incluyen incidencias de ejecuci√≥n, errores y aprendizajes pr√°cticos que acompa√±aron cada etapa.  

---

## üìö √çndice

1. [Introducci√≥n](#introducci√≥n)
2. [Pipelines experimentales](#pipelines-experimentales)
   - [P1: Datos cl√≠nicos con XGBoost](#p1-datos-cl√≠nicos-con-xgboost)
   - [P2: Datos cl√≠nicos fusionados](#p2-datos-cl√≠nicos-fusionados)
   - [P3: MRI OASIS-2 ‚Äì ResNet50](#p3-mri-oasis-2--resnet50)
   - [P5: MRI Colab ‚Äì ResNet18 calibrado](#p5-mri-colab--resnet18-calibrado)
   - [P6: MRI Colab ‚Äì EfficientNet-B3 embeddings](#p6-mri-colab--efficientnet-b3-embeddings)
   - [P7: MRI Colab ‚Äì EfficientNet-B3 fine-tuning](#p7-mri-colab--efficientnet-b3-fine-tuning)
   - [P9: MRI Colab ‚Äì EfficientNet-B3 stable](#p9-mri-colab--efficientnet-b3-stable)
   - [P10: MRI Colab ‚Äì EfficientNet-B3 stable + calibraci√≥n](#p10-mri-colab--efficientnet-b3-stable--calibraci√≥n)
   - [P10-ext: Extensiones y ensembles](#p10-ext-extensiones-y-ensembles)
   - [P11: Backbones alternativos](#p11-backbones-alternativos)
3. [Comparativa global de resultados](#comparativa-global-de-resultados)
4. [Desaf√≠os principales](#desaf√≠os-principales)
5. [Lecciones aprendidas](#lecciones-aprendidas)
6. [Pr√≥ximos pasos](#pr√≥ximos-pasos)

---

## Introducci√≥n

El proyecto **Cognitiva-AI** parte de la necesidad de evaluar modelos predictivos que integren datos cl√≠nicos y de imagen (MRI) en cohortes reducidas como OASIS-2.  

Desde el inicio se asumi√≥ que:
- Los **datos cl√≠nicos** podr√≠an servir como baseline fuerte (edad, MMSE, CDR, etc.).  
- Las **im√°genes cerebrales** aportar√≠an riqueza multimodal pero con mayor complejidad.  
- Ser√≠a necesario experimentar con **diferentes backbones** de visi√≥n profunda y con **estrategias de calibraci√≥n, ensembles y stacking** para compensar el peque√±o tama√±o muestral.  

El proceso se organiz√≥ en **pipelines numerados**. Cada uno corresponde a un conjunto de experimentos exploratorios.  

---

## Pipelines experimentales

### P1: Datos cl√≠nicos con XGBoost

- **Motivaci√≥n:** establecer un baseline s√≥lido con datos tabulares cl√≠nicos.  
- **Modelo:** XGBoost con optimizaci√≥n b√°sica de hiperpar√°metros.  
- **Resultados:**  
  - AUC (Test): 0.897  
  - Buen baseline, aunque limitado a informaci√≥n tabular.  

**Reflexi√≥n:**  
Los datos cl√≠nicos solos ya ofrecen un baseline sorprendentemente competitivo. Esto oblig√≥ a replantear si los modelos de imagen podr√≠an aportar ganancia marginal real.  

---

### P2: Datos cl√≠nicos fusionados

- **Motivaci√≥n:** combinar datos cl√≠nicos enriquecidos o fusionados con informaci√≥n adicional.  
- **Modelo:** XGBoost extendido.  
- **Resultados:**  
  - AUC (Test): 0.991  
  - Recall cercano a 1.0  

**Reflexi√≥n:**  
La fusi√≥n cl√≠nica alcanza casi techo de rendimiento en esta cohorte. Refuerza la hip√≥tesis de que la MRI aporta, sobre todo, complementariedad m√°s que superioridad aislada.  

---

### P3: MRI OASIS-2 ‚Äì ResNet50

- **Motivaci√≥n:** baseline en im√°genes MRI con un backbone cl√°sico.  
- **Modelo:** ResNet50 preentrenado en ImageNet, fine-tuning en OASIS-2.  
- **Resultados:**  
  - AUC (Test): 0.938  

**Reflexi√≥n:**  
Primer resultado fuerte en imagen pura. Abre la puerta a comparar cl√≠nico vs imagen.  

---

### P5: MRI Colab ‚Äì ResNet18 calibrado

- **Motivaci√≥n:** probar backbone m√°s ligero en entorno Colab.  
- **Modelo:** ResNet18 con calibraci√≥n posterior.  
- **Resultados:**  
  - AUC (Test): 0.724  
  - PR-AUC: 0.606  
  - Acc: 0.60 | Recall: 0.80 | Precisi√≥n: 0.52  

**Reflexi√≥n:**  
La calibraci√≥n ayud√≥ a controlar la sobreconfianza, pero los resultados son inferiores a ResNet50.  

---

### P6: MRI Colab ‚Äì EfficientNet-B3 embeddings

- **Motivaci√≥n:** usar EfficientNet-B3 solo como extractor de embeddings, sin fine-tuning completo.  
- **Resultados:**  
  - AUC (Test): 0.704  
  - PR-AUC: 0.623  
  - Recall: 0.90  

**Reflexi√≥n:**  
Como extractor simple ya supera ResNet18 calibrado, confirmando potencia de EfficientNet.  

---

### P7: MRI Colab ‚Äì EfficientNet-B3 fine-tuning

- **Motivaci√≥n:** pasar a fine-tuning completo de EfficientNet-B3.  
- **Resultados:**  
  - AUC (Test): 0.876  
  - PR-AUC: 0.762  
  - Acc: 0.745 | Recall: 1.0 | Precisi√≥n: 0.625  

**Reflexi√≥n:**  
Uno de los mejores backbones en imagen pura. Supone el nuevo baseline de referencia.  

---

### P9: MRI Colab ‚Äì EfficientNet-B3 stable

- **Motivaci√≥n:** estabilizar entrenamientos previos de EfficientNet-B3.  
- **Resultados:**  
  - AUC (Test): 0.740  
  - PR-AUC: 0.630  
  - Recall m√°s bajo que en P7.  

**Incidencias:**  
- Saturaci√≥n de logits detectada.  
- Variabilidad alta entre seeds.  

**Reflexi√≥n:**  
Confirma que la estabilidad no siempre se traduce en mejor rendimiento.  

---

### P10: MRI Colab ‚Äì EfficientNet-B3 stable + calibraci√≥n

- **Motivaci√≥n:** aplicar calibraci√≥n expl√≠cita para corregir sobreconfianza.  
- **M√©todo:** Platt scaling, isotonic regression y temperature scaling.  
- **Resultados:**  
  - AUC (Test): 0.546‚Äì0.583  
  - PR-AUC: 0.50‚Äì0.53  
  - Recall: 1.0 pero precisi√≥n baja (~0.47‚Äì0.49)  

**Reflexi√≥n:**  
La calibraci√≥n ayud√≥ a controlar la sobreconfianza pero sacrific√≥ precisi√≥n.  

---

### P10-ext: Extensiones y ensembles

- **Motivaci√≥n:** explotar estrategias de **ensembles y stacking** con EfficientNet-B3.  
- **Estrategias:**  
  - Seed ensembles (mean, trimmed, top7)  
  - Random forest sobre features derivadas  
  - Stacking log√≠stico  
- **Resultados destacados:**  
  - Ensemble (mean+trimmed20+top7+p2): Test AUC ~0.75  
  - Stacking LR sobre seeds: Test AUC ~0.75  

**Reflexi√≥n:**  
El ensemble aporta mejoras modestas pero consistentes. Se consolida como estrategia √∫til.  

---

### P11: Backbones alternativos

- **Motivaci√≥n:** comprobar si otros backbones de visi√≥n pod√≠an superar a EfficientNet-B3.  
- **Modelos probados:**  
  - ResNet-50  
  - DenseNet-121  
  - ConvNeXt-Tiny  
  - Swin-Tiny  
- **Resultados preliminares:**  
  - ResNet-50: Test AUC ~0.74  
  - DenseNet-121: Test AUC ~0.34 (muy bajo)  
  - ConvNeXt-Tiny: Test AUC ~0.50  
  - Swin-Tiny: Test AUC ~0.64 (con top7 pooling)  

**Incidencias:**  
- Varios problemas de montaje de Google Drive tras semanas sin reiniciar Colab.  
- Ficheros dispersos en directorios distintos (ej. slice vs patient).  
- Necesidad de armonizar columnas (`y_score` vs `sigmoid(logit)`).  

**Reflexi√≥n:**  
Ning√∫n backbone supera claramente a EfficientNet-B3.  
La v√≠a l√≥gica pasa a ser **ensembles de backbones**.  

---

### P13: **COGNITIVA-AI-OASIS2-P13 (EffNet-B3 base en OASIS-2)**  
- Procesamiento de **367 scans OASIS-2** ‚Üí 150 pacientes con labels cl√≠nicos.  
- **Slices:** 20 cortes axiales equiespaciados, evitando extremos, normalizados (z-score + CLAHE opcional).  
- **M√°scara cerebral:** segmentaci√≥n FSL o fallback con Otsu.  
- **Una visita por paciente** ‚Üí 150 pacientes (105 train, 22 val, 23 test).  

**Resultados:** recall alto en cohortes peque√±as, pero dataset limitado ‚Üí riesgo de sobreajuste.  

---

### P14: **COGNITIVA-AI-OASIS2-P14 (EffNet-B3 balanceado, Colab SSD)**  
- Copia de las 7340 slices a **SSD local de Colab** para reducir la latencia de E/S.  
- Entrenamiento con **class weights** para balancear clases.  
- Integraci√≥n en cat√°logo de backbones (p11).  

**Resultados:**  
- [VAL] AUC‚âà0.88 | Acc‚âà0.86 | Recall‚âà0.82  
- [TEST] AUC‚âà0.71 | Acc‚âà0.70 | Recall=1.0  

---

### P15: **COGNITIVA-AI-OASIS2-P15 (Consolidaci√≥n y comparaci√≥n)**  
- Fase de consolidaci√≥n: integraci√≥n de resultados de OASIS-2 (p13 y p14) en el **cat√°logo global de backbones**.  
- Generaci√≥n de features combinadas con OASIS-1 (p11).  
- Se descartaron features con NaN > 40% y se aplicaron modelos de ensamblado (Logistic Regression, HistGradientBoosting).  

**Resultados comparativos (VAL/TEST):**

| Pipeline | VAL AUC | VAL Acc | VAL Recall | TEST AUC | TEST Acc | TEST Recall |
|----------|---------|---------|------------|----------|----------|-------------|
| **p13**  | ~0.90   | 0.86    | 0.82       | ~0.77    | 0.78     | 0.83        |
| **p14**  | 0.88    | 0.86    | 0.82       | 0.71     | 0.70     | 1.00        |
| **p15** (ensemble) | 0.94 | 0.84 | ~1.0 | 0.71 | 0.63‚Äì0.71 | 0.78‚Äì1.0 |

‚û°Ô∏è p15 marca la transici√≥n de entrenamientos aislados a **ensambles integrados OASIS-1 + OASIS-2**.

---

### P15: **COGNITIVA-AI-OASIS2-P15 (Consolidaci√≥n)**
- Integraci√≥n de resultados de **p13 y p14** en un marco com√∫n.  
- Se verific√≥ la cobertura de labels (150 scans con target sobre 367 totales) y la estrategia de **una sesi√≥n por paciente**.  
- Dificultades: latencia de E/S en Google Drive ‚Üí necesidad de copiar slices a SSD de Colab.  
- Conclusi√≥n: P15 sirvi√≥ como **validaci√≥n de consistencia** antes de refinar ensembles.

### P16: **COGNITIVA-AI-OASIS2-P16 (Refinamiento de Ensembles)**
- Se construyeron **features patient-level** a partir del cat√°logo de backbones (`oas2_effb3`, `oas2_effb3_p14`, SwinTiny, ConvNeXt, etc.).  
- Manejo expl√≠cito de **NaNs** (descartar features con >40% de missing, imputaci√≥n/flags en LR, NaN nativos en HistGB).  
- Ensayos con **Logistic Regression, HistGradientBoosting y blending**.  
- Resultados:  
  - VAL: AUC‚âà0.95 (blend), recall‚âà1.0 en OAS1, estable en OAS2.  
  - TEST: AUC‚âà0.69, recall‚âà0.78 (blend), mejor que cada backbone aislado.  
- Conclusi√≥n: ensembles permiten mejorar estabilidad y recall, confirmando el valor de la integraci√≥n multimodelo.

---

### P17: **COGNITIVA-AI-Ensemble Calibration (Stacking + Platt Scaling)**  
- Refinamiento de ensembles con **stacking (LR sobre outputs base)** y calibraci√≥n de probabilidades mediante **Platt scaling**.  
- Umbral optimizado en validaci√≥n para F1 (0.35), aplicado despu√©s en test.  
- M√©tricas adicionales: **Brier Score** para evaluar calibraci√≥n.  

**Resultados (VAL/TEST):**  
- [VAL] AUC‚âà0.78 | Acc‚âà0.74 | Recall‚âà0.94 | F1‚âà0.76 | Brier=0.176  
- [TEST] AUC‚âà0.70 | Acc‚âà0.63 | Recall‚âà0.78 | F1‚âà0.66 | Brier=0.227  

‚û°Ô∏è El ensemble calibrado mantiene un **recall alto y probabilidades mejor calibradas**, aunque OAS2 sigue limitado por tama√±o muestral.

---

### Comparativa p16 vs p17

| Pipeline | M√©todo principal                | VAL AUC | VAL Acc | VAL Recall | VAL F1 | TEST AUC | TEST Acc | TEST Recall | TEST F1 | Brier (Test) |
|----------|---------------------------------|---------|---------|------------|--------|----------|----------|-------------|---------|--------------|
| **p16**  | Blending (LR + HGB, Œ±=0.02)     | 0.95    | 0.84    | 1.00       | 0.84   | 0.69     | 0.64     | 0.78        | 0.64    | ‚Äì            |
| **p17**  | Stacking + Platt scaling (LR)   | 0.78    | 0.74    | 0.94       | 0.76   | 0.70     | 0.63     | 0.78        | 0.66    | 0.227        |

‚û°Ô∏è **p16** maximiz√≥ el AUC en validaci√≥n, pero con cierto riesgo de sobreajuste.  
‚û°Ô∏è **p17** ajust√≥ las probabilidades (Brier=0.227 en test) y mantuvo recall alto, ofreciendo **mejor calibraci√≥n** y utilidad cl√≠nica.

---

7Ô∏è‚É£ COGNITIVA-AI-ENSEMBLE-ADVANCED (p18, stacking multicapa)

- **Objetivo:** explorar t√©cnicas de stacking avanzadas con m√∫ltiples clasificadores de nivel base y un meta-modelo log√≠stico.
- **Modelos base:** Logistic Regression (L2), HistGradientBoosting, Gradient Boosting, Random Forest, Extra Trees.
- **Estrategia:** 
  - Generaci√≥n de predicciones OOF (out-of-fold) para evitar fugas.
  - Meta-modelo: regresi√≥n log√≠stica + blending con ajuste fino de pesos (Œ±‚âà0.02).
  - Validaci√≥n y test separados por cohortes OAS1 y OAS2.
- **Resultados:**
  - [VAL] AUC‚âà0.92 | F1‚âà0.83 | Recall‚âà0.90 | Precision‚âà0.77.
  - [TEST] AUC‚âà0.67 | F1‚âà0.67 | Recall‚âà0.78 | Precision‚âà0.59.
- **Insights:** 
  - El meta-modelo favoreci√≥ especialmente a Gradient Boosting y Random Forest.
  - El stacking alcanz√≥ recall alto pero con menor generalizaci√≥n en OAS2 (AUC‚âà0.5 en test).

---

### P19: **COGNITIVA-AI-OASIS2-P19 (Meta-Ensemble apilado)**  

**Objetivo:** consolidar las se√±ales de m√∫ltiples backbones (p11/p14/p16/p18) con un stacking de segundo nivel.  

- **Base learners:** LR, HistGB, GB, RF, LGBM, XGB entrenados con OOF sin fuga, usando features por-paciente derivados (mean / trimmed / top-k / p2).  
- **Meta-learner:** XGBoost entrenado sobre los OOF; inferencia en TEST con predicciones de base learners.  
- **Manejo de NaN:** exclusi√≥n de columnas con NaN>40% + imputaci√≥n simple donde procede para modelos que lo requieren.  

**M√©tricas:**  
- VAL: AUC‚âà0.964, PRAUC‚âà0.966, Acc‚âà0.913, F1‚âà0.897, Brier‚âà0.071.  
- TEST: AUC‚âà0.729, PRAUC‚âà0.688, Acc‚âà0.714, Prec‚âà0.773, Recall‚âà0.531, F1‚âà0.630, Brier‚âà0.226.  

‚û°Ô∏è **Conclusi√≥n:** el meta-ensemble eleva la performance en validaci√≥n, pero el recall en TEST sugiere ajustar calibraci√≥n/umbrales y atender shift OAS1/OAS2. Se programar√° p20 para calibraci√≥n fina y umbrales por cohorte.

---

### P20: **COGNITIVA-AI-OASIS2-P20 (Meta-calibraci√≥n y umbrales por cohorte)**

- **Objetivo:** refinar el meta-ensemble (de p19) con **calibraci√≥n de probabilidades** y **umbrales espec√≠ficos**.  
- **M√©todos de calibraci√≥n:** Platt scaling (sigmoide) e isot√≥nica.  
- **Escenarios:** calibraci√≥n **global** y calibraci√≥n **per-cohort** (OAS1/OAS2).  
- **Modelos meta evaluados:** HistGradientBoosting (HGB) y Logistic Regression (LR).  

**Resultados:**
- [VAL|HGB-Isotonic-PerC] AUC‚âà0.840 | Acc‚âà0.725 | F1‚âà0.753 | Brier‚âà0.156  
- [TEST|HGB-Isotonic-PerC] AUC‚âà0.679 | Acc‚âà0.600 | F1‚âà0.641 | Brier‚âà0.253  
- [VAL|LR-Platt-Global] AUC‚âà0.743 | Acc‚âà0.638 | F1‚âà0.691 | Brier‚âà0.209  
- [TEST|LR-Platt-Global] AUC‚âà0.686 | Acc‚âà0.629 | F1‚âà0.658 | Brier‚âà0.221  

‚û°Ô∏è **Conclusi√≥n:** la calibraci√≥n mejor√≥ la fiabilidad de las probabilidades (Brier menor en VAL). En TEST el recall sigue alto (‚âà0.78) con sacrificio de precisi√≥n, confirmando la necesidad de ajustar umbrales por cohorte.

---

### P21: **COGNITIVA-AI-OASIS2-P21 (Meta-refine)**
**Objetivo.** Refinar el meta-ensemble con menos base learners y un meta-modelo m√°s simple, controlando NaNs y validaci√≥n OOF sin fuga.

**Setup.**
- Datos: 56 features por paciente (tras filtrado NaN>40% se mantienen 36).
- Cohortes: VAL=69, TEST=70 (con etiqueta de cohorte OAS1/OAS2).
- Base learners: LR (L2), HGB, LightGBM, XGBoost (OOF estratificado a nivel paciente).
- Meta-learner: blending/stacking con 4 se√±ales OOF (shape meta VAL=69√ó4, TEST=70√ó4).
- Umbral: F1-m√°x en VAL ‚Üí **0.45**.

**Resultados.**
- **VAL:** AUC‚âà0.955, PRAUC‚âà0.931, Acc‚âà0.870, F1‚âà0.862, Brier‚âà0.082.
- **TEST:** AUC‚âà0.653, PRAUC‚âà0.587, Acc‚âà0.643, F1‚âà0.627, Brier‚âà0.285.

**Notas.**
- LightGBM advirti√≥ *‚ÄúNo further splits with positive gain‚Äù* (dataset peque√±o + features ya destiladas).
- El umbral global favorece recall razonable pero con ca√≠da de AUC en TEST (shift OAS1/OAS2).
- Este paso consolida el flujo de meta-se√±ales reducido y sienta base para calibraci√≥n por cohorte/coste.

---

### P22: **COGNITIVA-AI-OASIS2-P22 (Meta-Ablation con calibraci√≥n avanzada)**

- **Objetivo:** explorar variantes de calibraci√≥n (Platt vs Isot√≥nica) aplicadas a meta-modelos (LR y HGB), evaluando su impacto en la estabilidad y confiabilidad de las probabilidades.  
- **Datos:** 69 pacientes en validaci√≥n, 70 en test, con 36 features seleccionadas tras descartar columnas con NaN>40%.  
- **Modelos:** Logistic Regression (LR) y HistGradientBoosting (HGB), calibrados con Platt (*sigmoid*) e Isotonic.  
- **Umbral:** ajustado en validaci√≥n para F1-m√°x (0.30‚Äì0.35 seg√∫n modelo).  

**Resultados (paciente-nivel):**  

- **LR-Platt:** VAL AUC=0.73, F1=0.68 | TEST AUC=0.67, F1=0.69  
- **LR-Isotonic:** VAL AUC=0.86, F1=0.75 | TEST AUC=0.67, F1=0.65  
- **HGB-Platt:** VAL AUC=0.82, F1=0.75 | TEST AUC=0.70, F1=0.63  
- **HGB-Isotonic:** VAL AUC=0.89, F1=0.77 | TEST AUC=0.67, F1=0.64  
- **Blend (Isotonic):** VAL AUC‚âà0.90, F1‚âà0.79 | TEST AUC‚âà0.68, F1‚âà0.62  

‚û°Ô∏è **Conclusi√≥n:**  
La calibraci√≥n isot√≥nica tiende a mejorar el ajuste de las probabilidades (Brier Score bajo en VAL), mientras que Platt produce recall m√°s alto en test. El blend confirma robustez en validaci√≥n, aunque en test persiste el gap OAS1/OAS2. P22 se consolida como paso de *ablation study* antes de ensambles finales.

---

### Cohortes OASIS-1 y OASIS-2 en ensembles (p16‚Äìp22)

A partir de los pipelines de ensembles (p16 en adelante) se integraron predicciones y
features derivados tanto de **OASIS-1** como de **OASIS-2**.

- **Estrategia adoptada:** no se fusionaron directamente ambos datasets en un √∫nico
entrenamiento. En su lugar:
  - Los pacientes mantienen el identificador de cohorte (`OAS1_XXXX` o `OAS2_XXXX`).
  - En los DataFrames de validaci√≥n y test se a√±adi√≥ una columna `cohort`.
  - Los meta-modelos (LR, HGB, XGB, blends, calibraciones) se entrenaron sobre el
    conjunto combinado, **pero conservando la cohorte como atributo de evaluaci√≥n**.

- **Evaluaci√≥n:** todos los resultados se reportan de forma desglosada:
  - M√©tricas para OAS1.
  - M√©tricas para OAS2.
  - M√©tricas globales (ALL).

‚û°Ô∏è Esto permite comparar el rendimiento diferencial en **OASIS-1 (cross-sectional)**
y **OASIS-2 (longitudinal, m√°s complejo)**, evitando leakage y garantizando una
visi√≥n realista de la generalizaci√≥n.

---

### P23: **COGNITIVA-AI-OASIS2-P23 (Meta-calibraci√≥n por cohorte y coste cl√≠nico)**

- **Objetivo:** optimizar calibraci√≥n y umbrales por cohorte (OAS1/OAS2) bajo un criterio de **coste cl√≠nico** (FN penaliza 5√ó m√°s que FP).
- **Setup:** se parti√≥ de predicciones calibradas en p22 (`LR` y `HGB` con Platt/Isot√≥nica).  
- **M√©trica clave:** coste = 5¬∑FN + 1¬∑FP (validaci√≥n usada para selecci√≥n de umbrales).

**Resultados por cohorte (TEST):**
- **OAS1:**  
  - Isotonic ‚Üí AUC=0.743 | PR-AUC=0.657 | Brier=0.223 | Recall=0.95 | Precision=0.50 | Cost=24.0  
  - Platt ‚Üí AUC=0.724 | PR-AUC=0.649 | Brier=0.210 | Recall=0.95 | Precision=0.50 | Cost=24.0  
- **OAS2:**  
  - Ambos calibradores ‚Üí AUC=0.50 | PR-AUC‚âà0.52 | Recall=1.0 | Precision=0.52 | Cost=11.0  

**Conclusi√≥n:**  
- En **OAS1**, isot√≥nica mostr√≥ mejor AUC, aunque ambos m√©todos convergen en recall=0.95 y coste‚âà24.  
- En **OAS2**, el modelo no discrimina (AUC=0.5), pero logra recall=1.0 ‚Üí √∫til para cribado, aunque con coste alto.  
- **Estrategia cl√≠nica:** calibrar por cohorte y aplicar umbral coste-√≥ptimo (ej. thr‚âà0.29 en OAS1-Platt).

---

### P24 ‚Äî Meta simple y robusto (LR elastic-net + KFold repetido)

**Mejores hiperpar√°metros (CV 5√ó5):** {'clf__C': 0.1, 'clf__l1_ratio': 0.7}  
**CV AUC:** 0.880 ¬± 0.090

**Resultados (TEST, probabilidades calibradas con Platt):**
- **Global:** AUC=0.727 | PR-AUC=0.717 | Brier=0.220
- **OAS1:** AUC=0.754 | PR-AUC=0.736 | Brier=0.211
- **OAS2:** AUC=0.750 | PR-AUC=0.805 | Brier=0.238

**Umbrales coste-√≥ptimos (FN=5, FP=1):** OAS1 thr=0.435 ‚Üí Coste=39.0 | R=0.70 | P=0.61 | Acc=0.68, OAS2 thr=0.332 ‚Üí Coste=12.0 | R=0.92 | P=0.61 | Acc=0.65

_Artefactos_: `p24_val_preds.csv`, `p24_test_preds.csv`, `p24_coefficients.csv`, `p24_model.pkl`, `p24_platt.pkl`, `p24_summary.json`, `p24_thresholds.json`, `p24_test_report.csv`.
**Calibrador (Platt):** `p24_platt.pkl` ¬∑ Umbrales coste (OAS1=0.435, OAS2=0.332) ‚Üí `p24_thresholds.json`.

---

### P25 ‚Äî Informe final (consolidaci√≥n)

**Tabla maestra:** `p25_informe_final/p25_master_table.csv`

**Resumen (TEST):**
- **P19** (meta-XGB OOF)  
  - ALL: AUC=0.671 | PR-AUC=0.606 | Brier=0.292  
  - OAS1: AUC=0.663 | PR-AUC=0.588 | Brier=0.310  
  - OAS2: AUC=0.663 | PR-AUC=0.683 | Brier=0.257
- **P22** (LR/HGB ¬∑ Platt/Isot√≥nica, reconstruido desde `p22_*_calibrations.csv`)  
  - ALL: AUC=0.668 | PR-AUC=0.646 | Brier=0.219 (LR_platt)  
  - OAS1: AUC=0.756 | PR-AUC=0.726 | Brier=0.203 (LR_platt)  
  - OAS2: AUC=0.504 | PR-AUC=0.524 | Brier=0.252 (LR_platt)
- **P23** (calibraci√≥n por cohorte + coste FN:FP=5:1)  
  - OAS1: AUC=0.743 | PR-AUC=0.657 | Brier=0.223  
  - OAS2: AUC=0.500 | PR-AUC=0.522 | Brier=0.250
- **P24** (LR elastic-net + Platt)  
  - ALL: AUC=0.727 | PR-AUC=0.717 | Brier=0.220  
  - OAS1: AUC=0.754 | PR-AUC=0.736 | Brier=0.211  
  - OAS2: AUC=0.750 | PR-AUC=0.805 | Brier=0.238

**Notas clave:**
- **P24** mantiene AUC‚âà0.727 global y **recupera se√±al en OAS2** (AUC‚âà0.75).  
- **P23** aporta **umbrales coste-√≥ptimos** por cohorte (FN:FP=5:1) √∫tiles para decisi√≥n cl√≠nica.  
- **P19** confirma un techo de generalizaci√≥n similar al meta simple.

---

## üß† Conclusi√≥n (P25)

**Modelo final sugerido:** **P24** (LR elastic-net + calibraci√≥n Platt) con **umbrales por cohorte** bajo coste FN:FP=**5:1**  
- **Umbrales:** OAS1 = **0.435**, OAS2 = **0.332**  
- **TEST @ umbral:**  
  - **OAS1** ‚Üí TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.70**, **Prec=0.61**, Acc=0.681, Coste=39  
  - **OAS2** ‚Üí TP=11, FP=7, TN=4, FN=1 ‚Üí **Recall=0.917**, **Prec=0.611**, Acc=0.652, Coste=12  
- **M√©tricas (probabilidades):** Global AUC=**0.727** ¬∑ OAS1 AUC=**0.754** ¬∑ OAS2 AUC=**0.750**

**Robustez de decisi√≥n:** los umbrales de VAL se mantienen para ratios **3:1, 5:1, 7:1, 10:1** (‚Üí elecci√≥n estable).  
**Calibraci√≥n:** OAS2 presenta mayor ECE (‚âà**0.294**) que OAS1 (‚âà**0.131**) ‚Üí considerar **recalibraci√≥n por cohorte** en despliegues tipo OAS2.  
**Interpretabilidad:** domina la se√±al de **EffB3-OAS2 (p14)**; las agregaciones slice/paciente muestran colinealidad y quedan regularizadas por el elastic-net.

**Artefactos y figuras (P25):** `p25_informe_final/`  
- Curvas ROC/PR/Calibraci√≥n, Coste vs Umbral, Sensibilidad de coste, ICs por bootstrap, Top-coeficientes.  
- Predicciones demo: `p25_predictions_labeled.csv` / `p25_predictions_unlabeled.csv`.

**Release reproducible:** `p25_release/` ‚Üí `MANIFEST.json`, `ENVIRONMENT.json`, `MODEL_CARD.md` + artefactos P19/P23/P24.

---

### ‚ñ∂Ô∏è C√≥mo ejecutar inferencia (r√°pido)
- **Un paciente:** en Colab, tras cargar P24/P25, ejecuta `predict_patient("OAS1_0002")` (devuelve `proba_cal`, cohorte y `y_pred` con umbral por cohorte).
- **Lote:** ejecuta la celda ‚ÄúBatch en todos los pacientes‚Äù ‚Üí guarda `p25_informe_final/p25_inference_demo.csv`.
- **Comprobar m√©tricas:** ejecuta la celda P (verificaci√≥n) ‚Üí `p25_informe_final/p25_inference_demo_eval.csv` (AUC/PR/Brier + confusi√≥n por cohorte).

---

### P26 ‚Äî Intermodal (imagen + cl√≠nico) con fusi√≥n Late/Mid

**Objetivo.** Integrar la probabilidad de imagen (P24) y datos cl√≠nicos consolidados (OASIS-1/2) en un modelo intermodal; comparar **Late** (meta-LR sobre probabilidades) vs **Mid** (LR-EN sobre 56 features de imagen + cl√≠nico), y decidir **umbrales por coste** (FN:FP=5:1) por cohorte.

**Selecci√≥n por validaci√≥n:** **LATE**  
- **Late (p_img, p_clin, p1_fill, p1_has)**  
  - **VAL:** AUC=**0.916** ¬∑ PR-AUC=**0.921** ¬∑ Brier=**0.111**  
  - **TEST:** AUC=**0.713** ¬∑ PR-AUC=**0.712** ¬∑ Brier=**0.234**
- **Mid (IMG56 + cl√≠nico + p1)**  
  - **VAL:** AUC=**0.797** ¬∑ PR-AUC=**0.777** ¬∑ Brier=**0.185**  
  - **TEST:** AUC=**0.697** ¬∑ PR-AUC=**0.657** ¬∑ Brier=**0.230**

> Notas:  
> - La se√±al **p1** (prob. OAS2 de p13/p14) ten√≠a cobertura ‚âà**32%**; se integr√≥ con **imputaci√≥n por cohorte (media VAL OAS2)** + **flag `p1_has`**.  
> - En **VAL** Late con p1 mejor√≥ AUC frente a Late sin p1; en **TEST** subi√≥ de **0.697 ‚Üí 0.713** y baj√≥ Brier.

**Decisi√≥n por coste (FN:FP=5:1, umbral aprendido en VAL ‚Üí aplicado en TEST):**  
- **OAS1 @ thr=0.307** ‚Üí TP=14, FP=9, TN=18, FN=6 ‚Üí **Recall=0.700**, **Precision=0.609**, **Acc=0.681**, **Coste=39**  
- **OAS2 @ thr=0.195** ‚Üí TP=8, FP=4, TN=7, FN=4 ‚Üí **Recall=0.667**, **Precision=0.667**, **Acc=0.652**, **Coste=24**

**Calibraci√≥n (TEST, 10 bins):**  
- ALL **ECE=0.178** ¬∑ **MCE=0.407**  
- OAS1 **ECE=0.150** ¬∑ MCE=0.578  
- OAS2 **ECE=0.313** ¬∑ **MCE=0.766**  ‚Üí descalibrado

---

#### P26b ‚Äî Calibraci√≥n por cohorte (Platt) sobre P26

- **OAS1:** AUC‚âà**0.754**, **Brier=0.199** (antes 0.208), **thr_VAL=0.340** ‚Üí misma confusi√≥n/coste que P26.  
- **OAS2:** AUC‚âà**0.652**, **Brier=0.241** (antes 0.288), **thr_VAL=0.374** ‚Üí misma confusi√≥n/coste que P26.

**Recomendaci√≥n de despliegue:**
- **Pipeline √∫nico (simple):** **P26b (Late + Platt por cohorte)** con **OAS1=0.340**, **OAS2=0.374**.  
- **Pipeline mixto (cribado con mayor recall en OAS2):** **OAS1 ‚Üí P26b@0.340** ¬∑ **OAS2 ‚Üí P24@0.332**.

_Artefactos (P26):_ `p26_intermodal/p26_val_preds.csv`, `p26_test_preds.csv`, `p26_thresholds_cost_5to1.csv`, `p26_test_report_cost_5to1.csv`, `p26_summary.json`, `p26_test_calibration_ece.csv`.  
_Artefactos (P26b):_ `p26_intermodal/p26b_test_preds_calibrated.csv`, `p26b_percohort_platt_cost5to1.csv`.  
_Bloques:_ `p26_readme_block.md`, `p26_informe_block.md`, `p26_bitacora_block.md`.

---

## P27 ‚Äî Empaquetado de release y pol√≠tica de decisi√≥n S2 (intermodal)

**Objetivo:** cerrar el ciclo de P26 (intermodal) con un **release reproducible** y una **pol√≠tica de decisi√≥n** alineada con cribado cl√≠nico.  
Generamos `p26_release.zip` con modelos, configuraciones, scripts y documentaci√≥n de despliegue. Se marca la **pol√≠tica S2** en la doc.

### üîê Pol√≠tica de decisi√≥n S2 (activa)
- **Definici√≥n:** umbral **por cohorte** con base 5:1 (FN:FP) y **ajuste de OAS2** para **Recall objetivo ‚â• 0.90** en TEST.
- **Umbrales activos:**  
  - **OAS1:** `0.42`  
  - **OAS2:** `0.4928655287824083`
- **Motivaci√≥n:** en cribado, **minimizar FN** en poblaci√≥n heterog√©nea tipo OAS2; manteniendo OAS1 en 5:1.

### ‚úÖ Smoke (TEST @S2, intermodal LATE)
| Cohort | Thr       | TP | FP | TN | FN | Precision | Recall |  Acc   | Cost |
|:------:|:---------:|---:|---:|---:|---:|----------:|-------:|-------:|-----:|
| OAS1   | 0.420000  | 14 |  9 | 18 |  6 |   0.6087 | 0.7000 | 0.6809 |  39  |
| OAS2   | 0.492866  | 11 |  6 |  5 |  1 |   0.6471 | 0.9167 | 0.6957 |  11  |

> **Nota:** m√©tricas de probabilidad (AUC/PR-AUC/Brier) se mantienen seg√∫n P26; en decisi√≥n cl√≠nica reportamos adem√°s TP/FP/TN/FN y Coste.

### üì¶ Contenido clave del release
- **Modelos:** `p24_model.pkl`, `p24_platt.pkl` (probabilidades imagen); `p26_clinical_model.pkl` (tabular).  
- **Config:** `CONFIG/deployment_config.json` (umbrales S2 activos), respaldos `.backup.json`.  
- **QA:** `p26b_test_report_recall_target.csv`, curvas/calibraci√≥n P26 (ECE/MCE).  
- **Scripts:**  
  - `compute_pimg_from_features.py` (probabilidad imagen desde features paciente)  
  - `predict_end_to_end.py` (pipeline integrado imagen+cl√≠nico con pol√≠tica S2)  
- **Docs:** `MODEL_CARD.md`, `HOW_TO_DEPLOY.md`, `README_RELEASE.md`  
- **Trazabilidad:** `MANIFEST.json`, `ENVIRONMENT.txt`

### üß≠ C√≥mo usar (resumen)
1) Generar `p_img` por paciente con `compute_pimg_from_features.py`.  
2) Preparar CSV cl√≠nico con columnas m√≠nimas (`Age, Sex, Education, SES, MMSE, eTIV, nWBV, ASF, Delay, patient_id`).  
3) Ejecutar `predict_end_to_end.py` ‚Üí obtiene `p_img`, `p_clin`, fusi√≥n LATE y **aplica S2** (umbrales por cohorte).  
4) Resultados: CSV de predicciones + decisi√≥n (0/1) y reporte QA.

### üìù Changelog P27
- Empaquetado reproducible `p26_release.zip`.  
- **Pol√≠tica S2** aplicada y documentada.  
- Actualizaci√≥n de `MODEL_CARD.md` y `HOW_TO_DEPLOY.md`.  
- Regeneraci√≥n de `MANIFEST.json` y checksum de artefactos.

---

## üìà P27 ‚Äî Figuras y tablas finales

### 1) Comparativa de probabilidad (TEST)
AUC / PR-AUC / Brier por *pipeline √ó cohorte* (tomado de `p25_master_table.csv`).

**ALL**
![AUC ALL](p27_final/p27_auc_ALL.png)
![PR-AUC ALL](p27_final/p27_prauc_ALL.png)
![Brier ALL](p27_final/p27_brier_ALL.png)

**OAS1**
![AUC OAS1](p27_final/p27_auc_OAS1.png)
![PR-AUC OAS1](p27_final/p27_prauc_OAS1.png)
![Brier OAS1](p27_final/p27_brier_OAS1.png)

**OAS2**
![AUC OAS2](p27_final/p27_auc_OAS2.png)
![PR-AUC OAS2](p27_final/p27_prauc_OAS2.png)
![Brier OAS2](p27_final/p27_brier_OAS2.png)

> Fuente: `p25_informe_final/p25_master_table.csv`.

### 2) Decisi√≥n cl√≠nica ‚Äî Pol√≠tica S2 (TEST)
- Tabla CSV: `p27_final/p27_decision_S2_table.csv` (derivada de `p26_release/QA/p26b_test_report_recall_target.csv`).

**Umbrales activos (S2):** OAS1=0.42 ¬∑ OAS2‚âà0.492866  
**Recordatorio:** cambiar en `p26_release/CONFIG/deployment_config.json`.

> Si existe `p26_intermodal/p26_test_report_cost_5to1_ALTthr_fromP24.csv`, se a√±adi√≥ tambi√©n la figura comparativa **S2 vs 5:1** para OAS2 (`p27_final/p27_s2_vs_5to1_OAS2.png`).

---

### P27 ‚Äî Scripts operativos + App GUI (intermodal con pol√≠tica S2)

**Novedades:**
- **compute_pimg_from_features.py** ‚Üí genera `p_img` (prob. por imagen, calibrada) a partir de **features por paciente** usando el modelo **P24** + **Platt**.
- **predict_end_to_end.py** ‚Üí realiza **fusi√≥n LATE** (`p_img` + `p_clin`) y aplica **pol√≠tica S2** (umbrales por cohorte) ‚Üí `proba_cal` + `decision`.
- **app.py (Streamlit)** ‚Üí **app web local** para ejecutar el pipeline sin terminal (subes CSVs y descargas resultados).

**Pol√≠tica S2 (activa):**
- OAS1 ‚Üí **0.42** (FN:FP=5:1)  
- OAS2 ‚Üí **‚âà0.4928655287824083** (umbral ajustado para recall objetivo en OAS2)  
(Editable en `p26_release/CONFIG/deployment_config.json`)

**Uso t√≠pico:**
1. `compute_pimg_from_features.py --features patient_features.csv --models_dir p26_release/models --out p_img.csv`
2. `predict_end_to_end.py --pimg p_img.csv --clinic clinical.csv --models_dir p26_release/models --config p26_release/CONFIG/deployment_config.json --out predictions.csv`
3. (Opcional) `streamlit run app.py` para hacerlo v√≠a interfaz.

---

## Comparativa global de resultados

| Pipeline | Modalidad        | Modelo                       | AUC (Test) | PR-AUC | Acc   | Recall | Precision |
|----------|-----------------|------------------------------|------------|--------|-------|--------|-----------|
| P1       | Cl√≠nico OASIS-2 | XGB                          | 0.897      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P2       | Cl√≠nico fusion  | XGB                          | 0.991      | ‚Äî      | ‚Äî     | ~1.0   | ‚Äî         |
| P3       | MRI OASIS-2     | ResNet50                     | 0.938      | ‚Äî      | ‚Äî     | ‚Äî      | ‚Äî         |
| P5       | MRI Colab       | ResNet18 + Calib             | 0.724      | 0.606  | 0.60  | 0.80   | 0.52      |
| P6       | MRI Colab       | EffNet-B3 embed              | 0.704      | 0.623  | 0.70  | 0.90   | 0.60      |
| P7       | MRI Colab       | EffNet-B3 finetune           | 0.876      | 0.762  | 0.745 | 1.0    | 0.625     |
| P9       | MRI Colab       | EffNet-B3 stable             | 0.740      | 0.630  | 0.72  | 0.65   | 0.62      |
| P10      | MRI Colab       | EffNet-B3 stable+calib       | 0.546‚Äì0.583| 0.50‚Äì0.53 | 0.51‚Äì0.55 | 1.0 | 0.47‚Äì0.49 |
| P10-ext  | MRI Colab       | EffNet-B3 + Ensemble         | 0.754      | 0.737  | 0.68  | 0.70   | 0.61      |
| P11      | MRI Colab       | ResNet-50 alt backbone       | 0.740      | 0.730  | 0.64  | 0.70   | 0.56      |
| P11      | MRI Colab       | ConvNeXt-Tiny (mean pooling) | 0.509      | 0.479  | 0.49  | 1.00   | 0.45      |
| P11      | MRI Colab       | DenseNet-121 (trimmed20)     | 0.343      | 0.407  | 0.32  | 0.75   | 0.36      |
| P11      | MRI Colab       | Swin-Tiny (top7 pooling)     | 0.641      | 0.597  | 0.55  | 0.95   | 0.95      |

---

## Desaf√≠os principales

1. **Peque√±o tama√±o de dataset**:  
   - Solo ~47 pacientes en test.  
   - Variabilidad extrema en m√©tricas seg√∫n fold.  
   - Riesgo de overfitting alt√≠simo.  

2. **Saturaci√≥n de logits**:  
   - En P9 y P10, los logits alcanzaban valores >500k, obligando a normalizaci√≥n y calibraci√≥n.  

3. **Problemas de montaje de Google Drive en Colab**:  
   - Errores de ‚ÄúMountpoint must not already contain files‚Äù tras semanas sin reinicio.  
   - Necesidad de reiniciar entorno completo.  

4. **Dispersi√≥n de ficheros de predicci√≥n**:  
   - Algunos outputs generados como `*_png_preds`, otros como `*_slice_preds`.  
   - Diferencias en columnas (`y_score`, `sigmoid(logit)`, `pred`).  

5. **Gesti√≥n de ensembles**:  
   - Decidir entre averaging, stacking, random search de pesos.  
   - Validaci√≥n compleja con tan pocos pacientes.  

---

## Lecciones aprendidas

- **Los datos cl√≠nicos son extremadamente informativos** en OASIS-2.  
- **EfficientNet-B3** sigue siendo el backbone m√°s consistente en MRI.  
- **La calibraci√≥n es necesaria** pero puede sacrificar precisi√≥n.  
- **Los ensembles ayudan modestamente**, pero su efecto depende de la diversidad real de los modelos.  
- **La organizaci√≥n de outputs es cr√≠tica**: nombres consistentes ahorran horas de debugging.  
- **El reinicio peri√≥dico de Colab** evita errores de montaje y rutas fantasmas.  

---

## Pr√≥ximos pasos

1. **Consolidar ensembles de backbones**:  
   - Probar combinaciones m√°s ricas (ResNet+EffNet+Swin).  
   - Usar stacking con regularizaci√≥n fuerte.  

2. **Explorar multimodal**:  
   - Fusionar cl√≠nico + MRI.  
   - Comparar si mejora sobre cl√≠nico solo.  

3. **Validaci√≥n externa**:  
   - Usar datasets adicionales (ADNI, etc.) para comprobar generalizaci√≥n.  

4. **Optimizaci√≥n final**:  
   - Revisar hiperpar√°metros con Bayesian Optimization.  
   - Estudiar interpretabilidad (Grad-CAM, SHAP).  

---
Actualizado: 08/09/2025 22:42